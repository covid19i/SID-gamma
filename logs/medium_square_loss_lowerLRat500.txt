(sid2) [ir967@gr011 Learning-to-See-in-the-Dark]$ vi medium_batched_square_loss.py
(sid2) [ir967@gr011 Learning-to-See-in-the-Dark]$ mkdir gt_Sony_medium_MSE_lowerLRat500
(sid2) [ir967@gr011 Learning-to-See-in-the-Dark]$ vi medium_batched_square_loss.py
(sid2) [ir967@gr011 Learning-to-See-in-the-Dark]$ python medium_batched_square_loss.py




Found 161 images to train with

Training on 161 images only

2020-12-12 13:42:09.529918: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-12 13:42:09.672236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:86:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-12 13:42:09.672271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-12 13:42:09.960106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-12 13:42:09.960143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-12 13:42:09.960170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-12 13:42:09.960274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5)
No checkpoint found at ./gt_Sony_medium_MSE_lowerLRat500/. Hence, will create the folder.
Gamma curve:
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95669, 0.00000, 100.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01648, 100.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 100.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00187, 300.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.02465, 100.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00467, 100.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00894, 100.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00233, 250.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00016, 300.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 250.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00012, 300.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 250.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00144, 300.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00307, 250.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00002, 250.00000, 6735543
rawpy read the 20th file at location: ./dataset/Sony/long/00072_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00003, 300.00000, 7298885
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00143, 250.00000, 1272259
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 142725
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00456, 300.00000, 822369
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00011, 300.00000, 2983955
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00114, 300.00000, 2393979
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.03574, 100.00000, 2641491
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00003, 100.00000, 1597850
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 300.00000, 1430113
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
rawpy read the 30th file at location: ./dataset/Sony/long/00039_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.07940, 100.00000, 535
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00247, 250.00000, 2877047
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00027, 300.00000, 271135
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 11918285
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00060, 100.00000, 3901
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 300.00000, 684739
rawpy read the 40th file at location: ./dataset/Sony/long/00200_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00299, 100.00000, 1458719
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.01101, 100.00000, 1212279
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00241, 250.00000, 2952517
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00235, 100.00000, 158803
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00165, 300.00000, 2486907
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00202, 250.00000, 7900835
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00006, 250.00000, 4543563
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.05083, 100.00000, 3437
rawpy read the 50th file at location: ./dataset/Sony/long/00024_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00048, 250.00000, 33748
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00375, 100.00000, 3626303
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01255, 250.00000, 304767
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00059, 250.00000, 5644
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00062, 100.00000, 4526
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00007, 250.00000, 11755519
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00012, 250.00000, 2512821
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01871, 250.00000, 2025
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00342, 100.00000, 5557479
rawpy read the 60th file at location: ./dataset/Sony/long/00084_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00347, 250.00000, 67803
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00210, 300.00000, 103
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 300.00000, 1696711
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00688, 100.00000, 2302635
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00053, 250.00000, 1589659
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00674, 250.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00563, 100.00000, 3437411
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00969, 250.00000, 1033619
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00001, 100.00000, 742143
rawpy read the 70th file at location: ./dataset/Sony/long/00164_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00444, 100.00000, 509891
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 433279
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00106, 250.00000, 6156358
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00004, 100.00000, 2110981
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00090, 100.00000, 277500
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.02923, 100.00000, 646472
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00058, 250.00000, 5676651
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 250.00000, 7066147
rawpy read the 80th file at location: ./dataset/Sony/long/00128_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00343, 100.00000, 4421929
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.01853, 250.00000, 489052
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 10328681
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00136, 100.00000, 2198927
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00010, 250.00000, 5346741
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00147, 250.00000, 646955
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00077, 300.00000, 3032047
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00651, 100.00000, 1407
rawpy read the 90th file at location: ./dataset/Sony/long/00057_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00013, 100.00000, 6606155
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00027, 250.00000, 353239
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00075, 250.00000, 877649
min, max, mean, gamma, argmax: 0.00000, 0.00288, 0.00000, 100.00000, 810977
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 4792466
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00045, 250.00000, 3173995
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00226, 100.00000, 3012800
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00086, 250.00000, 732975
rawpy read the 100th file at location: ./dataset/Sony/long/00059_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01523, 100.00000, 5126389
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 100.00000, 221629
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00000, 100.00000, 895895
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00090, 250.00000, 121547
min, max, mean, gamma, argmax: 0.00000, 0.89525, 0.00000, 250.00000, 6694829
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 2019203
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00106, 300.00000, 2924589
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 6922649
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00195, 100.00000, 8237
rawpy read the 110th file at location: ./dataset/Sony/long/00026_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00099, 250.00000, 255039
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00766, 300.00000, 3862619
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00162, 300.00000, 27523
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00467, 100.00000, 4373627
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00199, 250.00000, 6454
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00032, 250.00000, 4246091
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00129, 300.00000, 952285
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00499, 100.00000, 2253
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
rawpy read the 120th file at location: ./dataset/Sony/long/00012_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 250.00000, 6320171
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00035, 250.00000, 8352977
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00191, 100.00000, 2730987
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 100.00000, 830169
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00217, 250.00000, 106691
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00827, 100.00000, 2536575
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 6777631
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
rawpy read the 130th file at location: ./dataset/Sony/long/00090_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00265, 250.00000, 6265
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 100.00000, 9536203
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00922, 250.00000, 1211799
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00000, 100.00000, 1962014
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00132, 100.00000, 1095547
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00109, 250.00000, 208955
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00488, 300.00000, 1787501
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00048, 100.00000, 2237695
rawpy read the 140th file at location: ./dataset/Sony/long/00114_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00016, 100.00000, 2570045
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00002, 100.00000, 4933369
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00017, 300.00000, 2972
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00016, 100.00000, 8615375
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.06347, 100.00000, 1502619
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00135, 250.00000, 1940733
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00007, 300.00000, 8449
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00079, 250.00000, 506409
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
rawpy read the 150th file at location: ./dataset/Sony/long/00156_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00819, 250.00000, 2309
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00134, 250.00000, 1993235
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.03581, 300.00000, 2694439
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00922, 250.00000, 2353163
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00030, 300.00000, 2700797
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.01375, 300.00000, 7293
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00021, 100.00000, 581525
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00004, 250.00000, 4860611
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00430, 100.00000, 5285
rawpy read the 160th file at location: ./dataset/Sony/long/00219_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
161 images loaded to CPU RAM in Time=47.759 seconds.

Moved images data to a numpy array.
BATCH_SIZE 16 ,final_epoch 4001 ,no_of_batches 10 ,ps 128 ,result_dir ./gt_Sony_medium_MSE_lowerLRat500/ ,len(train_ids) 161
Starting Training on index [ 90 134 123  99  63  20 120 118 126  59  52 112  81  36 134 120], dataset index: [ 57 232  52  28 127  72  12 165 124  37  53  62  98  14 232  12]
Starting Training on gammas [100 100 100 250 100 300 250 100 100 100 250 300 250 300 100 250]
Epoch 0: at batch 1: Training dataset Loss=3.207, Batch Time=1.254
[[  0.        ]
 [ 56.61753845]
 [128.62471008]
 ...
 [  0.        ]
 [  0.        ]
 [  0.        ]]
Epoch 1: at batch 1: Training dataset Loss=108.680, Batch Time=0.026
Epoch 1: Epoch time = 2.037, Avg epoch time=0.297, Total Time=1.018

[[  0.31819156]
 [ 56.61753845]
 [128.62471008]
 ...
 [  0.        ]
 [  0.        ]
 [  0.        ]]
Epoch 2: at batch 1: Training dataset Loss=43.518, Batch Time=0.024
[[ 20.45995903]
 [ 56.61753845]
 [128.62471008]
 ...
 [  0.        ]
 [  0.        ]
 [  0.        ]]
Epoch 3: at batch 1: Training dataset Loss=10.568, Batch Time=0.028
[[0.32782236]
 [0.32820377]
 [0.31758735]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 4: at batch 1: Training dataset Loss=4.577, Batch Time=0.027
[[0.32782236]
 [0.33586311]
 [0.25834131]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 5: at batch 1: Training dataset Loss=1.132, Batch Time=0.029
[[0.32782236]
 [0.33586311]
 [0.3089774 ]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 6: at batch 1: Training dataset Loss=1.056, Batch Time=0.036
[[0.31014571]
 [0.33586311]
 [0.30637828]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 7: at batch 1: Training dataset Loss=0.796, Batch Time=0.029
[[0.31014571]
 [0.33586311]
 [0.30637828]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 8: at batch 1: Training dataset Loss=0.638, Batch Time=0.035
[[0.31014571]
 [0.33333334]
 [0.30637828]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 9: at batch 1: Training dataset Loss=0.459, Batch Time=0.033
[[0.31014571]
 [0.33333334]
 [0.33333334]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 11: at batch 1: Training dataset Loss=0.372, Batch Time=0.030
Epoch 21: at batch 1: Training dataset Loss=0.298, Batch Time=0.025
Epoch 31: at batch 1: Training dataset Loss=0.452, Batch Time=0.027
Epoch 41: at batch 1: Training dataset Loss=0.333, Batch Time=0.025
Epoch 51: at batch 1: Training dataset Loss=0.333, Batch Time=0.025
Epoch 61: at batch 1: Training dataset Loss=0.335, Batch Time=0.031
Epoch 71: at batch 1: Training dataset Loss=0.342, Batch Time=0.026
Epoch 81: at batch 1: Training dataset Loss=0.345, Batch Time=0.023
Epoch 91: at batch 1: Training dataset Loss=0.333, Batch Time=0.029
Epoch 101: at batch 1: Training dataset Loss=0.333, Batch Time=0.033
Epoch 101: Epoch time = 42.820, Avg epoch time=0.318, Total Time=0.420

[[0.33333334]
 [0.33333334]
 [0.33333334]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 111: at batch 1: Training dataset Loss=0.334, Batch Time=0.035
Epoch 121: at batch 1: Training dataset Loss=0.342, Batch Time=0.035
Epoch 131: at batch 1: Training dataset Loss=0.333, Batch Time=0.036
Epoch 141: at batch 1: Training dataset Loss=0.333, Batch Time=0.036
Epoch 151: at batch 1: Training dataset Loss=0.333, Batch Time=0.035
Epoch 161: at batch 1: Training dataset Loss=0.333, Batch Time=0.027
Epoch 171: at batch 1: Training dataset Loss=0.333, Batch Time=0.035
Epoch 181: at batch 1: Training dataset Loss=0.361, Batch Time=0.028
Epoch 191: at batch 1: Training dataset Loss=0.333, Batch Time=0.038
Epoch 201: at batch 1: Training dataset Loss=0.335, Batch Time=0.031
Epoch 201: Epoch time = 85.790, Avg epoch time=0.309, Total Time=0.425

[[0.33333334]
 [0.33333334]
 [0.36114773]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 211: at batch 1: Training dataset Loss=0.333, Batch Time=0.030
Epoch 221: at batch 1: Training dataset Loss=0.333, Batch Time=0.025
Epoch 231: at batch 1: Training dataset Loss=0.333, Batch Time=0.034
Epoch 241: at batch 1: Training dataset Loss=0.333, Batch Time=0.037
Epoch 251: at batch 1: Training dataset Loss=0.333, Batch Time=0.032
Epoch 261: at batch 1: Training dataset Loss=0.333, Batch Time=0.030
Epoch 271: at batch 1: Training dataset Loss=0.333, Batch Time=0.032
Epoch 281: at batch 1: Training dataset Loss=0.333, Batch Time=0.034
Epoch 291: at batch 1: Training dataset Loss=0.333, Batch Time=0.024
Epoch 301: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 301: Epoch time = 127.282, Avg epoch time=0.277, Total Time=0.421

[[0.33333334]
 [0.91608381]
 [0.33333334]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 311: at batch 1: Training dataset Loss=0.333, Batch Time=0.029
Epoch 321: at batch 1: Training dataset Loss=0.333, Batch Time=0.025
Epoch 331: at batch 1: Training dataset Loss=0.334, Batch Time=0.025
Epoch 341: at batch 1: Training dataset Loss=0.333, Batch Time=0.033
Epoch 351: at batch 1: Training dataset Loss=0.333, Batch Time=0.027
Epoch 361: at batch 1: Training dataset Loss=0.333, Batch Time=0.031
Epoch 371: at batch 1: Training dataset Loss=0.333, Batch Time=0.024
Epoch 381: at batch 1: Training dataset Loss=0.333, Batch Time=0.032
Epoch 391: at batch 1: Training dataset Loss=0.333, Batch Time=0.031
Epoch 401: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 401: Epoch time = 167.470, Avg epoch time=0.276, Total Time=0.417

[[0.33333334]
 [0.33333334]
 [0.33333334]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 411: at batch 1: Training dataset Loss=0.333, Batch Time=0.032
Epoch 421: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 431: at batch 1: Training dataset Loss=0.333, Batch Time=0.025
Epoch 441: at batch 1: Training dataset Loss=0.333, Batch Time=0.032
Epoch 451: at batch 1: Training dataset Loss=0.333, Batch Time=0.025
Epoch 461: at batch 1: Training dataset Loss=0.333, Batch Time=0.025
Epoch 471: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 481: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 491: at batch 1: Training dataset Loss=0.333, Batch Time=0.031
Epoch 501: at batch 1: Training dataset Loss=0.333, Batch Time=0.032
Epoch 501: Epoch time = 207.650, Avg epoch time=0.285, Total Time=0.414

[[0.33333334]
 [0.33333334]
 [0.33333334]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 511: at batch 1: Training dataset Loss=0.333, Batch Time=0.029
Epoch 521: at batch 1: Training dataset Loss=0.333, Batch Time=0.034
Epoch 531: at batch 1: Training dataset Loss=0.333, Batch Time=0.034
Epoch 541: at batch 1: Training dataset Loss=0.333, Batch Time=0.023
Epoch 551: at batch 1: Training dataset Loss=0.333, Batch Time=0.034
Epoch 561: at batch 1: Training dataset Loss=0.333, Batch Time=0.029
Epoch 571: at batch 1: Training dataset Loss=0.333, Batch Time=0.035
Epoch 581: at batch 1: Training dataset Loss=0.333, Batch Time=0.024
Epoch 591: at batch 1: Training dataset Loss=0.333, Batch Time=0.024
Epoch 601: at batch 1: Training dataset Loss=0.333, Batch Time=0.032
Epoch 601: Epoch time = 247.813, Avg epoch time=0.270, Total Time=0.412

[[0.33333334]
 [0.33333334]
 [0.33333334]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 611: at batch 1: Training dataset Loss=0.333, Batch Time=0.029
Epoch 621: at batch 1: Training dataset Loss=0.333, Batch Time=0.023
Epoch 631: at batch 1: Training dataset Loss=0.333, Batch Time=0.029
Epoch 641: at batch 1: Training dataset Loss=0.333, Batch Time=0.030
Epoch 651: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 661: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 671: at batch 1: Training dataset Loss=0.333, Batch Time=0.031
Epoch 681: at batch 1: Training dataset Loss=0.333, Batch Time=0.028
Epoch 691: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 701: at batch 1: Training dataset Loss=0.333, Batch Time=0.027
Epoch 701: Epoch time = 288.056, Avg epoch time=0.281, Total Time=0.410

[[0.33333334]
 [0.33333334]
 [0.33333334]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 711: at batch 1: Training dataset Loss=0.333, Batch Time=0.023
Epoch 721: at batch 1: Training dataset Loss=0.333, Batch Time=0.031
Epoch 731: at batch 1: Training dataset Loss=0.333, Batch Time=0.034
Epoch 741: at batch 1: Training dataset Loss=0.333, Batch Time=0.030
Epoch 751: at batch 1: Training dataset Loss=0.333, Batch Time=0.032
Epoch 761: at batch 1: Training dataset Loss=0.333, Batch Time=0.035
Epoch 771: at batch 1: Training dataset Loss=0.337, Batch Time=0.025
Epoch 781: at batch 1: Training dataset Loss=0.333, Batch Time=0.032
Epoch 791: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 801: at batch 1: Training dataset Loss=0.333, Batch Time=0.032
Epoch 801: Epoch time = 328.149, Avg epoch time=0.288, Total Time=0.409

[[0.33333334]
 [0.33333334]
 [0.33333334]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 811: at batch 1: Training dataset Loss=0.333, Batch Time=0.029
Epoch 821: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 831: at batch 1: Training dataset Loss=0.333, Batch Time=0.032
Epoch 841: at batch 1: Training dataset Loss=0.333, Batch Time=0.029
Epoch 851: at batch 1: Training dataset Loss=0.333, Batch Time=0.033
Epoch 861: at batch 1: Training dataset Loss=0.333, Batch Time=0.027
Epoch 871: at batch 1: Training dataset Loss=0.334, Batch Time=0.029
Epoch 881: at batch 1: Training dataset Loss=0.333, Batch Time=0.023
Epoch 891: at batch 1: Training dataset Loss=0.333, Batch Time=0.035
Epoch 901: at batch 1: Training dataset Loss=0.333, Batch Time=0.028
Epoch 901: Epoch time = 368.236, Avg epoch time=0.293, Total Time=0.408

[[0.33333334]
 [0.33333334]
 [0.33333334]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 911: at batch 1: Training dataset Loss=0.333, Batch Time=0.029
Epoch 921: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 931: at batch 1: Training dataset Loss=0.333, Batch Time=0.025
Epoch 941: at batch 1: Training dataset Loss=0.333, Batch Time=0.029
Epoch 951: at batch 1: Training dataset Loss=0.333, Batch Time=0.034
Epoch 961: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 971: at batch 1: Training dataset Loss=0.333, Batch Time=0.030
Epoch 981: at batch 1: Training dataset Loss=0.333, Batch Time=0.033
Epoch 991: at batch 1: Training dataset Loss=0.333, Batch Time=0.027
Epoch 1001: at batch 1: Training dataset Loss=0.333, Batch Time=0.032
Epoch 1001: Epoch time = 408.494, Avg epoch time=0.266, Total Time=0.408

[[0.33333334]
 [0.33333334]
 [0.33333334]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1011: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 1021: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 1031: at batch 1: Training dataset Loss=0.333, Batch Time=0.023
Epoch 1041: at batch 1: Training dataset Loss=0.333, Batch Time=0.032
Epoch 1051: at batch 1: Training dataset Loss=0.333, Batch Time=0.024
Epoch 1061: at batch 1: Training dataset Loss=0.333, Batch Time=0.027
Epoch 1071: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 1081: at batch 1: Training dataset Loss=0.333, Batch Time=0.033
Epoch 1091: at batch 1: Training dataset Loss=0.333, Batch Time=0.032
Epoch 1101: at batch 1: Training dataset Loss=0.333, Batch Time=0.024
Epoch 1101: Epoch time = 448.824, Avg epoch time=0.270, Total Time=0.407

[[0.33333334]
 [0.33333334]
 [0.33333334]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1111: at batch 1: Training dataset Loss=0.333, Batch Time=0.031
Epoch 1121: at batch 1: Training dataset Loss=0.333, Batch Time=0.030
Epoch 1131: at batch 1: Training dataset Loss=0.333, Batch Time=0.031
Epoch 1141: at batch 1: Training dataset Loss=0.333, Batch Time=0.027
Epoch 1151: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 1161: at batch 1: Training dataset Loss=0.333, Batch Time=0.028
Epoch 1171: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 1181: at batch 1: Training dataset Loss=0.333, Batch Time=0.024
Epoch 1191: at batch 1: Training dataset Loss=0.333, Batch Time=0.029
Epoch 1201: at batch 1: Training dataset Loss=0.333, Batch Time=0.032
Epoch 1201: Epoch time = 489.088, Avg epoch time=0.272, Total Time=0.407

[[0.33333334]
 [0.33333334]
 [0.33333334]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1211: at batch 1: Training dataset Loss=0.333, Batch Time=0.034
Epoch 1221: at batch 1: Training dataset Loss=0.333, Batch Time=0.036
Epoch 1231: at batch 1: Training dataset Loss=0.333, Batch Time=0.034
Epoch 1241: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 1251: at batch 1: Training dataset Loss=0.333, Batch Time=0.029
Epoch 1261: at batch 1: Training dataset Loss=0.333, Batch Time=0.032
Epoch 1271: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 1281: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 1291: at batch 1: Training dataset Loss=0.333, Batch Time=0.025
Epoch 1301: at batch 1: Training dataset Loss=0.333, Batch Time=0.028
Epoch 1301: Epoch time = 529.047, Avg epoch time=0.284, Total Time=0.406

[[0.33333334]
 [0.33333334]
 [0.33333334]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1311: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 1321: at batch 1: Training dataset Loss=0.333, Batch Time=0.031
Epoch 1331: at batch 1: Training dataset Loss=0.333, Batch Time=0.028
Epoch 1341: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 1351: at batch 1: Training dataset Loss=0.333, Batch Time=0.027
Epoch 1361: at batch 1: Training dataset Loss=0.333, Batch Time=0.023
Epoch 1371: at batch 1: Training dataset Loss=0.333, Batch Time=0.029
Epoch 1381: at batch 1: Training dataset Loss=0.333, Batch Time=0.024
Epoch 1391: at batch 1: Training dataset Loss=0.333, Batch Time=0.031
Epoch 1401: at batch 1: Training dataset Loss=0.333, Batch Time=0.023
Epoch 1401: Epoch time = 569.366, Avg epoch time=0.278, Total Time=0.406

[[0.33333334]
 [0.33333334]
 [0.33333334]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1411: at batch 1: Training dataset Loss=0.333, Batch Time=0.025
Epoch 1421: at batch 1: Training dataset Loss=0.333, Batch Time=0.029
Epoch 1431: at batch 1: Training dataset Loss=0.333, Batch Time=0.032
Epoch 1441: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 1451: at batch 1: Training dataset Loss=0.333, Batch Time=0.027
Epoch 1461: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 1471: at batch 1: Training dataset Loss=0.333, Batch Time=0.031
Epoch 1481: at batch 1: Training dataset Loss=0.333, Batch Time=0.029
Epoch 1491: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 1501: at batch 1: Training dataset Loss=0.333, Batch Time=0.032
Epoch 1501: Epoch time = 609.470, Avg epoch time=0.265, Total Time=0.406

[[0.33333334]
 [0.33333334]
 [0.33333334]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1511: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 1521: at batch 1: Training dataset Loss=0.333, Batch Time=0.035
Epoch 1531: at batch 1: Training dataset Loss=0.333, Batch Time=0.029
Epoch 1541: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 1551: at batch 1: Training dataset Loss=0.333, Batch Time=0.032
Epoch 1561: at batch 1: Training dataset Loss=0.333, Batch Time=0.032
Epoch 1571: at batch 1: Training dataset Loss=0.333, Batch Time=0.030
Epoch 1581: at batch 1: Training dataset Loss=0.333, Batch Time=0.029
Epoch 1591: at batch 1: Training dataset Loss=0.333, Batch Time=0.029
Epoch 1601: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 1601: Epoch time = 649.356, Avg epoch time=0.284, Total Time=0.405

[[0.33333334]
 [0.33333334]
 [0.33333334]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1611: at batch 1: Training dataset Loss=0.333, Batch Time=0.025
Epoch 1621: at batch 1: Training dataset Loss=0.333, Batch Time=0.035
Epoch 1631: at batch 1: Training dataset Loss=0.333, Batch Time=0.033
Epoch 1641: at batch 1: Training dataset Loss=0.333, Batch Time=0.025
Epoch 1651: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 1661: at batch 1: Training dataset Loss=0.333, Batch Time=0.023
Epoch 1671: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 1681: at batch 1: Training dataset Loss=0.333, Batch Time=0.030
Epoch 1691: at batch 1: Training dataset Loss=0.333, Batch Time=0.030
Epoch 1701: at batch 1: Training dataset Loss=0.333, Batch Time=0.031
Epoch 1701: Epoch time = 689.339, Avg epoch time=0.262, Total Time=0.405

[[0.33333334]
 [0.33333334]
 [0.33333334]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1711: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 1721: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 1731: at batch 1: Training dataset Loss=0.333, Batch Time=0.032
Epoch 1741: at batch 1: Training dataset Loss=0.333, Batch Time=0.033
Epoch 1751: at batch 1: Training dataset Loss=0.333, Batch Time=0.034
Epoch 1761: at batch 1: Training dataset Loss=0.333, Batch Time=0.037
Epoch 1771: at batch 1: Training dataset Loss=0.333, Batch Time=0.026
Epoch 1781: at batch 1: Training dataset Loss=0.333, Batch Time=0.032
Epoch 1791: at batch 1: Training dataset Loss=0.333, Batch Time=0.033
Epoch 1801: at batch 1: Training dataset Loss=0.333, Batch Time=0.028
Epoch 1801: Epoch time = 729.737, Avg epoch time=0.304, Total Time=0.405

[[0.33333334]
 [0.33333334]
 [0.33333334]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1811: at batch 1: Training dataset Loss=0.333, Batch Time=0.037
Epoch 1821: at batch 1: Training dataset Loss=0.333, Batch Time=0.033
Epoch 1831: at batch 1: Training dataset Loss=0.333, Batch Time=0.032
Epoch 1841: at batch 1: Training dataset Loss=0.333, Batch Time=0.027
Epoch 1851: at batch 1: Training dataset Loss=0.333, Batch Time=0.023
Epoch 1861: at batch 1: Training dataset Loss=0.333, Batch Time=0.028
Epoch 1871: at batch 1: Training dataset Loss=0.333, Batch Time=0.024
Epoch 1881: at batch 1: Training dataset Loss=0.335, Batch Time=0.029
Epoch 1891: at batch 1: Training dataset Loss=0.333, Batch Time=0.028
Epoch 1901: at batch 1: Training dataset Loss=0.333, Batch Time=0.031
Epoch 1901: Epoch time = 769.954, Avg epoch time=0.301, Total Time=0.405

[[0.33333334]
 [0.33333334]
 [0.33333334]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1911: at batch 1: Training dataset Loss=0.333, Batch Time=0.031
Epoch 1921: at batch 1: Training dataset Loss=0.333, Batch Time=0.030
^CTraceback (most recent call last):
  File "medium_batched_square_loss.py", line 295, in <module>
    input_patch[k,:,:,:] = input_images_numpy[ind[k], yy:yy + ps, xx:xx + ps, :]
KeyboardInterrupt
