Last login: Fri Dec 11 00:41:23 on ttys000

The default interactive shell is now zsh.
To update your account to use zsh, please run `chsh -s /bin/zsh`.
For more details, please visit https://support.apple.com/kb/HT208050.
(base) Ilyeechs-MacBook-Pro:~ ilyeech$ ssh -Y greene
 _   ___   ___   _   _   _ ____   ____ 
| \ | \ \ / / | | | | | | |  _ \ / ___|
|  \| |\ V /| | | | | |_| | |_) | |    
| |\  | | | | |_| | |  _  |  __/| |___ 
|_| \_| |_|  \___/  |_| |_|_|    \____|
 

  ____                          
 / ___|_ __ ___  ___ _ __   ___ 
| |  _| '__/ _ \/ _ \ '_ \ / _ \
| |_| | | |  __/  __/ | | |  __/
 \____|_|  \___|\___|_| |_|\___|

ir967@localhost's password: 
Permission denied, please try again.
ir967@localhost's password: 
Last failed login: Fri Dec 11 00:42:52 EST 2020 from 216.165.66.211 on ssh:notty
There was 1 failed login attempt since the last successful login.
Last login: Wed Dec  9 15:47:40 2020 from 216.165.66.211
[ir967@log-3 ~]$ vi /etc/ssh/sshd_config
[ir967@log-3 ~]$ pwd
/home/ir967
[ir967@log-3 ~]$ cd $SCRATCH/SID
[ir967@log-3 SID]$ cd Learning-to-See-in-the-Dark/
[ir967@log-3 Learning-to-See-in-the-Dark]$ pwd
/scratch/ir967/SID/Learning-to-See-in-the-Dark
[ir967@log-3 Learning-to-See-in-the-Dark]$ ls
 all_of_gt_Sony
 all_of_gt_Sony_avgpool
 all_of_gt_Sony_avgpool_2convlayers
 all_of_gt_Sony_GPU_efficient
 all_of_gt_Sony_GPU_efficient_flattened
 all_of_gt_Sony_GPU_efficient_flattened_1output
 all_of_gt_Sony_GPU_efficient_flattened_1output_value
 all_of_gt_Sony_GPU_efficient_flattened_3output
 all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler
 all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler_print
 all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler_wider
 all_of_gt_Sony_GPU_efficient_flattened_3output_print_test
 all_of_gt_Sony_GPU_efficient_flattened_3output_simpler
 checkpoint
 check.sh
 cluster_status.txt
 dataset
 debug_one_hot.txt
 download_dataset.py
 download_models.py
 efficiency
 exper.py
 exper.sbatch
 gamma_checkpoint
 gamma_experiment.py
 gamma_piecewise.txt
 gt_Sony_dead_simple
 half_of_gt_Sony
 HPC-hw4-1a.sh
 htop.txt
 images
 LICENSE.md
 logs
 lspci.out
 README.md
 result_Fuji
 result_Sony
'result_Sony__[1-5]_images'
 result_Sony_20_images
 result_Sony_checkDec6
 result_Sony_with_gamma_net
 result_Sony_with_gamma_net_3output
 run1_5_images_result_Sony
 scontrol_8hours.txt
 slurm-14070900.out
 slurm-14070902.out
 slurm-14070911.out
 slurm-14070912.out
 slurm-14070913.out
 slurm-14071347.out
 slurm-14071658.out
 slurm-14071926.out
 slurm-14071947.out
 slurm-14071947.out.success
 slurm-14077029.out
 slurm-14077193.out
 slurm-14077213.out
 slurm-14077214.out
 slurm-14077239.out
 slurm-14077406.out
 slurm-14077449.out
 slurm-14077943.out
 slurm-14078918.out
 slurm-14078920.out
 slurm-14079971.out
 slurm-14080077.out
 slurm-14080208.out
 _slurm_out
 sstat_8hours.txt
 test_for_gamma_Sony_3output.py
 test_for_gamma_Sony_3output.sbatch
 test_for_gamma_Sony.py
 test_for_gamma_Sony.sbatch
 test_Fuji.py
 test_Fuji.sbatch
 test_Sony.py
 test_Sony.sbatch
 test_Sony_with_gamma.py
 test_Sony_with_gamma.sbatch
 test_Sony_with_gamma_unflattened.py
 train_for_gamma_Sony_1output.py
 train_for_gamma_Sony_1output.sbatch
 train_for_gamma_Sony_1output_value.py
 train_for_gamma_Sony_1output_value.sbatch
 train_for_gamma_Sony_3output_more_simpler.py
 train_for_gamma_Sony_3output_more_simpler.sbatch
 train_for_gamma_Sony_3output_more_simpler_wider.py
 train_for_gamma_Sony_3output.py
 train_for_gamma_Sony_3output.sbatch
 train_for_gamma_Sony_3output_simpler.py
 train_for_gamma_Sony_3output_simpler.sbatch
 train_for_gamma_Sony_avgpool_2convlayers.py
 train_for_gamma_Sony_avgpool.py
 train_for_gamma_Sony_clean_code_not_working.py
 train_for_gamma_Sony_dead_simple.py
 train_for_gamma_Sony.py
 train_for_gamma_Sony.sbatch
 train_for_gamma_Sony_unflattened.py
 train_Fuji.py
 train_Fuji.sbatch
 train_Sony.py
 train_Sony.sbatch
[ir967@log-3 Learning-to-See-in-the-Dark]$ ls -al
total 4539
drwxrwxrwx+  32 ir967 root   8192 Dec  9 17:18  .
drwxrwxrwx+   3 ir967 root   4096 Dec  8 13:13  ..
drwxrwxrwx+  34 ir967 root   4096 Dec  8 13:27  all_of_gt_Sony
drwxrwxrwx+  29 ir967 root   4096 Dec  8 13:27  all_of_gt_Sony_avgpool
drwxrwxrwx+  26 ir967 root   4096 Dec  8 13:27  all_of_gt_Sony_avgpool_2convlayers
drwxrwxrwx+ 169 ir967 root   8192 Dec  8 13:27  all_of_gt_Sony_GPU_efficient
drwxrwxrwx+  18 ir967 root   4096 Dec  8 13:27  all_of_gt_Sony_GPU_efficient_flattened
drwxrwxrwx+   2 ir967 root   4096 Dec  8 13:27  all_of_gt_Sony_GPU_efficient_flattened_1output
drwxrwxrwx+   5 ir967 root   4096 Dec  8 13:27  all_of_gt_Sony_GPU_efficient_flattened_1output_value
drwxrwxrwx+  53 ir967 root   4096 Dec  8 13:27  all_of_gt_Sony_GPU_efficient_flattened_3output
drwxrwxrwx+ 139 ir967 root   8192 Dec  8 13:27  all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler
drwxrwxrwx+  25 ir967 root   4096 Dec  8 13:27  all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler_print
drwxrwxrwx+   2 ir967 root   4096 Dec  8 13:27  all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler_wider
drwxrwxrwx+  17 ir967 root   4096 Dec  8 13:27  all_of_gt_Sony_GPU_efficient_flattened_3output_print_test
drwxrwxrwx+   9 ir967 root   4096 Dec  8 13:27  all_of_gt_Sony_GPU_efficient_flattened_3output_simpler
drwxrwxrwx+   4 ir967 root   4096 Dec  8 13:27  checkpoint
-rwxrwxrwx+   1 ir967 root    120 Dec  8 13:27  check.sh
-rwxrwxrwx+   1 ir967 root   6443 Dec  8 13:24  cluster_status.txt
drwxrwxrwx+   4 ir967 root   4096 Dec  9 15:37  dataset
-rwxrwxrwx+   1 ir967 root  64900 Dec  8 13:24  debug_one_hot.txt
-rwxrwxrwx+   1 ir967 root   1262 Dec  8 13:24  download_dataset.py
-rwxrwxrwx+   1 ir967 root   1415 Dec  8 13:24  download_models.py
drwxrwxrwx+   2 ir967 root   4096 Dec  8 13:27  efficiency
-rwxrwxrwx+   1 ir967 root    710 Dec  8 13:24  exper.py
-rwxrwxrwx+   1 ir967 root   1352 Dec  8 13:24  exper.sbatch
drwxrwxrwx+   3 ir967 root   4096 Dec  8 13:28  gamma_checkpoint
-rwxrwxrwx+   1 ir967 root   2241 Dec  8 13:28  gamma_experiment.py
-rwxrwxrwx+   1 ir967 root   2689 Dec  8 13:28  gamma_piecewise.txt
drwxrwxrwx+  88 ir967 root   4096 Dec  8 13:28  gt_Sony_dead_simple
drwxrwxrwx+  10 ir967 root   4096 Dec  8 13:28  half_of_gt_Sony
-rwxrwxrwx+   1 ir967 root    487 Dec  8 13:28  HPC-hw4-1a.sh
-rwxrwxrwx+   1 ir967 root   6092 Dec  8 13:28  htop.txt
drwxrwxrwx+   2 ir967 root   4096 Dec  8 13:28  images
-rwxrwxrwx+   1 ir967 root   1108 Dec  8 13:28  LICENSE.md
drwxrwxrwx+   2 ir967 root   4096 Dec  8 13:28  logs
-rwxrwxrwx+   1 ir967 root  21531 Dec  8 13:28  lspci.out
-rwxrwxrwx+   1 ir967 root   5381 Dec  8 13:25  README.md
drwxrwxrwx+   4 ir967 root   4096 Dec  8 13:26  result_Fuji
drwxrwxrwx+  65 ir967 root   4096 Dec  8 13:26  result_Sony
drwxrwxrwx+   2 ir967 root   4096 Dec  8 13:26 'result_Sony__[1-5]_images'
drwxrwxrwx+   6 ir967 root   4096 Dec  8 13:26  result_Sony_20_images
drwxrwxrwx+   3 ir967 root   4096 Dec  8 13:26  result_Sony_checkDec6
drwxrwxrwx+   3 ir967 root   4096 Dec  8 13:26  result_Sony_with_gamma_net
drwxrwxrwx+   3 ir967 root   4096 Dec  8 13:26  result_Sony_with_gamma_net_3output
drwxrwxrwx+  85 ir967 root   4096 Dec  8 13:30  run1_5_images_result_Sony
-rwxrwxrwx+   1 ir967 root   1428 Dec  8 13:24  scontrol_8hours.txt
-rwxrwxrwx+   1 ir967 root   9476 Dec  8 13:25  slurm-14070900.out
-rwxrwxrwx+   1 ir967 root   1471 Dec  8 13:25  slurm-14070902.out
-rwxrwxrwx+   1 ir967 root   1471 Dec  8 13:25  slurm-14070911.out
-rwxrwxrwx+   1 ir967 root   1262 Dec  8 13:25  slurm-14070912.out
-rwxrwxrwx+   1 ir967 root   1262 Dec  8 13:25  slurm-14070913.out
-rwxrwxrwx+   1 ir967 root  42226 Dec  8 13:25  slurm-14071347.out
-rwxrwxrwx+   1 ir967 root   4902 Dec  8 13:25  slurm-14071658.out
-rwxrwxrwx+   1 ir967 root   1452 Dec  8 13:25  slurm-14071926.out
-rwxrwxrwx+   1 ir967 root   1284 Dec  8 13:25  slurm-14071947.out
-rwxrwxrwx+   1 ir967 root   1284 Dec  8 13:25  slurm-14071947.out.success
-rwxrwxrwx+   1 ir967 root    221 Dec  8 13:25  slurm-14077029.out
-rwxrwxrwx+   1 ir967 root   1521 Dec  8 13:25  slurm-14077193.out
-rwxrwxrwx+   1 ir967 root   1459 Dec  8 13:25  slurm-14077213.out
-rwxrwxrwx+   1 ir967 root   1290 Dec  8 13:25  slurm-14077214.out
-rwxrwxrwx+   1 ir967 root   1553 Dec  8 13:25  slurm-14077239.out
-rwxrwxrwx+   1 ir967 root   1531 Dec  8 13:25  slurm-14077406.out
-rwxrwxrwx+   1 ir967 root   1715 Dec  8 13:25  slurm-14077449.out
-rwxrwxrwx+   1 ir967 root   1489 Dec  8 13:25  slurm-14077943.out
-rwxrwxrwx+   1 ir967 root   2096 Dec  8 13:25  slurm-14078918.out
-rwxrwxrwx+   1 ir967 root   2096 Dec  8 13:25  slurm-14078920.out
-rwxrwxrwx+   1 ir967 root 558291 Dec  8 13:25  slurm-14079971.out
-rwxrwxrwx+   1 ir967 root   9427 Dec  8 13:25  slurm-14080077.out
-rwxrwxrwx+   1 ir967 root   6192 Dec  8 13:25  slurm-14080208.out
drwxrwxrwx+   2 ir967 root   4096 Dec  8 13:30  _slurm_out
-rwxrwxrwx+   1 ir967 root    652 Dec  8 13:24  sstat_8hours.txt
-rwxrwxrwx+   1 ir967 root   6703 Dec  8 13:24  test_for_gamma_Sony_3output.py
-rwxrwxrwx+   1 ir967 root   1377 Dec  8 13:24  test_for_gamma_Sony_3output.sbatch
-rwxrwxrwx+   1 ir967 root   5380 Dec  8 13:24  test_for_gamma_Sony.py
-rwxrwxrwx+   1 ir967 root   1371 Dec  8 13:24  test_for_gamma_Sony.sbatch
-rwxrwxrwx+   1 ir967 root   7167 Dec  8 13:24  test_Fuji.py
-rwxrwxrwx+   1 ir967 root   1353 Dec  8 13:24  test_Fuji.sbatch
-rwxrwxrwx+   1 ir967 root   6381 Dec  8 13:24  test_Sony.py
-rwxrwxrwx+   1 ir967 root   1360 Dec  8 13:24  test_Sony.sbatch
-rwxrwxrwx+   1 ir967 root   7574 Dec  8 13:24  test_Sony_with_gamma.py
-rwxrwxrwx+   1 ir967 root   1372 Dec  8 13:24  test_Sony_with_gamma.sbatch
-rwxrwxrwx+   1 ir967 root   7574 Dec  8 13:24  test_Sony_with_gamma_unflattened.py
-rwxrwxrwx+   1 ir967 root  13200 Dec  8 13:24  train_for_gamma_Sony_1output.py
-rwxrwxrwx+   1 ir967 root   1375 Dec  8 13:24  train_for_gamma_Sony_1output.sbatch
-rwxrwxrwx+   1 ir967 root  13156 Dec  8 13:24  train_for_gamma_Sony_1output_value.py
-rwxrwxrwx+   1 ir967 root   1381 Dec  8 13:24  train_for_gamma_Sony_1output_value.sbatch
-rwxrwxrwx+   1 ir967 root  15798 Dec  8 13:24  train_for_gamma_Sony_3output_more_simpler.py
-rwxrwxrwx+   1 ir967 root   1388 Dec  8 13:24  train_for_gamma_Sony_3output_more_simpler.sbatch
-rwxrwxrwx+   1 ir967 root  14738 Dec  8 13:24  train_for_gamma_Sony_3output_more_simpler_wider.py
-rwxrwxrwx+   1 ir967 root  13292 Dec  8 13:24  train_for_gamma_Sony_3output.py
-rwxrwxrwx+   1 ir967 root   1375 Dec  8 13:24  train_for_gamma_Sony_3output.sbatch
-rwxrwxrwx+   1 ir967 root  12739 Dec  8 13:24  train_for_gamma_Sony_3output_simpler.py
-rwxrwxrwx+   1 ir967 root   1383 Dec  8 13:24  train_for_gamma_Sony_3output_simpler.sbatch
-rwxrwxrwx+   1 ir967 root  14343 Dec  8 13:24  train_for_gamma_Sony_avgpool_2convlayers.py
-rwxrwxrwx+   1 ir967 root  14653 Dec  8 13:24  train_for_gamma_Sony_avgpool.py
-rwxrwxrwx+   1 ir967 root  13792 Dec  8 13:24  train_for_gamma_Sony_clean_code_not_working.py
-rwxrwxrwx+   1 ir967 root  15430 Dec  8 13:24  train_for_gamma_Sony_dead_simple.py
-rwxrwxrwx+   1 ir967 root  13271 Dec  8 13:24  train_for_gamma_Sony.py
-rwxrwxrwx+   1 ir967 root   1367 Dec  8 13:24  train_for_gamma_Sony.sbatch
-rwxrwxrwx+   1 ir967 root  12185 Dec  8 13:24  train_for_gamma_Sony_unflattened.py
-rwxrwxrwx+   1 ir967 root   8668 Dec  8 13:24  train_Fuji.py
-rwxrwxrwx+   1 ir967 root    519 Dec  8 13:24  train_Fuji.sbatch
-rwxrwxrwx+   1 ir967 root   8219 Dec  8 13:24  train_Sony.py
-rwxrwxrwx+   1 ir967 root    511 Dec  8 13:24  train_Sony.sbatch
[ir967@log-3 Learning-to-See-in-the-Dark]$ mv slurm-1* _slurm_out/
[ir967@log-3 Learning-to-See-in-the-Dark]$ ls -al
total 3258
drwxrwxrwx+  32 ir967 root  8192 Dec 11 00:58  .
drwxrwxrwx+   3 ir967 root  4096 Dec  8 13:13  ..
drwxrwxrwx+  34 ir967 root  4096 Dec  8 13:27  all_of_gt_Sony
drwxrwxrwx+  29 ir967 root  4096 Dec  8 13:27  all_of_gt_Sony_avgpool
drwxrwxrwx+  26 ir967 root  4096 Dec  8 13:27  all_of_gt_Sony_avgpool_2convlayers
drwxrwxrwx+ 169 ir967 root  8192 Dec  8 13:27  all_of_gt_Sony_GPU_efficient
drwxrwxrwx+  18 ir967 root  4096 Dec  8 13:27  all_of_gt_Sony_GPU_efficient_flattened
drwxrwxrwx+   2 ir967 root  4096 Dec  8 13:27  all_of_gt_Sony_GPU_efficient_flattened_1output
drwxrwxrwx+   5 ir967 root  4096 Dec  8 13:27  all_of_gt_Sony_GPU_efficient_flattened_1output_value
drwxrwxrwx+  53 ir967 root  4096 Dec  8 13:27  all_of_gt_Sony_GPU_efficient_flattened_3output
drwxrwxrwx+ 139 ir967 root  8192 Dec  8 13:27  all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler
drwxrwxrwx+  25 ir967 root  4096 Dec  8 13:27  all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler_print
drwxrwxrwx+   2 ir967 root  4096 Dec  8 13:27  all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler_wider
drwxrwxrwx+  17 ir967 root  4096 Dec  8 13:27  all_of_gt_Sony_GPU_efficient_flattened_3output_print_test
drwxrwxrwx+   9 ir967 root  4096 Dec  8 13:27  all_of_gt_Sony_GPU_efficient_flattened_3output_simpler
drwxrwxrwx+   4 ir967 root  4096 Dec  8 13:27  checkpoint
-rwxrwxrwx+   1 ir967 root   120 Dec  8 13:27  check.sh
-rwxrwxrwx+   1 ir967 root  6443 Dec  8 13:24  cluster_status.txt
drwxrwxrwx+   4 ir967 root  4096 Dec  9 15:37  dataset
-rwxrwxrwx+   1 ir967 root 64900 Dec  8 13:24  debug_one_hot.txt
-rwxrwxrwx+   1 ir967 root  1262 Dec  8 13:24  download_dataset.py
-rwxrwxrwx+   1 ir967 root  1415 Dec  8 13:24  download_models.py
drwxrwxrwx+   2 ir967 root  4096 Dec  8 13:27  efficiency
-rwxrwxrwx+   1 ir967 root   710 Dec  8 13:24  exper.py
-rwxrwxrwx+   1 ir967 root  1352 Dec  8 13:24  exper.sbatch
drwxrwxrwx+   3 ir967 root  4096 Dec  8 13:28  gamma_checkpoint
-rwxrwxrwx+   1 ir967 root  2241 Dec  8 13:28  gamma_experiment.py
-rwxrwxrwx+   1 ir967 root  2689 Dec  8 13:28  gamma_piecewise.txt
drwxrwxrwx+  88 ir967 root  4096 Dec  8 13:28  gt_Sony_dead_simple
drwxrwxrwx+  10 ir967 root  4096 Dec  8 13:28  half_of_gt_Sony
-rwxrwxrwx+   1 ir967 root   487 Dec  8 13:28  HPC-hw4-1a.sh
-rwxrwxrwx+   1 ir967 root  6092 Dec  8 13:28  htop.txt
drwxrwxrwx+   2 ir967 root  4096 Dec  8 13:28  images
-rwxrwxrwx+   1 ir967 root  1108 Dec  8 13:28  LICENSE.md
drwxrwxrwx+   2 ir967 root  4096 Dec  8 13:28  logs
-rwxrwxrwx+   1 ir967 root 21531 Dec  8 13:28  lspci.out
-rwxrwxrwx+   1 ir967 root  5381 Dec  8 13:25  README.md
drwxrwxrwx+   4 ir967 root  4096 Dec  8 13:26  result_Fuji
drwxrwxrwx+  65 ir967 root  4096 Dec  8 13:26  result_Sony
drwxrwxrwx+   2 ir967 root  4096 Dec  8 13:26 'result_Sony__[1-5]_images'
drwxrwxrwx+   6 ir967 root  4096 Dec  8 13:26  result_Sony_20_images
drwxrwxrwx+   3 ir967 root  4096 Dec  8 13:26  result_Sony_checkDec6
drwxrwxrwx+   3 ir967 root  4096 Dec  8 13:26  result_Sony_with_gamma_net
drwxrwxrwx+   3 ir967 root  4096 Dec  8 13:26  result_Sony_with_gamma_net_3output
drwxrwxrwx+  85 ir967 root  4096 Dec  8 13:30  run1_5_images_result_Sony
-rwxrwxrwx+   1 ir967 root  1428 Dec  8 13:24  scontrol_8hours.txt
drwxrwxrwx+   2 ir967 root  8192 Dec 11 00:58  _slurm_out
-rwxrwxrwx+   1 ir967 root   652 Dec  8 13:24  sstat_8hours.txt
-rwxrwxrwx+   1 ir967 root  6703 Dec  8 13:24  test_for_gamma_Sony_3output.py
-rwxrwxrwx+   1 ir967 root  1377 Dec  8 13:24  test_for_gamma_Sony_3output.sbatch
-rwxrwxrwx+   1 ir967 root  5380 Dec  8 13:24  test_for_gamma_Sony.py
-rwxrwxrwx+   1 ir967 root  1371 Dec  8 13:24  test_for_gamma_Sony.sbatch
-rwxrwxrwx+   1 ir967 root  7167 Dec  8 13:24  test_Fuji.py
-rwxrwxrwx+   1 ir967 root  1353 Dec  8 13:24  test_Fuji.sbatch
-rwxrwxrwx+   1 ir967 root  6381 Dec  8 13:24  test_Sony.py
-rwxrwxrwx+   1 ir967 root  1360 Dec  8 13:24  test_Sony.sbatch
-rwxrwxrwx+   1 ir967 root  7574 Dec  8 13:24  test_Sony_with_gamma.py
-rwxrwxrwx+   1 ir967 root  1372 Dec  8 13:24  test_Sony_with_gamma.sbatch
-rwxrwxrwx+   1 ir967 root  7574 Dec  8 13:24  test_Sony_with_gamma_unflattened.py
-rwxrwxrwx+   1 ir967 root 13200 Dec  8 13:24  train_for_gamma_Sony_1output.py
-rwxrwxrwx+   1 ir967 root  1375 Dec  8 13:24  train_for_gamma_Sony_1output.sbatch
-rwxrwxrwx+   1 ir967 root 13156 Dec  8 13:24  train_for_gamma_Sony_1output_value.py
-rwxrwxrwx+   1 ir967 root  1381 Dec  8 13:24  train_for_gamma_Sony_1output_value.sbatch
-rwxrwxrwx+   1 ir967 root 15798 Dec  8 13:24  train_for_gamma_Sony_3output_more_simpler.py
-rwxrwxrwx+   1 ir967 root  1388 Dec  8 13:24  train_for_gamma_Sony_3output_more_simpler.sbatch
-rwxrwxrwx+   1 ir967 root 14738 Dec  8 13:24  train_for_gamma_Sony_3output_more_simpler_wider.py
-rwxrwxrwx+   1 ir967 root 13292 Dec  8 13:24  train_for_gamma_Sony_3output.py
-rwxrwxrwx+   1 ir967 root  1375 Dec  8 13:24  train_for_gamma_Sony_3output.sbatch
-rwxrwxrwx+   1 ir967 root 12739 Dec  8 13:24  train_for_gamma_Sony_3output_simpler.py
-rwxrwxrwx+   1 ir967 root  1383 Dec  8 13:24  train_for_gamma_Sony_3output_simpler.sbatch
-rwxrwxrwx+   1 ir967 root 14343 Dec  8 13:24  train_for_gamma_Sony_avgpool_2convlayers.py
-rwxrwxrwx+   1 ir967 root 14653 Dec  8 13:24  train_for_gamma_Sony_avgpool.py
-rwxrwxrwx+   1 ir967 root 13792 Dec  8 13:24  train_for_gamma_Sony_clean_code_not_working.py
-rwxrwxrwx+   1 ir967 root 15430 Dec  8 13:24  train_for_gamma_Sony_dead_simple.py
-rwxrwxrwx+   1 ir967 root 13271 Dec  8 13:24  train_for_gamma_Sony.py
-rwxrwxrwx+   1 ir967 root  1367 Dec  8 13:24  train_for_gamma_Sony.sbatch
-rwxrwxrwx+   1 ir967 root 12185 Dec  8 13:24  train_for_gamma_Sony_unflattened.py
-rwxrwxrwx+   1 ir967 root  8668 Dec  8 13:24  train_Fuji.py
-rwxrwxrwx+   1 ir967 root   519 Dec  8 13:24  train_Fuji.sbatch
-rwxrwxrwx+   1 ir967 root  8219 Dec  8 13:24  train_Sony.py
-rwxrwxrwx+   1 ir967 root   511 Dec  8 13:24  train_Sony.sbatch
[ir967@log-3 Learning-to-See-in-the-Dark]$ mkdir _old_code
[ir967@log-3 Learning-to-See-in-the-Dark]$ mv *_avgpool* _old_code/
[ir967@log-3 Learning-to-See-in-the-Dark]$ mv *_clean* _old_code/
[ir967@log-3 Learning-to-See-in-the-Dark]$ mv *_1out* _old_code/
[ir967@log-3 Learning-to-See-in-the-Dark]$ ls -al
total 2616
drwxrwxrwx+  29 ir967 root   8192 Dec 11 01:00  .
drwxrwxrwx+   3 ir967 root   4096 Dec  8 13:13  ..
drwxrwxrwx+  34 ir967 root   4096 Dec  8 13:27  all_of_gt_Sony
drwxrwxrwx+ 169 ir967 root   8192 Dec  8 13:27  all_of_gt_Sony_GPU_efficient
drwxrwxrwx+  18 ir967 root   4096 Dec  8 13:27  all_of_gt_Sony_GPU_efficient_flattened
drwxrwxrwx+  53 ir967 root   4096 Dec  8 13:27  all_of_gt_Sony_GPU_efficient_flattened_3output
drwxrwxrwx+ 139 ir967 root   8192 Dec  8 13:27  all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler
drwxrwxrwx+  25 ir967 root   4096 Dec  8 13:27  all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler_print
drwxrwxrwx+   2 ir967 root   4096 Dec  8 13:27  all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler_wider
drwxrwxrwx+  17 ir967 root   4096 Dec  8 13:27  all_of_gt_Sony_GPU_efficient_flattened_3output_print_test
drwxrwxrwx+   9 ir967 root   4096 Dec  8 13:27  all_of_gt_Sony_GPU_efficient_flattened_3output_simpler
drwxrwxrwx+   4 ir967 root   4096 Dec  8 13:27  checkpoint
-rwxrwxrwx+   1 ir967 root    120 Dec  8 13:27  check.sh
-rwxrwxrwx+   1 ir967 root   6443 Dec  8 13:24  cluster_status.txt
drwxrwxrwx+   4 ir967 root   4096 Dec  9 15:37  dataset
-rwxrwxrwx+   1 ir967 root  64900 Dec  8 13:24  debug_one_hot.txt
-rwxrwxrwx+   1 ir967 root   1262 Dec  8 13:24  download_dataset.py
-rwxrwxrwx+   1 ir967 root   1415 Dec  8 13:24  download_models.py
drwxrwxrwx+   2 ir967 root   4096 Dec  8 13:27  efficiency
-rwxrwxrwx+   1 ir967 root    710 Dec  8 13:24  exper.py
-rwxrwxrwx+   1 ir967 root   1352 Dec  8 13:24  exper.sbatch
drwxrwxrwx+   3 ir967 root   4096 Dec  8 13:28  gamma_checkpoint
-rwxrwxrwx+   1 ir967 root   2241 Dec  8 13:28  gamma_experiment.py
-rwxrwxrwx+   1 ir967 root   2689 Dec  8 13:28  gamma_piecewise.txt
drwxrwxrwx+  88 ir967 root   4096 Dec  8 13:28  gt_Sony_dead_simple
drwxrwxrwx+  10 ir967 root   4096 Dec  8 13:28  half_of_gt_Sony
-rwxrwxrwx+   1 ir967 root    487 Dec  8 13:28  HPC-hw4-1a.sh
-rwxrwxrwx+   1 ir967 root   6092 Dec  8 13:28  htop.txt
drwxrwxrwx+   2 ir967 root   4096 Dec  8 13:28  images
-rwxrwxrwx+   1 ir967 root   1108 Dec  8 13:28  LICENSE.md
drwxrwxrwx+   2 ir967 root   4096 Dec  8 13:28  logs
-rwxrwxrwx+   1 ir967 root  21531 Dec  8 13:28  lspci.out
drwxrwxr-x    6 ir967 ir967  4096 Dec 11 01:00  _old_code
-rwxrwxrwx+   1 ir967 root   5381 Dec  8 13:25  README.md
drwxrwxrwx+   4 ir967 root   4096 Dec  8 13:26  result_Fuji
drwxrwxrwx+  65 ir967 root   4096 Dec  8 13:26  result_Sony
drwxrwxrwx+   2 ir967 root   4096 Dec  8 13:26 'result_Sony__[1-5]_images'
drwxrwxrwx+   6 ir967 root   4096 Dec  8 13:26  result_Sony_20_images
drwxrwxrwx+   3 ir967 root   4096 Dec  8 13:26  result_Sony_checkDec6
drwxrwxrwx+   3 ir967 root   4096 Dec  8 13:26  result_Sony_with_gamma_net
drwxrwxrwx+   3 ir967 root   4096 Dec  8 13:26  result_Sony_with_gamma_net_3output
drwxrwxrwx+  85 ir967 root   4096 Dec  8 13:30  run1_5_images_result_Sony
-rwxrwxrwx+   1 ir967 root   1428 Dec  8 13:24  scontrol_8hours.txt
drwxrwxrwx+   2 ir967 root   8192 Dec 11 00:58  _slurm_out
-rwxrwxrwx+   1 ir967 root    652 Dec  8 13:24  sstat_8hours.txt
-rwxrwxrwx+   1 ir967 root   6703 Dec  8 13:24  test_for_gamma_Sony_3output.py
-rwxrwxrwx+   1 ir967 root   1377 Dec  8 13:24  test_for_gamma_Sony_3output.sbatch
-rwxrwxrwx+   1 ir967 root   5380 Dec  8 13:24  test_for_gamma_Sony.py
-rwxrwxrwx+   1 ir967 root   1371 Dec  8 13:24  test_for_gamma_Sony.sbatch
-rwxrwxrwx+   1 ir967 root   7167 Dec  8 13:24  test_Fuji.py
-rwxrwxrwx+   1 ir967 root   1353 Dec  8 13:24  test_Fuji.sbatch
-rwxrwxrwx+   1 ir967 root   6381 Dec  8 13:24  test_Sony.py
-rwxrwxrwx+   1 ir967 root   1360 Dec  8 13:24  test_Sony.sbatch
-rwxrwxrwx+   1 ir967 root   7574 Dec  8 13:24  test_Sony_with_gamma.py
-rwxrwxrwx+   1 ir967 root   1372 Dec  8 13:24  test_Sony_with_gamma.sbatch
-rwxrwxrwx+   1 ir967 root   7574 Dec  8 13:24  test_Sony_with_gamma_unflattened.py
-rwxrwxrwx+   1 ir967 root  15798 Dec  8 13:24  train_for_gamma_Sony_3output_more_simpler.py
-rwxrwxrwx+   1 ir967 root   1388 Dec  8 13:24  train_for_gamma_Sony_3output_more_simpler.sbatch
-rwxrwxrwx+   1 ir967 root  14738 Dec  8 13:24  train_for_gamma_Sony_3output_more_simpler_wider.py
-rwxrwxrwx+   1 ir967 root  13292 Dec  8 13:24  train_for_gamma_Sony_3output.py
-rwxrwxrwx+   1 ir967 root   1375 Dec  8 13:24  train_for_gamma_Sony_3output.sbatch
-rwxrwxrwx+   1 ir967 root  12739 Dec  8 13:24  train_for_gamma_Sony_3output_simpler.py
-rwxrwxrwx+   1 ir967 root   1383 Dec  8 13:24  train_for_gamma_Sony_3output_simpler.sbatch
-rwxrwxrwx+   1 ir967 root  15430 Dec  8 13:24  train_for_gamma_Sony_dead_simple.py
-rwxrwxrwx+   1 ir967 root  13271 Dec  8 13:24  train_for_gamma_Sony.py
-rwxrwxrwx+   1 ir967 root   1367 Dec  8 13:24  train_for_gamma_Sony.sbatch
-rwxrwxrwx+   1 ir967 root  12185 Dec  8 13:24  train_for_gamma_Sony_unflattened.py
-rwxrwxrwx+   1 ir967 root   8668 Dec  8 13:24  train_Fuji.py
-rwxrwxrwx+   1 ir967 root    519 Dec  8 13:24  train_Fuji.sbatch
-rwxrwxrwx+   1 ir967 root   8219 Dec  8 13:24  train_Sony.py
-rwxrwxrwx+   1 ir967 root    511 Dec  8 13:24  train_Sony.sbatch
[ir967@log-3 Learning-to-See-in-the-Dark]$ mv *_unfl* _old_code/
[ir967@log-3 Learning-to-See-in-the-Dark]$ mv *pler.* _old_code/
[ir967@log-3 Learning-to-See-in-the-Dark]$ ls
 all_of_gt_Sony                                                      result_Fuji
 all_of_gt_Sony_GPU_efficient                                        result_Sony
 all_of_gt_Sony_GPU_efficient_flattened                             'result_Sony__[1-5]_images'
 all_of_gt_Sony_GPU_efficient_flattened_3output                      result_Sony_20_images
 all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler         result_Sony_checkDec6
 all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler_print   result_Sony_with_gamma_net
 all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler_wider   result_Sony_with_gamma_net_3output
 all_of_gt_Sony_GPU_efficient_flattened_3output_print_test           run1_5_images_result_Sony
 all_of_gt_Sony_GPU_efficient_flattened_3output_simpler              scontrol_8hours.txt
 checkpoint                                                          _slurm_out
 check.sh                                                            sstat_8hours.txt
 cluster_status.txt                                                  test_for_gamma_Sony_3output.py
 dataset                                                             test_for_gamma_Sony_3output.sbatch
 debug_one_hot.txt                                                   test_for_gamma_Sony.py
 download_dataset.py                                                 test_for_gamma_Sony.sbatch
 download_models.py                                                  test_Fuji.py
 efficiency                                                          test_Fuji.sbatch
 exper.py                                                            test_Sony.py
 exper.sbatch                                                        test_Sony.sbatch
 gamma_checkpoint                                                    test_Sony_with_gamma.py
 gamma_experiment.py                                                 test_Sony_with_gamma.sbatch
 gamma_piecewise.txt                                                 train_for_gamma_Sony_3output_more_simpler_wider.py
 gt_Sony_dead_simple                                                 train_for_gamma_Sony_3output.py
 half_of_gt_Sony                                                     train_for_gamma_Sony_3output.sbatch
 HPC-hw4-1a.sh                                                       train_for_gamma_Sony_dead_simple.py
 htop.txt                                                            train_for_gamma_Sony.py
 images                                                              train_for_gamma_Sony.sbatch
 LICENSE.md                                                          train_Fuji.py
 logs                                                                train_Fuji.sbatch
 lspci.out                                                           train_Sony.py
 _old_code                                                           train_Sony.sbatch
 README.md
[ir967@log-3 Learning-to-See-in-the-Dark]$ Connection to localhost closed by remote host.
Connection to localhost closed.
(base) Ilyeechs-MacBook-Pro:~ ilyeech$ ssh -Y greene
 _   ___   ___   _   _   _ ____   ____ 
| \ | \ \ / / | | | | | | |  _ \ / ___|
|  \| |\ V /| | | | | |_| | |_) | |    
| |\  | | | | |_| | |  _  |  __/| |___ 
|_| \_| |_|  \___/  |_| |_|_|    \____|
 

  ____                          
 / ___|_ __ ___  ___ _ __   ___ 
| |  _| '__/ _ \/ _ \ '_ \ / _ \
| |_| | | |  __/  __/ | | |  __/
 \____|_|  \___|\___|_| |_|\___|

ir967@localhost's password: 
Last login: Fri Dec 11 00:42:58 2020 from 216.165.66.211
[ir967@log-3 ~]$ cd $SCRATCH/SID
[ir967@log-3 SID]$ cd Learning-to-See-in-the-Dark/
[ir967@log-3 Learning-to-See-in-the-Dark]$ ls
 all_of_gt_Sony                                                      result_Fuji
 all_of_gt_Sony_GPU_efficient                                        result_Sony
 all_of_gt_Sony_GPU_efficient_flattened                             'result_Sony__[1-5]_images'
 all_of_gt_Sony_GPU_efficient_flattened_3output                      result_Sony_20_images
 all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler         result_Sony_checkDec6
 all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler_print   result_Sony_with_gamma_net
 all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler_wider   result_Sony_with_gamma_net_3output
 all_of_gt_Sony_GPU_efficient_flattened_3output_print_test           run1_5_images_result_Sony
 all_of_gt_Sony_GPU_efficient_flattened_3output_simpler              scontrol_8hours.txt
 checkpoint                                                          _slurm_out
 check.sh                                                            sstat_8hours.txt
 cluster_status.txt                                                  test_for_gamma_Sony_3output.py
 dataset                                                             test_for_gamma_Sony_3output.sbatch
 debug_one_hot.txt                                                   test_for_gamma_Sony.py
 download_dataset.py                                                 test_for_gamma_Sony.sbatch
 download_models.py                                                  test_Fuji.py
 efficiency                                                          test_Fuji.sbatch
 exper.py                                                            test_Sony.py
 exper.sbatch                                                        test_Sony.sbatch
 gamma_checkpoint                                                    test_Sony_with_gamma.py
 gamma_experiment.py                                                 test_Sony_with_gamma.sbatch
 gamma_piecewise.txt                                                 train_for_gamma_Sony_3output_more_simpler_wider.py
 gt_Sony_dead_simple                                                 train_for_gamma_Sony_3output.py
 half_of_gt_Sony                                                     train_for_gamma_Sony_3output.sbatch
 HPC-hw4-1a.sh                                                       train_for_gamma_Sony_dead_simple.py
 htop.txt                                                            train_for_gamma_Sony.py
 images                                                              train_for_gamma_Sony.sbatch
 LICENSE.md                                                          train_Fuji.py
 logs                                                                train_Fuji.sbatch
 lspci.out                                                           train_Sony.py
 _old_code                                                           train_Sony.sbatch
 README.md
[ir967@log-3 Learning-to-See-in-the-Dark]$ mls images/
-bash: mls: command not found
[ir967@log-3 Learning-to-See-in-the-Dark]$ ls images/
fig1.png
[ir967@log-3 Learning-to-See-in-the-Dark]$ conda create -n sid2 python=2.7 scipy=1.1.0 numpy=1.8.2
-bash: conda: command not found
[ir967@log-3 Learning-to-See-in-the-Dark]$ wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
--2020-12-11 02:57:52--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8303, ...
Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 94235922 (90M) [application/x-sh]
Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’

Miniconda3-latest-Linux-x86_64.sh    100%[====================================================================>]  89.87M   204MB/s    in 0.4s    

2020-12-11 02:57:52 (204 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [94235922/94235922]

[ir967@log-3 Learning-to-See-in-the-Dark]$ ls
 all_of_gt_Sony                                                      README.md
 all_of_gt_Sony_GPU_efficient                                        result_Fuji
 all_of_gt_Sony_GPU_efficient_flattened                              result_Sony
 all_of_gt_Sony_GPU_efficient_flattened_3output                     'result_Sony__[1-5]_images'
 all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler         result_Sony_20_images
 all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler_print   result_Sony_checkDec6
 all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler_wider   result_Sony_with_gamma_net
 all_of_gt_Sony_GPU_efficient_flattened_3output_print_test           result_Sony_with_gamma_net_3output
 all_of_gt_Sony_GPU_efficient_flattened_3output_simpler              run1_5_images_result_Sony
 checkpoint                                                          scontrol_8hours.txt
 check.sh                                                            _slurm_out
 cluster_status.txt                                                  sstat_8hours.txt
 dataset                                                             test_for_gamma_Sony_3output.py
 debug_one_hot.txt                                                   test_for_gamma_Sony_3output.sbatch
 download_dataset.py                                                 test_for_gamma_Sony.py
 download_models.py                                                  test_for_gamma_Sony.sbatch
 efficiency                                                          test_Fuji.py
 exper.py                                                            test_Fuji.sbatch
 exper.sbatch                                                        test_Sony.py
 gamma_checkpoint                                                    test_Sony.sbatch
 gamma_experiment.py                                                 test_Sony_with_gamma.py
 gamma_piecewise.txt                                                 test_Sony_with_gamma.sbatch
 gt_Sony_dead_simple                                                 train_for_gamma_Sony_3output_more_simpler_wider.py
 half_of_gt_Sony                                                     train_for_gamma_Sony_3output.py
 HPC-hw4-1a.sh                                                       train_for_gamma_Sony_3output.sbatch
 htop.txt                                                            train_for_gamma_Sony_dead_simple.py
 images                                                              train_for_gamma_Sony.py
 LICENSE.md                                                          train_for_gamma_Sony.sbatch
 logs                                                                train_Fuji.py
 lspci.out                                                           train_Fuji.sbatch
 Miniconda3-latest-Linux-x86_64.sh                                   train_Sony.py
 _old_code                                                           train_Sony.sbatch
[ir967@log-3 Learning-to-See-in-the-Dark]$ mv Miniconda3-latest-Linux-x86_64.sh ../../
miniconda3/ SID/        temp/       
[ir967@log-3 Learning-to-See-in-the-Dark]$ mv Miniconda3-latest-Linux-x86_64.sh ../../miniconda3/
[ir967@log-3 Learning-to-See-in-the-Dark]$ ls ../../miniconda3/
Miniconda3-latest-Linux-x86_64.sh  pkgs  x86_64-conda_cos6-linux-gnu
[ir967@log-3 Learning-to-See-in-the-Dark]$ cd ../../
[ir967@log-3 ir967]$ pwd
/scratch/ir967
[ir967@log-3 ir967]$ ls
miniconda3  SID  temp
[ir967@log-3 ir967]$ sh minconda3/Miniconda3-latest-Linux-x86_64.sh
sh: minconda3/Miniconda3-latest-Linux-x86_64.sh: No such file or directory
[ir967@log-3 ir967]$ sh miniconda3/Miniconda3-latest-Linux-x86_64.sh

Welcome to Miniconda3 py38_4.9.2

In order to continue the installation process, please review the license
agreement.
Please, press ENTER to continue
>>> 
===================================
End User License Agreement - Anaconda Individual Edition
===================================

Copyright 2015-2020, Anaconda, Inc.

All rights reserved under the 3-clause BSD License:

This End User License Agreement (the "Agreement") is a legal agreement between you and Anaconda, Inc. ("Anaconda") and governs your use of Anacond
a Individual Edition (which was formerly known as Anaconda Distribution).

Subject to the terms of this Agreement, Anaconda hereby grants you a non-exclusive, non-transferable license to:

  * Install and use the Anaconda Individual Edition (which was formerly known as Anaconda Distribution),
  * Modify and create derivative works of sample source code delivered in Anaconda Individual Edition from Anaconda's repository; and
  * Redistribute code files in source (if provided to you by Anaconda as source) and binary forms, with or without modification subject to the req
uirements set forth below.

Anaconda may, at its option, make available patches, workarounds or other updates to Anaconda Individual Edition. Unless the updates are provided 
with their separate governing terms, they are deemed part of Anaconda Individual Edition licensed to you as provided in this Agreement.  This Agre
ement does not entitle you to any support for Anaconda Individual Edition.

Anaconda reserves all rights not expressly granted to you in this Agreement.

Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:

  * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
  * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the document
ation and/or other materials provided with the distribution.
  * Neither the name of Anaconda nor the names of its contributors may be used to endorse or promote products derived from this software without s
pecific prior written permission.

You acknowledge that, as between you and Anaconda, Anaconda owns all right, title, and interest, including all intellectual property rights, in an
d to Anaconda Individual Edition and, with respect to third-party products distributed with or through Anaconda Individual Edition, the applicable
 third-party licensors own all right, title and interest, including all intellectual property rights, in and to such products.  If you send or tra
nsmit any communications or materials to Anaconda suggesting or recommending changes to the software or documentation, including without limitatio
n, new features or functionality relating thereto, or any comments, questions, suggestions or the like ("Feedback"), Anaconda is free to use such 
Feedback. You hereby assign to Anaconda all right, title, and interest in, and Anaconda is free to use, without any attribution or compensation to
 any party, any ideas, know-how, concepts, techniques or other intellectual property rights contained in the Feedback, for any purpose whatsoever,
 although Anaconda is not required to use any Feedback.

THIS SOFTWARE IS PROVIDED BY ANACONDA AND ITS CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLI
ED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL ANACONDA BE LIABLE FOR ANY DIRECT, INDIREC
T, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF U
SE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INC
LUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

TO THE MAXIMUM EXTENT PERMITTED BY LAW, ANACONDA AND ITS AFFILIATES SHALL NOT BE LIABLE FOR ANY SPECIAL, INCIDENTAL, PUNITIVE OR CONSEQUENTIAL DAM
AGES, OR ANY LOST PROFITS, LOSS OF USE, LOSS OF DATA OR LOSS OF GOODWILL, OR THE COSTS OF PROCURING SUBSTITUTE PRODUCTS, ARISING OUT OF OR IN CONN
ECTION WITH THIS AGREEMENT OR THE USE OR PERFORMANCE OF ANACONDA INDIVIDUAL EDITION, WHETHER SUCH LIABILITY ARISES FROM ANY CLAIM BASED UPON BREAC
H OF CONTRACT, BREACH OF WARRANTY, TORT (INCLUDING NEGLIGENCE), PRODUCT LIABILITY OR ANY OTHER CAUSE OF ACTION OR THEORY OF LIABILITY. IN NO EVENT
 WILL THE TOTAL CUMULATIVE LIABILITY OF ANACONDA AND ITS AFFILIATES UNDER OR ARISING OUT OF THIS AGREEMENT EXCEED US0.00.

If you want to terminate this Agreement, you may do so by discontinuing use of Anaconda Individual Edition.  Anaconda may, at any time, terminate 
this Agreement and the license granted hereunder if you fail to comply with any term of this Agreement.   Upon any termination of this Agreement, 
you agree to promptly discontinue use of the Anaconda Individual Edition and destroy all copies in your possession or control. Upon any terminatio
n of this Agreement all provisions survive except for the licenses granted to you.

This Agreement is governed by and construed in accordance with the internal laws of the State of Texas without giving effect to any choice or conf
lict of law provision or rule that would require or permit the application of the laws of any jurisdiction other than those of the State of Texas.
 Any legal suit, action, or proceeding arising out of or related to this Agreement or the licenses granted hereunder by you must be instituted exc
lusively in the federal courts of the United States or the courts of the State of Texas in each case located in Travis County, Texas, and you irre
vocably submit to the jurisdiction of such courts in any such suit, action, or proceeding.


Notice of Third Party Software Licenses
=======================================

Anaconda Individual Edition provides access to a repository which contains software packages or tools licensed on an open source basis from third 
parties and binary packages of these third party tools. These third party software packages or tools are provided on an "as is" basis and are subj
ect to their respective license agreements as well as this Agreement and the Terms of Service for the Repository located at https://know.anaconda.
com/TOS.html; provided, however, no restriction contained in the Terms of Service shall be construed so as to limit your ability to download the p
ackages contained in Anaconda Individual Edition provided you comply with the license for each such package.  These licenses may be accessed from 
within the Anaconda Individual Edition software or at https://docs.anaconda.com/anaconda/pkg-docs. Information regarding which license is applicab
le is available from within many of the third party software packages and tools and at https://repo.anaconda.com/pkgs/main/ and https://repo.anaco
nda.com/pkgs/r/. Anaconda reserves the right, in its sole discretion, to change which third party tools are included in the repository accessible 
through Anaconda Individual Edition.

Intel Math Kernel Library
-------------------------

Anaconda Individual Edition provides access to re-distributable, run-time, shared-library files from the Intel Math Kernel Library ("MKL binaries"
).

Copyright 2018 Intel Corporation.  License available at https://software.intel.com/en-us/license/intel-simplified-software-license (the "MKL Licen
se").

You may use and redistribute the MKL binaries, without modification, provided the following conditions are met:

  * Redistributions must reproduce the above copyright notice and the following terms of use in the MKL binaries and in the documentation and/or o
ther materials provided with the distribution.
  * Neither the name of Intel nor the names of its suppliers may be used to endorse or promote products derived from the MKL binaries without spec
ific prior written permission.
  * No reverse engineering, decompilation, or disassembly of the MKL binaries is permitted.

You are specifically authorized to use and redistribute the MKL binaries with your installation of Anaconda Individual Edition subject to the term
s set forth in the MKL License. You are also authorized to redistribute the MKL binaries with Anaconda Individual Edition or in the Anaconda packa
ge that contains the MKL binaries. If needed, instructions for removing the MKL binaries after installation of Anaconda Individual Edition are ava
ilable at https://docs.anaconda.com.

cuDNN Software
--------------

Anaconda Individual Edition also provides access to cuDNN software binaries ("cuDNN binaries") from NVIDIA Corporation. You are specifically autho
rized to use the cuDNN binaries with your installation of Anaconda Individual Edition subject to your compliance with the license agreement locate
d at https://docs.nvidia.com/deeplearning/sdk/cudnn-sla/index.html. You are also authorized to redistribute the cuDNN binaries with an Anaconda In
dividual Edition package that contains the cuDNN binaries. You can add or remove the cuDNN binaries utilizing the install and uninstall features i
n Anaconda Individual Edition.

cuDNN binaries contain source code provided by NVIDIA Corporation.


Export; Cryptography Notice
===========================

You must comply with all domestic and international export laws and regulations that apply to the software, which include restrictions on destinat
ions, end users, and end use.  Anaconda Individual Edition includes cryptographic software. The country in which you currently reside may have res
trictions on the import, possession, use, and/or re-export to another country, of encryption software. BEFORE using any encryption software, pleas
e check your country's laws, regulations and policies concerning the import, possession, or use, and re-export of encryption software, to see if t
his is permitted. See the Wassenaar Arrangement http://www.wassenaar.org/ for more information.

Anaconda has self-classified this software as Export Commodity Control Number (ECCN) 5D992.c, which includes mass market information security soft
ware using or performing cryptographic functions with asymmetric algorithms. No license is required for export of this software to non-embargoed c
ountries.

The Intel Math Kernel Library contained in Anaconda Individual Edition is classified by Intel as ECCN 5D992.c with no license required for export 
to non-embargoed countries.

The following packages are included in the repository accessible through Anaconda Individual Edition that relate to cryptography:

openssl
    The OpenSSL Project is a collaborative effort to develop a robust, commercial-grade, full-featured, and Open Source toolkit implementing the T
ransport Layer Security (TLS) and Secure Sockets Layer (SSL) protocols as well as a full-strength general purpose cryptography library.

pycrypto
    A collection of both secure hash functions (such as SHA256 and RIPEMD160), and various encryption algorithms (AES, DES, RSA, ElGamal, etc.).

pyopenssl
    A thin Python wrapper around (a subset of) the OpenSSL library.

kerberos (krb5, non-Windows platforms)
    A network authentication protocol designed to provide strong authentication for client/server applications by using secret-key cryptography.

cryptography
    A Python library which exposes cryptographic recipes and primitives.

pycryptodome
    A fork of PyCrypto. It is a self-contained Python package of low-level cryptographic primitives.

pycryptodomex
    A stand-alone version of pycryptodome.

libsodium
    A software library for encryption, decryption, signatures, password hashing and more.

pynacl
    A Python binding to the Networking and Cryptography library, a crypto library with the stated goal of improving usability, security and speed.


Last updated September 28, 2020


Do you accept the license terms? [yes|no]
[no] >>> yes

Miniconda3 will now be installed into this location:
/home/ir967/miniconda3

  - Press ENTER to confirm the location
  - Press CTRL-C to abort the installation
  - Or specify a different location below

[/home/ir967/miniconda3] >>> /home/ir967/install/miniconda3/                
PREFIX=/home/ir967/install/miniconda3
Unpacking payload ...
Collecting package metadata (current_repodata.json): done                                                                                         
Solving environment: done

## Package Plan ##

  environment location: /home/ir967/install/miniconda3

  added / updated specs:
    - _libgcc_mutex==0.1=main
    - brotlipy==0.7.0=py38h27cfd23_1003
    - ca-certificates==2020.10.14=0
    - certifi==2020.6.20=pyhd3eb1b0_3
    - cffi==1.14.3=py38h261ae71_2
    - chardet==3.0.4=py38h06a4308_1003
    - conda-package-handling==1.7.2=py38h03888b9_0
    - conda==4.9.2=py38h06a4308_0
    - cryptography==3.2.1=py38h3c74f83_1
    - idna==2.10=py_0
    - ld_impl_linux-64==2.33.1=h53a641e_7
    - libedit==3.1.20191231=h14c3975_1
    - libffi==3.3=he6710b0_2
    - libgcc-ng==9.1.0=hdf63c60_0
    - libstdcxx-ng==9.1.0=hdf63c60_0
    - ncurses==6.2=he6710b0_1
    - openssl==1.1.1h=h7b6447c_0
    - pip==20.2.4=py38h06a4308_0
    - pycosat==0.6.3=py38h7b6447c_1
    - pycparser==2.20=py_2
    - pyopenssl==19.1.0=pyhd3eb1b0_1
    - pysocks==1.7.1=py38h06a4308_0
    - python==3.8.5=h7579374_1
    - readline==8.0=h7b6447c_0
    - requests==2.24.0=py_0
    - ruamel_yaml==0.15.87=py38h7b6447c_1
    - setuptools==50.3.1=py38h06a4308_1
    - six==1.15.0=py38h06a4308_0
    - sqlite==3.33.0=h62c20be_0
    - tk==8.6.10=hbc83047_0
    - tqdm==4.51.0=pyhd3eb1b0_0
    - urllib3==1.25.11=py_0
    - wheel==0.35.1=pyhd3eb1b0_0
    - xz==5.2.5=h7b6447c_0
    - yaml==0.2.5=h7b6447c_0
    - zlib==1.2.11=h7b6447c_3


The following NEW packages will be INSTALLED:

  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main
  brotlipy           pkgs/main/linux-64::brotlipy-0.7.0-py38h27cfd23_1003
  ca-certificates    pkgs/main/linux-64::ca-certificates-2020.10.14-0
  certifi            pkgs/main/noarch::certifi-2020.6.20-pyhd3eb1b0_3
  cffi               pkgs/main/linux-64::cffi-1.14.3-py38h261ae71_2
  chardet            pkgs/main/linux-64::chardet-3.0.4-py38h06a4308_1003
  conda              pkgs/main/linux-64::conda-4.9.2-py38h06a4308_0
  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.7.2-py38h03888b9_0
  cryptography       pkgs/main/linux-64::cryptography-3.2.1-py38h3c74f83_1
  idna               pkgs/main/noarch::idna-2.10-py_0
  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.33.1-h53a641e_7
  libedit            pkgs/main/linux-64::libedit-3.1.20191231-h14c3975_1
  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2
  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0
  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0
  ncurses            pkgs/main/linux-64::ncurses-6.2-he6710b0_1
  openssl            pkgs/main/linux-64::openssl-1.1.1h-h7b6447c_0
  pip                pkgs/main/linux-64::pip-20.2.4-py38h06a4308_0
  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py38h7b6447c_1
  pycparser          pkgs/main/noarch::pycparser-2.20-py_2
  pyopenssl          pkgs/main/noarch::pyopenssl-19.1.0-pyhd3eb1b0_1
  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py38h06a4308_0
  python             pkgs/main/linux-64::python-3.8.5-h7579374_1
  readline           pkgs/main/linux-64::readline-8.0-h7b6447c_0
  requests           pkgs/main/noarch::requests-2.24.0-py_0
  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.87-py38h7b6447c_1
  setuptools         pkgs/main/linux-64::setuptools-50.3.1-py38h06a4308_1
  six                pkgs/main/linux-64::six-1.15.0-py38h06a4308_0
  sqlite             pkgs/main/linux-64::sqlite-3.33.0-h62c20be_0
  tk                 pkgs/main/linux-64::tk-8.6.10-hbc83047_0
  tqdm               pkgs/main/noarch::tqdm-4.51.0-pyhd3eb1b0_0
  urllib3            pkgs/main/noarch::urllib3-1.25.11-py_0
  wheel              pkgs/main/noarch::wheel-0.35.1-pyhd3eb1b0_0
  xz                 pkgs/main/linux-64::xz-5.2.5-h7b6447c_0
  yaml               pkgs/main/linux-64::yaml-0.2.5-h7b6447c_0
  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3


Preparing transaction: done
Executing transaction: done
installation finished.
Do you wish the installer to initialize Miniconda3
by running conda init? [yes|no]
[no] >>> yes
no change     /home/ir967/install/miniconda3/condabin/conda
no change     /home/ir967/install/miniconda3/bin/conda
no change     /home/ir967/install/miniconda3/bin/conda-env
no change     /home/ir967/install/miniconda3/bin/activate
no change     /home/ir967/install/miniconda3/bin/deactivate
no change     /home/ir967/install/miniconda3/etc/profile.d/conda.sh
no change     /home/ir967/install/miniconda3/etc/fish/conf.d/conda.fish
no change     /home/ir967/install/miniconda3/shell/condabin/Conda.psm1
no change     /home/ir967/install/miniconda3/shell/condabin/conda-hook.ps1
no change     /home/ir967/install/miniconda3/lib/python3.8/site-packages/xontrib/conda.xsh
no change     /home/ir967/install/miniconda3/etc/profile.d/conda.csh
modified      /home/ir967/.bashrc

==> For changes to take effect, close and re-open your current shell. <==

If you'd prefer that conda's base environment not be activated on startup, 
   set the auto_activate_base parameter to false: 

conda config --set auto_activate_base false

Thank you for installing Miniconda3!
[ir967@log-3 ir967]$ source ~/.bashrc
(base) [ir967@log-3 ir967]$ conda create -n sid2 python=2.7 scipy=1.1.0 numpy=1.8.2
Collecting package metadata (current_repodata.json): done
Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.
Collecting package metadata (repodata.json): done
Solving environment: failed

PackagesNotFoundError: The following packages are not available from current channels:

  - numpy=1.8.2

Current channels:

  - https://repo.anaconda.com/pkgs/main/linux-64
  - https://repo.anaconda.com/pkgs/main/noarch
  - https://repo.anaconda.com/pkgs/r/linux-64
  - https://repo.anaconda.com/pkgs/r/noarch

To search for alternate channels that may provide the conda package you're
looking for, navigate to

    https://anaconda.org

and use the search bar at the top of the page.


(base) [ir967@log-3 ir967]$ conda create -n sid2 python=2.7 scipy=1.1.0 numpy=1.8.1
Collecting package metadata (current_repodata.json): done
Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.
Collecting package metadata (repodata.json): done
Solving environment: failed

PackagesNotFoundError: The following packages are not available from current channels:

  - numpy=1.8.1

Current channels:

  - https://repo.anaconda.com/pkgs/main/linux-64
  - https://repo.anaconda.com/pkgs/main/noarch
  - https://repo.anaconda.com/pkgs/r/linux-64
  - https://repo.anaconda.com/pkgs/r/noarch

To search for alternate channels that may provide the conda package you're
looking for, navigate to

    https://anaconda.org

and use the search bar at the top of the page.


(base) [ir967@log-3 ir967]$ srun -t1:30:00 --mem=5460 --gres=gpu:1 --pty /bin/bash
(base) [ir967@gr029 ir967]$ conda create -n sid2 python=2.7.13 cudnn=7.1.2 cudatoolkit=9.0 tensorflow-gpu=1.11.0
Collecting package metadata (current_repodata.json): done
Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.
Collecting package metadata (repodata.json): done
Solving environment: done

## Package Plan ##

  environment location: /home/ir967/install/miniconda3/envs/sid2

  added / updated specs:
    - cudatoolkit=9.0
    - cudnn=7.1.2
    - python=2.7.13
    - tensorflow-gpu=1.11.0


The following packages will be downloaded:

    package                    |            build
    ---------------------------|-----------------
    _tflow_select-2.1.0        |              gpu           2 KB
    absl-py-0.11.0             |     pyhd3eb1b0_1         103 KB
    astor-0.8.0                |           py27_0          46 KB
    backports-1.0              |     pyhd3eb1b0_2         210 KB
    backports.weakref-1.0.post1|             py_1           8 KB
    blas-1.0                   |              mkl           6 KB
    c-ares-1.17.1              |       h27cfd23_0         108 KB
    ca-certificates-2020.12.8  |       h06a4308_0         121 KB
    cudatoolkit-9.0            |       h13b8566_0       237.0 MB
    cudnn-7.1.2                |        cuda9.0_0       243.0 MB
    cupti-9.0.176              |                0         1.4 MB
    enum34-1.1.6               |           py27_1          58 KB
    funcsigs-1.0.2             |           py27_0          22 KB
    futures-3.3.0              |           py27_0          29 KB
    gast-0.4.0                 |             py_0          15 KB
    grpcio-1.14.1              |   py27h9ba97e2_0         940 KB
    h5py-2.9.0                 |   py27h7918eee_0         961 KB
    hdf5-1.10.4                |       hb1b8bf9_0         3.9 MB
    intel-openmp-2020.2        |              254         786 KB
    keras-applications-1.0.8   |             py_1          29 KB
    keras-preprocessing-1.1.0  |             py_1          37 KB
    libedit-3.1                |       heed3624_0         151 KB
    libffi-3.2.1               |    hf484d3e_1007          48 KB
    libgfortran-ng-7.3.0       |       hdf63c60_0        1006 KB
    libprotobuf-3.11.2         |       hd408876_0         2.9 MB
    linecache2-1.0.0           |             py_1          14 KB
    markdown-3.1.1             |           py27_0         117 KB
    mkl-2020.2                 |              256       138.3 MB
    mkl-service-2.3.0          |   py27he904b0f_0         217 KB
    mkl_fft-1.0.15             |   py27ha843d7b_0         146 KB
    mkl_random-1.1.0           |   py27hd6b4f25_0         297 KB
    mock-3.0.5                 |           py27_0          49 KB
    ncurses-6.0                |       h9df7e31_2         781 KB
    numpy-1.16.6               |   py27hbc911f0_0          48 KB
    numpy-base-1.16.6          |   py27hde5b4d6_0         3.5 MB
    openssl-1.0.2u             |       h7b6447c_0         2.2 MB
    pip-19.3.1                 |           py27_0         1.7 MB
    protobuf-3.11.2            |   py27he6710b0_0         638 KB
    python-2.7.13              |      heccc3f1_16         7.6 MB
    readline-7.0               |       ha6073c6_4         848 KB
    scipy-1.2.1                |   py27h7c811a0_0        13.7 MB
    setuptools-44.0.0          |           py27_0         512 KB
    six-1.15.0                 |             py_0          13 KB
    sqlite-3.23.1              |       he433501_0         808 KB
    tensorboard-1.11.0         |   py27hf484d3e_0         3.0 MB
    tensorflow-1.11.0          |gpu_py27h99ab47f_0           4 KB
    tensorflow-base-1.11.0     |gpu_py27h8e0ae2d_0        85.6 MB
    tensorflow-gpu-1.11.0      |       h0d30ee6_0           2 KB
    termcolor-1.1.0            |           py27_1           8 KB
    traceback2-1.4.0           |           py27_0          31 KB
    unittest2-1.1.0            |           py27_0         149 KB
    werkzeug-1.0.1             |             py_0         240 KB
    wheel-0.36.1               |     pyhd3eb1b0_0          32 KB
    ------------------------------------------------------------
                                           Total:       753.1 MB

The following NEW packages will be INSTALLED:

  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main
  _tflow_select      pkgs/main/linux-64::_tflow_select-2.1.0-gpu
  absl-py            pkgs/main/noarch::absl-py-0.11.0-pyhd3eb1b0_1
  astor              pkgs/main/linux-64::astor-0.8.0-py27_0
  backports          pkgs/main/noarch::backports-1.0-pyhd3eb1b0_2
  backports.weakref  pkgs/main/noarch::backports.weakref-1.0.post1-py_1
  blas               pkgs/main/linux-64::blas-1.0-mkl
  c-ares             pkgs/main/linux-64::c-ares-1.17.1-h27cfd23_0
  ca-certificates    pkgs/main/linux-64::ca-certificates-2020.12.8-h06a4308_0
  certifi            pkgs/main/noarch::certifi-2020.6.20-pyhd3eb1b0_3
  cudatoolkit        pkgs/main/linux-64::cudatoolkit-9.0-h13b8566_0
  cudnn              pkgs/main/linux-64::cudnn-7.1.2-cuda9.0_0
  cupti              pkgs/main/linux-64::cupti-9.0.176-0
  enum34             pkgs/main/linux-64::enum34-1.1.6-py27_1
  funcsigs           pkgs/main/linux-64::funcsigs-1.0.2-py27_0
  futures            pkgs/main/linux-64::futures-3.3.0-py27_0
  gast               pkgs/main/noarch::gast-0.4.0-py_0
  grpcio             pkgs/main/linux-64::grpcio-1.14.1-py27h9ba97e2_0
  h5py               pkgs/main/linux-64::h5py-2.9.0-py27h7918eee_0
  hdf5               pkgs/main/linux-64::hdf5-1.10.4-hb1b8bf9_0
  intel-openmp       pkgs/main/linux-64::intel-openmp-2020.2-254
  keras-applications pkgs/main/noarch::keras-applications-1.0.8-py_1
  keras-preprocessi~ pkgs/main/noarch::keras-preprocessing-1.1.0-py_1
  libedit            pkgs/main/linux-64::libedit-3.1-heed3624_0
  libffi             pkgs/main/linux-64::libffi-3.2.1-hf484d3e_1007
  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0
  libgfortran-ng     pkgs/main/linux-64::libgfortran-ng-7.3.0-hdf63c60_0
  libprotobuf        pkgs/main/linux-64::libprotobuf-3.11.2-hd408876_0
  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0
  linecache2         pkgs/main/noarch::linecache2-1.0.0-py_1
  markdown           pkgs/main/linux-64::markdown-3.1.1-py27_0
  mkl                pkgs/main/linux-64::mkl-2020.2-256
  mkl-service        pkgs/main/linux-64::mkl-service-2.3.0-py27he904b0f_0
  mkl_fft            pkgs/main/linux-64::mkl_fft-1.0.15-py27ha843d7b_0
  mkl_random         pkgs/main/linux-64::mkl_random-1.1.0-py27hd6b4f25_0
  mock               pkgs/main/linux-64::mock-3.0.5-py27_0
  ncurses            pkgs/main/linux-64::ncurses-6.0-h9df7e31_2
  numpy              pkgs/main/linux-64::numpy-1.16.6-py27hbc911f0_0
  numpy-base         pkgs/main/linux-64::numpy-base-1.16.6-py27hde5b4d6_0
  openssl            pkgs/main/linux-64::openssl-1.0.2u-h7b6447c_0
  pip                pkgs/main/linux-64::pip-19.3.1-py27_0
  protobuf           pkgs/main/linux-64::protobuf-3.11.2-py27he6710b0_0
  python             pkgs/main/linux-64::python-2.7.13-heccc3f1_16
  readline           pkgs/main/linux-64::readline-7.0-ha6073c6_4
  scipy              pkgs/main/linux-64::scipy-1.2.1-py27h7c811a0_0
  setuptools         pkgs/main/linux-64::setuptools-44.0.0-py27_0
  six                pkgs/main/noarch::six-1.15.0-py_0
  sqlite             pkgs/main/linux-64::sqlite-3.23.1-he433501_0
  tensorboard        pkgs/main/linux-64::tensorboard-1.11.0-py27hf484d3e_0
  tensorflow         pkgs/main/linux-64::tensorflow-1.11.0-gpu_py27h99ab47f_0
  tensorflow-base    pkgs/main/linux-64::tensorflow-base-1.11.0-gpu_py27h8e0ae2d_0
  tensorflow-gpu     pkgs/main/linux-64::tensorflow-gpu-1.11.0-h0d30ee6_0
  termcolor          pkgs/main/linux-64::termcolor-1.1.0-py27_1
  tk                 pkgs/main/linux-64::tk-8.6.10-hbc83047_0
  traceback2         pkgs/main/linux-64::traceback2-1.4.0-py27_0
  unittest2          pkgs/main/linux-64::unittest2-1.1.0-py27_0
  werkzeug           pkgs/main/noarch::werkzeug-1.0.1-py_0
  wheel              pkgs/main/noarch::wheel-0.36.1-pyhd3eb1b0_0
  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3


Proceed ([y]/n)? y


Downloading and Extracting Packages
ncurses-6.0          | 781 KB    | ####################################################################################################### | 100% 
keras-preprocessing- | 37 KB     | ####################################################################################################### | 100% 
tensorflow-1.11.0    | 4 KB      | ####################################################################################################### | 100% 
six-1.15.0           | 13 KB     | ####################################################################################################### | 100% 
mkl_random-1.1.0     | 297 KB    | ####################################################################################################### | 100% 
tensorflow-base-1.11 | 85.6 MB   | ####################################################################################################### | 100% 
absl-py-0.11.0       | 103 KB    | ####################################################################################################### | 100% 
intel-openmp-2020.2  | 786 KB    | ####################################################################################################### | 100% 
tensorboard-1.11.0   | 3.0 MB    | ####################################################################################################### | 100% 
blas-1.0             | 6 KB      | ####################################################################################################### | 100% 
python-2.7.13        | 7.6 MB    | ####################################################################################################### | 100% 
funcsigs-1.0.2       | 22 KB     | ####################################################################################################### | 100% 
astor-0.8.0          | 46 KB     | ####################################################################################################### | 100% 
openssl-1.0.2u       | 2.2 MB    | ####################################################################################################### | 100% 
pip-19.3.1           | 1.7 MB    | ####################################################################################################### | 100% 
unittest2-1.1.0      | 149 KB    | ####################################################################################################### | 100% 
c-ares-1.17.1        | 108 KB    | ####################################################################################################### | 100% 
libgfortran-ng-7.3.0 | 1006 KB   | ####################################################################################################### | 100% 
keras-applications-1 | 29 KB     | ####################################################################################################### | 100% 
markdown-3.1.1       | 117 KB    | ####################################################################################################### | 100% 
mock-3.0.5           | 49 KB     | ####################################################################################################### | 100% 
protobuf-3.11.2      | 638 KB    | ####################################################################################################### | 100% 
traceback2-1.4.0     | 31 KB     | ####################################################################################################### | 100% 
numpy-1.16.6         | 48 KB     | ####################################################################################################### | 100% 
scipy-1.2.1          | 13.7 MB   | ####################################################################################################### | 100% 
readline-7.0         | 848 KB    | ####################################################################################################### | 100% 
wheel-0.36.1         | 32 KB     | ####################################################################################################### | 100% 
backports-1.0        | 210 KB    | ####################################################################################################### | 100% 
libprotobuf-3.11.2   | 2.9 MB    | ####################################################################################################### | 100% 
h5py-2.9.0           | 961 KB    | ####################################################################################################### | 100% 
mkl_fft-1.0.15       | 146 KB    | ####################################################################################################### | 100% 
libedit-3.1          | 151 KB    | ####################################################################################################### | 100% 
mkl-2020.2           | 138.3 MB  | ####################################################################################################### | 100% 
werkzeug-1.0.1       | 240 KB    | ####################################################################################################### | 100% 
_tflow_select-2.1.0  | 2 KB      | ####################################################################################################### | 100% 
termcolor-1.1.0      | 8 KB      | ####################################################################################################### | 100% 
tensorflow-gpu-1.11. | 2 KB      | ####################################################################################################### | 100% 
backports.weakref-1. | 8 KB      | ####################################################################################################### | 100% 
setuptools-44.0.0    | 512 KB    | ####################################################################################################### | 100% 
ca-certificates-2020 | 121 KB    | ####################################################################################################### | 100% 
grpcio-1.14.1        | 940 KB    | ####################################################################################################### | 100% 
hdf5-1.10.4          | 3.9 MB    | ####################################################################################################### | 100% 
mkl-service-2.3.0    | 217 KB    | ####################################################################################################### | 100% 
cudatoolkit-9.0      | 237.0 MB  | ####################################################################################################### | 100% 
gast-0.4.0           | 15 KB     | ####################################################################################################### | 100% 
futures-3.3.0        | 29 KB     | ####################################################################################################### | 100% 
libffi-3.2.1         | 48 KB     | ####################################################################################################### | 100% 
cupti-9.0.176        | 1.4 MB    | ####################################################################################################### | 100% 
enum34-1.1.6         | 58 KB     | ####################################################################################################### | 100% 
numpy-base-1.16.6    | 3.5 MB    | ####################################################################################################### | 100% 
linecache2-1.0.0     | 14 KB     | ####################################################################################################### | 100% 
sqlite-3.23.1        | 808 KB    | ####################################################################################################### | 100% 
cudnn-7.1.2          | 243.0 MB  | ####################################################################################################### | 100% 
Preparing transaction: done
Verifying transaction: done
Executing transaction: done
ERROR conda.core.link:_execute(698): An error occurred while installing package 'defaults::ncurses-6.0-h9df7e31_2'.
Rolling back transaction: done

[Errno 122] Disk quota exceeded: 'c108-w' -> '/home/ir967/install/miniconda3/envs/sid2/share/terminfo/c/concept108-w-8'
()

(base) [ir967@gr029 ir967]$ ls /home/ir967/install/miniconda3/envs
sid2
(base) [ir967@gr029 ir967]$ rm -r /home/ir967/install/miniconda3/envs/sid2
(base) [ir967@gr029 ir967]$ ls /home/ir967/install/miniconda3/envs
(base) [ir967@gr029 ir967]$ rm -r /home/ir967/install/
rm: remove write-protected regular file '/home/ir967/install/miniconda3/pkgs/mkl-2020.2-256/info/licenses/mkl/info/licenses/license.txt'? yes
rm: remove write-protected regular file '/home/ir967/install/miniconda3/pkgs/intel-openmp-2020.2-254/info/licenses/mkl/info/licenses/license.txt'? y
(base) [ir967@gr029 ir967]$ conda deactivate
bash: /home/ir967/install/miniconda3/bin/conda: No such file or directory
(base) [ir967@gr029 ir967]$ exit
exit
srun: error: gr029-ib0: task 0: Exited with exit code 127
srun: Terminating job step 401574.0
(base) [ir967@log-3 ir967]$ conda deactivate
-bash: /home/ir967/install/miniconda3/bin/conda: No such file or directory
(base) [ir967@log-3 ir967]$ exit
logout
Connection to localhost closed.
(base) Ilyeechs-MacBook-Pro:~ ilyeech$ ssh -Y greene
 _   ___   ___   _   _   _ ____   ____ 
| \ | \ \ / / | | | | | | |  _ \ / ___|
|  \| |\ V /| | | | | |_| | |_) | |    
| |\  | | | | |_| | |  _  |  __/| |___ 
|_| \_| |_|  \___/  |_| |_|_|    \____|
 

  ____                          
 / ___|_ __ ___  ___ _ __   ___ 
| |  _| '__/ _ \/ _ \ '_ \ / _ \
| |_| | | |  __/  __/ | | |  __/
 \____|_|  \___|\___|_| |_|\___|

ir967@localhost's password: 
Permission denied, please try again.
ir967@localhost's password: 
Last failed login: Fri Dec 11 03:09:04 EST 2020 from 216.165.66.211 on ssh:notty
There was 1 failed login attempt since the last successful login.
Last login: Fri Dec 11 02:52:49 2020 from 216.165.66.211
[ir967@log-3 ~]$ ls
ir967
[ir967@log-3 ~]$ pwd
/home/ir967
[ir967@log-3 ~]$ wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
--2020-12-11 03:09:40--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8203, ...
Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 94235922 (90M) [application/x-sh]
Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’

Miniconda3-latest-Linux-x86_64.sh    100%[====================================================================>]  89.87M   286MB/s    in 0.3s    

2020-12-11 03:09:41 (286 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [94235922/94235922]

[ir967@log-3 ~]$ sh Miniconda3-latest-Linux-x86_64.sh 

Welcome to Miniconda3 py38_4.9.2

In order to continue the installation process, please review the license
agreement.
Please, press ENTER to continue
>>> 
===================================
End User License Agreement - Anaconda Individual Edition
===================================

Copyright 2015-2020, Anaconda, Inc.

All rights reserved under the 3-clause BSD License:

This End User License Agreement (the "Agreement") is a legal agreement between you and Anaconda, Inc. ("Anaconda") and governs your use of Anacond
a Individual Edition (which was formerly known as Anaconda Distribution).

Subject to the terms of this Agreement, Anaconda hereby grants you a non-exclusive, non-transferable license to:

  * Install and use the Anaconda Individual Edition (which was formerly known as Anaconda Distribution),
  * Modify and create derivative works of sample source code delivered in Anaconda Individual Edition from Anaconda's repository; and
  * Redistribute code files in source (if provided to you by Anaconda as source) and binary forms, with or without modification subject to the req
uirements set forth below.

Anaconda may, at its option, make available patches, workarounds or other updates to Anaconda Individual Edition. Unless the updates are provided 
with their separate governing terms, they are deemed part of Anaconda Individual Edition licensed to you as provided in this Agreement.  This Agre
ement does not entitle you to any support for Anaconda Individual Edition.

Anaconda reserves all rights not expressly granted to you in this Agreement.

Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:

  * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
  * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the document
ation and/or other materials provided with the distribution.
  * Neither the name of Anaconda nor the names of its contributors may be used to endorse or promote products derived from this software without s
pecific prior written permission.

You acknowledge that, as between you and Anaconda, Anaconda owns all right, title, and interest, including all intellectual property rights, in an
d to Anaconda Individual Edition and, with respect to third-party products distributed with or through Anaconda Individual Edition, the applicable
 third-party licensors own all right, title and interest, including all intellectual property rights, in and to such products.  If you send or tra
nsmit any communications or materials to Anaconda suggesting or recommending changes to the software or documentation, including without limitatio
n, new features or functionality relating thereto, or any comments, questions, suggestions or the like ("Feedback"), Anaconda is free to use such 
Feedback. You hereby assign to Anaconda all right, title, and interest in, and Anaconda is free to use, without any attribution or compensation to
 any party, any ideas, know-how, concepts, techniques or other intellectual property rights contained in the Feedback, for any purpose whatsoever,
 although Anaconda is not required to use any Feedback.

THIS SOFTWARE IS PROVIDED BY ANACONDA AND ITS CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLI
ED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL ANACONDA BE LIABLE FOR ANY DIRECT, INDIREC
T, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF U
SE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INC
LUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

TO THE MAXIMUM EXTENT PERMITTED BY LAW, ANACONDA AND ITS AFFILIATES SHALL NOT BE LIABLE FOR ANY SPECIAL, INCIDENTAL, PUNITIVE OR CONSEQUENTIAL DAM
AGES, OR ANY LOST PROFITS, LOSS OF USE, LOSS OF DATA OR LOSS OF GOODWILL, OR THE COSTS OF PROCURING SUBSTITUTE PRODUCTS, ARISING OUT OF OR IN CONN
ECTION WITH THIS AGREEMENT OR THE USE OR PERFORMANCE OF ANACONDA INDIVIDUAL EDITION, WHETHER SUCH LIABILITY ARISES FROM ANY CLAIM BASED UPON BREAC
H OF CONTRACT, BREACH OF WARRANTY, TORT (INCLUDING NEGLIGENCE), PRODUCT LIABILITY OR ANY OTHER CAUSE OF ACTION OR THEORY OF LIABILITY. IN NO EVENT
 WILL THE TOTAL CUMULATIVE LIABILITY OF ANACONDA AND ITS AFFILIATES UNDER OR ARISING OUT OF THIS AGREEMENT EXCEED US0.00.

If you want to terminate this Agreement, you may do so by discontinuing use of Anaconda Individual Edition.  Anaconda may, at any time, terminate 
this Agreement and the license granted hereunder if you fail to comply with any term of this Agreement.   Upon any termination of this Agreement, 
you agree to promptly discontinue use of the Anaconda Individual Edition and destroy all copies in your possession or control. Upon any terminatio
n of this Agreement all provisions survive except for the licenses granted to you.

This Agreement is governed by and construed in accordance with the internal laws of the State of Texas without giving effect to any choice or conf
lict of law provision or rule that would require or permit the application of the laws of any jurisdiction other than those of the State of Texas.
 Any legal suit, action, or proceeding arising out of or related to this Agreement or the licenses granted hereunder by you must be instituted exc
lusively in the federal courts of the United States or the courts of the State of Texas in each case located in Travis County, Texas, and you irre
vocably submit to the jurisdiction of such courts in any such suit, action, or proceeding.


Notice of Third Party Software Licenses
=======================================

Anaconda Individual Edition provides access to a repository which contains software packages or tools licensed on an open source basis from third 
parties and binary packages of these third party tools. These third party software packages or tools are provided on an "as is" basis and are subj
ect to their respective license agreements as well as this Agreement and the Terms of Service for the Repository located at https://know.anaconda.
com/TOS.html; provided, however, no restriction contained in the Terms of Service shall be construed so as to limit your ability to download the p
ackages contained in Anaconda Individual Edition provided you comply with the license for each such package.  These licenses may be accessed from 
within the Anaconda Individual Edition software or at https://docs.anaconda.com/anaconda/pkg-docs. Information regarding which license is applicab
le is available from within many of the third party software packages and tools and at https://repo.anaconda.com/pkgs/main/ and https://repo.anaco
nda.com/pkgs/r/. Anaconda reserves the right, in its sole discretion, to change which third party tools are included in the repository accessible 
through Anaconda Individual Edition.

Intel Math Kernel Library
-------------------------

Anaconda Individual Edition provides access to re-distributable, run-time, shared-library files from the Intel Math Kernel Library ("MKL binaries"
).

Copyright 2018 Intel Corporation.  License available at https://software.intel.com/en-us/license/intel-simplified-software-license (the "MKL Licen
se").

You may use and redistribute the MKL binaries, without modification, provided the following conditions are met:

  * Redistributions must reproduce the above copyright notice and the following terms of use in the MKL binaries and in the documentation and/or o
ther materials provided with the distribution.
  * Neither the name of Intel nor the names of its suppliers may be used to endorse or promote products derived from the MKL binaries without spec
ific prior written permission.
  * No reverse engineering, decompilation, or disassembly of the MKL binaries is permitted.

You are specifically authorized to use and redistribute the MKL binaries with your installation of Anaconda Individual Edition subject to the term
s set forth in the MKL License. You are also authorized to redistribute the MKL binaries with Anaconda Individual Edition or in the Anaconda packa
ge that contains the MKL binaries. If needed, instructions for removing the MKL binaries after installation of Anaconda Individual Edition are ava
ilable at https://docs.anaconda.com.

cuDNN Software
--------------

Anaconda Individual Edition also provides access to cuDNN software binaries ("cuDNN binaries") from NVIDIA Corporation. You are specifically autho
rized to use the cuDNN binaries with your installation of Anaconda Individual Edition subject to your compliance with the license agreement locate
d at https://docs.nvidia.com/deeplearning/sdk/cudnn-sla/index.html. You are also authorized to redistribute the cuDNN binaries with an Anaconda In
dividual Edition package that contains the cuDNN binaries. You can add or remove the cuDNN binaries utilizing the install and uninstall features i
n Anaconda Individual Edition.

cuDNN binaries contain source code provided by NVIDIA Corporation.


Export; Cryptography Notice
===========================

You must comply with all domestic and international export laws and regulations that apply to the software, which include restrictions on destinat
ions, end users, and end use.  Anaconda Individual Edition includes cryptographic software. The country in which you currently reside may have res
trictions on the import, possession, use, and/or re-export to another country, of encryption software. BEFORE using any encryption software, pleas
e check your country's laws, regulations and policies concerning the import, possession, or use, and re-export of encryption software, to see if t
his is permitted. See the Wassenaar Arrangement http://www.wassenaar.org/ for more information.

Anaconda has self-classified this software as Export Commodity Control Number (ECCN) 5D992.c, which includes mass market information security soft
ware using or performing cryptographic functions with asymmetric algorithms. No license is required for export of this software to non-embargoed c
ountries.

The Intel Math Kernel Library contained in Anaconda Individual Edition is classified by Intel as ECCN 5D992.c with no license required for export 
to non-embargoed countries.

The following packages are included in the repository accessible through Anaconda Individual Edition that relate to cryptography:

openssl
    The OpenSSL Project is a collaborative effort to develop a robust, commercial-grade, full-featured, and Open Source toolkit implementing the T
ransport Layer Security (TLS) and Secure Sockets Layer (SSL) protocols as well as a full-strength general purpose cryptography library.

pycrypto
    A collection of both secure hash functions (such as SHA256 and RIPEMD160), and various encryption algorithms (AES, DES, RSA, ElGamal, etc.).

pyopenssl
    A thin Python wrapper around (a subset of) the OpenSSL library.

kerberos (krb5, non-Windows platforms)
    A network authentication protocol designed to provide strong authentication for client/server applications by using secret-key cryptography.

cryptography
    A Python library which exposes cryptographic recipes and primitives.

pycryptodome
    A fork of PyCrypto. It is a self-contained Python package of low-level cryptographic primitives.

pycryptodomex
    A stand-alone version of pycryptodome.

libsodium
    A software library for encryption, decryption, signatures, password hashing and more.

pynacl
    A Python binding to the Networking and Cryptography library, a crypto library with the stated goal of improving usability, security and speed.


Last updated September 28, 2020


Do you accept the license terms? [yes|no]
[no] >>> yes

Miniconda3 will now be installed into this location:
/home/ir967/miniconda3

  - Press ENTER to confirm the location
  - Press CTRL-C to abort the installation
  - Or specify a different location below

[/home/ir967/miniconda3] >>> /scratch/ir967/install/minconda3/
PREFIX=/scratch/ir967/install/minconda3
Unpacking payload ...
Extracting : brotlipy-0.7.0-py38h27cfd23_1003.conda:  86%|████████████████████████████████████████████████▏       | 31/36 [00:00<00:01,  3.20it/s]^CProcess ForkProcess-89:
Process ForkProcess-94:
Process ForkProcess-93:
Process ForkProcess-96:
Process ForkProcess-90:
Process ForkProcess-92:
Process ForkProcess-85:
Process ForkProcess-95:
Process ForkProcess-88:
Process ForkProcess-86:
Process ForkProcess-81:
Process ForkProcess-79:
Process ForkProcess-91:
Process ForkProcess-82:
Process ForkProcess-80:
Process ForkProcess-83:
Process ForkProcess-87:
Process ForkProcess-77:
Process ForkProcess-73:
Process ForkProcess-74:
Process ForkProcess-72:
Process ForkProcess-76:
Process ForkProcess-70:
Process ForkProcess-75:
Process ForkProcess-71:
Process ForkProcess-67:
Process ForkProcess-32:
Process ForkProcess-28:
Process ForkProcess-69:
Process ForkProcess-64:
Process ForkProcess-68:
Process ForkProcess-65:
Process ForkProcess-60:
Process ForkProcess-63:
Process ForkProcess-62:
Process ForkProcess-66:
Process ForkProcess-58:
Process ForkProcess-61:
Process ForkProcess-84:
Process ForkProcess-56:
Process ForkProcess-57:
Process ForkProcess-18:
Process ForkProcess-59:
Process ForkProcess-54:
Process ForkProcess-55:
Process ForkProcess-53:
Process ForkProcess-50:
Process ForkProcess-52:
Process ForkProcess-51:
Process ForkProcess-31:
Process ForkProcess-29:
Process ForkProcess-35:
Process ForkProcess-36:
Process ForkProcess-19:
Process ForkProcess-30:
Process ForkProcess-12:
Process ForkProcess-26:
Process ForkProcess-4:
Process ForkProcess-25:
Process ForkProcess-24:
Process ForkProcess-14:
Process ForkProcess-1:
Process ForkProcess-15:
Process ForkProcess-21:
                                                                                                                                                  Process ForkProcess-16:
Process ForkProcess-10:
Process ForkProcess-42:
Process ForkProcess-5:
Process ForkProcess-3:
Process ForkProcess-2:
Process ForkProcess-6:
Process ForkProcess-7:
Process ForkProcess-13:
Traceback (most recent call last):
  File "entry_point.py", line 69, in <module>
Process ForkProcess-78:
Process ForkProcess-37:
Process ForkProcess-38:
Process ForkProcess-44:
Process ForkProcess-8:
  File "concurrent/futures/process.py", line 484, in _chain_from_iterable_of_lists
Process ForkProcess-47:
Process ForkProcess-40:
Process ForkProcess-46:
  File "concurrent/futures/_base.py", line 611, in result_iterator
Process ForkProcess-41:
Process ForkProcess-34:
  File "concurrent/futures/_base.py", line 434, in result
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "threading.py", line 302, in wait
Traceback (most recent call last):
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "concurrent/futures/process.py", line 233, in _process_worker
Traceback (most recent call last):
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
  File "multiprocessing/process.py", line 108, in run
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
Traceback (most recent call last):
  File "multiprocessing/process.py", line 108, in run
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "concurrent/futures/process.py", line 233, in _process_worker
Traceback (most recent call last):
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
Traceback (most recent call last):
  File "multiprocessing/process.py", line 108, in run
Traceback (most recent call last):
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
[4053274] Traceback (most recent call last):
Process ForkProcess-22:
Traceback (most recent call last):
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 108, in run
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
Traceback (most recent call last):
Traceback (most recent call last):
  File "multiprocessing/process.py", line 108, in run
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
Traceback (most recent call last):
  File "concurrent/futures/process.py", line 233, in _process_worker
Traceback (most recent call last):
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 108, in run
Traceback (most recent call last):
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/synchronize.py", line 95, in __enter__
KeyboardInterrupt
  File "concurrent/futures/process.py", line 233, in _process_worker
Traceback (most recent call last):
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 233, in _process_worker
Traceback (most recent call last):
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
Failed to execute script entry_point
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
Traceback (most recent call last):
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/queues.py", line 96, in get
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 108, in run
KeyboardInterrupt
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/process.py", line 108, in run
KeyboardInterrupt
  File "multiprocessing/queues.py", line 96, in get
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/queues.py", line 96, in get
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/queues.py", line 96, in get
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 233, in _process_worker
KeyboardInterrupt
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/process.py", line 108, in run
Traceback (most recent call last):
  File "concurrent/futures/process.py", line 233, in _process_worker
Traceback (most recent call last):
Traceback (most recent call last):
  File "multiprocessing/process.py", line 108, in run
Process ForkProcess-20:
  File "multiprocessing/process.py", line 108, in run
Traceback (most recent call last):
KeyboardInterrupt
Process ForkProcess-45:
  File "multiprocessing/queues.py", line 96, in get
Process ForkProcess-43:
  File "multiprocessing/process.py", line 108, in run
KeyboardInterrupt
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/process.py", line 108, in run
Traceback (most recent call last):
Process ForkProcess-11:
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/queues.py", line 96, in get
Traceback (most recent call last):
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 233, in _process_worker
Traceback (most recent call last):
Process ForkProcess-39:
  File "multiprocessing/queues.py", line 96, in get
Traceback (most recent call last):
  File "multiprocessing/queues.py", line 96, in get
Traceback (most recent call last):
Process ForkProcess-27:
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/queues.py", line 96, in get
Process ForkProcess-9:
  File "multiprocessing/queues.py", line 96, in get
Process ForkProcess-23:
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "concurrent/futures/process.py", line 233, in _process_worker
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "concurrent/futures/process.py", line 233, in _process_worker
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/queues.py", line 96, in get
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "concurrent/futures/process.py", line 233, in _process_worker
Traceback (most recent call last):
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "concurrent/futures/process.py", line 233, in _process_worker
Traceback (most recent call last):
  File "multiprocessing/queues.py", line 96, in get
Traceback (most recent call last):
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/queues.py", line 96, in get
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/queues.py", line 96, in get
  File "concurrent/futures/process.py", line 233, in _process_worker
Traceback (most recent call last):
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/queues.py", line 96, in get
KeyboardInterrupt
  File "multiprocessing/process.py", line 108, in run
KeyboardInterrupt
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/queues.py", line 96, in get
KeyboardInterrupt
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 108, in run
KeyboardInterrupt
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 108, in run
KeyboardInterrupt
  File "multiprocessing/process.py", line 108, in run
Traceback (most recent call last):
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/queues.py", line 96, in get
  File "concurrent/futures/process.py", line 233, in _process_worker
KeyboardInterrupt
KeyboardInterrupt
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
Traceback (most recent call last):
  File "multiprocessing/queues.py", line 96, in get
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/process.py", line 108, in run
KeyboardInterrupt
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "concurrent/futures/process.py", line 233, in _process_worker
Traceback (most recent call last):
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
KeyboardInterrupt
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/synchronize.py", line 95, in __enter__
KeyboardInterrupt
Traceback (most recent call last):
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "concurrent/futures/process.py", line 233, in _process_worker
Traceback (most recent call last):
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "concurrent/futures/process.py", line 233, in _process_worker
Traceback (most recent call last):
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/queues.py", line 96, in get
KeyboardInterrupt
  File "multiprocessing/process.py", line 315, in _bootstrap
Traceback (most recent call last):
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/queues.py", line 96, in get
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/process.py", line 108, in run
KeyboardInterrupt
KeyboardInterrupt
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 315, in _bootstrap
KeyboardInterrupt
  File "concurrent/futures/process.py", line 233, in _process_worker
KeyboardInterrupt
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/queues.py", line 96, in get
KeyboardInterrupt
  File "multiprocessing/queues.py", line 96, in get
KeyboardInterrupt
KeyboardInterrupt
KeyboardInterrupt
KeyboardInterrupt
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/queues.py", line 96, in get
KeyboardInterrupt
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "concurrent/futures/process.py", line 233, in _process_worker
KeyboardInterrupt
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/queues.py", line 96, in get
  File "concurrent/futures/process.py", line 233, in _process_worker
KeyboardInterrupt
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 315, in _bootstrap
Process ForkProcess-17:
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/queues.py", line 96, in get
KeyboardInterrupt
KeyboardInterrupt
  File "multiprocessing/process.py", line 108, in run
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/queues.py", line 96, in get
KeyboardInterrupt
  File "multiprocessing/process.py", line 108, in run
KeyboardInterrupt
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "concurrent/futures/process.py", line 233, in _process_worker
KeyboardInterrupt
KeyboardInterrupt
  File "concurrent/futures/process.py", line 233, in _process_worker
KeyboardInterrupt
  File "multiprocessing/synchronize.py", line 95, in __enter__
KeyboardInterrupt
  File "multiprocessing/synchronize.py", line 95, in __enter__
KeyboardInterrupt
KeyboardInterrupt
KeyboardInterrupt
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "concurrent/futures/process.py", line 233, in _process_worker
Traceback (most recent call last):
KeyboardInterrupt
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/queues.py", line 96, in get
KeyboardInterrupt
KeyboardInterrupt
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/queues.py", line 96, in get
KeyboardInterrupt
KeyboardInterrupt
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 108, in run
KeyboardInterrupt
KeyboardInterrupt
  File "concurrent/futures/process.py", line 233, in _process_worker
KeyboardInterrupt
  File "multiprocessing/queues.py", line 96, in get
KeyboardInterrupt
KeyboardInterrupt
  File "multiprocessing/synchronize.py", line 95, in __enter__
KeyboardInterrupt
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
Process ForkProcess-48:
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/synchronize.py", line 95, in __enter__
KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/synchronize.py", line 95, in __enter__
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/queues.py", line 96, in get
KeyboardInterrupt
  File "multiprocessing/synchronize.py", line 95, in __enter__
KeyboardInterrupt
Traceback (most recent call last):
  File "multiprocessing/process.py", line 315, in _bootstrap
  File "multiprocessing/process.py", line 108, in run
  File "concurrent/futures/process.py", line 233, in _process_worker
  File "multiprocessing/queues.py", line 96, in get
  File "multiprocessing/synchronize.py", line 95, in __enter__
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "site-packages/tqdm/_monitor.py", line 43, in exit
  File "threading.py", line 1011, in join
  File "threading.py", line 1027, in _wait_for_tstate_lock
KeyboardInterrupt
[ir967@log-3 ~]$ sh Miniconda3-latest-Linux-x86_64.sh 

Welcome to Miniconda3 py38_4.9.2

In order to continue the installation process, please review the license
agreement.
Please, press ENTER to continue
>>> 
===================================
End User License Agreement - Anaconda Individual Edition
===================================

Copyright 2015-2020, Anaconda, Inc.

All rights reserved under the 3-clause BSD License:

This End User License Agreement (the "Agreement") is a legal agreement between you and Anaconda, Inc. ("Anaconda") and governs your use of Anacond
a Individual Edition (which was formerly known as Anaconda Distribution).

Subject to the terms of this Agreement, Anaconda hereby grants you a non-exclusive, non-transferable license to:

  * Install and use the Anaconda Individual Edition (which was formerly known as Anaconda Distribution),
  * Modify and create derivative works of sample source code delivered in Anaconda Individual Edition from Anaconda's repository; and
  * Redistribute code files in source (if provided to you by Anaconda as source) and binary forms, with or without modification subject to the req
uirements set forth below.

Anaconda may, at its option, make available patches, workarounds or other updates to Anaconda Individual Edition. Unless the updates are provided 
with their separate governing terms, they are deemed part of Anaconda Individual Edition licensed to you as provided in this Agreement.  This Agre
ement does not entitle you to any support for Anaconda Individual Edition.

Anaconda reserves all rights not expressly granted to you in this Agreement.

Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:

  * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
  * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the document
ation and/or other materials provided with the distribution.
  * Neither the name of Anaconda nor the names of its contributors may be used to endorse or promote products derived from this software without s
pecific prior written permission.

You acknowledge that, as between you and Anaconda, Anaconda owns all right, title, and interest, including all intellectual property rights, in an
d to Anaconda Individual Edition and, with respect to third-party products distributed with or through Anaconda Individual Edition, the applicable
 third-party licensors own all right, title and interest, including all intellectual property rights, in and to such products.  If you send or tra
nsmit any communications or materials to Anaconda suggesting or recommending changes to the software or documentation, including without limitatio
n, new features or functionality relating thereto, or any comments, questions, suggestions or the like ("Feedback"), Anaconda is free to use such 
Feedback. You hereby assign to Anaconda all right, title, and interest in, and Anaconda is free to use, without any attribution or compensation to
 any party, any ideas, know-how, concepts, techniques or other intellectual property rights contained in the Feedback, for any purpose whatsoever,
 although Anaconda is not required to use any Feedback.

THIS SOFTWARE IS PROVIDED BY ANACONDA AND ITS CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLI
ED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL ANACONDA BE LIABLE FOR ANY DIRECT, INDIREC
T, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF U
SE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INC
LUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

TO THE MAXIMUM EXTENT PERMITTED BY LAW, ANACONDA AND ITS AFFILIATES SHALL NOT BE LIABLE FOR ANY SPECIAL, INCIDENTAL, PUNITIVE OR CONSEQUENTIAL DAM
AGES, OR ANY LOST PROFITS, LOSS OF USE, LOSS OF DATA OR LOSS OF GOODWILL, OR THE COSTS OF PROCURING SUBSTITUTE PRODUCTS, ARISING OUT OF OR IN CONN
ECTION WITH THIS AGREEMENT OR THE USE OR PERFORMANCE OF ANACONDA INDIVIDUAL EDITION, WHETHER SUCH LIABILITY ARISES FROM ANY CLAIM BASED UPON BREAC
H OF CONTRACT, BREACH OF WARRANTY, TORT (INCLUDING NEGLIGENCE), PRODUCT LIABILITY OR ANY OTHER CAUSE OF ACTION OR THEORY OF LIABILITY. IN NO EVENT
 WILL THE TOTAL CUMULATIVE LIABILITY OF ANACONDA AND ITS AFFILIATES UNDER OR ARISING OUT OF THIS AGREEMENT EXCEED US0.00.

If you want to terminate this Agreement, you may do so by discontinuing use of Anaconda Individual Edition.  Anaconda may, at any time, terminate 
this Agreement and the license granted hereunder if you fail to comply with any term of this Agreement.   Upon any termination of this Agreement, 
you agree to promptly discontinue use of the Anaconda Individual Edition and destroy all copies in your possession or control. Upon any terminatio
n of this Agreement all provisions survive except for the licenses granted to you.

This Agreement is governed by and construed in accordance with the internal laws of the State of Texas without giving effect to any choice or conf
lict of law provision or rule that would require or permit the application of the laws of any jurisdiction other than those of the State of Texas.
 Any legal suit, action, or proceeding arising out of or related to this Agreement or the licenses granted hereunder by you must be instituted exc
lusively in the federal courts of the United States or the courts of the State of Texas in each case located in Travis County, Texas, and you irre
vocably submit to the jurisdiction of such courts in any such suit, action, or proceeding.


Notice of Third Party Software Licenses
=======================================

Anaconda Individual Edition provides access to a repository which contains software packages or tools licensed on an open source basis from third 
parties and binary packages of these third party tools. These third party software packages or tools are provided on an "as is" basis and are subj
ect to their respective license agreements as well as this Agreement and the Terms of Service for the Repository located at https://know.anaconda.
com/TOS.html; provided, however, no restriction contained in the Terms of Service shall be construed so as to limit your ability to download the p
ackages contained in Anaconda Individual Edition provided you comply with the license for each such package.  These licenses may be accessed from 
within the Anaconda Individual Edition software or at https://docs.anaconda.com/anaconda/pkg-docs. Information regarding which license is applicab
le is available from within many of the third party software packages and tools and at https://repo.anaconda.com/pkgs/main/ and https://repo.anaco
nda.com/pkgs/r/. Anaconda reserves the right, in its sole discretion, to change which third party tools are included in the repository accessible 
through Anaconda Individual Edition.

Intel Math Kernel Library
-------------------------

Anaconda Individual Edition provides access to re-distributable, run-time, shared-library files from the Intel Math Kernel Library ("MKL binaries"
).

Copyright 2018 Intel Corporation.  License available at https://software.intel.com/en-us/license/intel-simplified-software-license (the "MKL Licen
se").

You may use and redistribute the MKL binaries, without modification, provided the following conditions are met:

  * Redistributions must reproduce the above copyright notice and the following terms of use in the MKL binaries and in the documentation and/or o
ther materials provided with the distribution.
  * Neither the name of Intel nor the names of its suppliers may be used to endorse or promote products derived from the MKL binaries without spec
ific prior written permission.
  * No reverse engineering, decompilation, or disassembly of the MKL binaries is permitted.

You are specifically authorized to use and redistribute the MKL binaries with your installation of Anaconda Individual Edition subject to the term
s set forth in the MKL License. You are also authorized to redistribute the MKL binaries with Anaconda Individual Edition or in the Anaconda packa
ge that contains the MKL binaries. If needed, instructions for removing the MKL binaries after installation of Anaconda Individual Edition are ava
ilable at https://docs.anaconda.com.

cuDNN Software
--------------

Anaconda Individual Edition also provides access to cuDNN software binaries ("cuDNN binaries") from NVIDIA Corporation. You are specifically autho
rized to use the cuDNN binaries with your installation of Anaconda Individual Edition subject to your compliance with the license agreement locate
d at https://docs.nvidia.com/deeplearning/sdk/cudnn-sla/index.html. You are also authorized to redistribute the cuDNN binaries with an Anaconda In
dividual Edition package that contains the cuDNN binaries. You can add or remove the cuDNN binaries utilizing the install and uninstall features i
n Anaconda Individual Edition.

cuDNN binaries contain source code provided by NVIDIA Corporation.


Export; Cryptography Notice
===========================

You must comply with all domestic and international export laws and regulations that apply to the software, which include restrictions on destinat
ions, end users, and end use.  Anaconda Individual Edition includes cryptographic software. The country in which you currently reside may have res
trictions on the import, possession, use, and/or re-export to another country, of encryption software. BEFORE using any encryption software, pleas
e check your country's laws, regulations and policies concerning the import, possession, or use, and re-export of encryption software, to see if t
his is permitted. See the Wassenaar Arrangement http://www.wassenaar.org/ for more information.

Anaconda has self-classified this software as Export Commodity Control Number (ECCN) 5D992.c, which includes mass market information security soft
ware using or performing cryptographic functions with asymmetric algorithms. No license is required for export of this software to non-embargoed c
ountries.

The Intel Math Kernel Library contained in Anaconda Individual Edition is classified by Intel as ECCN 5D992.c with no license required for export 
to non-embargoed countries.

The following packages are included in the repository accessible through Anaconda Individual Edition that relate to cryptography:

openssl
    The OpenSSL Project is a collaborative effort to develop a robust, commercial-grade, full-featured, and Open Source toolkit implementing the T
ransport Layer Security (TLS) and Secure Sockets Layer (SSL) protocols as well as a full-strength general purpose cryptography library.

pycrypto
    A collection of both secure hash functions (such as SHA256 and RIPEMD160), and various encryption algorithms (AES, DES, RSA, ElGamal, etc.).

pyopenssl
    A thin Python wrapper around (a subset of) the OpenSSL library.

kerberos (krb5, non-Windows platforms)
    A network authentication protocol designed to provide strong authentication for client/server applications by using secret-key cryptography.

cryptography
    A Python library which exposes cryptographic recipes and primitives.

pycryptodome
    A fork of PyCrypto. It is a self-contained Python package of low-level cryptographic primitives.

pycryptodomex
    A stand-alone version of pycryptodome.

libsodium
    A software library for encryption, decryption, signatures, password hashing and more.

pynacl
    A Python binding to the Networking and Cryptography library, a crypto library with the stated goal of improving usability, security and speed.


Last updated September 28, 2020


Do you accept the license terms? [yes|no]
[no] >>> yes

Miniconda3 will now be installed into this location:
/home/ir967/miniconda3

  - Press ENTER to confirm the location
  - Press CTRL-C to abort the installation
  - Or specify a different location below

[/home/ir967/miniconda3] >>> /scratch/ir967/install/miniconda3/
PREFIX=/scratch/ir967/install/miniconda3
Unpacking payload ...
Collecting package metadata (current_repodata.json): done                                                                                         
Solving environment: done

## Package Plan ##

  environment location: /scratch/ir967/install/miniconda3

  added / updated specs:
    - _libgcc_mutex==0.1=main
    - brotlipy==0.7.0=py38h27cfd23_1003
    - ca-certificates==2020.10.14=0
    - certifi==2020.6.20=pyhd3eb1b0_3
    - cffi==1.14.3=py38h261ae71_2
    - chardet==3.0.4=py38h06a4308_1003
    - conda-package-handling==1.7.2=py38h03888b9_0
    - conda==4.9.2=py38h06a4308_0
    - cryptography==3.2.1=py38h3c74f83_1
    - idna==2.10=py_0
    - ld_impl_linux-64==2.33.1=h53a641e_7
    - libedit==3.1.20191231=h14c3975_1
    - libffi==3.3=he6710b0_2
    - libgcc-ng==9.1.0=hdf63c60_0
    - libstdcxx-ng==9.1.0=hdf63c60_0
    - ncurses==6.2=he6710b0_1
    - openssl==1.1.1h=h7b6447c_0
    - pip==20.2.4=py38h06a4308_0
    - pycosat==0.6.3=py38h7b6447c_1
    - pycparser==2.20=py_2
    - pyopenssl==19.1.0=pyhd3eb1b0_1
    - pysocks==1.7.1=py38h06a4308_0
    - python==3.8.5=h7579374_1
    - readline==8.0=h7b6447c_0
    - requests==2.24.0=py_0
    - ruamel_yaml==0.15.87=py38h7b6447c_1
    - setuptools==50.3.1=py38h06a4308_1
    - six==1.15.0=py38h06a4308_0
    - sqlite==3.33.0=h62c20be_0
    - tk==8.6.10=hbc83047_0
    - tqdm==4.51.0=pyhd3eb1b0_0
    - urllib3==1.25.11=py_0
    - wheel==0.35.1=pyhd3eb1b0_0
    - xz==5.2.5=h7b6447c_0
    - yaml==0.2.5=h7b6447c_0
    - zlib==1.2.11=h7b6447c_3


The following NEW packages will be INSTALLED:

  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main
  brotlipy           pkgs/main/linux-64::brotlipy-0.7.0-py38h27cfd23_1003
  ca-certificates    pkgs/main/linux-64::ca-certificates-2020.10.14-0
  certifi            pkgs/main/noarch::certifi-2020.6.20-pyhd3eb1b0_3
  cffi               pkgs/main/linux-64::cffi-1.14.3-py38h261ae71_2
  chardet            pkgs/main/linux-64::chardet-3.0.4-py38h06a4308_1003
  conda              pkgs/main/linux-64::conda-4.9.2-py38h06a4308_0
  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.7.2-py38h03888b9_0
  cryptography       pkgs/main/linux-64::cryptography-3.2.1-py38h3c74f83_1
  idna               pkgs/main/noarch::idna-2.10-py_0
  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.33.1-h53a641e_7
  libedit            pkgs/main/linux-64::libedit-3.1.20191231-h14c3975_1
  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2
  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0
  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0
  ncurses            pkgs/main/linux-64::ncurses-6.2-he6710b0_1
  openssl            pkgs/main/linux-64::openssl-1.1.1h-h7b6447c_0
  pip                pkgs/main/linux-64::pip-20.2.4-py38h06a4308_0
  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py38h7b6447c_1
  pycparser          pkgs/main/noarch::pycparser-2.20-py_2
  pyopenssl          pkgs/main/noarch::pyopenssl-19.1.0-pyhd3eb1b0_1
  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py38h06a4308_0
  python             pkgs/main/linux-64::python-3.8.5-h7579374_1
  readline           pkgs/main/linux-64::readline-8.0-h7b6447c_0
  requests           pkgs/main/noarch::requests-2.24.0-py_0
  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.87-py38h7b6447c_1
  setuptools         pkgs/main/linux-64::setuptools-50.3.1-py38h06a4308_1
  six                pkgs/main/linux-64::six-1.15.0-py38h06a4308_0
  sqlite             pkgs/main/linux-64::sqlite-3.33.0-h62c20be_0
  tk                 pkgs/main/linux-64::tk-8.6.10-hbc83047_0
  tqdm               pkgs/main/noarch::tqdm-4.51.0-pyhd3eb1b0_0
  urllib3            pkgs/main/noarch::urllib3-1.25.11-py_0
  wheel              pkgs/main/noarch::wheel-0.35.1-pyhd3eb1b0_0
  xz                 pkgs/main/linux-64::xz-5.2.5-h7b6447c_0
  yaml               pkgs/main/linux-64::yaml-0.2.5-h7b6447c_0
  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3


Preparing transaction: done
Executing transaction: done
installation finished.
Do you wish the installer to initialize Miniconda3
by running conda init? [yes|no]
[no] >>> yes
no change     /scratch/ir967/install/miniconda3/condabin/conda
no change     /scratch/ir967/install/miniconda3/bin/conda
no change     /scratch/ir967/install/miniconda3/bin/conda-env
no change     /scratch/ir967/install/miniconda3/bin/activate
no change     /scratch/ir967/install/miniconda3/bin/deactivate
no change     /scratch/ir967/install/miniconda3/etc/profile.d/conda.sh
no change     /scratch/ir967/install/miniconda3/etc/fish/conf.d/conda.fish
no change     /scratch/ir967/install/miniconda3/shell/condabin/Conda.psm1
no change     /scratch/ir967/install/miniconda3/shell/condabin/conda-hook.ps1
no change     /scratch/ir967/install/miniconda3/lib/python3.8/site-packages/xontrib/conda.xsh
no change     /scratch/ir967/install/miniconda3/etc/profile.d/conda.csh
modified      /home/ir967/.bashrc

==> For changes to take effect, close and re-open your current shell. <==

If you'd prefer that conda's base environment not be activated on startup, 
   set the auto_activate_base parameter to false: 

conda config --set auto_activate_base false

Thank you for installing Miniconda3!
[ir967@log-3 ~]$ source ~/.bashrc
(base) [ir967@log-3 ~]$ srun -t1:30:00 --mem=5460 --gres=gpu:1 --pty /bin/bash
(base) [ir967@gr043 ~]$ conda create -n sid2 python=2.7.13 cudnn=7.1.2 cudatoolkit=9.0 tensorflow-gpu=1.11.0
Collecting package metadata (current_repodata.json): done
Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.
Collecting package metadata (repodata.json): done
Solving environment: done

## Package Plan ##

  environment location: /scratch/ir967/install/miniconda3/envs/sid2

  added / updated specs:
    - cudatoolkit=9.0
    - cudnn=7.1.2
    - python=2.7.13
    - tensorflow-gpu=1.11.0


The following packages will be downloaded:

    package                    |            build
    ---------------------------|-----------------
    _tflow_select-2.1.0        |              gpu           2 KB
    absl-py-0.11.0             |     pyhd3eb1b0_1         103 KB
    astor-0.8.0                |           py27_0          46 KB
    backports-1.0              |     pyhd3eb1b0_2         210 KB
    backports.weakref-1.0.post1|             py_1           8 KB
    blas-1.0                   |              mkl           6 KB
    c-ares-1.17.1              |       h27cfd23_0         108 KB
    ca-certificates-2020.12.8  |       h06a4308_0         121 KB
    cudatoolkit-9.0            |       h13b8566_0       237.0 MB
    cudnn-7.1.2                |        cuda9.0_0       243.0 MB
    cupti-9.0.176              |                0         1.4 MB
    enum34-1.1.6               |           py27_1          58 KB
    funcsigs-1.0.2             |           py27_0          22 KB
    futures-3.3.0              |           py27_0          29 KB
    gast-0.4.0                 |             py_0          15 KB
    grpcio-1.14.1              |   py27h9ba97e2_0         940 KB
    h5py-2.9.0                 |   py27h7918eee_0         961 KB
    hdf5-1.10.4                |       hb1b8bf9_0         3.9 MB
    intel-openmp-2020.2        |              254         786 KB
    keras-applications-1.0.8   |             py_1          29 KB
    keras-preprocessing-1.1.0  |             py_1          37 KB
    libedit-3.1                |       heed3624_0         151 KB
    libffi-3.2.1               |    hf484d3e_1007          48 KB
    libgfortran-ng-7.3.0       |       hdf63c60_0        1006 KB
    libprotobuf-3.11.2         |       hd408876_0         2.9 MB
    linecache2-1.0.0           |             py_1          14 KB
    markdown-3.1.1             |           py27_0         117 KB
    mkl-2020.2                 |              256       138.3 MB
    mkl-service-2.3.0          |   py27he904b0f_0         217 KB
    mkl_fft-1.0.15             |   py27ha843d7b_0         146 KB
    mkl_random-1.1.0           |   py27hd6b4f25_0         297 KB
    mock-3.0.5                 |           py27_0          49 KB
    ncurses-6.0                |       h9df7e31_2         781 KB
    numpy-1.16.6               |   py27hbc911f0_0          48 KB
    numpy-base-1.16.6          |   py27hde5b4d6_0         3.5 MB
    openssl-1.0.2u             |       h7b6447c_0         2.2 MB
    pip-19.3.1                 |           py27_0         1.7 MB
    protobuf-3.11.2            |   py27he6710b0_0         638 KB
    python-2.7.13              |      heccc3f1_16         7.6 MB
    readline-7.0               |       ha6073c6_4         848 KB
    scipy-1.2.1                |   py27h7c811a0_0        13.7 MB
    setuptools-44.0.0          |           py27_0         512 KB
    six-1.15.0                 |             py_0          13 KB
    sqlite-3.23.1              |       he433501_0         808 KB
    tensorboard-1.11.0         |   py27hf484d3e_0         3.0 MB
    tensorflow-1.11.0          |gpu_py27h99ab47f_0           4 KB
    tensorflow-base-1.11.0     |gpu_py27h8e0ae2d_0        85.6 MB
    tensorflow-gpu-1.11.0      |       h0d30ee6_0           2 KB
    termcolor-1.1.0            |           py27_1           8 KB
    traceback2-1.4.0           |           py27_0          31 KB
    unittest2-1.1.0            |           py27_0         149 KB
    werkzeug-1.0.1             |             py_0         240 KB
    wheel-0.36.1               |     pyhd3eb1b0_0          32 KB
    ------------------------------------------------------------
                                           Total:       753.1 MB

The following NEW packages will be INSTALLED:

  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main
  _tflow_select      pkgs/main/linux-64::_tflow_select-2.1.0-gpu
  absl-py            pkgs/main/noarch::absl-py-0.11.0-pyhd3eb1b0_1
  astor              pkgs/main/linux-64::astor-0.8.0-py27_0
  backports          pkgs/main/noarch::backports-1.0-pyhd3eb1b0_2
  backports.weakref  pkgs/main/noarch::backports.weakref-1.0.post1-py_1
  blas               pkgs/main/linux-64::blas-1.0-mkl
  c-ares             pkgs/main/linux-64::c-ares-1.17.1-h27cfd23_0
  ca-certificates    pkgs/main/linux-64::ca-certificates-2020.12.8-h06a4308_0
  certifi            pkgs/main/noarch::certifi-2020.6.20-pyhd3eb1b0_3
  cudatoolkit        pkgs/main/linux-64::cudatoolkit-9.0-h13b8566_0
  cudnn              pkgs/main/linux-64::cudnn-7.1.2-cuda9.0_0
  cupti              pkgs/main/linux-64::cupti-9.0.176-0
  enum34             pkgs/main/linux-64::enum34-1.1.6-py27_1
  funcsigs           pkgs/main/linux-64::funcsigs-1.0.2-py27_0
  futures            pkgs/main/linux-64::futures-3.3.0-py27_0
  gast               pkgs/main/noarch::gast-0.4.0-py_0
  grpcio             pkgs/main/linux-64::grpcio-1.14.1-py27h9ba97e2_0
  h5py               pkgs/main/linux-64::h5py-2.9.0-py27h7918eee_0
  hdf5               pkgs/main/linux-64::hdf5-1.10.4-hb1b8bf9_0
  intel-openmp       pkgs/main/linux-64::intel-openmp-2020.2-254
  keras-applications pkgs/main/noarch::keras-applications-1.0.8-py_1
  keras-preprocessi~ pkgs/main/noarch::keras-preprocessing-1.1.0-py_1
  libedit            pkgs/main/linux-64::libedit-3.1-heed3624_0
  libffi             pkgs/main/linux-64::libffi-3.2.1-hf484d3e_1007
  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0
  libgfortran-ng     pkgs/main/linux-64::libgfortran-ng-7.3.0-hdf63c60_0
  libprotobuf        pkgs/main/linux-64::libprotobuf-3.11.2-hd408876_0
  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0
  linecache2         pkgs/main/noarch::linecache2-1.0.0-py_1
  markdown           pkgs/main/linux-64::markdown-3.1.1-py27_0
  mkl                pkgs/main/linux-64::mkl-2020.2-256
  mkl-service        pkgs/main/linux-64::mkl-service-2.3.0-py27he904b0f_0
  mkl_fft            pkgs/main/linux-64::mkl_fft-1.0.15-py27ha843d7b_0
  mkl_random         pkgs/main/linux-64::mkl_random-1.1.0-py27hd6b4f25_0
  mock               pkgs/main/linux-64::mock-3.0.5-py27_0
  ncurses            pkgs/main/linux-64::ncurses-6.0-h9df7e31_2
  numpy              pkgs/main/linux-64::numpy-1.16.6-py27hbc911f0_0
  numpy-base         pkgs/main/linux-64::numpy-base-1.16.6-py27hde5b4d6_0
  openssl            pkgs/main/linux-64::openssl-1.0.2u-h7b6447c_0
  pip                pkgs/main/linux-64::pip-19.3.1-py27_0
  protobuf           pkgs/main/linux-64::protobuf-3.11.2-py27he6710b0_0
  python             pkgs/main/linux-64::python-2.7.13-heccc3f1_16
  readline           pkgs/main/linux-64::readline-7.0-ha6073c6_4
  scipy              pkgs/main/linux-64::scipy-1.2.1-py27h7c811a0_0
  setuptools         pkgs/main/linux-64::setuptools-44.0.0-py27_0
  six                pkgs/main/noarch::six-1.15.0-py_0
  sqlite             pkgs/main/linux-64::sqlite-3.23.1-he433501_0
  tensorboard        pkgs/main/linux-64::tensorboard-1.11.0-py27hf484d3e_0
  tensorflow         pkgs/main/linux-64::tensorflow-1.11.0-gpu_py27h99ab47f_0
  tensorflow-base    pkgs/main/linux-64::tensorflow-base-1.11.0-gpu_py27h8e0ae2d_0
  tensorflow-gpu     pkgs/main/linux-64::tensorflow-gpu-1.11.0-h0d30ee6_0
  termcolor          pkgs/main/linux-64::termcolor-1.1.0-py27_1
  tk                 pkgs/main/linux-64::tk-8.6.10-hbc83047_0
  traceback2         pkgs/main/linux-64::traceback2-1.4.0-py27_0
  unittest2          pkgs/main/linux-64::unittest2-1.1.0-py27_0
  werkzeug           pkgs/main/noarch::werkzeug-1.0.1-py_0
  wheel              pkgs/main/noarch::wheel-0.36.1-pyhd3eb1b0_0
  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3


Proceed ([y]/n)? y


Downloading and Extracting Packages
readline-7.0         | 848 KB    | ####################################################################################################### | 100% 
grpcio-1.14.1        | 940 KB    | ####################################################################################################### | 100% 
ncurses-6.0          | 781 KB    | ####################################################################################################### | 100% 
markdown-3.1.1       | 117 KB    | ####################################################################################################### | 100% 
mkl-service-2.3.0    | 217 KB    | ####################################################################################################### | 100% 
openssl-1.0.2u       | 2.2 MB    | ####################################################################################################### | 100% 
unittest2-1.1.0      | 149 KB    | ####################################################################################################### | 100% 
libgfortran-ng-7.3.0 | 1006 KB   | ####################################################################################################### | 100% 
linecache2-1.0.0     | 14 KB     | ####################################################################################################### | 100% 
keras-preprocessing- | 37 KB     | ####################################################################################################### | 100% 
protobuf-3.11.2      | 638 KB    | ####################################################################################################### | 100% 
cudatoolkit-9.0      | 237.0 MB  | ####################################################################################################### | 100% 
intel-openmp-2020.2  | 786 KB    | ####################################################################################################### | 100% 
mkl-2020.2           | 138.3 MB  | ####################################################################################################### | 100% 
python-2.7.13        | 7.6 MB    | ####################################################################################################### | 100% 
backports.weakref-1. | 8 KB      | ####################################################################################################### | 100% 
tensorflow-1.11.0    | 4 KB      | ####################################################################################################### | 100% 
sqlite-3.23.1        | 808 KB    | ####################################################################################################### | 100% 
ca-certificates-2020 | 121 KB    | ####################################################################################################### | 100% 
cudnn-7.1.2          | 243.0 MB  | ####################################################################################################### | 100% 
enum34-1.1.6         | 58 KB     | ####################################################################################################### | 100% 
termcolor-1.1.0      | 8 KB      | ####################################################################################################### | 100% 
astor-0.8.0          | 46 KB     | ####################################################################################################### | 100% 
wheel-0.36.1         | 32 KB     | ####################################################################################################### | 100% 
mock-3.0.5           | 49 KB     | ####################################################################################################### | 100% 
pip-19.3.1           | 1.7 MB    | ####################################################################################################### | 100% 
numpy-1.16.6         | 48 KB     | ####################################################################################################### | 100% 
libedit-3.1          | 151 KB    | ####################################################################################################### | 100% 
scipy-1.2.1          | 13.7 MB   | ####################################################################################################### | 100% 
tensorflow-gpu-1.11. | 2 KB      | ####################################################################################################### | 100% 
hdf5-1.10.4          | 3.9 MB    | ####################################################################################################### | 100% 
libffi-3.2.1         | 48 KB     | ####################################################################################################### | 100% 
c-ares-1.17.1        | 108 KB    | ####################################################################################################### | 100% 
six-1.15.0           | 13 KB     | ####################################################################################################### | 100% 
traceback2-1.4.0     | 31 KB     | ####################################################################################################### | 100% 
mkl_fft-1.0.15       | 146 KB    | ####################################################################################################### | 100% 
setuptools-44.0.0    | 512 KB    | ####################################################################################################### | 100% 
tensorflow-base-1.11 | 85.6 MB   | ####################################################################################################### | 100% 
numpy-base-1.16.6    | 3.5 MB    | ####################################################################################################### | 100% 
funcsigs-1.0.2       | 22 KB     | ####################################################################################################### | 100% 
h5py-2.9.0           | 961 KB    | ####################################################################################################### | 100% 
futures-3.3.0        | 29 KB     | ####################################################################################################### | 100% 
keras-applications-1 | 29 KB     | ####################################################################################################### | 100% 
absl-py-0.11.0       | 103 KB    | ####################################################################################################### | 100% 
_tflow_select-2.1.0  | 2 KB      | ####################################################################################################### | 100% 
mkl_random-1.1.0     | 297 KB    | ####################################################################################################### | 100% 
gast-0.4.0           | 15 KB     | ####################################################################################################### | 100% 
werkzeug-1.0.1       | 240 KB    | ####################################################################################################### | 100% 
backports-1.0        | 210 KB    | ####################################################################################################### | 100% 
libprotobuf-3.11.2   | 2.9 MB    | ####################################################################################################### | 100% 
tensorboard-1.11.0   | 3.0 MB    | ####################################################################################################### | 100% 
blas-1.0             | 6 KB      | ####################################################################################################### | 100% 
cupti-9.0.176        | 1.4 MB    | ####################################################################################################### | 100% 
Preparing transaction: done
Verifying transaction: done
Executing transaction: done
#
# To activate this environment, use
#
#     $ conda activate sid2
#
# To deactivate an active environment, use
#
#     $ conda deactivate

(base) [ir967@gr043 ~]$ conda activate sid2
(sid2) [ir967@gr043 ~]$ conda install Pillow
Collecting package metadata (current_repodata.json): done
Solving environment: failed with initial frozen solve. Retrying with flexible solve.
Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.
Collecting package metadata (repodata.json): done
Solving environment: done

## Package Plan ##

  environment location: /scratch/ir967/install/miniconda3/envs/sid2

  added / updated specs:
    - pillow


The following packages will be downloaded:

    package                    |            build
    ---------------------------|-----------------
    freetype-2.10.4            |       h5ab3b9f_0         596 KB
    jpeg-9b                    |       h024ee3a_2         214 KB
    libpng-1.6.37              |       hbc83047_0         278 KB
    libtiff-4.1.0              |       h2733197_1         449 KB
    lz4-c-1.9.2                |       heb0550a_3         175 KB
    olefile-0.46               |           py27_0          49 KB
    pillow-6.2.1               |   py27h34e0f95_0         587 KB
    zstd-1.4.5                 |       h9ceee32_0         619 KB
    ------------------------------------------------------------
                                           Total:         2.9 MB

The following NEW packages will be INSTALLED:

  freetype           pkgs/main/linux-64::freetype-2.10.4-h5ab3b9f_0
  jpeg               pkgs/main/linux-64::jpeg-9b-h024ee3a_2
  libpng             pkgs/main/linux-64::libpng-1.6.37-hbc83047_0
  libtiff            pkgs/main/linux-64::libtiff-4.1.0-h2733197_1
  lz4-c              pkgs/main/linux-64::lz4-c-1.9.2-heb0550a_3
  olefile            pkgs/main/linux-64::olefile-0.46-py27_0
  pillow             pkgs/main/linux-64::pillow-6.2.1-py27h34e0f95_0
  xz                 pkgs/main/linux-64::xz-5.2.5-h7b6447c_0
  zstd               pkgs/main/linux-64::zstd-1.4.5-h9ceee32_0


Proceed ([y]/n)? y


Downloading and Extracting Packages
zstd-1.4.5           | 619 KB    | ####################################################################################################### | 100% 
freetype-2.10.4      | 596 KB    | ####################################################################################################### | 100% 
olefile-0.46         | 49 KB     | ####################################################################################################### | 100% 
lz4-c-1.9.2          | 175 KB    | ####################################################################################################### | 100% 
libtiff-4.1.0        | 449 KB    | ####################################################################################################### | 100% 
pillow-6.2.1         | 587 KB    | ####################################################################################################### | 100% 
jpeg-9b              | 214 KB    | ####################################################################################################### | 100% 
libpng-1.6.37        | 278 KB    | ####################################################################################################### | 100% 
Preparing transaction: done
Verifying transaction: done
Executing transaction: done
(sid2) [ir967@gr043 ~]$ pwd
/home/ir967
(sid2) [ir967@gr043 ~]$ cd $SCRATCH/SID/
(sid2) [ir967@gr043 SID]$ cd Learning-to-See-in-the-Dark/
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ pwd
/scratch/ir967/SID/Learning-to-See-in-the-Dark
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ vi train_for_gamma_Sony_dead_simple.py 
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ python train_for_gamma_Sony_dead_simple.py 
Traceback (most recent call last):
  File "train_for_gamma_Sony_dead_simple.py", line 8, in <module>
    import rawpy
ImportError: No module named rawpy
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ conda install rawpy==0.13.0
Collecting package metadata (current_repodata.json): done
Solving environment: failed with initial frozen solve. Retrying with flexible solve.
Collecting package metadata (repodata.json): done
Solving environment: failed with initial frozen solve. Retrying with flexible solve.

PackagesNotFoundError: The following packages are not available from current channels:

  - rawpy==0.13.0

Current channels:

  - https://repo.anaconda.com/pkgs/main/linux-64
  - https://repo.anaconda.com/pkgs/main/noarch
  - https://repo.anaconda.com/pkgs/r/linux-64
  - https://repo.anaconda.com/pkgs/r/noarch

To search for alternate channels that may provide the conda package you're
looking for, navigate to

    https://anaconda.org

and use the search bar at the top of the page.


(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ pip3 install rawpy==0.13.0
Collecting rawpy==0.13.0
  Downloading https://files.pythonhosted.org/packages/79/1e/63007c7c6efff9ad42832505c6f98866184eb2c55ea66bc79760aa602f8e/rawpy-0.13.0-cp36-cp36m-manylinux1_x86_64.whl (682kB)
    100% |████████████████████████████████| 686kB 2.2MB/s 
Collecting numpy (from rawpy==0.13.0)
  Downloading https://files.pythonhosted.org/packages/a6/fc/36e52d0ae2aa502b211f1bcd2fdeec72d343d58224eabcdddc1bcb052db1/numpy-1.19.4-cp36-cp36m-manylinux1_x86_64.whl (13.4MB)
    100% |████████████████████████████████| 13.4MB 116kB/s 
Installing collected packages: numpy, rawpy
Exception:
Traceback (most recent call last):
  File "/usr/lib/python3.6/site-packages/pip/basecommand.py", line 215, in main
    status = self.run(options, args)
  File "/usr/lib/python3.6/site-packages/pip/commands/install.py", line 365, in run
    strip_file_prefix=options.strip_file_prefix,
  File "/usr/lib/python3.6/site-packages/pip/req/req_set.py", line 789, in install
    **kwargs
  File "/usr/lib/python3.6/site-packages/pip/req/req_install.py", line 854, in install
    strip_file_prefix=strip_file_prefix
  File "/usr/lib/python3.6/site-packages/pip/req/req_install.py", line 1069, in move_wheel_files
    strip_file_prefix=strip_file_prefix,
  File "/usr/lib/python3.6/site-packages/pip/wheel.py", line 345, in move_wheel_files
    clobber(source, lib_dir, True)
  File "/usr/lib/python3.6/site-packages/pip/wheel.py", line 287, in clobber
    ensure_dir(dest)  # common for the 'include' path
  File "/usr/lib/python3.6/site-packages/pip/utils/__init__.py", line 83, in ensure_dir
    os.makedirs(path)
  File "/usr/lib64/python3.6/os.py", line 210, in makedirs
    makedirs(head, mode, exist_ok)
  File "/usr/lib64/python3.6/os.py", line 220, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/usr/local/lib64/python3.6'
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ conda search rawpy
Loading channels: done
No match found for: rawpy. Search: *rawpy*

PackagesNotFoundError: The following packages are not available from current channels:

  - rawpy

Current channels:

  - https://repo.anaconda.com/pkgs/main/linux-64
  - https://repo.anaconda.com/pkgs/main/noarch
  - https://repo.anaconda.com/pkgs/r/linux-64
  - https://repo.anaconda.com/pkgs/r/noarch

To search for alternate channels that may provide the conda package you're
looking for, navigate to

    https://anaconda.org

and use the search bar at the top of the page.


(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ pip install rawpy==0.13.0
DEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support
Collecting rawpy==0.13.0
  Downloading https://files.pythonhosted.org/packages/06/68/7d5e739b1e5054a54e6466e1f34b6d5f3988d9e6aa5ba7fc2985b36b92e4/rawpy-0.13.0-cp27-cp27mu-manylinux1_x86_64.whl (645kB)
     |████████████████████████████████| 655kB 18.3MB/s 
Requirement already satisfied: numpy in /scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages (from rawpy==0.13.0) (1.16.6)
Requirement already satisfied: enum34 in /scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages (from rawpy==0.13.0) (1.1.6)
Installing collected packages: rawpy
Successfully installed rawpy-0.13.0
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ python train_for_gamma_Sony_dead_simple.py 




Found 161 images to train with
2020-12-11 03:27:39.665170: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 03:27:39.789007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:2f:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 03:27:39.789041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 03:27:40.256235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 03:27:40.256269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 03:27:40.256281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 03:27:40.256423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:2f:00.0, compute capability: 7.5)
loaded ./gt_Sony_dead_simple/model.ckpt
a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065
a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467
a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 850
rawpy read the file at location: ./dataset/Sony/long/00018_00_10s.ARW
Traceback (most recent call last):
  File "train_for_gamma_Sony_dead_simple.py", line 238, in <module>
    scipy.misc.toimage(input_image * 255, high=255, low=0, cmin=0, cmax=255).save(
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/numpy/lib/utils.py", line 101, in newfunc
    return func(*args, **kwds)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/scipy/misc/pilutil.py", line 327, in toimage
    raise ValueError("'arr' does not have a suitable array shape for "
ValueError: 'arr' does not have a suitable array shape for any mode.
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ vi train_for_gamma_Sony_dead_simple.py 
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ python train_for_gamma_Sony_dead_simple.py 




Found 161 images to train with
2020-12-11 03:33:45.979664: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 03:33:46.123984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:2f:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 03:33:46.124018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 03:33:46.400176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 03:33:46.400213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 03:33:46.400230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 03:33:46.400327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:2f:00.0, compute capability: 7.5)
loaded ./gt_Sony_dead_simple/model.ckpt
a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065
a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467
a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 850
rawpy read the file at location: ./dataset/Sony/long/00018_00_10s.ARW
Traceback (most recent call last):
  File "train_for_gamma_Sony_dead_simple.py", line 240, in <module>
    scipy.misc.toimage(input_image_copy * 255, high=255, low=0, cmin=0, cmax=255).save(
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/numpy/lib/utils.py", line 101, in newfunc
    return func(*args, **kwds)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/scipy/misc/pilutil.py", line 327, in toimage
    raise ValueError("'arr' does not have a suitable array shape for "
ValueError: 'arr' does not have a suitable array shape for any mode.
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ vi train_for_gamma_Sony_dead_simple.py 
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ python train_for_gamma_Sony_dead_simple.py 




Found 161 images to train with
2020-12-11 03:35:32.683746: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 03:35:32.828767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:2f:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 03:35:32.828806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 03:35:33.104584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 03:35:33.104621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 03:35:33.104638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 03:35:33.104733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:2f:00.0, compute capability: 7.5)
loaded ./gt_Sony_dead_simple/model.ckpt
a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065
a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467
a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 850
rawpy read the file at location: ./dataset/Sony/long/00018_00_10s.ARW
(1, 1424, 2128, 4)
Traceback (most recent call last):
  File "train_for_gamma_Sony_dead_simple.py", line 241, in <module>
    scipy.misc.toimage(input_image_copy * 255, high=255, low=0, cmin=0, cmax=255).save(
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/numpy/lib/utils.py", line 101, in newfunc
    return func(*args, **kwds)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/scipy/misc/pilutil.py", line 327, in toimage
    raise ValueError("'arr' does not have a suitable array shape for "
ValueError: 'arr' does not have a suitable array shape for any mode.
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ vi train_for_gamma_Sony_dead_simple.py 
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ python train_for_gamma_Sony_dead_simple.py 




Found 161 images to train with
2020-12-11 03:39:05.353339: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 03:39:05.505166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:2f:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 03:39:05.505200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 03:39:05.780078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 03:39:05.780115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 03:39:05.780125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 03:39:05.780216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:2f:00.0, compute capability: 7.5)
loaded ./gt_Sony_dead_simple/model.ckpt
a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065
a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467
a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 850
rawpy read the file at location: ./dataset/Sony/long/00018_00_10s.ARW
Traceback (most recent call last):
  File "train_for_gamma_Sony_dead_simple.py", line 240, in <module>
    print("min, max, mean, argmax: " % (np.min(input_image), np.max(input_image), np.mean(input_image), np.argmax(input_image)))
TypeError: not all arguments converted during string formatting
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ vi train_for_gamma_Sony_dead_simple.py 
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ python train_for_gamma_Sony_dead_simple.py 




Found 161 images to train with
2020-12-11 03:40:32.351597: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 03:40:32.494824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:2f:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 03:40:32.494857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 03:40:32.768216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 03:40:32.768253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 03:40:32.768280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 03:40:32.768377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:2f:00.0, compute capability: 7.5)
loaded ./gt_Sony_dead_simple/model.ckpt
a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065
a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467
a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 850
rawpy read the file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
rawpy read the file at location: ./dataset/Sony/long/00038_00_10s.ARW
^CTraceback (most recent call last):
  File "train_for_gamma_Sony_dead_simple.py", line 214, in <module>
    input_image = np.expand_dims(pack_raw(gt_raw), axis=0)#adding dimension because they use only one image in batch
  File "train_for_gamma_Sony_dead_simple.py", line 79, in pack_raw
    im = np.maximum(im - 512, 0) / (16383 - 512)  # subtract the black level
KeyboardInterrupt
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ python train_for_gamma_Sony_dead_simple.py 




Found 161 images to train with
2020-12-11 03:40:58.395901: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 03:40:58.544527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:2f:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 03:40:58.544560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 03:40:58.817119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 03:40:58.817156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 03:40:58.817170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 03:40:58.817266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:2f:00.0, compute capability: 7.5)
loaded ./gt_Sony_dead_simple/model.ckpt
a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065
a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467
a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 850
rawpy read the file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
rawpy read the file at location: ./dataset/Sony/long/00038_00_10s.ARW
20 images loaded to CPU RAM in Time=4.176 seconds.
[[0 0 1]]
[[0 0 0]]
Epoch 851: batch 1: Loss=1.099, Moving loss=0.011, Time=7.129
[[1 0 0]]
[[0 0 0]]
[[0 0 1]]
[[0 0 0]]
[[0 0 1]]
[[0 0 0]]
[[0 1 0]]
[[0 0 0]]
[[1 0 0]]
[[0 0 0]]
[[0 0 1]]
[[0 0 0]]
[[0 0 1]]
[[0 0 0]]
[[0 1 0]]
[[0 0 0]]
[[0 0 1]]
[[0 0 0]]
[[1 0 0]]
[[0 0 0]]
[[0 0 1]]
[[0 0 0]]
[[1 0 0]]
[[0 0 0]]
[[0 0 1]]
[[0 0 0]]
[[0 0 1]]
[[0 0 0]]
[[0 0 1]]
[[0 0 0]]
[[0 1 0]]
[[0 0 0]]
[[0 1 0]]
[[0 0 0]]
[[0 1 0]]
[[0 0 0]]
[[1 0 0]]
[[0 0 0]]
Epoch 851: Moving loss=0.200, Time=7.487, Epoch time = 7.486, Avg epoch time=3.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
[[1 0 0]]
[[0 0 0]]
Epoch 852: batch 1: Loss=1.099, Moving loss=0.209, Time=0.020
[[0 0 1]]
[[0 0 0]]
[[0 0 1]]
[[0 0 0]]
[[0 0 1]]
[[0 0 0]]
[[0 0 1]]
[[0 0 0]]
[[0 0 1]]
[[0 0 0]]
[[0 0 1]]
[[0 0 0]]
[[1 0 0]]
[[0 0 0]]
[[0 0 1]]
[[0 0 0]]
[[0 1 0]]
[[0 0 0]]
[[0 1 0]]
[[0 0 0]]
[[0 0 1]]
[[0 0 0]]
[[1 0 0]]
[[0 0 0]]
[[0 0 1]]
[[0 0 0]]
[[0 1 0]]
[[0 0 0]]
[[1 0 0]]
[[0 0 0]]
[[0 1 0]]
[[0 0 0]]
[[0 1 0]]
[[0 0 0]]
[[1 0 0]]
[[0 0 0]]
[[0 0 1]]
[[0 0 0]]
[[0 0 1]]
[[0 0 0]]
Epoch 853: batch 1: Loss=1.099, Moving loss=0.371, Time=0.021
[[1 0 0]]
[[0 0 0]]
[[0 1 0]]
[[0 0 0]]
[[0 1 0]]
[[0 0 0]]
[[0 0 1]]
[[0 0 0]]
^CTraceback (most recent call last):
  File "train_for_gamma_Sony_dead_simple.py", line 297, in <module>
    feed_dict={in_image: input_patch, gt_gamma: assigned_image_gamma_index, lr: learning_rate})
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 887, in run
    run_metadata_ptr)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1110, in _run
    feed_dict_tensor, options, run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1286, in _do_run
    run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1292, in _do_call
    return fn(*args)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1277, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1367, in _call_tf_sessionrun
    run_metadata)
KeyboardInterrupt
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ rm train_for_gamma_Sony_dead_simple.py 
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ vi train_for_gamma_Sony_dead_simple.py 
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ python train_for_gamma_Sony_dead_simple.py 




Found 161 images to train with
2020-12-11 03:42:20.804494: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 03:42:20.959694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:2f:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 03:42:20.959726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 03:42:21.241452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 03:42:21.241489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 03:42:21.241515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 03:42:21.241612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:2f:00.0, compute capability: 7.5)
loaded ./gt_Sony_dead_simple/model.ckpt
Traceback (most recent call last):
  File "train_for_gamma_Sony_dead_simple.py", line 124, in <module>
    saver.restore(sess, ckpt.model_checkpoint_path)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/training/saver.py", line 1574, in restore
    err, "a mismatch between the current graph and the graph")
tensorflow.python.framework.errors_impl.InvalidArgumentError: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:

Assign requires shapes of both tensors to match. lhs shape= [12288,3] rhs shape= [12288,100]
	 [[{{node save/Assign_7}} = Assign[T=DT_FLOAT, _class=["loc:@fc_1/weights"], use_locking=true, validate_shape=true, _device="/job:localhost/replica:0/task:0/device:GPU:0"](fc_1/weights/Adam_1, save/RestoreV2/_15)]]

Caused by op u'save/Assign_7', defined at:
  File "train_for_gamma_Sony_dead_simple.py", line 119, in <module>
    saver = tf.train.Saver()
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/training/saver.py", line 1094, in __init__
    self.build()
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/training/saver.py", line 1106, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/training/saver.py", line 1143, in _build
    build_save=build_save, build_restore=build_restore)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/training/saver.py", line 787, in _build_internal
    restore_sequentially, reshape)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/training/saver.py", line 428, in _AddRestoreOps
    assign_ops.append(saveable.restore(saveable_tensors, shapes))
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/training/saver.py", line 119, in restore
    self.op.get_shape().is_fully_defined())
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/state_ops.py", line 221, in assign
    validate_shape=validate_shape)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py", line 61, in assign
    use_locking=use_locking, name=name)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py", line 488, in new_func
    return func(*args, **kwargs)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py", line 3272, in create_op
    op_def=op_def)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py", line 1768, in __init__
    self._traceback = tf_stack.extract_stack()

InvalidArgumentError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:

Assign requires shapes of both tensors to match. lhs shape= [12288,3] rhs shape= [12288,100]
	 [[{{node save/Assign_7}} = Assign[T=DT_FLOAT, _class=["loc:@fc_1/weights"], use_locking=true, validate_shape=true, _device="/job:localhost/replica:0/task:0/device:GPU:0"](fc_1/weights/Adam_1, save/RestoreV2/_15)]]

(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ rm train_for_gamma_Sony_dead_simple.py 
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ vi train_for_gamma_Sony_dead_simple.py 
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ python train_for_gamma_Sony_dead_simple.py 




Found 161 images to train with
2020-12-11 03:44:07.159508: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 03:44:07.314071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:2f:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 03:44:07.314103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 03:44:07.594040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 03:44:07.594076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 03:44:07.594093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 03:44:07.594189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:2f:00.0, compute capability: 7.5)
a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065
a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467
a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
rawpy read the file at location: ./dataset/Sony/long/00038_00_10s.ARW
rawpy read the file at location: ./dataset/Sony/long/00072_00_30s.ARW
rawpy read the file at location: ./dataset/Sony/long/00039_00_10s.ARW
rawpy read the file at location: ./dataset/Sony/long/00200_00_10s.ARW
rawpy read the file at location: ./dataset/Sony/long/00024_00_10s.ARW
Killed
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ rm train_for_gamma_Sony_dead_simple.py 
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ vi train_for_gamma_Sony_dead_simple.py 
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ python train_for_gamma_Sony_dead_simple.py 




Found 161 images to train with
2020-12-11 03:45:19.366429: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 03:45:19.528534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:2f:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 03:45:19.528571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 03:45:20.250595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 03:45:20.250633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 03:45:20.250672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 03:45:20.250891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:2f:00.0, compute capability: 7.5)
a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065
a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467
a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.95669, 0.00000, 3485919
min, max, mean, argmax: 0.00000, 1.00000, 0.01633, 1
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 1.00000, 0.00164, 1177951
min, max, mean, argmax: 0.00000, 0.94221, 0.00187, 803131
min, max, mean, argmax: 0.00000, 0.94221, 0.02266, 3700
min, max, mean, argmax: 0.00000, 0.95160, 0.00427, 2882267
min, max, mean, argmax: 0.00000, 0.98035, 0.00001, 5540515
rawpy read the file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, argmax: 0.00000, 1.00000, 0.00894, 2598691
min, max, mean, argmax: 0.00000, 0.95160, 0.00233, 4653941
min, max, mean, argmax: 0.00000, 1.00000, 0.00016, 6102869
min, max, mean, argmax: 0.00000, 1.00000, 0.00611, 1458187
min, max, mean, argmax: 0.00000, 0.94221, 0.00012, 3426263
min, max, mean, argmax: 0.00000, 1.00000, 0.00116, 4586373
min, max, mean, argmax: 0.00000, 0.98035, 0.00155, 909101
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.95160, 0.00307, 3630407
min, max, mean, argmax: 0.00000, 0.98035, 0.00003, 6735543
rawpy read the file at location: ./dataset/Sony/long/00072_00_30s.ARW
min, max, mean, argmax: 0.00000, 0.98035, 0.00003, 7298885
min, max, mean, argmax: 0.00000, 0.94221, 0.00141, 1272259
min, max, mean, argmax: 0.00000, 0.95160, 0.00000, 142725
min, max, mean, argmax: 0.00000, 0.95160, 0.00466, 822369
min, max, mean, argmax: 0.00000, 1.00000, 0.00011, 2983955
min, max, mean, argmax: 0.00000, 0.94221, 0.00114, 2393979
min, max, mean, argmax: 0.00000, 0.94221, 0.03307, 2641491
min, max, mean, argmax: 0.00000, 1.00000, 0.00003, 1597850
min, max, mean, argmax: 0.00000, 1.00000, 0.00010, 1430113
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
rawpy read the file at location: ./dataset/Sony/long/00039_00_10s.ARW
min, max, mean, argmax: 0.00000, 1.00000, 0.07888, 535
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 1.00000, 0.00247, 2877047
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 1.00000, 0.00027, 271135
min, max, mean, argmax: 0.00000, 0.98035, 0.00001, 11918285
min, max, mean, argmax: 0.00000, 0.94221, 0.00056, 3901
min, max, mean, argmax: 0.00000, 1.00000, 0.00017, 684739
rawpy read the file at location: ./dataset/Sony/long/00200_00_10s.ARW
min, max, mean, argmax: 0.00000, 0.98035, 0.00299, 1458719
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.98035, 0.01101, 1212279
min, max, mean, argmax: 0.00000, 0.95160, 0.00241, 2952517
min, max, mean, argmax: 0.00000, 0.94221, 0.00215, 158803
min, max, mean, argmax: 0.00000, 0.94221, 0.00165, 2486907
min, max, mean, argmax: 0.00000, 0.98035, 0.00215, 7900835
min, max, mean, argmax: 0.00000, 0.95160, 0.00006, 4543563
min, max, mean, argmax: 0.00000, 1.00000, 0.05081, 3437
rawpy read the file at location: ./dataset/Sony/long/00024_00_10s.ARW
min, max, mean, argmax: 0.00000, 1.00000, 0.00048, 33748
min, max, mean, argmax: 0.00000, 0.95160, 0.00352, 3626303
min, max, mean, argmax: 0.00000, 1.00000, 0.01253, 304767
Killed
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ vi images-with-gamma-statistics.txt
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ nvidia-smi
Fri Dec 11 03:48:41 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Quadro RTX 8000     On   | 00000000:2F:00.0 Off |                    0 |
| N/A   27C    P8    13W / 250W |      0MiB / 45556MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ exitexit
bash: exitexit: command not found
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ exit
exit
slurmstepd: error: Detected 2 oom-kill event(s) in step 401580.0 cgroup. Some of your processes may have been killed by the cgroup out-of-memory handler.
srun: error: gr043-ib0: task 0: Out Of Memory
srun: Terminating job step 401580.0
(base) [ir967@log-3 ~]$ srun -t0:30:00 --mem=18460 --gres=gpu:1 --pty /bin/bash
(base) [ir967@gr043 ~]$ python train_for_gamma_Sony_dead_simple.py 
python: can't open file 'train_for_gamma_Sony_dead_simple.py': [Errno 2] No such file or directory
(base) [ir967@gr043 ~]$ cd $SCRATCH/SID
(base) [ir967@gr043 SID]$ cd Learning-to-See-in-the-Dark/
(base) [ir967@gr043 Learning-to-See-in-the-Dark]$ python train_for_gamma_Sony_dead_simple.py 
Traceback (most recent call last):
  File "train_for_gamma_Sony_dead_simple.py", line 4, in <module>
    import os, time, scipy.io
ModuleNotFoundError: No module named 'scipy'
(base) [ir967@gr043 Learning-to-See-in-the-Dark]$ conda activate sid2
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ python train_for_gamma_Sony_dead_simple.py 




Found 161 images to train with
2020-12-11 03:50:26.056042: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 03:50:26.190981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 03:50:26.191017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 03:50:26.553950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 03:50:26.553987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 03:50:26.554017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 03:50:26.554158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)
a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065
a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467
a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.89525, 0.00000, 3485919
min, max, mean, argmax: 0.00000, 1.00000, 0.01631, 1
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 1.00000, 0.00165, 1177951
min, max, mean, argmax: 0.00000, 0.94221, 0.00187, 803131
min, max, mean, argmax: 0.00000, 0.98035, 0.02465, 3700
min, max, mean, argmax: 0.00000, 0.95160, 0.00427, 2882267
min, max, mean, argmax: 0.00000, 0.95160, 0.00001, 5540515
rawpy read the file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, argmax: 0.00000, 1.00000, 0.00886, 2598691
min, max, mean, argmax: 0.00000, 0.98035, 0.00248, 4653941
min, max, mean, argmax: 0.00000, 1.00000, 0.00016, 6102869
min, max, mean, argmax: 0.00000, 1.00000, 0.00613, 1458187
min, max, mean, argmax: 0.00000, 0.95160, 0.00012, 3426263
min, max, mean, argmax: 0.00000, 1.00000, 0.00116, 4586373
min, max, mean, argmax: 0.00000, 0.95160, 0.00146, 909101
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.98035, 0.00327, 3630407
min, max, mean, argmax: 0.00000, 0.95160, 0.00002, 6735543
rawpy read the file at location: ./dataset/Sony/long/00072_00_30s.ARW
min, max, mean, argmax: 0.00000, 0.94221, 0.00003, 7298885
min, max, mean, argmax: 0.00000, 0.94221, 0.00141, 1272259
min, max, mean, argmax: 0.00000, 0.94221, 0.00000, 142725
min, max, mean, argmax: 0.00000, 0.95160, 0.00466, 822369
min, max, mean, argmax: 0.00000, 1.00000, 0.00011, 2983955
min, max, mean, argmax: 0.00000, 0.95160, 0.00116, 2393979
min, max, mean, argmax: 0.00000, 0.98035, 0.03574, 2641491
min, max, mean, argmax: 0.00000, 1.00000, 0.00003, 1597850
min, max, mean, argmax: 0.00000, 1.00000, 0.00010, 1430113
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
rawpy read the file at location: ./dataset/Sony/long/00039_00_10s.ARW
min, max, mean, argmax: 0.00000, 1.00000, 0.07888, 535
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 1.00000, 0.00247, 2877047
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 1.00000, 0.00027, 271135
min, max, mean, argmax: 0.00000, 0.95160, 0.00001, 11918285
min, max, mean, argmax: 0.00000, 0.98035, 0.00060, 3901
min, max, mean, argmax: 0.00000, 1.00000, 0.00017, 684739
rawpy read the file at location: ./dataset/Sony/long/00200_00_10s.ARW
min, max, mean, argmax: 0.00000, 0.94221, 0.00235, 1458719
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.98035, 0.01101, 1212279
min, max, mean, argmax: 0.00000, 0.94221, 0.00237, 2952517
min, max, mean, argmax: 0.00000, 0.95160, 0.00219, 158803
min, max, mean, argmax: 0.00000, 0.95160, 0.00168, 2486907
min, max, mean, argmax: 0.00000, 0.95160, 0.00202, 7900835
min, max, mean, argmax: 0.00000, 0.94221, 0.00005, 4543563
min, max, mean, argmax: 0.00000, 1.00000, 0.05081, 3437
rawpy read the file at location: ./dataset/Sony/long/00024_00_10s.ARW
min, max, mean, argmax: 0.00000, 1.00000, 0.00048, 33748
min, max, mean, argmax: 0.00000, 0.98035, 0.00375, 3626303
min, max, mean, argmax: 0.00000, 1.00000, 0.01267, 304767
min, max, mean, argmax: 0.00000, 0.95160, 0.00059, 5644
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 1.00000, 0.00062, 4526
min, max, mean, argmax: 0.00000, 0.95160, 0.00007, 11755519
min, max, mean, argmax: 0.00000, 0.95160, 0.00012, 2512821
min, max, mean, argmax: 0.00000, 1.00000, 0.01871, 2025
min, max, mean, argmax: 0.00000, 1.00000, 0.00338, 5557479
rawpy read the file at location: ./dataset/Sony/long/00084_00_30s.ARW
min, max, mean, argmax: 0.00000, 0.94221, 0.00340, 67803
min, max, mean, argmax: 0.00000, 0.98035, 0.00228, 103
min, max, mean, argmax: 0.00000, 1.00000, 0.00000, 1696711
min, max, mean, argmax: 0.00000, 0.98035, 0.00688, 2302635
min, max, mean, argmax: 0.00000, 1.00000, 0.00053, 1589659
min, max, mean, argmax: 0.00000, 0.98035, 0.00720, 1
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.94221, 0.00517, 3437411
min, max, mean, argmax: 0.00000, 0.95160, 0.00969, 1033619
min, max, mean, argmax: 0.00000, 1.00000, 0.00001, 742143
rawpy read the file at location: ./dataset/Sony/long/00164_00_30s.ARW
min, max, mean, argmax: 0.00000, 0.94221, 0.00411, 509891
min, max, mean, argmax: 0.00000, 0.94221, 0.00001, 433279
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.98035, 0.00114, 6156358
min, max, mean, argmax: 0.00000, 0.98035, 0.00004, 2110981
min, max, mean, argmax: 0.00000, 0.94221, 0.00084, 277500
min, max, mean, argmax: 0.00000, 1.00000, 0.02919, 646472
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.98035, 0.00062, 5676651
min, max, mean, argmax: 0.00000, 1.00000, 0.00000, 7066147
rawpy read the file at location: ./dataset/Sony/long/00128_00_30s.ARW
min, max, mean, argmax: 0.00000, 0.95160, 0.00320, 4421929
min, max, mean, argmax: 0.00000, 0.94221, 0.01822, 489052
min, max, mean, argmax: 0.00000, 0.98035, 0.00000, 10328681
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.94221, 0.00124, 2198927
min, max, mean, argmax: 0.00000, 0.94221, 0.00009, 5346741
min, max, mean, argmax: 0.00000, 0.94221, 0.00144, 646955
min, max, mean, argmax: 0.00000, 0.94221, 0.00077, 3032047
min, max, mean, argmax: 0.00000, 0.95160, 0.00608, 1407
rawpy read the file at location: ./dataset/Sony/long/00057_00_10s.ARW
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.98035, 0.00013, 6606155
min, max, mean, argmax: 0.00000, 1.00000, 0.00027, 353239
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 1.00000, 0.00075, 877649
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.95160, 0.00000, 4792466
min, max, mean, argmax: 0.00000, 0.95160, 0.00045, 3173995
min, max, mean, argmax: 0.00000, 0.95160, 0.00212, 3012800
min, max, mean, argmax: 0.00000, 1.00000, 0.00086, 732975
rawpy read the file at location: ./dataset/Sony/long/00059_00_10s.ARW
min, max, mean, argmax: 0.00000, 1.00000, 0.01515, 5126389
min, max, mean, argmax: 0.00000, 1.00000, 0.00000, 221629
min, max, mean, argmax: 0.00000, 0.98035, 0.00000, 895895
min, max, mean, argmax: 0.00000, 0.94221, 0.00088, 121547
min, max, mean, argmax: 0.00000, 0.89525, 0.00000, 6694829
min, max, mean, argmax: 0.00000, 0.98035, 0.00001, 2019203
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.95160, 0.00108, 2924589
min, max, mean, argmax: 0.00000, 0.98035, 0.00000, 6922649
min, max, mean, argmax: 0.00000, 0.94221, 0.00179, 8237
rawpy read the file at location: ./dataset/Sony/long/00026_00_10s.ARW
min, max, mean, argmax: 0.00000, 1.00000, 0.00100, 255039
min, max, mean, argmax: 0.00000, 0.98035, 0.00826, 3862619
min, max, mean, argmax: 0.00000, 1.00000, 0.00162, 27523
min, max, mean, argmax: 0.00000, 0.95160, 0.00438, 4373627
min, max, mean, argmax: 0.00000, 0.95160, 0.00199, 6454
min, max, mean, argmax: 0.00000, 1.00000, 0.00032, 4246091
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.94221, 0.00129, 952285
min, max, mean, argmax: 0.00000, 0.98035, 0.00499, 2253
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
rawpy read the file at location: ./dataset/Sony/long/00012_00_10s.ARW
min, max, mean, argmax: 0.00000, 1.00000, 0.00000, 6320171
min, max, mean, argmax: 0.00000, 0.98035, 0.00037, 8352977
min, max, mean, argmax: 0.00000, 0.98035, 0.00191, 2730987
min, max, mean, argmax: 0.00000, 1.00000, 0.00010, 830169
min, max, mean, argmax: 0.00000, 1.00000, 0.00218, 106691
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.94221, 0.00767, 2536575
min, max, mean, argmax: 0.00000, 0.95160, 0.00000, 6777631
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
rawpy read the file at location: ./dataset/Sony/long/00090_00_30s.ARW
min, max, mean, argmax: 0.00000, 0.98035, 0.00283, 6265
min, max, mean, argmax: 0.00000, 1.00000, 0.00000, 9536203
min, max, mean, argmax: 0.00000, 0.95160, 0.00922, 1211799
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.94221, 0.00000, 1962014
min, max, mean, argmax: 0.00000, 0.95160, 0.00124, 1095547
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 1.00000, 0.00110, 208955
min, max, mean, argmax: 0.00000, 0.98035, 0.00527, 1787501
min, max, mean, argmax: 0.00000, 0.98035, 0.00048, 2237695
rawpy read the file at location: ./dataset/Sony/long/00114_00_30s.ARW
min, max, mean, argmax: 0.00000, 0.98035, 0.00016, 2570045
min, max, mean, argmax: 0.00000, 1.00000, 0.00002, 4933369
min, max, mean, argmax: 0.00000, 0.98035, 0.00018, 2972
min, max, mean, argmax: 0.00000, 0.94221, 0.00014, 8615375
min, max, mean, argmax: 0.00000, 1.00000, 0.06347, 1502619
min, max, mean, argmax: 0.00000, 0.98035, 0.00151, 1940733
min, max, mean, argmax: 0.00000, 1.00000, 0.00007, 8449
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 1.00000, 0.00079, 506409
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
rawpy read the file at location: ./dataset/Sony/long/00156_00_30s.ARW
min, max, mean, argmax: 0.00000, 0.95160, 0.00819, 2309
min, max, mean, argmax: 0.00000, 0.94221, 0.00131, 1993235
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
min, max, mean, argmax: 0.00000, 0.95160, 0.03645, 2694439
min, max, mean, argmax: 0.00000, 1.00000, 0.00922, 2353163
min, max, mean, argmax: 0.00000, 1.00000, 0.00030, 2700797
min, max, mean, argmax: 0.00000, 0.94221, 0.01375, 7293
min, max, mean, argmax: 0.00000, 1.00000, 0.00021, 581525
min, max, mean, argmax: 0.00000, 1.00000, 0.00004, 4860611
min, max, mean, argmax: 0.00000, 0.98035, 0.00430, 5285
rawpy read the file at location: ./dataset/Sony/long/00219_00_10s.ARW
min, max, mean, argmax: 0.00000, 0.00000, 0.00000, 0
161 images loaded to CPU RAM in Time=41.918 seconds.
Starting Training on index 93
[[1 0 0]]
[[0 0 0]]
Epoch 0: batch 1: Loss=1.099, Moving loss=0.011, Time=1.204
Traceback (most recent call last):
  File "train_for_gamma_Sony_dead_simple.py", line 329, in <module>
    os.mkdir(result_dir + '%04d' % epoch)
OSError: [Errno 2] No such file or directory: './gt_Sony_dead_simple_new/0000'
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ mkdir gt_Sony_dead_simple_new
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ vi train_for_gamma_Sony_dead_simple.py 
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ python train_for_gamma_Sony_dead_simple.py 




Found 161 images to train with

2020-12-11 04:00:54.375711: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 04:00:54.491080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 04:00:54.491113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 04:00:54.770619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 04:00:54.770657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 04:00:54.770674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 04:00:54.770773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.89525, 0.00000, 250.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01648, 100.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 250.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00190, 250.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.02310, 250.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00417, 300.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00894, 100.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00228, 300.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 250.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 250.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00012, 100.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 300.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00144, 300.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00301, 300.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00002, 250.00000, 6735543
rawpy read the 20th file at location: ./dataset/Sony/long/00072_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00003, 300.00000, 7298885
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00153, 100.00000, 1272259
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 142725
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00497, 100.00000, 822369
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00011, 300.00000, 2983955
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00116, 250.00000, 2393979
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.03368, 250.00000, 2641491
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00003, 100.00000, 1597850
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 250.00000, 1430113
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
rawpy read the 30th file at location: ./dataset/Sony/long/00039_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.07893, 250.00000, 535
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00249, 100.00000, 2877047
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00027, 300.00000, 271135
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 11918285
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00060, 100.00000, 3901
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 100.00000, 684739
rawpy read the 40th file at location: ./dataset/Sony/long/00200_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00299, 100.00000, 1458719
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.01101, 100.00000, 1212279
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00237, 300.00000, 2952517
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00215, 300.00000, 158803
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00165, 300.00000, 2486907
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00202, 250.00000, 7900835
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00007, 100.00000, 4543563
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.05081, 300.00000, 3437
rawpy read the 50th file at location: ./dataset/Sony/long/00024_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00048, 300.00000, 33748
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00375, 100.00000, 3626303
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01253, 300.00000, 304767
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00059, 250.00000, 5644
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00062, 100.00000, 4526
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00008, 100.00000, 11755519
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00012, 250.00000, 2512821
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01871, 250.00000, 2025
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00342, 100.00000, 5557479
rawpy read the 60th file at location: ./dataset/Sony/long/00084_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00340, 300.00000, 67803
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00228, 100.00000, 103
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 250.00000, 1696711
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00637, 250.00000, 2302635
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00053, 250.00000, 1589659
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00720, 100.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00517, 300.00000, 3437411
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00952, 300.00000, 1033619
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00001, 100.00000, 742143
rawpy read the 70th file at location: ./dataset/Sony/long/00164_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00411, 300.00000, 509891
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 433279
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00114, 100.00000, 6156358
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00004, 100.00000, 2110981
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00084, 300.00000, 277500
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.02923, 100.00000, 646472
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00062, 100.00000, 5676651
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 100.00000, 7066147
rawpy read the 80th file at location: ./dataset/Sony/long/00128_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00313, 300.00000, 4421929
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.01822, 300.00000, 489052
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 10328681
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00136, 100.00000, 2198927
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00009, 300.00000, 5346741
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00147, 250.00000, 646955
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00077, 300.00000, 3032047
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00651, 100.00000, 1407
rawpy read the 90th file at location: ./dataset/Sony/long/00057_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00013, 100.00000, 6606155
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00027, 300.00000, 353239
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00076, 100.00000, 877649
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00000, 100.00000, 4792466
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00045, 250.00000, 3173995
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00212, 250.00000, 3012800
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00087, 100.00000, 732975
rawpy read the 100th file at location: ./dataset/Sony/long/00059_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01514, 300.00000, 5126389
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 300.00000, 221629
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 895895
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00088, 300.00000, 121547
min, max, mean, gamma, argmax: 0.00000, 0.87565, 0.00000, 300.00000, 6694829
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 2019203
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00106, 300.00000, 2924589
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 6922649
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00179, 300.00000, 8237
rawpy read the 110th file at location: ./dataset/Sony/long/00026_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00099, 300.00000, 255039
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00781, 250.00000, 3862619
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00162, 250.00000, 27523
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00429, 300.00000, 4373627
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00212, 100.00000, 6454
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00032, 250.00000, 4246091
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00129, 300.00000, 952285
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00499, 100.00000, 2253
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
rawpy read the 120th file at location: ./dataset/Sony/long/00012_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 300.00000, 6320171
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00034, 300.00000, 8352977
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00180, 250.00000, 2730987
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 250.00000, 830169
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00217, 250.00000, 106691
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00767, 300.00000, 2536575
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 6777631
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
rawpy read the 130th file at location: ./dataset/Sony/long/00090_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00260, 300.00000, 6265
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 100.00000, 9536203
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00905, 300.00000, 1211799
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 1962014
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00124, 250.00000, 1095547
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00109, 250.00000, 208955
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00488, 300.00000, 1787501
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00048, 100.00000, 2237695
rawpy read the 140th file at location: ./dataset/Sony/long/00114_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00016, 100.00000, 2570045
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00002, 100.00000, 4933369
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00018, 100.00000, 2972
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00014, 250.00000, 8615375
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.06347, 100.00000, 1502619
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00135, 250.00000, 1940733
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00007, 250.00000, 8449
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00079, 250.00000, 506409
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
rawpy read the 150th file at location: ./dataset/Sony/long/00156_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00875, 100.00000, 2309
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00134, 250.00000, 1993235
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.03581, 300.00000, 2694439
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00922, 250.00000, 2353163
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00030, 300.00000, 2700797
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.01404, 250.00000, 7293
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00021, 250.00000, 581525
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00004, 250.00000, 4860611
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00430, 100.00000, 5285
rawpy read the 160th file at location: ./dataset/Sony/long/00219_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
161 images loaded to CPU RAM in Time=38.931 seconds.
Starting Training on index 36
[[0 0 1]]
[[0 0 0]]
Epoch 0: batch 1: Loss=1.099, Moving loss=0.011, Time=1.014
[[0 0 1]]
[[0 0 0]]
[[0 1 0]]
[[0 0 0]]
[[0 0 1]]
[[0 0 0]]
[[0 0 1]]
[[0 0 0]]
[[0 1 0]]
[[0 0 0]]
[[0 1 0]]
[[0 0 0]]
[[1 0 0]]
[[0 0 0]]
[[1 0 0]]
[[0 0 0]]
[[0 1 0]]
[[0 0 0]]
[[0 0 1]]
[[0.0840100944 0.0355344489 0]]
[[0 0 1]]
[[0 0 0.000245488161]]
[[0 1 0]]
[[0 0 0.000991773442]]
[[0 1 0]]
[[0 0 0.00121146743]]
[[0 1 0]]
[[0 0 0.00105076155]]
[[0 0 1]]
[[0 0 0.000673674105]]
[[0 1 0]]
[[0 0 0.000786456862]]
[[0 1 0]]
[[0 0 0.000715094851]]
[[1 0 0]]
[[0 0 0.000504346041]]
[[1 0 0]]
[[0 0 0.000192021776]]
[[0 1 0]]
[[0 0 0]]
[[1 0 0]]
[[0 0 0]]
[[0 0 1]]
[[0 0 0]]
[[0 1 0]]
[[0 0 0]]
[[0 1 0]]
[[0 0 0]]
[[0 1 0]]
[[0 0.0117105907 0]]
[[1 0 0]]
[[0.0168389641 0 0]]
[[1 0 0]]
[[0 0 0]]
[[1 0 0]]
[[1.85658573e-05 0 0]]
[[1 0 0]]
[[0.159037054 0.0279057547 0.0848877057]]
[[1 0 0]]
[[0.0012763181 9.26922803e-05 0]]
[[0 1 0]]
[[0.0022513147 0 0]]
[[0 1 0]]
[[0.00295963255 0 0]]
[[0 1 0]]
[[0.0033727109 0 0]]
[[1 0 0]]
[[0.00349856541 0 0]]
[[0 0 1]]
[[0.00404426828 0 0]]
[[0 0 1]]
[[0.00431299023 0 0]]
[[0 1 0]]
[[0.00432380149 0 0]]
[[1 0 0]]
[[0.00411017705 0 0]]
[[1 0 0]]
[[0.00435747 0 0]]
[[0 1 0]]
[[0.0049971668 0 0]]
[[1 0 0]]
[[0.00535847 0 0]]
[[1 0 0]]
[[0.00714087579 0 0]]
[[0 0 1]]
[[0.00729375193 0 0]]
[[0 1 0]]
[[0.0394823626 0.00382424239 0]]
[[0 1 0]]
[[0.00843288098 0 0]]
[[0 1 0]]
[[0.00846377946 0 0]]
[[0 0 1]]
[[0.00822356343 0 0]]
[[0 1 0]]
[[0.00775359571 0 0]]
[[0 0 1]]
[[0.00711819669 0 0]]
[[0 1 0]]
[[0.00635015033 0 0]]
[[0 1 0]]
[[0.00548513 6.88733417e-05 0]]
[[0 1 0]]
[[0.0045610955 0.000517054112 0]]
[[0 0 1]]
[[0.00363769 0.00106432673 0]]
[[0 1 0]]
[[0.00274368166 0.00139768771 0]]
[[1 0 0]]
[[0.00188639399 0.00179497048 0]]
[[0 1 0]]
[[0.00141471205 0.00204578508 0]]
[[0 1 0]]
[[0.000897132035 0.00240154937 0]]
[[0 0 1]]
[[0.000359199 0.00284584984 0]]
[[0 1 0]]
[[0 0.00313994521 0]]
[[0 1 0]]
[[0 0.00357873645 0]]
[[0 0 1]]
[[0 0.00417641923 0]]
[[0 0 1]]
[[0 0.00460789 0]]
[[0 0 1]]
[[0 0.00486056972 0]]
[[0 1 0]]
[[0 0.00493113417 0]]
[[1 0 0]]
[[0 0.00527752796 0]]
[[0 0 1]]
[[0 0.00543299271 0]]
[[0 1 0]]
[[0 0.00540887425 0]]
[[0 0 1]]
[[0 0.0057018 0]]
[[1 0 0]]
[[0 0.00580833759 0]]
[[1 0 0]]
[[0 0.00573390769 0]]
[[1 0 0]]
[[0.0116556 0.0282838512 0.00548009621]]
[[0 0 1]]
[[0 0.00518144667 0]]
[[0 1 0]]
[[0 0.00474639097 0]]
[[0 1 0]]
[[0 0.00466727 0]]
[[0 1 0]]
[[0 0.00488290749 0]]
[[0 0 1]]
[[0 0.00535532925 0]]
[[0 0 1]]
[[0.0523811691 0 0]]
[[1 0 0]]
[[0 0.00590208266 0]]
[[0 1 0]]
[[0 0.00598690147 0]]
[[0 0 1]]
[[0 0.00635788077 0]]
[[1 0 0]]
[[0 0.00654182443 0]]
[[0 0 1]]
[[0 0 5.59101463e-05]]
[[1 0 0]]
[[0 0.00643079495 0]]
[[0 0 1]]
[[0 0.00753218587 0]]
[[0 1 0]]
[[0 0.00580187608 0]]
[[0 1 0]]
[[0 0.0057491092 0]]
[[0 1 0]]
[[0 0.00596842449 0]]
[[0 1 0]]
[[0 0.00643088436 0]]
[[0 0 1]]
[[0 0.00712266751 0]]
[[0 0 1]]
[[0 0.0104529038 0]]
[[1 0 0]]
[[0 0.00789871439 0]]
[[0 0 1]]
[[0 0.00800772291 0]]
[[1 0 0]]
[[0 0.00795226917 0]]
[[0 0 1]]
[[0 0.0077517936 0]]
[[1 0 0]]
[[0 0.00742733292 0]]
[[1 0 0]]
[[0 0.0069988519 0]]
[[1 0 0]]
[[0 0.0064857495 0.000278601801]]
[[0 1 0]]
[[0 0.00595138501 0.000238710229]]
[[1 0 0]]
[[0 0.00577344652 0]]
[[1 0 0]]
[[0 0.00712359324 0]]
[[1 0 0]]
[[0 0.00515416311 0]]
[[0 1 0]]
[[0 0.00473811058 0]]
[[0 0 1]]
[[0 0.00458707381 0]]
[[0 1 0]]
[[0 0.00435224222 0]]
[[0 0 1]]
[[0 0.00434267335 0]]
[[0 1 0]]
[[0.0524874069 0 0]]
[[0 0 1]]
[[0 0.00415159948 0]]
[[0 1 0]]
[[0 0.0039820252 0]]
[[0 0 1]]
[[0 0.00401354488 0]]
[[0 1 0]]
[[0 0.0039511025 0]]
[[0 0 1]]
[[0.00357564865 0.00139572727 0]]
[[0 0 1]]
[[0 0.00410802197 0]]
[[0 0 1]]
[[0 0.00404850813 0]]
[[0 1 0]]
[[0 0.00390573824 0]]
[[0 0 1]]
[[0.354369581 0 0]]
[[0 1 0]]
[[0 0.00402016565 0]]
[[1 0 0]]
[[0 0.00426360965 0]]
[[1 0 0]]
[[0 0.00439087441 0]]
[[0 1 0]]
[[0 0.00441046618 0]]
[[0 1 0]]
[[0 0.00461920025 0]]
[[1 0 0]]
[[0 0.00500343693 0]]
[[0 1 0]]
[[0 0.00525357295 0]]
[[0 0 1]]
[[0 0.00568471756 0]]
[[0 0 1]]
[[0 0.00597248971 0]]
[[1 0 0]]
[[0 0.00612367038 0]]
[[0 0 1]]
[[0 0.00614875462 0]]
[[0 0 1]]
[[0 0.0197085515 0]]
[[1 0 0]]
[[0 0.00589004951 0]]
[[1 0 0]]
[[0 0 0.0101079214]]
[[0 0 1]]
[[0 0.00546207605 0]]
[[0 1 0]]
[[0 0.00520779425 0]]
[[1 0 0]]
[[0 0 0]]
[[1 0 0]]
[[0 0.00515169464 0]]
[[0 1 0]]
[[0 0.00502926856 0]]
[[0 1 0]]
[[0 0.00511209 0]]
[[1 0 0]]
[[0 0.00538062491 0]]
[[0 0 1]]
[[0 0.00552407885 0]]
[[0 0 1]]
[[0 0.00559489708 0]]
[[1 0 0]]
[[0 0.0054806117 0]]
[[0 0 1]]
[[0 0.00531644 0]]
[[0 0 1]]
[[0 0.00507278321 0]]
[[0 0 1]]
[[0 0.00476168469 0]]
[[0 1 0]]
[[0 0.00439453125 0]]
[[0 1 0]]
[[0 0.00424778 0]]
[[0 0 1]]
[[0 0.0042909272 0]]
[[1 0 0]]
[[0 0.00424242159 0]]
[[1 0 0]]
[[0 0.00411273865 0]]
[[0 0 1]]
[[0 0.00391240465 0]]
[[1 0 0]]
[[0 0.0036476627 0]]
[[1 0 0]]
[[0 0.00331264921 0]]
[[0 0 1]]
[[0 0.00292165624 0]]
[[0 1 0]]
[[0 0.00248906971 0]]
[[0 1 0]]
[[0 0.00228725979 0]]
[[0 1 0]]
[[0 0.00227548881 0]]
[[1 0 0]]
[[0 0.00242561963 0]]
[[0 1 0]]
[[0 0.0024770603 0]]
[[0 0 1]]
[[0 0.00267560058 0]]
[[1 0 0]]
[[0 0.00277572172 0]]
[[1 0 0]]
[[0 0.00278462283 0]]
[[1 0 0]]
[[0 0.00272191595 0]]
[[0 0 1]]
[[0 0.00259863795 0]]
Epoch 1: batch 1: Loss=1.100, Moving loss=0.883, Time=0.020
[[0 1 0]]
[[0 0.00242218468 0]]
[[0 1 0]]
[[0 0.00239587133 0]]
[[1 0 0]]
[[0 0.00250167097 0]]
[[0 0 1]]
[[0 0.00253176666 0]]
[[1 0 0]]
[[0 0.0024943098 0]]
[[1 0 0]]
[[0 0.00239683711 0]]
[[0 1 0]]
[[0.0365621075 0 0.0102199474]]
[[0 0 1]]
[[0 0.0021483975 0]]
[[0 0 1]]
[[0.00276066689 0.00497596338 0]]
[[0 1 0]]
[[0 0.00181916065 0]]
[[0 1 0]]
[[0 0 0]]
[[0 1 0]]
[[0 0.00175103417 0]]
[[0 1 0]]
[[0 0.00185716921 0]]
[[0 1 0]]
[[0 0.00209371746 0]]
[[1 0 0]]
[[0 0.00245323568 0]]
[[0 1 0]]
[[0 0.00271134474 0]]
[[0 0 1]]
[[0 0.00310297171 0]]
[[0 1 0]]
[[0 0.00338199665 0]]
[[0 0 1]]
[[0 0.00380619848 0]]
[[0 0 1]]
[[0 0.00410713581 0]]
[[0 1 0]]
[[0 0.0042876075 0]]
[[0 0 1]]
[[0 0.0046432768 0]]
[[1 0 0]]
[[0 0 0]]
[[0 0 1]]
[[0 0.00506973593 0]]
[[0 1 0]]
[[0 0.0347880311 0.0331563093]]
[[0 1 0]]
[[0 0.0528699458 0.0451671332]]
[[1 0 0]]
[[0 0 0.0500649475]]
[[0 1 0]]
[[0 0.00655486528 0]]
[[0 1 0]]
[[0 0.0073664682 0]]
[[0 1 0]]
[[0.0240392573 0 0]]
[[1 0 0]]
[[0 0.00957275089 0]]
[[0 1 0]]
[[0 0.0104249222 0]]
[[1 0 0]]
[[0 0.0116827125 0]]
[[0 0 1]]
[[0 0.0126095405 0]]
[[0 1 0]]
[[0 0.0131855756 0]]
[[0 0 1]]
[[0 0.0142865386 0]]
[[0 0 1]]
[[0 0.0149923535 0]]
[[1 0 0]]
[[0.0890419483 0 0]]
[[0 0 1]]
[[0 0.0154365068 0]]
[[1 0 0]]
[[0 0.015221376 0]]
[[0 1 0]]
[[0 0.0147126717 0]]
[[0 1 0]]
[[0 0.0148690427 0]]
[[1 0 0]]
[[0 0.0156085 0]]
^CTraceback (most recent call last):
  File "train_for_gamma_Sony_dead_simple.py", line 298, in <module>
    feed_dict={in_image: input_patch, gt_gamma: assigned_image_gamma_index, lr: learning_rate})
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 887, in run
    run_metadata_ptr)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1110, in _run
    feed_dict_tensor, options, run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1286, in _do_run
    run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1292, in _do_call
    return fn(*args)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1277, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1367, in _call_tf_sessionrun
    run_metadata)
KeyboardInterrupt
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ vi images-with-gamma-statistics.txt
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ rm train_for_gamma_Sony_dead_simple.py 
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ vi train_for_gamma_Sony_dead_simple.py 
(sid2) [ir967@gr043 Learning-to-See-in-the-Dark]$ python train_for_gamma_Sony_dead_simple.py 




Found 161 images to train with

2020-12-11 04:12:49.605199: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 04:12:49.719343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 04:12:49.719377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 04:12:49.999682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 04:12:49.999719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 04:12:49.999748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 04:12:49.999917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)
loaded ./gt_Sony_dead_simple_new/model.ckpt

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.87565, 0.00000, 300.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01631, 300.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 250.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00190, 250.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.02310, 250.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00467, 100.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00887, 250.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00228, 300.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 250.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00613, 100.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00012, 300.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 250.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00155, 100.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00301, 300.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00002, 250.00000, 6735543
rawpy read the 20th file at location: ./dataset/Sony/long/00072_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00003, 100.00000, 7298885
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00143, 250.00000, 1272259
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 142725
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00497, 100.00000, 822369
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00012, 100.00000, 2983955
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00123, 100.00000, 2393979
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.03368, 250.00000, 2641491
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00003, 300.00000, 1597850
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 100.00000, 1430113
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
rawpy read the 30th file at location: ./dataset/Sony/long/00039_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.07888, 300.00000, 535
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00247, 250.00000, 2877047
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00027, 300.00000, 271135
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 11918285
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00057, 250.00000, 3901
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 250.00000, 684739
rawpy read the 40th file at location: ./dataset/Sony/long/00200_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00246, 250.00000, 1458719
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00976, 300.00000, 1212279
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00257, 100.00000, 2952517
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00235, 100.00000, 158803
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00168, 250.00000, 2486907
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00202, 250.00000, 7900835
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00005, 300.00000, 4543563
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.05083, 100.00000, 3437
rawpy read the 50th file at location: ./dataset/Sony/long/00024_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00048, 100.00000, 33748
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00375, 100.00000, 3626303
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01253, 300.00000, 304767
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00059, 250.00000, 5644
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00062, 300.00000, 4526
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00008, 100.00000, 11755519
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00012, 300.00000, 2512821
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01888, 100.00000, 2025
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00338, 300.00000, 5557479
rawpy read the 60th file at location: ./dataset/Sony/long/00084_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00340, 300.00000, 67803
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00228, 100.00000, 103
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 250.00000, 1696711
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00622, 300.00000, 2302635
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00053, 300.00000, 1589659
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00720, 100.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00528, 250.00000, 3437411
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00952, 300.00000, 1033619
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00001, 300.00000, 742143
rawpy read the 70th file at location: ./dataset/Sony/long/00164_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00444, 100.00000, 509891
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 433279
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00104, 300.00000, 6156358
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00004, 100.00000, 2110981
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00090, 100.00000, 277500
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.02923, 100.00000, 646472
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00062, 100.00000, 5676651
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 300.00000, 7066147
rawpy read the 80th file at location: ./dataset/Sony/long/00128_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00320, 250.00000, 4421929
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.01853, 250.00000, 489052
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00000, 100.00000, 10328681
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00124, 300.00000, 2198927
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00010, 250.00000, 5346741
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00147, 250.00000, 646955
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00077, 300.00000, 3032047
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00651, 100.00000, 1407
rawpy read the 90th file at location: ./dataset/Sony/long/00057_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00010, 300.00000, 6606155
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00027, 250.00000, 353239
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00075, 300.00000, 877649
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 4792466
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00045, 250.00000, 3173995
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00226, 100.00000, 3012800
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00086, 250.00000, 732975
rawpy read the 100th file at location: ./dataset/Sony/long/00059_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01523, 100.00000, 5126389
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 300.00000, 221629
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 895895
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00088, 300.00000, 121547
min, max, mean, gamma, argmax: 0.00000, 0.87565, 0.00000, 300.00000, 6694829
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 2019203
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00106, 300.00000, 2924589
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 6922649
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00195, 100.00000, 8237
rawpy read the 110th file at location: ./dataset/Sony/long/00026_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00100, 100.00000, 255039
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00766, 300.00000, 3862619
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00162, 300.00000, 27523
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00467, 100.00000, 4373627
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00212, 100.00000, 6454
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00032, 300.00000, 4246091
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00129, 300.00000, 952285
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00472, 250.00000, 2253
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
rawpy read the 120th file at location: ./dataset/Sony/long/00012_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 300.00000, 6320171
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00034, 300.00000, 8352977
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00180, 250.00000, 2730987
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 100.00000, 830169
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00218, 100.00000, 106691
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00827, 100.00000, 2536575
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 6777631
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
rawpy read the 130th file at location: ./dataset/Sony/long/00090_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00260, 300.00000, 6265
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 300.00000, 9536203
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00905, 300.00000, 1211799
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 1962014
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00122, 300.00000, 1095547
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00109, 250.00000, 208955
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00497, 250.00000, 1787501
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00045, 250.00000, 2237695
rawpy read the 140th file at location: ./dataset/Sony/long/00114_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00015, 250.00000, 2570045
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00002, 250.00000, 4933369
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00017, 250.00000, 2972
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00014, 250.00000, 8615375
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.06321, 300.00000, 1502619
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00135, 250.00000, 1940733
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00007, 300.00000, 8449
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00083, 100.00000, 506409
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
rawpy read the 150th file at location: ./dataset/Sony/long/00156_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00875, 100.00000, 2309
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00143, 100.00000, 1993235
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.03859, 100.00000, 2694439
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00925, 100.00000, 2353163
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00030, 300.00000, 2700797
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.01503, 100.00000, 7293
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00021, 300.00000, 581525
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00004, 100.00000, 4860611
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00430, 100.00000, 5285
rawpy read the 160th file at location: ./dataset/Sony/long/00219_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
161 images loaded to CPU RAM in Time=37.608 seconds.
Epoch 1: batch 1: Loss=1.099, Moving loss=0.011, Time=1.026
Epoch 1: Moving loss=0.880, Time=3.809, Epoch time = 3.809, Avg epoch time=1.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 2: batch 1: Loss=1.098, Moving loss=0.883, Time=0.011
Epoch 3: batch 1: Loss=1.098, Moving loss=1.055, Time=0.011
Epoch 4: batch 1: Loss=1.101, Moving loss=1.090, Time=0.010
Epoch 5: batch 1: Loss=1.097, Moving loss=1.097, Time=0.011
Epoch 6: batch 1: Loss=1.098, Moving loss=1.097, Time=0.010
Epoch 7: batch 1: Loss=1.094, Moving loss=1.096, Time=0.019
Epoch 8: batch 1: Loss=1.096, Moving loss=1.094, Time=0.020
Epoch 9: batch 1: Loss=1.095, Moving loss=1.096, Time=0.019
Epoch 10: batch 1: Loss=1.095, Moving loss=1.094, Time=0.011
Epoch 11: batch 1: Loss=1.094, Moving loss=1.093, Time=0.010
Epoch 11: Moving loss=1.093, Time=31.344, Epoch time = 2.777, Avg epoch time=2.000

[[1.16505527]
 [1.00994503]
 [0.95972711]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 12: batch 1: Loss=1.092, Moving loss=1.093, Time=0.010
Epoch 13: batch 1: Loss=1.095, Moving loss=1.093, Time=0.019
Epoch 14: batch 1: Loss=1.095, Moving loss=1.094, Time=0.011
Epoch 15: batch 1: Loss=1.100, Moving loss=1.098, Time=0.019
Epoch 16: batch 1: Loss=1.085, Moving loss=1.092, Time=0.011
Epoch 17: batch 1: Loss=1.099, Moving loss=1.092, Time=0.011
Epoch 18: batch 1: Loss=1.091, Moving loss=1.094, Time=0.011
Epoch 19: batch 1: Loss=1.096, Moving loss=1.095, Time=0.010
Epoch 20: batch 1: Loss=1.089, Moving loss=1.093, Time=0.013
Epoch 21: batch 1: Loss=1.095, Moving loss=1.094, Time=0.011
Epoch 21: Moving loss=1.092, Time=59.113, Epoch time = 2.701, Avg epoch time=2.000

[[1.27981484]
 [0.93123865]
 [0.98833156]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 22: batch 1: Loss=1.092, Moving loss=1.092, Time=0.020
Epoch 23: batch 1: Loss=1.093, Moving loss=1.092, Time=0.010
Epoch 24: batch 1: Loss=1.092, Moving loss=1.093, Time=0.010
Epoch 25: batch 1: Loss=1.090, Moving loss=1.090, Time=0.010
Epoch 26: batch 1: Loss=1.091, Moving loss=1.089, Time=0.010
Epoch 27: batch 1: Loss=1.089, Moving loss=1.089, Time=0.011
Epoch 28: batch 1: Loss=1.092, Moving loss=1.090, Time=0.011
Epoch 29: batch 1: Loss=1.089, Moving loss=1.087, Time=0.010
Epoch 30: batch 1: Loss=1.090, Moving loss=1.088, Time=0.016
Epoch 31: batch 1: Loss=1.086, Moving loss=1.089, Time=0.013
Epoch 31: Moving loss=1.088, Time=86.794, Epoch time = 2.720, Avg epoch time=2.000

[[1.3214525 ]
 [0.91928792]
 [0.93239653]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 32: batch 1: Loss=1.089, Moving loss=1.088, Time=0.010
Epoch 33: batch 1: Loss=1.096, Moving loss=1.092, Time=0.011
Epoch 34: batch 1: Loss=1.088, Moving loss=1.091, Time=0.011
Epoch 35: batch 1: Loss=1.089, Moving loss=1.089, Time=0.011
Epoch 36: batch 1: Loss=1.092, Moving loss=1.090, Time=0.020
Epoch 37: batch 1: Loss=1.088, Moving loss=1.090, Time=0.011
Epoch 38: batch 1: Loss=1.092, Moving loss=1.089, Time=0.010
Epoch 39: batch 1: Loss=1.092, Moving loss=1.090, Time=0.010
Epoch 40: batch 1: Loss=1.088, Moving loss=1.089, Time=0.010
Epoch 41: batch 1: Loss=1.089, Moving loss=1.088, Time=0.010
Epoch 41: Moving loss=1.088, Time=114.496, Epoch time = 2.698, Avg epoch time=2.000

[[1.35642064]
 [0.86110127]
 [0.94452131]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 42: batch 1: Loss=1.088, Moving loss=1.088, Time=0.011
Epoch 43: batch 1: Loss=1.090, Moving loss=1.089, Time=0.011
Epoch 44: batch 1: Loss=1.093, Moving loss=1.090, Time=0.010
Epoch 45: batch 1: Loss=1.089, Moving loss=1.090, Time=0.010
Epoch 46: batch 1: Loss=1.091, Moving loss=1.090, Time=0.010
Epoch 47: batch 1: Loss=1.086, Moving loss=1.087, Time=0.010
Epoch 48: batch 1: Loss=1.089, Moving loss=1.087, Time=0.010
Epoch 49: batch 1: Loss=1.092, Moving loss=1.091, Time=0.020
Epoch 50: batch 1: Loss=1.092, Moving loss=1.091, Time=0.020
Epoch 51: batch 1: Loss=1.091, Moving loss=1.090, Time=0.018
Epoch 51: Moving loss=1.091, Time=142.474, Epoch time = 2.716, Avg epoch time=2.000

[[1.29911661]
 [0.92902929]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 52: batch 1: Loss=1.090, Moving loss=1.091, Time=0.011
Epoch 53: batch 1: Loss=1.090, Moving loss=1.089, Time=0.020
Epoch 54: batch 1: Loss=1.089, Moving loss=1.089, Time=0.010
Epoch 55: batch 1: Loss=1.090, Moving loss=1.089, Time=0.020
Epoch 56: batch 1: Loss=1.094, Moving loss=1.092, Time=0.004
Epoch 57: batch 1: Loss=1.090, Moving loss=1.092, Time=0.011
Epoch 58: batch 1: Loss=1.087, Moving loss=1.089, Time=0.020
Epoch 59: batch 1: Loss=1.087, Moving loss=1.088, Time=0.010
Epoch 60: batch 1: Loss=1.090, Moving loss=1.088, Time=0.020
Epoch 61: batch 1: Loss=1.093, Moving loss=1.090, Time=0.011
Epoch 61: Moving loss=1.089, Time=170.154, Epoch time = 2.812, Avg epoch time=2.000

[[1.31542516]
 [0.94007874]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 62: batch 1: Loss=1.088, Moving loss=1.089, Time=0.010
Epoch 63: batch 1: Loss=1.091, Moving loss=1.089, Time=0.010
Epoch 64: batch 1: Loss=1.089, Moving loss=1.089, Time=0.010
Epoch 65: batch 1: Loss=1.089, Moving loss=1.089, Time=0.010
Epoch 66: batch 1: Loss=1.094, Moving loss=1.091, Time=0.011
Epoch 67: batch 1: Loss=1.091, Moving loss=1.091, Time=0.011
Epoch 68: batch 1: Loss=1.092, Moving loss=1.092, Time=0.010
Epoch 69: batch 1: Loss=1.086, Moving loss=1.087, Time=0.011
Epoch 70: batch 1: Loss=1.089, Moving loss=1.087, Time=0.010
Epoch 71: batch 1: Loss=1.091, Moving loss=1.089, Time=0.011
Epoch 71: Moving loss=1.087, Time=197.924, Epoch time = 2.672, Avg epoch time=2.000

[[1.264606  ]
 [0.9251104 ]
 [0.95097935]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 72: batch 1: Loss=1.087, Moving loss=1.087, Time=0.011
Epoch 73: batch 1: Loss=1.092, Moving loss=1.089, Time=0.019
Epoch 74: batch 1: Loss=1.086, Moving loss=1.089, Time=0.011
Epoch 75: batch 1: Loss=1.084, Moving loss=1.085, Time=0.010
Epoch 76: batch 1: Loss=1.088, Moving loss=1.087, Time=0.011
Epoch 77: batch 1: Loss=1.089, Moving loss=1.088, Time=0.010
Epoch 78: batch 1: Loss=1.088, Moving loss=1.087, Time=0.019
Epoch 79: batch 1: Loss=1.088, Moving loss=1.089, Time=0.019
Epoch 80: batch 1: Loss=1.090, Moving loss=1.089, Time=0.010
Epoch 81: batch 1: Loss=1.090, Moving loss=1.091, Time=0.011
Epoch 81: Moving loss=1.090, Time=225.690, Epoch time = 2.756, Avg epoch time=2.000

[[1.32118857]
 [0.92583418]
 [0.93554139]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 82: batch 1: Loss=1.092, Moving loss=1.090, Time=0.010
Epoch 83: batch 1: Loss=1.087, Moving loss=1.089, Time=0.010
Epoch 84: batch 1: Loss=1.085, Moving loss=1.087, Time=0.010
Epoch 85: batch 1: Loss=1.088, Moving loss=1.088, Time=0.011
Epoch 86: batch 1: Loss=1.089, Moving loss=1.088, Time=0.011
Epoch 87: batch 1: Loss=1.093, Moving loss=1.091, Time=0.013
Epoch 88: batch 1: Loss=1.088, Moving loss=1.091, Time=0.019
Epoch 89: batch 1: Loss=1.093, Moving loss=1.093, Time=0.011
Epoch 90: batch 1: Loss=1.093, Moving loss=1.094, Time=0.019
Epoch 91: batch 1: Loss=1.089, Moving loss=1.090, Time=0.011
Epoch 91: Moving loss=1.087, Time=253.393, Epoch time = 2.784, Avg epoch time=2.000

[[1.34731138]
 [0.94188184]
 [0.93927348]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 92: batch 1: Loss=1.085, Moving loss=1.087, Time=0.019
Epoch 93: batch 1: Loss=1.123, Moving loss=1.108, Time=0.004
Epoch 94: batch 1: Loss=1.095, Moving loss=1.107, Time=0.010
Epoch 95: batch 1: Loss=1.088, Moving loss=1.093, Time=0.012
Epoch 96: batch 1: Loss=1.088, Moving loss=1.089, Time=0.010
Epoch 97: batch 1: Loss=1.092, Moving loss=1.092, Time=0.011
Epoch 98: batch 1: Loss=1.086, Moving loss=1.088, Time=0.019
Epoch 99: batch 1: Loss=1.089, Moving loss=1.089, Time=0.011
Epoch 100: batch 1: Loss=1.087, Moving loss=1.088, Time=0.020
Epoch 101: batch 1: Loss=1.086, Moving loss=1.086, Time=0.010
Epoch 101: Moving loss=1.086, Time=281.009, Epoch time = 2.727, Avg epoch time=2.000

[[1.36799002]
 [0.93416816]
 [0.90218687]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 102: batch 1: Loss=1.088, Moving loss=1.086, Time=0.020
Epoch 103: batch 1: Loss=1.090, Moving loss=1.089, Time=0.010
Epoch 104: batch 1: Loss=1.086, Moving loss=1.088, Time=0.012
Epoch 105: batch 1: Loss=1.090, Moving loss=1.089, Time=0.010
Epoch 106: batch 1: Loss=1.091, Moving loss=1.090, Time=0.011
Epoch 107: batch 1: Loss=1.088, Moving loss=1.089, Time=0.020
Epoch 108: batch 1: Loss=1.084, Moving loss=1.085, Time=0.008
Epoch 109: batch 1: Loss=1.090, Moving loss=1.085, Time=0.011
Epoch 110: batch 1: Loss=1.086, Moving loss=1.087, Time=0.010
Epoch 111: batch 1: Loss=1.092, Moving loss=1.088, Time=0.011
Epoch 111: Moving loss=1.091, Time=308.651, Epoch time = 2.781, Avg epoch time=2.000

[[1.31718004]
 [0.93550247]
 [0.91432214]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 112: batch 1: Loss=1.091, Moving loss=1.091, Time=0.011
Epoch 113: batch 1: Loss=1.087, Moving loss=1.090, Time=0.010
Epoch 114: batch 1: Loss=1.084, Moving loss=1.084, Time=0.010
Epoch 115: batch 1: Loss=1.090, Moving loss=1.086, Time=0.010
Epoch 116: batch 1: Loss=1.087, Moving loss=1.088, Time=0.011
Epoch 117: batch 1: Loss=1.089, Moving loss=1.089, Time=0.014
Epoch 118: batch 1: Loss=1.088, Moving loss=1.087, Time=0.010
Epoch 119: batch 1: Loss=1.089, Moving loss=1.088, Time=0.019
Epoch 120: batch 1: Loss=1.085, Moving loss=1.087, Time=0.020
Epoch 121: batch 1: Loss=1.087, Moving loss=1.088, Time=0.004
Epoch 121: Moving loss=1.087, Time=336.608, Epoch time = 2.772, Avg epoch time=2.000

[[1.32597566]
 [0.9182505 ]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 122: batch 1: Loss=1.088, Moving loss=1.087, Time=0.010
Epoch 123: batch 1: Loss=1.087, Moving loss=1.086, Time=0.010
Epoch 124: batch 1: Loss=1.091, Moving loss=1.089, Time=0.010
Epoch 125: batch 1: Loss=1.085, Moving loss=1.088, Time=0.010
Epoch 126: batch 1: Loss=1.088, Moving loss=1.087, Time=0.011
Epoch 127: batch 1: Loss=1.090, Moving loss=1.088, Time=0.010
Epoch 128: batch 1: Loss=1.093, Moving loss=1.091, Time=0.010
Epoch 129: batch 1: Loss=1.090, Moving loss=1.089, Time=0.011
Epoch 130: batch 1: Loss=1.088, Moving loss=1.089, Time=0.004
Epoch 131: batch 1: Loss=1.088, Moving loss=1.088, Time=0.010
Epoch 131: Moving loss=1.085, Time=364.112, Epoch time = 2.764, Avg epoch time=2.000

[[1.38002777]
 [0.92772782]
 [0.90808207]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 132: batch 1: Loss=1.084, Moving loss=1.085, Time=0.011
Epoch 133: batch 1: Loss=1.091, Moving loss=1.086, Time=0.014
Epoch 134: batch 1: Loss=1.084, Moving loss=1.086, Time=0.010
Epoch 135: batch 1: Loss=1.090, Moving loss=1.088, Time=0.010
Epoch 136: batch 1: Loss=1.089, Moving loss=1.089, Time=0.010
Epoch 137: batch 1: Loss=1.088, Moving loss=1.090, Time=0.011
Epoch 138: batch 1: Loss=1.088, Moving loss=1.090, Time=0.011
Epoch 139: batch 1: Loss=1.086, Moving loss=1.088, Time=0.011
Epoch 140: batch 1: Loss=1.092, Moving loss=1.089, Time=0.010
Epoch 141: batch 1: Loss=1.086, Moving loss=1.087, Time=0.010
Epoch 141: Moving loss=1.086, Time=391.760, Epoch time = 2.729, Avg epoch time=2.000

[[1.34508538]
 [0.9408443 ]
 [0.9311049 ]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 142: batch 1: Loss=1.087, Moving loss=1.086, Time=0.020
srun: Force Terminated job 401604
slurmstepd: error: *** STEP 401604.0 ON gr043-ib0 CANCELLED AT 2020-12-11T04:20:02 DUE TO TIME LIMIT ***
Epoch 143: batch 1: Loss=1.085, Moving loss=1.084, Time=0.011
Epoch 144: batch 1: Loss=1.091, Moving loss=1.087, Time=0.010
Epoch 145: batch 1: Loss=1.088, Moving loss=1.090, Time=0.019
Epoch 146: batch 1: Loss=1.090, Moving loss=1.087, Time=0.010
Epoch 147: batch 1: Loss=1.087, Moving loss=1.087, Time=0.011
Epoch 148: batch 1: Loss=1.090, Moving loss=1.088, Time=0.010
Epoch 149: batch 1: Loss=1.089, Moving loss=1.091, Time=0.011
Epoch 150: batch 1: Loss=1.088, Moving loss=1.089, Time=0.019
Epoch 151: batch 1: Loss=1.086, Moving loss=1.087, Time=0.011
Epoch 151: Moving loss=1.085, Time=419.226, Epoch time = 2.691, Avg epoch time=2.000

[[1.35611653]
 [0.92913985]
 [0.91961014]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 152: batch 1: Loss=1.085, Moving loss=1.085, Time=0.010
Epoch 153: batch 1: Loss=1.091, Moving loss=1.090, Time=0.020
srun: error: gr043-ib0: task 0: Killed
srun: Terminating job step 401604.0
srun: Force Terminated job step 401604.0
(base) [ir967@log-3 ~]$ pwd
/home/ir967
(base) [ir967@log-3 ~]$ cd $SCRATCH/SID
(base) [ir967@log-3 SID]$ cd Learning-to-See-in-the-Dark/
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ vi dead_simple_logs1.tx
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ vi dead_simple_logs1.txt
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ srun -t0:20:00 --mem=18460 --gres=gpu:1 --pty /bin/bash
srun: job 401621 queued and waiting for resources
srun: job 401621 has been allocated resources
(base) [ir967@gr018 Learning-to-See-in-the-Dark]$ conda activate sid2
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ cd $SCRATCH/SID
(sid2) [ir967@gr018 SID]$ cd Learning-to-See-in-the-Dark/
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ python train_for_gamma_Sony_dead_simple.py 




Found 161 images to train with

2020-12-11 04:23:04.318494: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 04:23:04.463993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:86:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 04:23:04.464028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 04:23:06.246053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 04:23:06.246091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 04:23:06.246096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 04:23:06.246246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5)
loaded ./gt_Sony_dead_simple_new/model.ckpt

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 150
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95669, 0.00000, 100.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01648, 100.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 100.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00187, 300.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.02465, 100.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00417, 300.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00894, 100.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00233, 250.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 250.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 300.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00012, 300.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 250.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00144, 300.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00307, 250.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00002, 250.00000, 6735543
rawpy read the 20th file at location: ./dataset/Sony/long/00072_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00003, 250.00000, 7298885
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00153, 100.00000, 1272259
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 142725
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00497, 100.00000, 822369
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00011, 300.00000, 2983955
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00114, 300.00000, 2393979
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.03368, 250.00000, 2641491
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00003, 300.00000, 1597850
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 300.00000, 1430113
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
rawpy read the 30th file at location: ./dataset/Sony/long/00039_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.07940, 100.00000, 535
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00249, 100.00000, 2877047
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00027, 300.00000, 271135
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 11918285
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00056, 300.00000, 3901
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 250.00000, 684739
rawpy read the 40th file at location: ./dataset/Sony/long/00200_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00246, 250.00000, 1458719
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00998, 250.00000, 1212279
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00237, 300.00000, 2952517
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00235, 100.00000, 158803
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00179, 100.00000, 2486907
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00198, 300.00000, 7900835
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00007, 100.00000, 4543563
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.05083, 100.00000, 3437
rawpy read the 50th file at location: ./dataset/Sony/long/00024_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00048, 300.00000, 33748
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00352, 250.00000, 3626303
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01267, 100.00000, 304767
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00059, 250.00000, 5644
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00062, 100.00000, 4526
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00007, 250.00000, 11755519
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00012, 300.00000, 2512821
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01870, 300.00000, 2025
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00338, 250.00000, 5557479
rawpy read the 60th file at location: ./dataset/Sony/long/00084_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00375, 100.00000, 67803
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00228, 100.00000, 103
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 250.00000, 1696711
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00622, 300.00000, 2302635
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00054, 100.00000, 1589659
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00674, 250.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00528, 250.00000, 3437411
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00969, 250.00000, 1033619
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00001, 250.00000, 742143
rawpy read the 70th file at location: ./dataset/Sony/long/00164_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00411, 300.00000, 509891
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 433279
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00106, 250.00000, 6156358
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00004, 300.00000, 2110981
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00084, 300.00000, 277500
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.02918, 300.00000, 646472
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00058, 250.00000, 5676651
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 250.00000, 7066147
rawpy read the 80th file at location: ./dataset/Sony/long/00128_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00343, 100.00000, 4421929
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.01853, 250.00000, 489052
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 10328681
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00127, 250.00000, 2198927
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00010, 250.00000, 5346741
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00144, 300.00000, 646955
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00084, 100.00000, 3032047
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00608, 250.00000, 1407
rawpy read the 90th file at location: ./dataset/Sony/long/00057_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00011, 250.00000, 6606155
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00028, 100.00000, 353239
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00075, 250.00000, 877649
min, max, mean, gamma, argmax: 0.00000, 0.00288, 0.00000, 100.00000, 810977
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 4792466
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00045, 250.00000, 3173995
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00212, 250.00000, 3012800
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00086, 300.00000, 732975
rawpy read the 100th file at location: ./dataset/Sony/long/00059_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01514, 300.00000, 5126389
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 300.00000, 221629
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 895895
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00095, 100.00000, 121547
min, max, mean, gamma, argmax: 0.00000, 0.87565, 0.00000, 300.00000, 6694829
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 2019203
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00114, 100.00000, 2924589
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 6922649
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00179, 300.00000, 8237
rawpy read the 110th file at location: ./dataset/Sony/long/00026_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00099, 300.00000, 255039
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00766, 300.00000, 3862619
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00162, 250.00000, 27523
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00438, 250.00000, 4373627
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00199, 250.00000, 6454
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00032, 300.00000, 4246091
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00129, 300.00000, 952285
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00499, 100.00000, 2253
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
rawpy read the 120th file at location: ./dataset/Sony/long/00012_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 100.00000, 6320171
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00035, 250.00000, 8352977
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00191, 100.00000, 2730987
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 300.00000, 830169
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00218, 100.00000, 106691
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00827, 100.00000, 2536575
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 6777631
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
rawpy read the 130th file at location: ./dataset/Sony/long/00090_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00260, 300.00000, 6265
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 100.00000, 9536203
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00905, 300.00000, 1211799
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 1962014
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00132, 100.00000, 1095547
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00109, 250.00000, 208955
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00527, 100.00000, 1787501
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00048, 100.00000, 2237695
rawpy read the 140th file at location: ./dataset/Sony/long/00114_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00016, 100.00000, 2570045
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00002, 100.00000, 4933369
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00018, 100.00000, 2972
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00014, 250.00000, 8615375
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.06324, 250.00000, 1502619
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00151, 100.00000, 1940733
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00007, 300.00000, 8449
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00083, 100.00000, 506409
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
rawpy read the 150th file at location: ./dataset/Sony/long/00156_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00875, 100.00000, 2309
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00134, 250.00000, 1993235
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.03859, 100.00000, 2694439
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00922, 300.00000, 2353163
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00031, 100.00000, 2700797
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.01375, 300.00000, 7293
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00021, 100.00000, 581525
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00004, 250.00000, 4860611
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00430, 100.00000, 5285
rawpy read the 160th file at location: ./dataset/Sony/long/00219_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
161 images loaded to CPU RAM in Time=42.637 seconds.
Epoch 151: batch 1: Loss=1.067, Moving loss=0.011, Time=1.684
Epoch 151: Moving loss=0.893, Time=4.437, Epoch time = 4.435, Avg epoch time=2.000

[[0.98768401]
 [1.08204949]
 [1.20598042]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 152: batch 1: Loss=1.114, Moving loss=0.895, Time=0.011
Epoch 153: batch 1: Loss=1.106, Moving loss=1.067, Time=0.010
Epoch 154: batch 1: Loss=1.102, Moving loss=1.096, Time=0.012
Epoch 155: batch 1: Loss=1.099, Moving loss=1.100, Time=0.010
Epoch 156: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 157: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 158: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 159: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 160: batch 1: Loss=1.091, Moving loss=1.097, Time=0.010
Epoch 161: batch 1: Loss=1.177, Moving loss=1.157, Time=0.010
Epoch 161: Moving loss=1.157, Time=38.257, Epoch time = 2.745, Avg epoch time=3.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 162: batch 1: Loss=1.099, Moving loss=1.157, Time=0.019
Epoch 163: batch 1: Loss=1.099, Moving loss=1.110, Time=0.011
Epoch 164: batch 1: Loss=1.099, Moving loss=1.101, Time=0.008
Epoch 165: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 166: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 167: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 168: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 169: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 170: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 171: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 171: Moving loss=1.099, Time=66.883, Epoch time = 2.792, Avg epoch time=3.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 172: batch 1: Loss=1.098, Moving loss=1.099, Time=0.010
Epoch 173: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 174: batch 1: Loss=1.103, Moving loss=1.100, Time=0.010
Epoch 175: batch 1: Loss=1.099, Moving loss=1.101, Time=0.019
Epoch 176: batch 1: Loss=1.098, Moving loss=1.098, Time=0.010
Epoch 177: batch 1: Loss=1.101, Moving loss=1.099, Time=0.010
Epoch 178: batch 1: Loss=1.098, Moving loss=1.099, Time=0.010
Epoch 179: batch 1: Loss=1.100, Moving loss=1.099, Time=0.019
Epoch 180: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 181: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 181: Moving loss=1.099, Time=95.586, Epoch time = 2.897, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 182: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 183: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 184: batch 1: Loss=1.097, Moving loss=1.098, Time=0.010
Epoch 185: batch 1: Loss=1.099, Moving loss=1.098, Time=0.010
Epoch 186: batch 1: Loss=1.099, Moving loss=1.098, Time=0.010
Epoch 187: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 188: batch 1: Loss=1.098, Moving loss=1.098, Time=0.010
Epoch 189: batch 1: Loss=1.099, Moving loss=1.098, Time=0.010
Epoch 190: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 191: batch 1: Loss=1.097, Moving loss=1.099, Time=0.010
Epoch 191: Moving loss=1.098, Time=124.277, Epoch time = 2.887, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09985304]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 192: batch 1: Loss=1.099, Moving loss=1.098, Time=0.010
Epoch 193: batch 1: Loss=1.095, Moving loss=1.098, Time=0.010
Epoch 194: batch 1: Loss=1.100, Moving loss=1.099, Time=0.010
Epoch 195: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 196: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 197: batch 1: Loss=1.101, Moving loss=1.100, Time=0.019
Epoch 198: batch 1: Loss=1.099, Moving loss=1.100, Time=0.011
Epoch 199: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 200: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 201: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 201: Moving loss=1.099, Time=152.702, Epoch time = 2.805, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 202: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 203: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 204: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 205: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 206: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 207: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 208: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 209: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 210: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 211: batch 1: Loss=1.099, Moving loss=1.099, Time=0.013
Epoch 211: Moving loss=1.099, Time=181.433, Epoch time = 2.858, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 212: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 213: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 214: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 215: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 216: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 217: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 218: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 219: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 220: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 221: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 221: Moving loss=1.099, Time=209.992, Epoch time = 2.886, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 222: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 223: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 224: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 225: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 226: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 227: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 228: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 229: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 230: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 231: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 231: Moving loss=1.099, Time=238.616, Epoch time = 2.889, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 232: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 233: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 234: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 235: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 236: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 237: batch 1: Loss=1.099, Moving loss=1.099, Time=0.007
Epoch 238: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 239: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 240: batch 1: Loss=1.099, Moving loss=1.099, Time=0.013
Epoch 241: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 241: Moving loss=1.099, Time=267.215, Epoch time = 2.784, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 242: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 243: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 244: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 245: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 246: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 247: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 248: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 249: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 250: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 251: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 251: Moving loss=1.099, Time=295.855, Epoch time = 2.856, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 252: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 253: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 254: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 255: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 256: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 257: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 258: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 259: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 260: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 261: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 261: Moving loss=1.099, Time=324.541, Epoch time = 2.855, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 262: batch 1: Loss=1.099, Moving loss=1.099, Time=0.013
Epoch 263: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 264: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 265: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 266: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 267: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 268: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 269: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 270: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 271: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 271: Moving loss=1.099, Time=353.014, Epoch time = 2.762, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 272: batch 1: Loss=1.099, Moving loss=1.099, Time=0.008
Epoch 273: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 274: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 275: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 276: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 277: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 278: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 279: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 280: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 281: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 281: Moving loss=1.099, Time=381.505, Epoch time = 2.770, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 282: batch 1: Loss=1.099, Moving loss=1.099, Time=0.021
Epoch 283: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 284: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 285: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 286: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 287: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 288: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 289: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 290: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 291: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 291: Moving loss=1.099, Time=410.095, Epoch time = 2.803, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 292: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 293: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 294: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 295: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 296: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 297: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 298: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 299: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 300: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 301: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 301: Moving loss=1.099, Time=438.615, Epoch time = 2.821, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 302: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 303: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 304: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 305: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 306: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 307: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 308: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 309: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 310: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 311: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 311: Moving loss=1.099, Time=466.996, Epoch time = 2.779, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 312: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 313: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 314: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 315: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 316: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 317: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 318: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 319: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 320: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 321: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 321: Moving loss=1.099, Time=495.490, Epoch time = 2.830, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 322: batch 1: Loss=1.099, Moving loss=1.099, Time=0.006
Epoch 323: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 324: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 325: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 326: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 327: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 328: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 329: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 330: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 331: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 331: Moving loss=1.099, Time=524.098, Epoch time = 2.898, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 332: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 333: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 334: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 335: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 336: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 337: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 338: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 339: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 340: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 341: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 341: Moving loss=1.099, Time=552.664, Epoch time = 2.807, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 342: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 343: batch 1: Loss=1.099, Moving loss=1.099, Time=0.006
Epoch 344: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 345: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 346: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 347: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 348: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 349: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 350: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 351: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 351: Moving loss=1.099, Time=581.538, Epoch time = 2.851, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 352: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 353: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 354: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 355: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 356: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 357: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 358: batch 1: Loss=1.099, Moving loss=1.099, Time=0.013
Epoch 359: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 360: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 361: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 361: Moving loss=1.099, Time=610.340, Epoch time = 2.860, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 362: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 363: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 364: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 365: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 366: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 367: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 368: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 369: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 370: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 371: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 371: Moving loss=1.099, Time=639.084, Epoch time = 2.815, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 372: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 373: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 374: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 375: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 376: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 377: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 378: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 379: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 380: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 381: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 381: Moving loss=1.099, Time=667.692, Epoch time = 2.882, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 382: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 383: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 384: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 385: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 386: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 387: batch 1: Loss=1.099, Moving loss=1.099, Time=0.008
Epoch 388: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 389: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 390: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 391: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 391: Moving loss=1.099, Time=696.523, Epoch time = 2.853, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 392: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 393: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 394: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 395: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 396: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 397: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 398: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 399: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 400: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 401: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 401: Moving loss=1.099, Time=724.973, Epoch time = 2.863, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 402: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 403: batch 1: Loss=1.099, Moving loss=1.099, Time=0.006
Epoch 404: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 405: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 406: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 407: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 408: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 409: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 410: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 411: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 411: Moving loss=1.099, Time=753.588, Epoch time = 2.838, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 412: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 413: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 414: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 415: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 416: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 417: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 418: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 419: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 420: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 421: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 421: Moving loss=1.099, Time=782.058, Epoch time = 2.709, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 422: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 423: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 424: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 425: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 426: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 427: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 428: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 429: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 430: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 431: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 431: Moving loss=1.099, Time=810.355, Epoch time = 2.733, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 432: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 433: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 434: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 435: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 436: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 437: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 438: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 439: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 440: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 441: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 441: Moving loss=1.099, Time=838.938, Epoch time = 2.853, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 442: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 443: batch 1: Loss=1.099, Moving loss=1.099, Time=0.009
Epoch 444: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 445: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 446: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 447: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 448: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 449: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 450: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 451: batch 1: Loss=1.099, Moving loss=1.099, Time=0.016
Epoch 451: Moving loss=1.099, Time=867.393, Epoch time = 2.821, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 452: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 453: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 454: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 455: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 456: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 457: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 458: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 459: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 460: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 461: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 461: Moving loss=1.099, Time=896.156, Epoch time = 2.852, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 462: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 463: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 464: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 465: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 466: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 467: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 468: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 469: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 470: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 471: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 471: Moving loss=1.099, Time=924.820, Epoch time = 2.889, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 472: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 473: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 474: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 475: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 476: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 477: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 478: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 479: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 480: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 481: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 481: Moving loss=1.099, Time=953.358, Epoch time = 2.765, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 482: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 483: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 484: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 485: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 486: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 487: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 488: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 489: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 490: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 491: batch 1: Loss=1.099, Moving loss=1.099, Time=0.020
Epoch 491: Moving loss=1.099, Time=981.760, Epoch time = 2.851, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 492: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 493: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 494: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 495: batch 1: Loss=1.099, Moving loss=1.099, Time=0.019
Epoch 496: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 497: batch 1: Loss=1.099, Moving loss=1.099, Time=0.010
Epoch 498: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Epoch 499: batch 1: Loss=1.099, Moving loss=1.099, Time=0.011
Connection to localhost closed by remote host.
Connection to localhost closed.
(base) Ilyeechs-MacBook-Pro:~ ilyeech$ ssh -Y greene
 _   ___   ___   _   _   _ ____   ____ 
| \ | \ \ / / | | | | | | |  _ \ / ___|
|  \| |\ V /| | | | | |_| | |_) | |    
| |\  | | | | |_| | |  _  |  __/| |___ 
|_| \_| |_|  \___/  |_| |_|_|    \____|
 

  ____                          
 / ___|_ __ ___  ___ _ __   ___ 
| |  _| '__/ _ \/ _ \ '_ \ / _ \
| |_| | | |  __/  __/ | | |  __/
 \____|_|  \___|\___|_| |_|\___|

ir967@localhost's password: 
Permission denied, please try again.
ir967@localhost's password: 
Permission denied, please try again.
ir967@localhost's password: 
Last failed login: Fri Dec 11 05:18:14 EST 2020 from 216.165.66.211 on ssh:notty
There were 2 failed login attempts since the last successful login.
Last login: Fri Dec 11 03:09:13 2020 from 216.165.66.211
(base) [ir967@log-3 ~]$ cd $SCRATCH/SID
(base) [ir967@log-3 SID]$ cd Learning-to-See-in-the-Dark/
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ lsvi train_for_gamma_Sony_dead_simple.sbatch
-bash: lsvi: command not found
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ vi train_for_gamma_Sony_dead_simple.sbatch
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ vi train_for_gamma_Sony_dead_simple.sbatch
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ sbatch train_for_gamma_Sony_dead_simple.sbatch 
Submitted batch job 401646
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ squeue -u ir967
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON) 
            401646   rtx8000 gam_dead    ir967  R       4:35      1 gr014-ib0 
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ vi slurm-401646.out 
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ ssh gr014-ib0
Warning: Permanently added 'gr014-ib0,10.0.3.78' (ECDSA) to the list of known hosts.
(base) [ir967@gr014 ~]$ nvidia-smi
Fri Dec 11 05:29:06 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Quadro RTX 8000     On   | 00000000:06:00.0 Off |                    0 |
| N/A   39C    P0    58W / 250W |  43578MiB / 45556MiB |      6%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A    278783      C   python                          43575MiB |
+-----------------------------------------------------------------------------+
(base) [ir967@gr014 ~]$ nvidia-smi
Fri Dec 11 05:29:09 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Quadro RTX 8000     On   | 00000000:06:00.0 Off |                    0 |
| N/A   39C    P0    58W / 250W |  43578MiB / 45556MiB |      5%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A    278783      C   python                          43575MiB |
+-----------------------------------------------------------------------------+
(base) [ir967@gr014 ~]$ nvidia-smi
Fri Dec 11 05:29:10 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Quadro RTX 8000     On   | 00000000:06:00.0 Off |                    0 |
| N/A   39C    P0    58W / 250W |  43578MiB / 45556MiB |      5%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A    278783      C   python                          43575MiB |
+-----------------------------------------------------------------------------+
(base) [ir967@gr014 ~]$ nvidia-smi
Fri Dec 11 05:29:11 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Quadro RTX 8000     On   | 00000000:06:00.0 Off |                    0 |
| N/A   39C    P0    58W / 250W |  43578MiB / 45556MiB |      4%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A    278783      C   python                          43575MiB |
+-----------------------------------------------------------------------------+
(base) [ir967@gr014 ~]$ nvidia-smi
Fri Dec 11 05:29:13 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Quadro RTX 8000     On   | 00000000:06:00.0 Off |                    0 |
| N/A   39C    P0    58W / 250W |  43578MiB / 45556MiB |      5%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A    278783      C   python                          43575MiB |
+-----------------------------------------------------------------------------+
(base) [ir967@gr014 ~]$ nvidia-smi
Fri Dec 11 05:29:21 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Quadro RTX 8000     On   | 00000000:06:00.0 Off |                    0 |
| N/A   39C    P0    59W / 250W |  43578MiB / 45556MiB |      4%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A    278783      C   python                          43575MiB |
+-----------------------------------------------------------------------------+
(base) [ir967@gr014 ~]$ nvidia-smi
Fri Dec 11 05:29:28 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Quadro RTX 8000     On   | 00000000:06:00.0 Off |                    0 |
| N/A   39C    P0    58W / 250W |  43578MiB / 45556MiB |      5%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A    278783      C   python                          43575MiB |
+-----------------------------------------------------------------------------+
(base) [ir967@gr014 ~]$ exit
logout
Connection to gr014-ib0 closed.
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ ssh gr014-ib0
Last login: Fri Dec 11 05:29:02 2020 from 10.0.0.6
(base) [ir967@gr014 ~]$ nvidia-smi
Fri Dec 11 05:29:53 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Quadro RTX 8000     On   | 00000000:06:00.0 Off |                    0 |
| N/A   39C    P0    58W / 250W |  43578MiB / 45556MiB |      5%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A    278783      C   python                          43575MiB |
+-----------------------------------------------------------------------------+
(base) [ir967@gr014 ~]$ nvidia-smi
Fri Dec 11 05:29:55 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Quadro RTX 8000     On   | 00000000:06:00.0 Off |                    0 |
| N/A   39C    P0    59W / 250W |  43578MiB / 45556MiB |      5%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A    278783      C   python                          43575MiB |
+-----------------------------------------------------------------------------+
(base) [ir967@gr014 ~]$ exit
logout
Connection to gr014-ib0 closed.
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ vi slurm-401646.out 
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ ls | grep check
checkpoint
check.sh
gamma_checkpoint
result_Sony_checkDec6
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ bash check.sh 401646
       JobID AveCPUFreq AveDiskWrite                                                                   TRESUsageInMax 
------------ ---------- ------------                            ----------------------------------------------------- 
401646.exte+          0                                                                                               
401646.batch      3.50M     92846062    cpu=00:06:57,energy=0,fs/disk=4320522922,mem=17719660K,pages=0,vmem=69840740K 
JobId=401646 JobName=gam_dead_simple
   UserId=ir967(3395734) GroupId=ir967(3395734) MCS_label=N/A
   Priority=51112 Nice=0 Account=users QOS=gpu48
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   DerivedExitCode=0:0
   RunTime=00:07:21 TimeLimit=04:00:00 TimeMin=N/A
   SubmitTime=2020-12-11T05:22:45 EligibleTime=2020-12-11T05:22:45
   AccrueTime=2020-12-11T05:22:45
   StartTime=2020-12-11T05:23:40 EndTime=2020-12-11T09:23:40 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2020-12-11T05:23:40
   Partition=rtx8000 AllocNode:Sid=log-3:4086319
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=gr014-ib0
   BatchHost=gr014-ib0
   NumNodes=1 NumCPUs=1 NumTasks=1 CPUs/Task=1 ReqB:S:C:T=0:0:*:*
   TRES=cpu=1,mem=19460M,node=1,billing=1,gres/gpu=1
   Socks/Node=* NtasksPerN:B:S:C=1:0:*:* CoreSpec=*
   JOB_GRES=gpu:1
     Nodes=gr014-ib0 CPU_IDs=0 Mem=19460 GRES=gpu:1(IDX:0)
   MinCPUsNode=1 MinMemoryNode=19460M MinTmpDiskNode=0
   Features=(null) DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/scratch/ir967/SID/Learning-to-See-in-the-Dark/train_for_gamma_Sony_dead_simple.sbatch
   WorkDir=/scratch/ir967/SID/Learning-to-See-in-the-Dark
   StdErr=/scratch/ir967/SID/Learning-to-See-in-the-Dark/slurm-401646.out
   StdIn=/dev/null
   StdOut=/scratch/ir967/SID/Learning-to-See-in-the-Dark/slurm-401646.out
   Power=
   TresPerNode=gpu:1
   MailUser=ir967 MailType=BEGIN,END,FAIL

(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ vi train_for_gamma_Sony_dead_simple_3gammas.py
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ vi train_for_gamma_Sony_dead_simple_3gammas.sbatch
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ vi train_for_gamma_Sony_dead_simple_3gammas.py
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ mkdir gt_Sony_dead_simple_3gammas
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ sbatch train_for_gamma_Sony_dead_simple_3gammas.sbatch
Submitted batch job 401650
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ squeue -u ir967
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON) 
            401646   rtx8000 gam_dead    ir967  R      17:31      1 gr014-ib0 
            401650 rtx8000,v gamma_So    ir967 PD       0:00      1 (Resources) 
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ squeue -u ir967
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON) 
            401646   rtx8000 gam_dead    ir967  R      17:45      1 gr014-ib0 
            401650 rtx8000,v gamma_So    ir967 PD       0:00      1 (Resources) 
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ scancel 401650
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ srun -t0:20:00 --mem=5460 --gres=gpu:1 --pty /bin/bash
srun: job 401651 queued and waiting for resources
^Csrun: Job allocation 401651 has been revoked
srun: Force Terminated job 401651
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ squeue -u ir967
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON) 
            401646   rtx8000 gam_dead    ir967  R      23:02      1 gr014-ib0 
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ vi slurm-401646.out 
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ Connection to localhost closed by remote host.
Connection to localhost closed.
(base) Ilyeechs-MacBook-Pro:~ ilyeech$ ssh -Y greene
 _   ___   ___   _   _   _ ____   ____ 
| \ | \ \ / / | | | | | | |  _ \ / ___|
|  \| |\ V /| | | | | |_| | |_) | |    
| |\  | | | | |_| | |  _  |  __/| |___ 
|_| \_| |_|  \___/  |_| |_|_|    \____|
 

  ____                          
 / ___|_ __ ___  ___ _ __   ___ 
| |  _| '__/ _ \/ _ \ '_ \ / _ \
| |_| | | |  __/  __/ | | |  __/
 \____|_|  \___|\___|_| |_|\___|

ir967@localhost's password: 
Last login: Fri Dec 11 05:18:25 2020 from 216.165.66.211
(base) [ir967@log-3 ~]$ cd $SCRATCH/SOID
-bash: cd: /scratch/ir967/SOID: No such file or directory
(base) [ir967@log-3 ~]$ cd $SCRATCH/SID
(base) [ir967@log-3 SID]$ cd Learning-to-See-in-the-Dark/
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ ls
 all_of_gt_Sony                                                      result_Fuji
 all_of_gt_Sony_GPU_efficient                                        result_Sony
 all_of_gt_Sony_GPU_efficient_flattened                             'result_Sony__[1-5]_images'
 all_of_gt_Sony_GPU_efficient_flattened_3output                      result_Sony_20_images
 all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler         result_Sony_checkDec6
 all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler_print   result_Sony_with_gamma_net
 all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler_wider   result_Sony_with_gamma_net_3output
 all_of_gt_Sony_GPU_efficient_flattened_3output_print_test           run1_5_images_result_Sony
 all_of_gt_Sony_GPU_efficient_flattened_3output_simpler              scontrol_8hours.txt
 checkpoint                                                          slurm-401646.out
 check.sh                                                            _slurm_out
 cluster_status.txt                                                  sstat_8hours.txt
 dataset                                                             test_for_gamma_Sony_3output.py
 dead_simple_logs1.txt                                               test_for_gamma_Sony_3output.sbatch
 debug_one_hot.txt                                                   test_for_gamma_Sony.py
 download_dataset.py                                                 test_for_gamma_Sony.sbatch
 download_models.py                                                  test_Fuji.py
 efficiency                                                          test_Fuji.sbatch
 exper.py                                                            test_Sony.py
 exper.sbatch                                                        test_Sony.sbatch
 gamma_checkpoint                                                    test_Sony_with_gamma.py
 gamma_experiment.py                                                 test_Sony_with_gamma.sbatch
 gamma_piecewise.txt                                                 train_for_gamma_Sony_3output_more_simpler_wider.py
 gt_Sony_dead_simple                                                 train_for_gamma_Sony_3output.py
 gt_Sony_dead_simple_3gammas                                         train_for_gamma_Sony_3output.sbatch
 gt_Sony_dead_simple_new                                             train_for_gamma_Sony_dead_simple_3gammas.py
 half_of_gt_Sony                                                     train_for_gamma_Sony_dead_simple_3gammas.sbatch
 HPC-hw4-1a.sh                                                       train_for_gamma_Sony_dead_simple.py
 htop.txt                                                            train_for_gamma_Sony_dead_simple.sbatch
 images                                                              train_for_gamma_Sony.py
 images-with-gamma-statistics.txt                                    train_for_gamma_Sony.sbatch
 LICENSE.md                                                          train_Fuji.py
 logs                                                                train_Fuji.sbatch
 lspci.out                                                           train_Sony.py
 _old_code                                                           train_Sony.sbatch
 README.md
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ vi slurm-401646.out 
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ Connection to localhost closed by remote host.
Connection to localhost closed.
(base) Ilyeechs-MacBook-Pro:~ ilyeech$ ssh -Y greene
 _   ___   ___   _   _   _ ____   ____ 
| \ | \ \ / / | | | | | | |  _ \ / ___|
|  \| |\ V /| | | | | |_| | |_) | |    
| |\  | | | | |_| | |  _  |  __/| |___ 
|_| \_| |_|  \___/  |_| |_|_|    \____|
 

  ____                          
 / ___|_ __ ___  ___ _ __   ___ 
| |  _| '__/ _ \/ _ \ '_ \ / _ \
| |_| | | |  __/  __/ | | |  __/
 \____|_|  \___|\___|_| |_|\___|

ir967@localhost's password: 

Last login: Fri Dec 11 01:21:22 2020 from 10.27.19.125
(base) [ir967@log-2 ~]$ cd $SCRATCH/SID
(base) [ir967@log-2 SID]$ cd Learning-to-See-in-the-Dark/
(base) [ir967@log-2 Learning-to-See-in-the-Dark]$ srun -t3:00:00 --mem=18460 --gres=gpu:1 --pty /bin/bash
srun: job 401926 queued and waiting for resources
srun: job 401926 has been allocated resources
(base) [ir967@gr034 Learning-to-See-in-the-Dark]$ conda activate sid2
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ cd $SCRATCH/SID
(sid2) [ir967@gr034 SID]$ cd Learning-to-See-in-the-Dark/
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ vi train_for_gamma_Sony_dead_simple_3gammas.PY
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ pythong train_for_gamma_Sony_dead_simple_3gammas.PY
bash: pythong: command not found
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ mv train_for_gamma_Sony_dead_simple_3gammas.PY train_for_gamma_Sony_dead_simple_3gammas.py
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ python train_for_gamma_Sony_dead_simple_3gammas.py




Found 161 images to train with

2020-12-11 13:50:39.014280: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 13:50:39.140842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 13:50:39.140878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 13:50:41.909195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 13:50:41.909230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 13:50:41.909254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 13:50:41.909395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)
loaded ./gt_Sony_dead_simple_new/model.ckpt

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 4000
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95669, 0.00000, 100.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01648, 100.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 100.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00201, 100.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.02465, 100.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00467, 100.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00894, 100.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00248, 100.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 100.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00613, 100.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00012, 100.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00117, 100.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00155, 100.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00327, 100.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00003, 100.00000, 6735543
rawpy read the 20th file at location: ./dataset/Sony/long/00072_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00003, 100.00000, 7298885
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00153, 100.00000, 1272259
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00000, 100.00000, 142725
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00497, 100.00000, 822369
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00012, 100.00000, 2983955
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00123, 100.00000, 2393979
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.03574, 100.00000, 2641491
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00003, 100.00000, 1597850
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 100.00000, 1430113
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
rawpy read the 30th file at location: ./dataset/Sony/long/00039_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.07940, 100.00000, 535
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00249, 100.00000, 2877047
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00027, 100.00000, 271135
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 11918285
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00060, 100.00000, 3901
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 100.00000, 684739
rawpy read the 40th file at location: ./dataset/Sony/long/00200_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00299, 100.00000, 1458719
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.01101, 100.00000, 1212279
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00257, 100.00000, 2952517
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00235, 100.00000, 158803
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00179, 100.00000, 2486907
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00215, 100.00000, 7900835
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00007, 100.00000, 4543563
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.05083, 100.00000, 3437
rawpy read the 50th file at location: ./dataset/Sony/long/00024_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00048, 100.00000, 33748
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00375, 100.00000, 3626303
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01267, 100.00000, 304767
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00063, 100.00000, 5644
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00062, 100.00000, 4526
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00008, 100.00000, 11755519
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00016, 100.00000, 2512821
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01888, 100.00000, 2025
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00342, 100.00000, 5557479
rawpy read the 60th file at location: ./dataset/Sony/long/00084_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00375, 100.00000, 67803
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00228, 100.00000, 103
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 100.00000, 1696711
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00688, 100.00000, 2302635
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00054, 100.00000, 1589659
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00720, 100.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00563, 100.00000, 3437411
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.01027, 100.00000, 1033619
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00001, 100.00000, 742143
rawpy read the 70th file at location: ./dataset/Sony/long/00164_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00444, 100.00000, 509891
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 433279
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00114, 100.00000, 6156358
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00004, 100.00000, 2110981
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00090, 100.00000, 277500
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.02923, 100.00000, 646472
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00062, 100.00000, 5676651
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 100.00000, 7066147
rawpy read the 80th file at location: ./dataset/Sony/long/00128_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00343, 100.00000, 4421929
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.01954, 100.00000, 489052
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00000, 100.00000, 10328681
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00136, 100.00000, 2198927
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00012, 100.00000, 5346741
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00156, 100.00000, 646955
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00084, 100.00000, 3032047
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00651, 100.00000, 1407
rawpy read the 90th file at location: ./dataset/Sony/long/00057_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00013, 100.00000, 6606155
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00028, 100.00000, 353239
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00076, 100.00000, 877649
min, max, mean, gamma, argmax: 0.00000, 0.00288, 0.00000, 100.00000, 810977
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00000, 100.00000, 4792466
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00051, 100.00000, 3173995
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00226, 100.00000, 3012800
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00087, 100.00000, 732975
rawpy read the 100th file at location: ./dataset/Sony/long/00059_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01523, 100.00000, 5126389
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 100.00000, 221629
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00000, 100.00000, 895895
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00095, 100.00000, 121547
min, max, mean, gamma, argmax: 0.00000, 0.95669, 0.00000, 100.00000, 6694829
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 2019203
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00114, 100.00000, 2924589
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00000, 100.00000, 6922649
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00195, 100.00000, 8237
rawpy read the 110th file at location: ./dataset/Sony/long/00026_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00100, 100.00000, 255039
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00826, 100.00000, 3862619
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00166, 100.00000, 27523
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00467, 100.00000, 4373627
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00212, 100.00000, 6454
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00032, 100.00000, 4246091
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00139, 100.00000, 952285
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00499, 100.00000, 2253
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
rawpy read the 120th file at location: ./dataset/Sony/long/00012_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 100.00000, 6320171
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00037, 100.00000, 8352977
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00191, 100.00000, 2730987
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 100.00000, 830169
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00218, 100.00000, 106691
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00827, 100.00000, 2536575
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 6777631
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
rawpy read the 130th file at location: ./dataset/Sony/long/00090_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00283, 100.00000, 6265
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 100.00000, 9536203
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00981, 100.00000, 1211799
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00000, 100.00000, 1962014
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00132, 100.00000, 1095547
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00110, 100.00000, 208955
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00527, 100.00000, 1787501
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00048, 100.00000, 2237695
rawpy read the 140th file at location: ./dataset/Sony/long/00114_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00016, 100.00000, 2570045
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00002, 100.00000, 4933369
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00018, 100.00000, 2972
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00016, 100.00000, 8615375
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.06347, 100.00000, 1502619
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00151, 100.00000, 1940733
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00007, 100.00000, 8449
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00083, 100.00000, 506409
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
rawpy read the 150th file at location: ./dataset/Sony/long/00156_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00875, 100.00000, 2309
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00143, 100.00000, 1993235
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.03859, 100.00000, 2694439
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00925, 100.00000, 2353163
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00031, 100.00000, 2700797
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.01503, 100.00000, 7293
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00021, 100.00000, 581525
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00004, 100.00000, 4860611
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00430, 100.00000, 5285
rawpy read the 160th file at location: ./dataset/Sony/long/00219_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.89525, 0.00000, 250.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01633, 250.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 250.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00190, 250.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.02310, 250.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00427, 250.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00887, 250.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00233, 250.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 250.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 250.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00012, 250.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 250.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00146, 250.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00307, 250.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00002, 250.00000, 6735543
rawpy read the 20th file at location: ./dataset/Sony/long/00072_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00003, 250.00000, 7298885
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00143, 250.00000, 1272259
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 142725
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00466, 250.00000, 822369
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00011, 250.00000, 2983955
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00116, 250.00000, 2393979
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.03368, 250.00000, 2641491
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00003, 250.00000, 1597850
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 250.00000, 1430113
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
rawpy read the 30th file at location: ./dataset/Sony/long/00039_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.07893, 250.00000, 535
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00247, 250.00000, 2877047
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00027, 250.00000, 271135
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 11918285
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00057, 250.00000, 3901
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 250.00000, 684739
rawpy read the 40th file at location: ./dataset/Sony/long/00200_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00246, 250.00000, 1458719
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00998, 250.00000, 1212279
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00241, 250.00000, 2952517
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00219, 250.00000, 158803
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00168, 250.00000, 2486907
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00202, 250.00000, 7900835
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00006, 250.00000, 4543563
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.05081, 250.00000, 3437
rawpy read the 50th file at location: ./dataset/Sony/long/00024_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00048, 250.00000, 33748
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00352, 250.00000, 3626303
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01255, 250.00000, 304767
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00059, 250.00000, 5644
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00062, 250.00000, 4526
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00007, 250.00000, 11755519
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00012, 250.00000, 2512821
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01871, 250.00000, 2025
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00338, 250.00000, 5557479
rawpy read the 60th file at location: ./dataset/Sony/long/00084_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00347, 250.00000, 67803
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00214, 250.00000, 103
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 250.00000, 1696711
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00637, 250.00000, 2302635
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00053, 250.00000, 1589659
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00674, 250.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00528, 250.00000, 3437411
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00969, 250.00000, 1033619
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00001, 250.00000, 742143
rawpy read the 70th file at location: ./dataset/Sony/long/00164_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00419, 250.00000, 509891
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 433279
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00106, 250.00000, 6156358
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00004, 250.00000, 2110981
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00085, 250.00000, 277500
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.02919, 250.00000, 646472
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00058, 250.00000, 5676651
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 250.00000, 7066147
rawpy read the 80th file at location: ./dataset/Sony/long/00128_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00320, 250.00000, 4421929
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.01853, 250.00000, 489052
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 10328681
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00127, 250.00000, 2198927
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00010, 250.00000, 5346741
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00147, 250.00000, 646955
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00079, 250.00000, 3032047
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00608, 250.00000, 1407
rawpy read the 90th file at location: ./dataset/Sony/long/00057_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00011, 250.00000, 6606155
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00027, 250.00000, 353239
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00075, 250.00000, 877649
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 4792466
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00045, 250.00000, 3173995
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00212, 250.00000, 3012800
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00086, 250.00000, 732975
rawpy read the 100th file at location: ./dataset/Sony/long/00059_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01515, 250.00000, 5126389
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 250.00000, 221629
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 895895
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00090, 250.00000, 121547
min, max, mean, gamma, argmax: 0.00000, 0.89525, 0.00000, 250.00000, 6694829
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 2019203
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00108, 250.00000, 2924589
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 6922649
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00182, 250.00000, 8237
rawpy read the 110th file at location: ./dataset/Sony/long/00026_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00099, 250.00000, 255039
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00781, 250.00000, 3862619
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00162, 250.00000, 27523
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00438, 250.00000, 4373627
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00199, 250.00000, 6454
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00032, 250.00000, 4246091
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00131, 250.00000, 952285
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00472, 250.00000, 2253
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
rawpy read the 120th file at location: ./dataset/Sony/long/00012_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 250.00000, 6320171
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00035, 250.00000, 8352977
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00180, 250.00000, 2730987
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 250.00000, 830169
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00217, 250.00000, 106691
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00781, 250.00000, 2536575
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 6777631
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
rawpy read the 130th file at location: ./dataset/Sony/long/00090_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00265, 250.00000, 6265
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 250.00000, 9536203
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00922, 250.00000, 1211799
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 1962014
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00124, 250.00000, 1095547
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00109, 250.00000, 208955
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00497, 250.00000, 1787501
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00045, 250.00000, 2237695
rawpy read the 140th file at location: ./dataset/Sony/long/00114_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00015, 250.00000, 2570045
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00002, 250.00000, 4933369
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00017, 250.00000, 2972
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00014, 250.00000, 8615375
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.06324, 250.00000, 1502619
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00135, 250.00000, 1940733
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00007, 250.00000, 8449
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00079, 250.00000, 506409
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
rawpy read the 150th file at location: ./dataset/Sony/long/00156_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00819, 250.00000, 2309
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00134, 250.00000, 1993235
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.03645, 250.00000, 2694439
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00922, 250.00000, 2353163
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00030, 250.00000, 2700797
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.01404, 250.00000, 7293
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00021, 250.00000, 581525
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00004, 250.00000, 4860611
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00336, 250.00000, 5285
rawpy read the 160th file at location: ./dataset/Sony/long/00219_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.87565, 0.00000, 300.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01631, 300.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00164, 300.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00187, 300.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.02266, 300.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00417, 300.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00886, 300.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00228, 300.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00016, 300.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 300.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00012, 300.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 300.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00144, 300.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00301, 300.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00002, 300.00000, 6735543
rawpy read the 20th file at location: ./dataset/Sony/long/00072_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00003, 300.00000, 7298885
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00141, 300.00000, 1272259
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 142725
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00456, 300.00000, 822369
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00011, 300.00000, 2983955
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00114, 300.00000, 2393979
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.03307, 300.00000, 2641491
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00003, 300.00000, 1597850
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 300.00000, 1430113
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
rawpy read the 30th file at location: ./dataset/Sony/long/00039_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.07888, 300.00000, 535
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00247, 300.00000, 2877047
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00027, 300.00000, 271135
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 11918285
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00056, 300.00000, 3901
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 300.00000, 684739
rawpy read the 40th file at location: ./dataset/Sony/long/00200_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00235, 300.00000, 1458719
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00976, 300.00000, 1212279
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00237, 300.00000, 2952517
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00215, 300.00000, 158803
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00165, 300.00000, 2486907
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00198, 300.00000, 7900835
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00005, 300.00000, 4543563
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.05081, 300.00000, 3437
rawpy read the 50th file at location: ./dataset/Sony/long/00024_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00048, 300.00000, 33748
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00346, 300.00000, 3626303
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01253, 300.00000, 304767
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00058, 300.00000, 5644
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00062, 300.00000, 4526
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00007, 300.00000, 11755519
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00012, 300.00000, 2512821
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01870, 300.00000, 2025
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00338, 300.00000, 5557479
rawpy read the 60th file at location: ./dataset/Sony/long/00084_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00340, 300.00000, 67803
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00210, 300.00000, 103
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 300.00000, 1696711
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00622, 300.00000, 2302635
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00053, 300.00000, 1589659
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00661, 300.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00517, 300.00000, 3437411
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00952, 300.00000, 1033619
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00001, 300.00000, 742143
rawpy read the 70th file at location: ./dataset/Sony/long/00164_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00411, 300.00000, 509891
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 433279
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00104, 300.00000, 6156358
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00004, 300.00000, 2110981
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00084, 300.00000, 277500
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.02918, 300.00000, 646472
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00057, 300.00000, 5676651
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 300.00000, 7066147
rawpy read the 80th file at location: ./dataset/Sony/long/00128_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00313, 300.00000, 4421929
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.01822, 300.00000, 489052
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 10328681
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00124, 300.00000, 2198927
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00009, 300.00000, 5346741
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00144, 300.00000, 646955
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00077, 300.00000, 3032047
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00596, 300.00000, 1407
rawpy read the 90th file at location: ./dataset/Sony/long/00057_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00010, 300.00000, 6606155
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00027, 300.00000, 353239
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00075, 300.00000, 877649
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 4792466
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00044, 300.00000, 3173995
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00208, 300.00000, 3012800
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00086, 300.00000, 732975
rawpy read the 100th file at location: ./dataset/Sony/long/00059_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01514, 300.00000, 5126389
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 300.00000, 221629
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 895895
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00088, 300.00000, 121547
min, max, mean, gamma, argmax: 0.00000, 0.87565, 0.00000, 300.00000, 6694829
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 2019203
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00106, 300.00000, 2924589
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 6922649
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00179, 300.00000, 8237
rawpy read the 110th file at location: ./dataset/Sony/long/00026_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00099, 300.00000, 255039
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00766, 300.00000, 3862619
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00162, 300.00000, 27523
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00429, 300.00000, 4373627
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00196, 300.00000, 6454
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00032, 300.00000, 4246091
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00129, 300.00000, 952285
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00464, 300.00000, 2253
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
rawpy read the 120th file at location: ./dataset/Sony/long/00012_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 300.00000, 6320171
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00034, 300.00000, 8352977
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00176, 300.00000, 2730987
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 300.00000, 830169
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00216, 300.00000, 106691
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00767, 300.00000, 2536575
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 6777631
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
rawpy read the 130th file at location: ./dataset/Sony/long/00090_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00260, 300.00000, 6265
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 300.00000, 9536203
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00905, 300.00000, 1211799
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 1962014
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00122, 300.00000, 1095547
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00109, 300.00000, 208955
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00488, 300.00000, 1787501
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00044, 300.00000, 2237695
rawpy read the 140th file at location: ./dataset/Sony/long/00114_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00015, 300.00000, 2570045
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00002, 300.00000, 4933369
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00017, 300.00000, 2972
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00014, 300.00000, 8615375
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.06321, 300.00000, 1502619
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00130, 300.00000, 1940733
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00007, 300.00000, 8449
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00078, 300.00000, 506409
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
rawpy read the 150th file at location: ./dataset/Sony/long/00156_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00804, 300.00000, 2309
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00131, 300.00000, 1993235
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.03581, 300.00000, 2694439
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00922, 300.00000, 2353163
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00030, 300.00000, 2700797
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.01375, 300.00000, 7293
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00021, 300.00000, 581525
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00004, 300.00000, 4860611
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00320, 300.00000, 5285
rawpy read the 160th file at location: ./dataset/Sony/long/00219_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
483 images loaded to CPU RAM in Time=117.640 seconds.
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ mkdir gt_Sony_dead_simple_3gammas
mkdir: cannot create directory ‘gt_Sony_dead_simple_3gammas’: File exists
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ vi train_for_gamma_Sony_dead_simple_3gammas.py
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ vi train_for_gamma_Sony_dead_simple_3gammas.py
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ python train_for_gamma_Sony_dead_simple_3gammas.py




Found 161 images to train with

2020-12-11 13:56:51.548536: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 13:56:51.692817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 13:56:51.692848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 13:56:51.977757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 13:56:51.977792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 13:56:51.977809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 13:56:51.977902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95669, 0.00000, 100.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01648, 100.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 100.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00201, 100.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.02465, 100.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00467, 100.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00894, 100.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00248, 100.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 100.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00613, 100.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00012, 100.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00117, 100.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00155, 100.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00327, 100.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00003, 100.00000, 6735543
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.89525, 0.00000, 250.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01633, 250.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 250.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00190, 250.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.02310, 250.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00427, 250.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00887, 250.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00233, 250.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 250.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 250.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00012, 250.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 250.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00146, 250.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00307, 250.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00002, 250.00000, 6735543
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.87565, 0.00000, 300.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01631, 300.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00164, 300.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00187, 300.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.02266, 300.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00417, 300.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00886, 300.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00228, 300.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00016, 300.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 300.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00012, 300.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 300.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00144, 300.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00301, 300.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00002, 300.00000, 6735543
60 images loaded to CPU RAM in Time=13.923 seconds.
Starting Training on index 6
Epoch 0: batch 1: Loss=1.097, Time=2.071
Epoch 1: batch 1: Loss=1.099, Time=0.011
Epoch 1: Time=2.779, Epoch time = 0.333, Avg epoch time=1.000

[[1.09869087]
 [1.09930599]
 [1.09781516]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 2: batch 1: Loss=1.099, Time=0.012
Epoch 3: batch 1: Loss=1.095, Time=0.020
Epoch 4: batch 1: Loss=1.098, Time=0.011
Epoch 5: batch 1: Loss=1.095, Time=0.011
Epoch 6: batch 1: Loss=1.099, Time=0.011
Epoch 7: batch 1: Loss=1.100, Time=0.020
Epoch 8: batch 1: Loss=1.099, Time=0.009
Epoch 9: batch 1: Loss=1.100, Time=0.010
Epoch 10: batch 1: Loss=1.100, Time=0.011
Epoch 11: batch 1: Loss=1.095, Time=0.010
Epoch 11: Time=6.277, Epoch time = 0.348, Avg epoch time=0.000

[[1.12401915]
 [1.13982141]
 [1.03514934]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 12: batch 1: Loss=1.103, Time=0.019
Epoch 13: batch 1: Loss=1.108, Time=0.010
Epoch 14: batch 1: Loss=1.101, Time=0.010
Epoch 15: batch 1: Loss=1.099, Time=0.010
Epoch 16: batch 1: Loss=1.098, Time=0.010
Epoch 17: batch 1: Loss=1.106, Time=0.019
Epoch 18: batch 1: Loss=1.099, Time=0.019
Epoch 19: batch 1: Loss=1.101, Time=0.011
Epoch 20: batch 1: Loss=1.099, Time=0.010
Epoch 21: batch 1: Loss=1.099, Time=0.011
Epoch 21: Time=9.927, Epoch time = 0.307, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 22: batch 1: Loss=1.098, Time=0.011
Epoch 23: batch 1: Loss=1.099, Time=0.010
Epoch 24: batch 1: Loss=1.099, Time=0.010
Epoch 25: batch 1: Loss=1.099, Time=0.010
Epoch 26: batch 1: Loss=1.099, Time=0.010
Epoch 27: batch 1: Loss=1.099, Time=0.019
Epoch 28: batch 1: Loss=1.099, Time=0.019
Epoch 29: batch 1: Loss=1.099, Time=0.010
Epoch 30: batch 1: Loss=1.099, Time=0.012
Epoch 31: batch 1: Loss=1.099, Time=0.011
Epoch 31: Time=13.529, Epoch time = 0.353, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 32: batch 1: Loss=1.099, Time=0.019
Epoch 33: batch 1: Loss=1.098, Time=0.011
Epoch 34: batch 1: Loss=1.097, Time=0.010
Epoch 35: batch 1: Loss=1.100, Time=0.011
Epoch 36: batch 1: Loss=1.099, Time=0.018
Epoch 37: batch 1: Loss=1.099, Time=0.010
Epoch 38: batch 1: Loss=1.099, Time=0.010
Epoch 39: batch 1: Loss=1.099, Time=0.010
Epoch 40: batch 1: Loss=1.099, Time=0.010
Epoch 41: batch 1: Loss=1.099, Time=0.014
Epoch 41: Time=17.128, Epoch time = 0.336, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 42: batch 1: Loss=1.099, Time=0.019
Epoch 43: batch 1: Loss=1.099, Time=0.010
Epoch 44: batch 1: Loss=1.099, Time=0.012
Epoch 45: batch 1: Loss=1.099, Time=0.010
Epoch 46: batch 1: Loss=1.099, Time=0.015
Epoch 47: batch 1: Loss=1.099, Time=0.010
Epoch 48: batch 1: Loss=1.099, Time=0.011
Epoch 49: batch 1: Loss=1.099, Time=0.019
Epoch 50: batch 1: Loss=1.099, Time=0.011
Epoch 51: batch 1: Loss=1.099, Time=0.010
Epoch 51: Time=20.787, Epoch time = 0.346, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 52: batch 1: Loss=1.099, Time=0.010
Epoch 53: batch 1: Loss=1.099, Time=0.010
Epoch 54: batch 1: Loss=1.099, Time=0.010
Epoch 55: batch 1: Loss=1.099, Time=0.012
Epoch 56: batch 1: Loss=1.099, Time=0.010
Epoch 57: batch 1: Loss=1.099, Time=0.010
Epoch 58: batch 1: Loss=1.099, Time=0.010
Epoch 59: batch 1: Loss=1.099, Time=0.010
Epoch 60: batch 1: Loss=1.094, Time=0.010
Epoch 61: batch 1: Loss=1.099, Time=0.012
Epoch 61: Time=24.202, Epoch time = 0.326, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 62: batch 1: Loss=1.099, Time=0.010
Epoch 63: batch 1: Loss=1.099, Time=0.011
Epoch 64: batch 1: Loss=1.099, Time=0.010
Epoch 65: batch 1: Loss=1.095, Time=0.010
Epoch 66: batch 1: Loss=1.099, Time=0.010
Epoch 67: batch 1: Loss=1.099, Time=0.010
Epoch 68: batch 1: Loss=1.100, Time=0.010
Epoch 69: batch 1: Loss=1.103, Time=0.010
Epoch 70: batch 1: Loss=1.099, Time=0.010
Epoch 71: batch 1: Loss=1.099, Time=0.011
Epoch 71: Time=27.835, Epoch time = 0.330, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 72: batch 1: Loss=1.099, Time=0.010
Epoch 73: batch 1: Loss=1.099, Time=0.010
Epoch 74: batch 1: Loss=1.099, Time=0.019
Epoch 75: batch 1: Loss=1.099, Time=0.010
Epoch 76: batch 1: Loss=1.097, Time=0.019
Epoch 77: batch 1: Loss=1.099, Time=0.010
Epoch 78: batch 1: Loss=1.099, Time=0.010
Epoch 79: batch 1: Loss=1.099, Time=0.010
Epoch 80: batch 1: Loss=1.099, Time=0.010
Epoch 81: batch 1: Loss=1.099, Time=0.019
Epoch 81: Time=31.446, Epoch time = 0.354, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 82: batch 1: Loss=1.099, Time=0.010
Epoch 83: batch 1: Loss=1.099, Time=0.019
Epoch 84: batch 1: Loss=1.099, Time=0.010
Epoch 85: batch 1: Loss=1.099, Time=0.010
Epoch 86: batch 1: Loss=1.099, Time=0.012
Epoch 87: batch 1: Loss=1.099, Time=0.010
Epoch 88: batch 1: Loss=1.099, Time=0.019
Epoch 89: batch 1: Loss=1.099, Time=0.010
Epoch 90: batch 1: Loss=1.099, Time=0.010
Epoch 91: batch 1: Loss=1.099, Time=0.010
Epoch 91: Time=35.047, Epoch time = 0.358, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 92: batch 1: Loss=1.099, Time=0.010
Epoch 93: batch 1: Loss=1.099, Time=0.010
Epoch 94: batch 1: Loss=1.099, Time=0.012
Epoch 95: batch 1: Loss=1.099, Time=0.010
Epoch 96: batch 1: Loss=1.099, Time=0.010
Epoch 97: batch 1: Loss=1.099, Time=0.014
Epoch 98: batch 1: Loss=1.099, Time=0.011
Epoch 99: batch 1: Loss=1.099, Time=0.010
Epoch 100: batch 1: Loss=1.099, Time=0.010
Epoch 101: batch 1: Loss=1.099, Time=0.010
Epoch 101: Time=38.532, Epoch time = 0.335, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 102: batch 1: Loss=1.099, Time=0.010
Epoch 103: batch 1: Loss=1.099, Time=0.011
Epoch 104: batch 1: Loss=1.099, Time=0.010
Epoch 105: batch 1: Loss=1.099, Time=0.011
Epoch 106: batch 1: Loss=1.102, Time=0.010
Epoch 107: batch 1: Loss=1.099, Time=0.019
Epoch 108: batch 1: Loss=1.099, Time=0.011
Epoch 109: batch 1: Loss=1.099, Time=0.011
Epoch 110: batch 1: Loss=1.099, Time=0.010
Epoch 111: batch 1: Loss=1.099, Time=0.015
Epoch 111: Time=42.117, Epoch time = 0.326, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 112: batch 1: Loss=1.099, Time=0.011
Epoch 113: batch 1: Loss=1.099, Time=0.010
Epoch 114: batch 1: Loss=1.099, Time=0.010
Epoch 115: batch 1: Loss=1.099, Time=0.006
Epoch 116: batch 1: Loss=1.099, Time=0.010
Epoch 117: batch 1: Loss=1.099, Time=0.014
Epoch 118: batch 1: Loss=1.099, Time=0.010
Epoch 119: batch 1: Loss=1.099, Time=0.011
Epoch 120: batch 1: Loss=1.099, Time=0.019
Epoch 121: batch 1: Loss=1.099, Time=0.010
Epoch 121: Time=45.522, Epoch time = 0.337, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 122: batch 1: Loss=1.099, Time=0.019
Epoch 123: batch 1: Loss=1.099, Time=0.019
Epoch 124: batch 1: Loss=1.099, Time=0.010
Epoch 125: batch 1: Loss=1.099, Time=0.010
Epoch 126: batch 1: Loss=1.099, Time=0.004
Epoch 127: batch 1: Loss=1.099, Time=0.010
Epoch 128: batch 1: Loss=1.099, Time=0.010
Epoch 129: batch 1: Loss=1.099, Time=0.010
Epoch 130: batch 1: Loss=1.099, Time=0.010
Epoch 131: batch 1: Loss=1.099, Time=0.011
Epoch 131: Time=49.120, Epoch time = 0.334, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 132: batch 1: Loss=1.099, Time=0.010
Epoch 133: batch 1: Loss=1.099, Time=0.019
Epoch 134: batch 1: Loss=1.099, Time=0.010
Epoch 135: batch 1: Loss=1.099, Time=0.010
Epoch 136: batch 1: Loss=1.099, Time=0.010
Epoch 137: batch 1: Loss=1.099, Time=0.010
Epoch 138: batch 1: Loss=1.099, Time=0.011
Epoch 139: batch 1: Loss=1.100, Time=0.010
Epoch 140: batch 1: Loss=1.099, Time=0.010
Epoch 141: batch 1: Loss=1.099, Time=0.011
Epoch 141: Time=52.528, Epoch time = 0.301, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 142: batch 1: Loss=1.099, Time=0.019
Epoch 143: batch 1: Loss=1.099, Time=0.011
Epoch 144: batch 1: Loss=1.099, Time=0.010
Epoch 145: batch 1: Loss=1.099, Time=0.010
Epoch 146: batch 1: Loss=1.099, Time=0.010
Epoch 147: batch 1: Loss=1.099, Time=0.010
Epoch 148: batch 1: Loss=1.099, Time=0.010
Epoch 149: batch 1: Loss=1.099, Time=0.019
Epoch 150: batch 1: Loss=1.099, Time=0.019
Epoch 151: batch 1: Loss=1.099, Time=0.010
Epoch 151: Time=56.158, Epoch time = 0.348, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 152: batch 1: Loss=1.099, Time=0.019
Epoch 153: batch 1: Loss=1.099, Time=0.019
Epoch 154: batch 1: Loss=1.099, Time=0.010
Epoch 155: batch 1: Loss=1.099, Time=0.010
Epoch 156: batch 1: Loss=1.099, Time=0.010
Epoch 157: batch 1: Loss=1.099, Time=0.010
Epoch 158: batch 1: Loss=1.099, Time=0.019
Epoch 159: batch 1: Loss=1.099, Time=0.019
Epoch 160: batch 1: Loss=1.099, Time=0.021
Epoch 161: batch 1: Loss=1.099, Time=0.019
Epoch 161: Time=59.746, Epoch time = 0.359, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 162: batch 1: Loss=1.099, Time=0.021
Epoch 163: batch 1: Loss=1.099, Time=0.011
Epoch 164: batch 1: Loss=1.099, Time=0.019
Epoch 165: batch 1: Loss=1.099, Time=0.010
Epoch 166: batch 1: Loss=1.099, Time=0.019
Epoch 167: batch 1: Loss=1.099, Time=0.010
Epoch 168: batch 1: Loss=1.099, Time=0.019
Epoch 169: batch 1: Loss=1.099, Time=0.011
Epoch 170: batch 1: Loss=1.099, Time=0.010
Epoch 171: batch 1: Loss=1.099, Time=0.010
Epoch 171: Time=63.325, Epoch time = 0.338, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 172: batch 1: Loss=1.099, Time=0.010
Epoch 173: batch 1: Loss=1.099, Time=0.010
Epoch 174: batch 1: Loss=1.099, Time=0.010
Epoch 175: batch 1: Loss=1.099, Time=0.019
Epoch 176: batch 1: Loss=1.099, Time=0.010
Epoch 177: batch 1: Loss=1.099, Time=0.019
Epoch 178: batch 1: Loss=1.099, Time=0.010
Epoch 179: batch 1: Loss=1.099, Time=0.010
Epoch 180: batch 1: Loss=1.099, Time=0.010
Epoch 181: batch 1: Loss=1.099, Time=0.010
Epoch 181: Time=66.844, Epoch time = 0.311, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 182: batch 1: Loss=1.099, Time=0.010
Epoch 183: batch 1: Loss=1.099, Time=0.010
Epoch 184: batch 1: Loss=1.099, Time=0.010
Epoch 185: batch 1: Loss=1.099, Time=0.010
Epoch 186: batch 1: Loss=1.099, Time=0.010
Epoch 187: batch 1: Loss=1.099, Time=0.019
Epoch 188: batch 1: Loss=1.099, Time=0.010
Epoch 189: batch 1: Loss=1.099, Time=0.010
Epoch 190: batch 1: Loss=1.099, Time=0.015
Epoch 191: batch 1: Loss=1.099, Time=0.011
Epoch 191: Time=70.426, Epoch time = 0.321, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 192: batch 1: Loss=1.099, Time=0.010
Epoch 193: batch 1: Loss=1.099, Time=0.016
Epoch 194: batch 1: Loss=1.099, Time=0.010
Epoch 195: batch 1: Loss=1.099, Time=0.019
Epoch 196: batch 1: Loss=1.099, Time=0.010
Epoch 197: batch 1: Loss=1.099, Time=0.010
Epoch 198: batch 1: Loss=1.099, Time=0.010
Epoch 199: batch 1: Loss=1.099, Time=0.010
Epoch 200: batch 1: Loss=1.099, Time=0.007
Epoch 201: batch 1: Loss=1.099, Time=0.011
Epoch 201: Time=73.999, Epoch time = 0.346, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 202: batch 1: Loss=1.099, Time=0.010
Epoch 203: batch 1: Loss=1.099, Time=0.010
Epoch 204: batch 1: Loss=1.099, Time=0.010
Epoch 205: batch 1: Loss=1.099, Time=0.010
Epoch 206: batch 1: Loss=1.099, Time=0.010
Epoch 207: batch 1: Loss=1.099, Time=0.021
Epoch 208: batch 1: Loss=1.099, Time=0.011
Epoch 209: batch 1: Loss=1.099, Time=0.010
Epoch 210: batch 1: Loss=1.099, Time=0.010
Epoch 211: batch 1: Loss=1.099, Time=0.015
Epoch 211: Time=77.564, Epoch time = 0.327, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 212: batch 1: Loss=1.099, Time=0.020
Epoch 213: batch 1: Loss=1.099, Time=0.019
Epoch 214: batch 1: Loss=1.099, Time=0.011
Epoch 215: batch 1: Loss=1.099, Time=0.010
Epoch 216: batch 1: Loss=1.099, Time=0.010
Epoch 217: batch 1: Loss=1.099, Time=0.016
Epoch 218: batch 1: Loss=1.099, Time=0.019
Epoch 219: batch 1: Loss=1.099, Time=0.019
Epoch 220: batch 1: Loss=1.099, Time=0.010
Epoch 221: batch 1: Loss=1.099, Time=0.013
Epoch 221: Time=81.112, Epoch time = 0.355, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 222: batch 1: Loss=1.099, Time=0.011
Epoch 223: batch 1: Loss=1.099, Time=0.010
Epoch 224: batch 1: Loss=1.099, Time=0.021
Epoch 225: batch 1: Loss=1.099, Time=0.019
Epoch 226: batch 1: Loss=1.099, Time=0.019
Epoch 227: batch 1: Loss=1.099, Time=0.010
Epoch 228: batch 1: Loss=1.099, Time=0.010
Epoch 229: batch 1: Loss=1.099, Time=0.010
Epoch 230: batch 1: Loss=1.099, Time=0.010
Epoch 231: batch 1: Loss=1.099, Time=0.010
Epoch 231: Time=84.694, Epoch time = 0.340, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 232: batch 1: Loss=1.099, Time=0.010
Epoch 233: batch 1: Loss=1.099, Time=0.019
Epoch 234: batch 1: Loss=1.099, Time=0.010
Epoch 235: batch 1: Loss=1.099, Time=0.010
Epoch 236: batch 1: Loss=1.099, Time=0.010
Epoch 237: batch 1: Loss=1.099, Time=0.019
Epoch 238: batch 1: Loss=1.099, Time=0.010
Epoch 239: batch 1: Loss=1.099, Time=0.010
Epoch 240: batch 1: Loss=1.099, Time=0.010
Epoch 241: batch 1: Loss=1.099, Time=0.010
Epoch 241: Time=88.341, Epoch time = 0.336, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 242: batch 1: Loss=1.099, Time=0.010
Epoch 243: batch 1: Loss=1.099, Time=0.010
Epoch 244: batch 1: Loss=1.099, Time=0.010
Epoch 245: batch 1: Loss=1.099, Time=0.010
Epoch 246: batch 1: Loss=1.099, Time=0.010
Epoch 247: batch 1: Loss=1.099, Time=0.010
Epoch 248: batch 1: Loss=1.099, Time=0.010
Epoch 249: batch 1: Loss=1.099, Time=0.010
Epoch 250: batch 1: Loss=1.099, Time=0.019
Epoch 251: batch 1: Loss=1.099, Time=0.019
Epoch 251: Time=91.984, Epoch time = 0.331, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 252: batch 1: Loss=1.099, Time=0.015
Epoch 253: batch 1: Loss=1.099, Time=0.019
Epoch 254: batch 1: Loss=1.099, Time=0.010
Epoch 255: batch 1: Loss=1.099, Time=0.013
Epoch 256: batch 1: Loss=1.099, Time=0.010
Epoch 257: batch 1: Loss=1.099, Time=0.010
Epoch 258: batch 1: Loss=1.099, Time=0.010
Epoch 259: batch 1: Loss=1.099, Time=0.010
Epoch 260: batch 1: Loss=1.099, Time=0.010
Epoch 261: batch 1: Loss=1.099, Time=0.010
Epoch 261: Time=95.621, Epoch time = 0.353, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 262: batch 1: Loss=1.099, Time=0.010
Epoch 263: batch 1: Loss=1.099, Time=0.010
Epoch 264: batch 1: Loss=1.099, Time=0.019
Epoch 265: batch 1: Loss=1.099, Time=0.011
Epoch 266: batch 1: Loss=1.099, Time=0.010
Epoch 267: batch 1: Loss=1.099, Time=0.010
Epoch 268: batch 1: Loss=1.099, Time=0.012
Epoch 269: batch 1: Loss=1.099, Time=0.010
Epoch 270: batch 1: Loss=1.099, Time=0.010
Epoch 271: batch 1: Loss=1.099, Time=0.010
Epoch 271: Time=99.169, Epoch time = 0.341, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 272: batch 1: Loss=1.099, Time=0.011
Epoch 273: batch 1: Loss=1.099, Time=0.010
Epoch 274: batch 1: Loss=1.099, Time=0.010
Epoch 275: batch 1: Loss=1.099, Time=0.019
Epoch 276: batch 1: Loss=1.099, Time=0.010
Epoch 277: batch 1: Loss=1.099, Time=0.010
Epoch 278: batch 1: Loss=1.099, Time=0.010
Epoch 279: batch 1: Loss=1.099, Time=0.014
Epoch 280: batch 1: Loss=1.099, Time=0.010
Epoch 281: batch 1: Loss=1.099, Time=0.011
Epoch 281: Time=102.806, Epoch time = 0.344, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 282: batch 1: Loss=1.099, Time=0.008
Epoch 283: batch 1: Loss=1.099, Time=0.020
Epoch 284: batch 1: Loss=1.099, Time=0.020
Epoch 285: batch 1: Loss=1.099, Time=0.010
Epoch 286: batch 1: Loss=1.099, Time=0.010
Epoch 287: batch 1: Loss=1.099, Time=0.010
Epoch 288: batch 1: Loss=1.099, Time=0.010
Epoch 289: batch 1: Loss=1.099, Time=0.019
Epoch 290: batch 1: Loss=1.099, Time=0.010
Epoch 291: batch 1: Loss=1.099, Time=0.011
Epoch 291: Time=106.327, Epoch time = 0.342, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 292: batch 1: Loss=1.099, Time=0.010
Epoch 293: batch 1: Loss=1.099, Time=0.019
Epoch 294: batch 1: Loss=1.099, Time=0.010
Epoch 295: batch 1: Loss=1.099, Time=0.007
Epoch 296: batch 1: Loss=1.099, Time=0.010
Epoch 297: batch 1: Loss=1.099, Time=0.010
Epoch 298: batch 1: Loss=1.099, Time=0.019
Epoch 299: batch 1: Loss=1.099, Time=0.010
Epoch 300: batch 1: Loss=1.099, Time=0.010
Epoch 301: batch 1: Loss=1.099, Time=0.020
Epoch 301: Time=109.901, Epoch time = 0.351, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 302: batch 1: Loss=1.099, Time=0.010
Epoch 303: batch 1: Loss=1.099, Time=0.010
Epoch 304: batch 1: Loss=1.099, Time=0.010
Epoch 305: batch 1: Loss=1.099, Time=0.010
Epoch 306: batch 1: Loss=1.099, Time=0.010
Epoch 307: batch 1: Loss=1.099, Time=0.008
Epoch 308: batch 1: Loss=1.099, Time=0.019
Epoch 309: batch 1: Loss=1.099, Time=0.010
Epoch 310: batch 1: Loss=1.099, Time=0.012
Epoch 311: batch 1: Loss=1.099, Time=0.010
Epoch 311: Time=113.539, Epoch time = 0.361, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 312: batch 1: Loss=1.099, Time=0.010
Epoch 313: batch 1: Loss=1.099, Time=0.010
Epoch 314: batch 1: Loss=1.099, Time=0.004
Epoch 315: batch 1: Loss=1.099, Time=0.010
Epoch 316: batch 1: Loss=1.099, Time=0.010
Epoch 317: batch 1: Loss=1.099, Time=0.019
Epoch 318: batch 1: Loss=1.099, Time=0.010
Epoch 319: batch 1: Loss=1.099, Time=0.019
Epoch 320: batch 1: Loss=1.099, Time=0.019
Epoch 321: batch 1: Loss=1.099, Time=0.020
Epoch 321: Time=117.145, Epoch time = 0.360, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 322: batch 1: Loss=1.099, Time=0.019
Epoch 323: batch 1: Loss=1.099, Time=0.010
Epoch 324: batch 1: Loss=1.099, Time=0.010
Epoch 325: batch 1: Loss=1.099, Time=0.011
Epoch 326: batch 1: Loss=1.099, Time=0.010
Epoch 327: batch 1: Loss=1.099, Time=0.010
Epoch 328: batch 1: Loss=1.099, Time=0.010
Epoch 329: batch 1: Loss=1.099, Time=0.010
Epoch 330: batch 1: Loss=1.099, Time=0.019
Epoch 331: batch 1: Loss=1.099, Time=0.019
Epoch 331: Time=120.723, Epoch time = 0.357, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 332: batch 1: Loss=1.099, Time=0.010
Epoch 333: batch 1: Loss=1.099, Time=0.010
Epoch 334: batch 1: Loss=1.099, Time=0.010
Epoch 335: batch 1: Loss=1.099, Time=0.019
Epoch 336: batch 1: Loss=1.099, Time=0.010
Epoch 337: batch 1: Loss=1.099, Time=0.010
Epoch 338: batch 1: Loss=1.099, Time=0.010
Epoch 339: batch 1: Loss=1.099, Time=0.019
Epoch 340: batch 1: Loss=1.099, Time=0.010
Epoch 341: batch 1: Loss=1.099, Time=0.010
Epoch 341: Time=124.224, Epoch time = 0.341, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 342: batch 1: Loss=1.099, Time=0.013
Epoch 343: batch 1: Loss=1.099, Time=0.011
Epoch 344: batch 1: Loss=1.099, Time=0.010
Epoch 345: batch 1: Loss=1.099, Time=0.010
Epoch 346: batch 1: Loss=1.099, Time=0.011
Epoch 347: batch 1: Loss=1.099, Time=0.005
Epoch 348: batch 1: Loss=1.099, Time=0.010
Epoch 349: batch 1: Loss=1.099, Time=0.021
Epoch 350: batch 1: Loss=1.099, Time=0.010
Epoch 351: batch 1: Loss=1.099, Time=0.010
Epoch 351: Time=127.853, Epoch time = 0.337, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 352: batch 1: Loss=1.099, Time=0.020
Epoch 353: batch 1: Loss=1.099, Time=0.017
Epoch 354: batch 1: Loss=1.099, Time=0.010
Epoch 355: batch 1: Loss=1.099, Time=0.010
Epoch 356: batch 1: Loss=1.099, Time=0.010
Epoch 357: batch 1: Loss=1.099, Time=0.005
Epoch 358: batch 1: Loss=1.099, Time=0.011
Epoch 359: batch 1: Loss=1.099, Time=0.019
Epoch 360: batch 1: Loss=1.099, Time=0.013
Epoch 361: batch 1: Loss=1.099, Time=0.010
Epoch 361: Time=131.531, Epoch time = 0.359, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 362: batch 1: Loss=1.099, Time=0.019
Epoch 363: batch 1: Loss=1.099, Time=0.010
Epoch 364: batch 1: Loss=1.099, Time=0.019
Epoch 365: batch 1: Loss=1.099, Time=0.010
Epoch 366: batch 1: Loss=1.099, Time=0.010
Epoch 367: batch 1: Loss=1.099, Time=0.012
Epoch 368: batch 1: Loss=1.099, Time=0.010
Epoch 369: batch 1: Loss=1.099, Time=0.010
Epoch 370: batch 1: Loss=1.099, Time=0.010
Epoch 371: batch 1: Loss=1.099, Time=0.021
Epoch 371: Time=135.122, Epoch time = 0.320, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 372: batch 1: Loss=1.099, Time=0.019
Epoch 373: batch 1: Loss=1.099, Time=0.010
Epoch 374: batch 1: Loss=1.099, Time=0.010
Epoch 375: batch 1: Loss=1.099, Time=0.010
Epoch 376: batch 1: Loss=1.099, Time=0.010
Epoch 377: batch 1: Loss=1.099, Time=0.006
Epoch 378: batch 1: Loss=1.099, Time=0.019
Epoch 379: batch 1: Loss=1.099, Time=0.010
Epoch 380: batch 1: Loss=1.099, Time=0.019
Epoch 381: batch 1: Loss=1.099, Time=0.010
Epoch 381: Time=138.733, Epoch time = 0.339, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 382: batch 1: Loss=1.099, Time=0.016
Epoch 383: batch 1: Loss=1.099, Time=0.010
Epoch 384: batch 1: Loss=1.099, Time=0.010
Epoch 385: batch 1: Loss=1.099, Time=0.010
Epoch 386: batch 1: Loss=1.099, Time=0.010
Epoch 387: batch 1: Loss=1.099, Time=0.011
Epoch 388: batch 1: Loss=1.098, Time=0.010
Epoch 389: batch 1: Loss=1.105, Time=0.010
Epoch 390: batch 1: Loss=1.093, Time=0.010
Epoch 391: batch 1: Loss=1.098, Time=0.010
Epoch 391: Time=142.345, Epoch time = 0.338, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.06206894]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 392: batch 1: Loss=1.096, Time=0.011
Epoch 393: batch 1: Loss=1.100, Time=0.005
Epoch 394: batch 1: Loss=1.055, Time=0.019
Epoch 395: batch 1: Loss=1.128, Time=0.010
Epoch 396: batch 1: Loss=1.099, Time=0.010
Epoch 397: batch 1: Loss=1.099, Time=0.010
Epoch 398: batch 1: Loss=1.099, Time=0.020
Epoch 399: batch 1: Loss=1.099, Time=0.010
Epoch 400: batch 1: Loss=1.099, Time=0.010
Epoch 401: batch 1: Loss=1.099, Time=0.011
Epoch 401: Time=145.891, Epoch time = 0.318, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 402: batch 1: Loss=1.062, Time=0.011
Epoch 403: batch 1: Loss=1.099, Time=0.010
Epoch 404: batch 1: Loss=1.099, Time=0.010
Epoch 405: batch 1: Loss=1.099, Time=0.019
Epoch 406: batch 1: Loss=1.105, Time=0.010
Epoch 407: batch 1: Loss=1.095, Time=0.011
Epoch 408: batch 1: Loss=1.091, Time=0.010
Epoch 409: batch 1: Loss=1.085, Time=0.010
Epoch 410: batch 1: Loss=1.526, Time=0.010
Epoch 411: batch 1: Loss=1.099, Time=0.019
Epoch 411: Time=149.522, Epoch time = 0.328, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 412: batch 1: Loss=1.090, Time=0.010
Epoch 413: batch 1: Loss=1.099, Time=0.010
Epoch 414: batch 1: Loss=1.169, Time=0.019
Epoch 415: batch 1: Loss=1.121, Time=0.010
Epoch 416: batch 1: Loss=1.147, Time=0.010
Epoch 417: batch 1: Loss=1.099, Time=0.010
Epoch 418: batch 1: Loss=1.099, Time=0.005
Epoch 419: batch 1: Loss=1.099, Time=0.019
Epoch 420: batch 1: Loss=1.099, Time=0.010
Epoch 421: batch 1: Loss=1.099, Time=0.010
Epoch 421: Time=153.148, Epoch time = 0.321, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 422: batch 1: Loss=1.099, Time=0.014
Epoch 423: batch 1: Loss=1.099, Time=0.019
Epoch 424: batch 1: Loss=1.099, Time=0.010
Epoch 425: batch 1: Loss=1.099, Time=0.010
Epoch 426: batch 1: Loss=1.099, Time=0.006
Epoch 427: batch 1: Loss=1.099, Time=0.010
Epoch 428: batch 1: Loss=1.099, Time=0.010
Epoch 429: batch 1: Loss=1.099, Time=0.010
Epoch 430: batch 1: Loss=1.099, Time=0.010
Epoch 431: batch 1: Loss=1.099, Time=0.010
Epoch 431: Time=156.716, Epoch time = 0.319, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 432: batch 1: Loss=1.099, Time=0.010
Epoch 433: batch 1: Loss=1.099, Time=0.011
Epoch 434: batch 1: Loss=1.099, Time=0.011
Epoch 435: batch 1: Loss=1.099, Time=0.021
Epoch 436: batch 1: Loss=1.099, Time=0.011
Epoch 437: batch 1: Loss=1.099, Time=0.010
Epoch 438: batch 1: Loss=1.099, Time=0.019
Epoch 439: batch 1: Loss=1.099, Time=0.019
Epoch 440: batch 1: Loss=1.099, Time=0.010
Epoch 441: batch 1: Loss=1.099, Time=0.010
Epoch 441: Time=160.271, Epoch time = 0.355, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 442: batch 1: Loss=1.099, Time=0.010
Epoch 443: batch 1: Loss=1.099, Time=0.010
Epoch 444: batch 1: Loss=1.099, Time=0.010
Epoch 445: batch 1: Loss=1.099, Time=0.010
Epoch 446: batch 1: Loss=1.099, Time=0.010
Epoch 447: batch 1: Loss=1.099, Time=0.010
Epoch 448: batch 1: Loss=1.099, Time=0.010
Epoch 449: batch 1: Loss=1.099, Time=0.010
Epoch 450: batch 1: Loss=1.099, Time=0.010
Epoch 451: batch 1: Loss=1.099, Time=0.019
Epoch 451: Time=163.901, Epoch time = 0.353, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 452: batch 1: Loss=1.099, Time=0.011
Epoch 453: batch 1: Loss=1.099, Time=0.010
Epoch 454: batch 1: Loss=1.099, Time=0.010
Epoch 455: batch 1: Loss=1.099, Time=0.010
Epoch 456: batch 1: Loss=1.099, Time=0.010
Epoch 457: batch 1: Loss=1.099, Time=0.019
Epoch 458: batch 1: Loss=1.099, Time=0.018
Epoch 459: batch 1: Loss=1.099, Time=0.019
Epoch 460: batch 1: Loss=1.099, Time=0.019
Epoch 461: batch 1: Loss=1.099, Time=0.010
Epoch 461: Time=167.511, Epoch time = 0.344, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 462: batch 1: Loss=1.099, Time=0.011
Epoch 463: batch 1: Loss=1.097, Time=0.011
Epoch 464: batch 1: Loss=1.099, Time=0.010
Epoch 465: batch 1: Loss=1.099, Time=0.010
Epoch 466: batch 1: Loss=1.099, Time=0.010
Epoch 467: batch 1: Loss=1.099, Time=0.019
Epoch 468: batch 1: Loss=1.099, Time=0.010
Epoch 469: batch 1: Loss=1.099, Time=0.010
Epoch 470: batch 1: Loss=1.086, Time=0.010
Epoch 471: batch 1: Loss=1.089, Time=0.005
Epoch 471: Time=171.059, Epoch time = 0.329, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 472: batch 1: Loss=1.099, Time=0.010
Epoch 473: batch 1: Loss=1.099, Time=0.010
Epoch 474: batch 1: Loss=1.099, Time=0.010
Epoch 475: batch 1: Loss=1.137, Time=0.010
Epoch 476: batch 1: Loss=1.099, Time=0.019
Epoch 477: batch 1: Loss=1.099, Time=0.019
Epoch 478: batch 1: Loss=1.099, Time=0.019
Epoch 479: batch 1: Loss=1.099, Time=0.019
Epoch 480: batch 1: Loss=1.099, Time=0.010
Epoch 481: batch 1: Loss=1.099, Time=0.011
Epoch 481: Time=174.595, Epoch time = 0.347, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 482: batch 1: Loss=1.099, Time=0.010
Epoch 483: batch 1: Loss=1.099, Time=0.007
Epoch 484: batch 1: Loss=1.099, Time=0.010
Epoch 485: batch 1: Loss=1.100, Time=0.011
Epoch 486: batch 1: Loss=1.097, Time=0.010
Epoch 487: batch 1: Loss=1.099, Time=0.010
Epoch 488: batch 1: Loss=1.099, Time=0.019
Epoch 489: batch 1: Loss=1.099, Time=0.010
Epoch 490: batch 1: Loss=1.099, Time=0.021
Epoch 491: batch 1: Loss=1.100, Time=0.010
Epoch 491: Time=178.108, Epoch time = 0.336, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 492: batch 1: Loss=1.100, Time=0.005
Epoch 493: batch 1: Loss=1.100, Time=0.010
Epoch 494: batch 1: Loss=1.099, Time=0.019
Epoch 495: batch 1: Loss=1.099, Time=0.019
Epoch 496: batch 1: Loss=1.099, Time=0.010
Epoch 497: batch 1: Loss=1.099, Time=0.010
Epoch 498: batch 1: Loss=1.099, Time=0.019
Epoch 499: batch 1: Loss=1.099, Time=0.010
Epoch 500: batch 1: Loss=1.099, Time=0.019
Epoch 501: batch 1: Loss=1.099, Time=0.010
Epoch 501: Time=181.770, Epoch time = 0.337, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 502: batch 1: Loss=1.099, Time=0.010
Epoch 503: batch 1: Loss=1.099, Time=0.011
Epoch 504: batch 1: Loss=1.099, Time=0.010
Epoch 505: batch 1: Loss=1.099, Time=0.010
Epoch 506: batch 1: Loss=1.099, Time=0.019
Epoch 507: batch 1: Loss=1.099, Time=0.019
Epoch 508: batch 1: Loss=1.099, Time=0.010
Epoch 509: batch 1: Loss=1.099, Time=0.010
Epoch 510: batch 1: Loss=1.099, Time=0.019
Epoch 511: batch 1: Loss=1.099, Time=0.019
Epoch 511: Time=185.347, Epoch time = 0.347, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 512: batch 1: Loss=1.099, Time=0.011
Epoch 513: batch 1: Loss=1.099, Time=0.015
Epoch 514: batch 1: Loss=1.099, Time=0.020
Epoch 515: batch 1: Loss=1.099, Time=0.005
Epoch 516: batch 1: Loss=1.099, Time=0.010
Epoch 517: batch 1: Loss=1.099, Time=0.010
Epoch 518: batch 1: Loss=1.099, Time=0.011
Epoch 519: batch 1: Loss=1.099, Time=0.010
Epoch 520: batch 1: Loss=1.103, Time=0.010
Epoch 521: batch 1: Loss=1.099, Time=0.010
Epoch 521: Time=188.872, Epoch time = 0.333, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [0.91293484]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 522: batch 1: Loss=1.089, Time=0.010
Epoch 523: batch 1: Loss=1.099, Time=0.019
Epoch 524: batch 1: Loss=1.099, Time=0.010
Epoch 525: batch 1: Loss=1.099, Time=0.008
Epoch 526: batch 1: Loss=1.099, Time=0.011
Epoch 527: batch 1: Loss=1.103, Time=0.011
Epoch 528: batch 1: Loss=1.099, Time=0.009
Epoch 529: batch 1: Loss=1.099, Time=0.010
Epoch 530: batch 1: Loss=1.109, Time=0.010
Epoch 531: batch 1: Loss=1.099, Time=0.010
Epoch 531: Time=192.457, Epoch time = 0.351, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 532: batch 1: Loss=1.099, Time=0.006
Epoch 533: batch 1: Loss=1.099, Time=0.010
Epoch 534: batch 1: Loss=1.099, Time=0.010
Epoch 535: batch 1: Loss=1.099, Time=0.010
Epoch 536: batch 1: Loss=1.099, Time=0.019
Epoch 537: batch 1: Loss=1.099, Time=0.010
Epoch 538: batch 1: Loss=1.099, Time=0.010
Epoch 539: batch 1: Loss=1.099, Time=0.010
Epoch 540: batch 1: Loss=1.099, Time=0.010
Epoch 541: batch 1: Loss=1.099, Time=0.019
Epoch 541: Time=196.015, Epoch time = 0.352, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 542: batch 1: Loss=1.099, Time=0.011
Epoch 543: batch 1: Loss=1.099, Time=0.009
Epoch 544: batch 1: Loss=1.099, Time=0.014
Epoch 545: batch 1: Loss=1.099, Time=0.010
Epoch 546: batch 1: Loss=1.099, Time=0.010
Epoch 547: batch 1: Loss=1.099, Time=0.010
Epoch 548: batch 1: Loss=1.099, Time=0.011
Epoch 549: batch 1: Loss=1.099, Time=0.010
Epoch 550: batch 1: Loss=1.099, Time=0.010
Epoch 551: batch 1: Loss=1.099, Time=0.019
Epoch 551: Time=199.535, Epoch time = 0.317, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 552: batch 1: Loss=1.099, Time=0.011
Epoch 553: batch 1: Loss=1.099, Time=0.010
Epoch 554: batch 1: Loss=1.099, Time=0.019
Epoch 555: batch 1: Loss=1.099, Time=0.011
Epoch 556: batch 1: Loss=1.099, Time=0.005
Epoch 557: batch 1: Loss=1.099, Time=0.010
Epoch 558: batch 1: Loss=1.099, Time=0.010
Epoch 559: batch 1: Loss=1.099, Time=0.011
Epoch 560: batch 1: Loss=1.099, Time=0.011
Epoch 561: batch 1: Loss=1.099, Time=0.010
Epoch 561: Time=203.158, Epoch time = 0.348, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 562: batch 1: Loss=1.099, Time=0.010
Epoch 563: batch 1: Loss=1.099, Time=0.010
Epoch 564: batch 1: Loss=1.099, Time=0.010
Epoch 565: batch 1: Loss=1.099, Time=0.010
Epoch 566: batch 1: Loss=1.099, Time=0.020
Epoch 567: batch 1: Loss=1.099, Time=0.019
Epoch 568: batch 1: Loss=1.099, Time=0.010
Epoch 569: batch 1: Loss=1.099, Time=0.010
Epoch 570: batch 1: Loss=1.099, Time=0.010
Epoch 571: batch 1: Loss=1.099, Time=0.011
Epoch 571: Time=206.723, Epoch time = 0.339, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 572: batch 1: Loss=1.099, Time=0.011
Epoch 573: batch 1: Loss=1.099, Time=0.010
Epoch 574: batch 1: Loss=1.099, Time=0.019
Epoch 575: batch 1: Loss=1.099, Time=0.010
Epoch 576: batch 1: Loss=1.099, Time=0.010
Epoch 577: batch 1: Loss=1.099, Time=0.020
Epoch 578: batch 1: Loss=1.099, Time=0.010
Epoch 579: batch 1: Loss=1.099, Time=0.010
Epoch 580: batch 1: Loss=1.099, Time=0.010
Epoch 581: batch 1: Loss=1.099, Time=0.006
Epoch 581: Time=210.278, Epoch time = 0.328, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 582: batch 1: Loss=1.099, Time=0.019
Epoch 583: batch 1: Loss=1.099, Time=0.020
Epoch 584: batch 1: Loss=1.099, Time=0.010
Epoch 585: batch 1: Loss=1.099, Time=0.010
Epoch 586: batch 1: Loss=1.099, Time=0.019
Epoch 587: batch 1: Loss=1.099, Time=0.010
Epoch 588: batch 1: Loss=1.099, Time=0.010
Epoch 589: batch 1: Loss=1.099, Time=0.019
Epoch 590: batch 1: Loss=1.099, Time=0.010
Epoch 591: batch 1: Loss=1.099, Time=0.013
Epoch 591: Time=213.901, Epoch time = 0.322, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 592: batch 1: Loss=1.099, Time=0.019
Epoch 593: batch 1: Loss=1.099, Time=0.010
Epoch 594: batch 1: Loss=1.099, Time=0.011
Epoch 595: batch 1: Loss=1.099, Time=0.010
Epoch 596: batch 1: Loss=1.099, Time=0.010
Epoch 597: batch 1: Loss=1.099, Time=0.010
Epoch 598: batch 1: Loss=1.099, Time=0.019
Epoch 599: batch 1: Loss=1.099, Time=0.011
Epoch 600: batch 1: Loss=1.099, Time=0.010
Epoch 601: batch 1: Loss=1.099, Time=0.011
Epoch 601: Time=217.481, Epoch time = 0.360, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 602: batch 1: Loss=1.099, Time=0.011
Epoch 603: batch 1: Loss=1.099, Time=0.010
Epoch 604: batch 1: Loss=1.099, Time=0.010
Epoch 605: batch 1: Loss=1.099, Time=0.010
Epoch 606: batch 1: Loss=1.099, Time=0.010
Epoch 607: batch 1: Loss=1.099, Time=0.010
Epoch 608: batch 1: Loss=1.099, Time=0.010
Epoch 609: batch 1: Loss=1.099, Time=0.019
Epoch 610: batch 1: Loss=1.099, Time=0.019
Epoch 611: batch 1: Loss=1.099, Time=0.010
Epoch 611: Time=221.040, Epoch time = 0.323, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 612: batch 1: Loss=1.099, Time=0.020
Epoch 613: batch 1: Loss=1.099, Time=0.010
Epoch 614: batch 1: Loss=1.099, Time=0.019
Epoch 615: batch 1: Loss=1.099, Time=0.019
Epoch 616: batch 1: Loss=1.099, Time=0.019
Epoch 617: batch 1: Loss=1.099, Time=0.010
Epoch 618: batch 1: Loss=1.099, Time=0.010
Epoch 619: batch 1: Loss=1.099, Time=0.010
Epoch 620: batch 1: Loss=1.099, Time=0.010
Epoch 621: batch 1: Loss=1.099, Time=0.010
Epoch 621: Time=224.638, Epoch time = 0.345, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 622: batch 1: Loss=1.099, Time=0.010
Epoch 623: batch 1: Loss=1.099, Time=0.010
Epoch 624: batch 1: Loss=1.099, Time=0.010
Epoch 625: batch 1: Loss=1.099, Time=0.010
Epoch 626: batch 1: Loss=1.099, Time=0.010
Epoch 627: batch 1: Loss=1.099, Time=0.010
Epoch 628: batch 1: Loss=1.099, Time=0.019
Epoch 629: batch 1: Loss=1.099, Time=0.010
Epoch 630: batch 1: Loss=1.099, Time=0.010
Epoch 631: batch 1: Loss=1.099, Time=0.010
Epoch 631: Time=228.242, Epoch time = 0.351, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 632: batch 1: Loss=1.099, Time=0.011
Epoch 633: batch 1: Loss=1.099, Time=0.010
Epoch 634: batch 1: Loss=1.099, Time=0.010
Epoch 635: batch 1: Loss=1.099, Time=0.010
Epoch 636: batch 1: Loss=1.099, Time=0.010
Epoch 637: batch 1: Loss=1.099, Time=0.010
Epoch 638: batch 1: Loss=1.099, Time=0.010
Epoch 639: batch 1: Loss=1.099, Time=0.012
Epoch 640: batch 1: Loss=1.099, Time=0.010
Epoch 641: batch 1: Loss=1.099, Time=0.011
Epoch 641: Time=231.855, Epoch time = 0.312, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 642: batch 1: Loss=1.099, Time=0.019
Epoch 643: batch 1: Loss=1.099, Time=0.010
Epoch 644: batch 1: Loss=1.099, Time=0.019
Epoch 645: batch 1: Loss=1.099, Time=0.011
Epoch 646: batch 1: Loss=1.099, Time=0.019
Epoch 647: batch 1: Loss=1.099, Time=0.006
Epoch 648: batch 1: Loss=1.099, Time=0.010
Epoch 649: batch 1: Loss=1.099, Time=0.010
Epoch 650: batch 1: Loss=1.099, Time=0.011
Epoch 651: batch 1: Loss=1.099, Time=0.007
Epoch 651: Time=235.341, Epoch time = 0.320, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 652: batch 1: Loss=1.099, Time=0.019
Epoch 653: batch 1: Loss=1.099, Time=0.019
Epoch 654: batch 1: Loss=1.099, Time=0.011
Epoch 655: batch 1: Loss=1.099, Time=0.010
Epoch 656: batch 1: Loss=1.099, Time=0.019
Epoch 657: batch 1: Loss=1.099, Time=0.010
Epoch 658: batch 1: Loss=1.099, Time=0.019
Epoch 659: batch 1: Loss=1.099, Time=0.019
Epoch 660: batch 1: Loss=1.099, Time=0.019
Epoch 661: batch 1: Loss=1.099, Time=0.010
Epoch 661: Time=239.014, Epoch time = 0.316, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 662: batch 1: Loss=1.099, Time=0.010
Epoch 663: batch 1: Loss=1.099, Time=0.010
Epoch 664: batch 1: Loss=1.099, Time=0.013
Epoch 665: batch 1: Loss=1.099, Time=0.010
Epoch 666: batch 1: Loss=1.099, Time=0.010
Epoch 667: batch 1: Loss=1.099, Time=0.010
Epoch 668: batch 1: Loss=1.099, Time=0.010
Epoch 669: batch 1: Loss=1.099, Time=0.010
Epoch 670: batch 1: Loss=1.099, Time=0.019
Epoch 671: batch 1: Loss=1.099, Time=0.011
Epoch 671: Time=242.605, Epoch time = 0.342, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 672: batch 1: Loss=1.099, Time=0.011
Epoch 673: batch 1: Loss=1.099, Time=0.010
Epoch 674: batch 1: Loss=1.099, Time=0.010
Epoch 675: batch 1: Loss=1.099, Time=0.010
Epoch 676: batch 1: Loss=1.099, Time=0.019
Epoch 677: batch 1: Loss=1.099, Time=0.010
Epoch 678: batch 1: Loss=1.099, Time=0.012
Epoch 679: batch 1: Loss=1.099, Time=0.010
Epoch 680: batch 1: Loss=1.099, Time=0.010
Epoch 681: batch 1: Loss=1.099, Time=0.020
Epoch 681: Time=246.130, Epoch time = 0.319, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 682: batch 1: Loss=1.099, Time=0.019
Epoch 683: batch 1: Loss=1.099, Time=0.010
Epoch 684: batch 1: Loss=1.099, Time=0.019
Epoch 685: batch 1: Loss=1.099, Time=0.010
Epoch 686: batch 1: Loss=1.099, Time=0.010
Epoch 687: batch 1: Loss=1.099, Time=0.011
Epoch 688: batch 1: Loss=1.099, Time=0.010
Epoch 689: batch 1: Loss=1.099, Time=0.012
Epoch 690: batch 1: Loss=1.099, Time=0.010
Epoch 691: batch 1: Loss=1.099, Time=0.010
Epoch 691: Time=249.735, Epoch time = 0.341, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 692: batch 1: Loss=1.099, Time=0.014
Epoch 693: batch 1: Loss=1.099, Time=0.010
Epoch 694: batch 1: Loss=1.099, Time=0.010
Epoch 695: batch 1: Loss=1.099, Time=0.010
Epoch 696: batch 1: Loss=1.099, Time=0.019
Epoch 697: batch 1: Loss=1.099, Time=0.010
Epoch 698: batch 1: Loss=1.099, Time=0.019
Epoch 699: batch 1: Loss=1.099, Time=0.010
Epoch 700: batch 1: Loss=1.099, Time=0.019
Epoch 701: batch 1: Loss=1.099, Time=0.011
Epoch 701: Time=253.305, Epoch time = 0.316, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 702: batch 1: Loss=1.099, Time=0.011
Epoch 703: batch 1: Loss=1.099, Time=0.010
Epoch 704: batch 1: Loss=1.099, Time=0.010
Epoch 705: batch 1: Loss=1.099, Time=0.010
Epoch 706: batch 1: Loss=1.099, Time=0.010
Epoch 707: batch 1: Loss=1.099, Time=0.019
Epoch 708: batch 1: Loss=1.099, Time=0.010
Epoch 709: batch 1: Loss=1.099, Time=0.019
Epoch 710: batch 1: Loss=1.099, Time=0.011
Epoch 711: batch 1: Loss=1.099, Time=0.010
Epoch 711: Time=256.844, Epoch time = 0.306, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 712: batch 1: Loss=1.099, Time=0.019
Epoch 713: batch 1: Loss=1.099, Time=0.019
Epoch 714: batch 1: Loss=1.099, Time=0.016
Epoch 715: batch 1: Loss=1.099, Time=0.019
Epoch 716: batch 1: Loss=1.099, Time=0.011
Epoch 717: batch 1: Loss=1.099, Time=0.010
Epoch 718: batch 1: Loss=1.099, Time=0.010
Epoch 719: batch 1: Loss=1.099, Time=0.010
Epoch 720: batch 1: Loss=1.099, Time=0.011
Epoch 721: batch 1: Loss=1.099, Time=0.010
Epoch 721: Time=260.448, Epoch time = 0.326, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 722: batch 1: Loss=1.099, Time=0.019
Epoch 723: batch 1: Loss=1.099, Time=0.010
Epoch 724: batch 1: Loss=1.099, Time=0.010
Epoch 725: batch 1: Loss=1.099, Time=0.010
Epoch 726: batch 1: Loss=1.099, Time=0.010
Epoch 727: batch 1: Loss=1.099, Time=0.010
Epoch 728: batch 1: Loss=1.099, Time=0.010
Epoch 729: batch 1: Loss=1.099, Time=0.011
Epoch 730: batch 1: Loss=1.099, Time=0.010
Epoch 731: batch 1: Loss=1.099, Time=0.010
Epoch 731: Time=263.998, Epoch time = 0.319, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 732: batch 1: Loss=1.099, Time=0.017
Epoch 733: batch 1: Loss=1.099, Time=0.010
Epoch 734: batch 1: Loss=1.099, Time=0.013
Epoch 735: batch 1: Loss=1.099, Time=0.019
Epoch 736: batch 1: Loss=1.099, Time=0.016
Epoch 737: batch 1: Loss=1.099, Time=0.010
Epoch 738: batch 1: Loss=1.099, Time=0.010
Epoch 739: batch 1: Loss=1.099, Time=0.019
Epoch 740: batch 1: Loss=1.099, Time=0.010
Epoch 741: batch 1: Loss=1.099, Time=0.010
Epoch 741: Time=267.591, Epoch time = 0.358, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 742: batch 1: Loss=1.099, Time=0.010
Epoch 743: batch 1: Loss=1.099, Time=0.010
Epoch 744: batch 1: Loss=1.099, Time=0.010
Epoch 745: batch 1: Loss=1.099, Time=0.010
Epoch 746: batch 1: Loss=1.099, Time=0.019
Epoch 747: batch 1: Loss=1.099, Time=0.019
Epoch 748: batch 1: Loss=1.099, Time=0.012
Epoch 749: batch 1: Loss=1.099, Time=0.011
Epoch 750: batch 1: Loss=1.099, Time=0.010
Epoch 751: batch 1: Loss=1.099, Time=0.019
Epoch 751: Time=271.165, Epoch time = 0.344, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 752: batch 1: Loss=1.099, Time=0.010
Epoch 753: batch 1: Loss=1.099, Time=0.011
Epoch 754: batch 1: Loss=1.099, Time=0.011
Epoch 755: batch 1: Loss=1.099, Time=0.019
Epoch 756: batch 1: Loss=1.099, Time=0.011
Epoch 757: batch 1: Loss=1.099, Time=0.010
Epoch 758: batch 1: Loss=1.099, Time=0.011
Epoch 759: batch 1: Loss=1.099, Time=0.020
Epoch 760: batch 1: Loss=1.099, Time=0.019
Epoch 761: batch 1: Loss=1.099, Time=0.010
Epoch 761: Time=274.732, Epoch time = 0.348, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 762: batch 1: Loss=1.099, Time=0.012
Epoch 763: batch 1: Loss=1.099, Time=0.010
Epoch 764: batch 1: Loss=1.099, Time=0.010
Epoch 765: batch 1: Loss=1.099, Time=0.010
Epoch 766: batch 1: Loss=1.099, Time=0.006
Epoch 767: batch 1: Loss=1.099, Time=0.011
Epoch 768: batch 1: Loss=1.099, Time=0.020
Epoch 769: batch 1: Loss=1.099, Time=0.010
Epoch 770: batch 1: Loss=1.099, Time=0.010
Epoch 771: batch 1: Loss=1.099, Time=0.020
Epoch 771: Time=278.169, Epoch time = 0.321, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 772: batch 1: Loss=1.099, Time=0.010
Epoch 773: batch 1: Loss=1.099, Time=0.010
Epoch 774: batch 1: Loss=1.099, Time=0.010
Epoch 775: batch 1: Loss=1.099, Time=0.010
Epoch 776: batch 1: Loss=1.099, Time=0.011
Epoch 777: batch 1: Loss=1.099, Time=0.019
Epoch 778: batch 1: Loss=1.099, Time=0.019
Epoch 779: batch 1: Loss=1.099, Time=0.010
Epoch 780: batch 1: Loss=1.099, Time=0.019
Epoch 781: batch 1: Loss=1.099, Time=0.011
Epoch 781: Time=281.751, Epoch time = 0.327, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 782: batch 1: Loss=1.099, Time=0.012
Epoch 783: batch 1: Loss=1.099, Time=0.010
Epoch 784: batch 1: Loss=1.099, Time=0.010
Epoch 785: batch 1: Loss=1.099, Time=0.010
Epoch 786: batch 1: Loss=1.099, Time=0.010
Epoch 787: batch 1: Loss=1.099, Time=0.010
Epoch 788: batch 1: Loss=1.099, Time=0.019
Epoch 789: batch 1: Loss=1.099, Time=0.019
Epoch 790: batch 1: Loss=1.099, Time=0.007
Epoch 791: batch 1: Loss=1.099, Time=0.010
Epoch 791: Time=285.290, Epoch time = 0.338, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 792: batch 1: Loss=1.099, Time=0.020
Epoch 793: batch 1: Loss=1.099, Time=0.010
Epoch 794: batch 1: Loss=1.099, Time=0.016
Epoch 795: batch 1: Loss=1.099, Time=0.019
Epoch 796: batch 1: Loss=1.099, Time=0.011
Epoch 797: batch 1: Loss=1.099, Time=0.010
Epoch 798: batch 1: Loss=1.099, Time=0.010
Epoch 799: batch 1: Loss=1.099, Time=0.018
Epoch 800: batch 1: Loss=1.099, Time=0.020
Epoch 801: batch 1: Loss=1.099, Time=0.011
Epoch 801: Time=288.854, Epoch time = 0.309, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 802: batch 1: Loss=1.099, Time=0.010
Epoch 803: batch 1: Loss=1.099, Time=0.010
Epoch 804: batch 1: Loss=1.099, Time=0.019
Epoch 805: batch 1: Loss=1.099, Time=0.010
Epoch 806: batch 1: Loss=1.099, Time=0.010
Epoch 807: batch 1: Loss=1.099, Time=0.010
Epoch 808: batch 1: Loss=1.099, Time=0.010
Epoch 809: batch 1: Loss=1.099, Time=0.010
Epoch 810: batch 1: Loss=1.099, Time=0.010
Epoch 811: batch 1: Loss=1.099, Time=0.010
Epoch 811: Time=292.467, Epoch time = 0.345, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 812: batch 1: Loss=1.099, Time=0.011
Epoch 813: batch 1: Loss=1.099, Time=0.010
Epoch 814: batch 1: Loss=1.099, Time=0.010
Epoch 815: batch 1: Loss=1.099, Time=0.007
Epoch 816: batch 1: Loss=1.099, Time=0.010
Epoch 817: batch 1: Loss=1.099, Time=0.010
Epoch 818: batch 1: Loss=1.099, Time=0.010
Epoch 819: batch 1: Loss=1.099, Time=0.010
Epoch 820: batch 1: Loss=1.099, Time=0.019
Epoch 821: batch 1: Loss=1.099, Time=0.010
Epoch 821: Time=296.020, Epoch time = 0.328, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 822: batch 1: Loss=1.099, Time=0.010
Epoch 823: batch 1: Loss=1.099, Time=0.010
Epoch 824: batch 1: Loss=1.099, Time=0.010
Epoch 825: batch 1: Loss=1.099, Time=0.019
Epoch 826: batch 1: Loss=1.099, Time=0.010
Epoch 827: batch 1: Loss=1.099, Time=0.010
Epoch 828: batch 1: Loss=1.099, Time=0.010
Epoch 829: batch 1: Loss=1.099, Time=0.010
Epoch 830: batch 1: Loss=1.099, Time=0.019
Epoch 831: batch 1: Loss=1.099, Time=0.010
Epoch 831: Time=299.670, Epoch time = 0.337, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 832: batch 1: Loss=1.099, Time=0.010
Epoch 833: batch 1: Loss=1.099, Time=0.019
Epoch 834: batch 1: Loss=1.099, Time=0.010
Epoch 835: batch 1: Loss=1.099, Time=0.010
Epoch 836: batch 1: Loss=1.099, Time=0.010
Epoch 837: batch 1: Loss=1.099, Time=0.020
Epoch 838: batch 1: Loss=1.099, Time=0.010
Epoch 839: batch 1: Loss=1.099, Time=0.019
Epoch 840: batch 1: Loss=1.099, Time=0.010
Epoch 841: batch 1: Loss=1.099, Time=0.010
Epoch 841: Time=303.225, Epoch time = 0.323, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 842: batch 1: Loss=1.099, Time=0.011
Epoch 843: batch 1: Loss=1.099, Time=0.010
Epoch 844: batch 1: Loss=1.099, Time=0.010
Epoch 845: batch 1: Loss=1.099, Time=0.019
Epoch 846: batch 1: Loss=1.099, Time=0.010
Epoch 847: batch 1: Loss=1.099, Time=0.010
Epoch 848: batch 1: Loss=1.099, Time=0.011
Epoch 849: batch 1: Loss=1.099, Time=0.010
Epoch 850: batch 1: Loss=1.099, Time=0.010
Epoch 851: batch 1: Loss=1.099, Time=0.019
Epoch 851: Time=306.787, Epoch time = 0.343, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 852: batch 1: Loss=1.099, Time=0.010
Epoch 853: batch 1: Loss=1.099, Time=0.010
Epoch 854: batch 1: Loss=1.099, Time=0.019
Epoch 855: batch 1: Loss=1.099, Time=0.011
Epoch 856: batch 1: Loss=1.099, Time=0.010
Epoch 857: batch 1: Loss=1.099, Time=0.011
Epoch 858: batch 1: Loss=1.099, Time=0.010
Epoch 859: batch 1: Loss=1.099, Time=0.010
Epoch 860: batch 1: Loss=1.099, Time=0.008
Epoch 861: batch 1: Loss=1.099, Time=0.019
Epoch 861: Time=310.438, Epoch time = 0.381, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 862: batch 1: Loss=1.099, Time=0.019
Epoch 863: batch 1: Loss=1.099, Time=0.010
Epoch 864: batch 1: Loss=1.099, Time=0.010
Epoch 865: batch 1: Loss=1.099, Time=0.010
Epoch 866: batch 1: Loss=1.099, Time=0.010
Epoch 867: batch 1: Loss=1.099, Time=0.010
Epoch 868: batch 1: Loss=1.099, Time=0.010
Epoch 869: batch 1: Loss=1.099, Time=0.010
Epoch 870: batch 1: Loss=1.099, Time=0.010
Epoch 871: batch 1: Loss=1.099, Time=0.010
Epoch 871: Time=314.013, Epoch time = 0.330, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 872: batch 1: Loss=1.099, Time=0.010
Epoch 873: batch 1: Loss=1.099, Time=0.010
Epoch 874: batch 1: Loss=1.099, Time=0.012
Epoch 875: batch 1: Loss=1.099, Time=0.010
Epoch 876: batch 1: Loss=1.099, Time=0.010
Epoch 877: batch 1: Loss=1.099, Time=0.019
Epoch 878: batch 1: Loss=1.099, Time=0.010
Epoch 879: batch 1: Loss=1.099, Time=0.010
Epoch 880: batch 1: Loss=1.099, Time=0.019
Epoch 881: batch 1: Loss=1.099, Time=0.019
Epoch 881: Time=317.656, Epoch time = 0.317, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 882: batch 1: Loss=1.099, Time=0.011
Epoch 883: batch 1: Loss=1.099, Time=0.010
Epoch 884: batch 1: Loss=1.099, Time=0.010
Epoch 885: batch 1: Loss=1.099, Time=0.020
Epoch 886: batch 1: Loss=1.099, Time=0.019
Epoch 887: batch 1: Loss=1.099, Time=0.019
Epoch 888: batch 1: Loss=1.099, Time=0.019
Epoch 889: batch 1: Loss=1.099, Time=0.019
Epoch 890: batch 1: Loss=1.099, Time=0.009
Epoch 891: batch 1: Loss=1.099, Time=0.010
Epoch 891: Time=321.274, Epoch time = 0.319, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 892: batch 1: Loss=1.099, Time=0.010
Epoch 893: batch 1: Loss=1.099, Time=0.010
Epoch 894: batch 1: Loss=1.099, Time=0.019
Epoch 895: batch 1: Loss=1.099, Time=0.010
Epoch 896: batch 1: Loss=1.099, Time=0.010
Epoch 897: batch 1: Loss=1.099, Time=0.010
Epoch 898: batch 1: Loss=1.099, Time=0.010
Epoch 899: batch 1: Loss=1.099, Time=0.010
Epoch 900: batch 1: Loss=1.099, Time=0.010
Epoch 901: batch 1: Loss=1.099, Time=0.010
Epoch 901: Time=324.806, Epoch time = 0.318, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 902: batch 1: Loss=1.099, Time=0.011
Epoch 903: batch 1: Loss=1.099, Time=0.011
Epoch 904: batch 1: Loss=1.099, Time=0.019
Epoch 905: batch 1: Loss=1.099, Time=0.010
Epoch 906: batch 1: Loss=1.099, Time=0.010
Epoch 907: batch 1: Loss=1.099, Time=0.010
Epoch 908: batch 1: Loss=1.099, Time=0.010
Epoch 909: batch 1: Loss=1.099, Time=0.019
Epoch 910: batch 1: Loss=1.099, Time=0.019
Epoch 911: batch 1: Loss=1.099, Time=0.010
Epoch 911: Time=328.364, Epoch time = 0.315, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 912: batch 1: Loss=1.099, Time=0.011
Epoch 913: batch 1: Loss=1.099, Time=0.010
Epoch 914: batch 1: Loss=1.099, Time=0.010
Epoch 915: batch 1: Loss=1.099, Time=0.019
Epoch 916: batch 1: Loss=1.099, Time=0.012
Epoch 917: batch 1: Loss=1.099, Time=0.014
Epoch 918: batch 1: Loss=1.099, Time=0.010
Epoch 919: batch 1: Loss=1.099, Time=0.010
Epoch 920: batch 1: Loss=1.099, Time=0.010
Epoch 921: batch 1: Loss=1.099, Time=0.011
Epoch 921: Time=331.872, Epoch time = 0.337, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 922: batch 1: Loss=1.099, Time=0.010
Epoch 923: batch 1: Loss=1.099, Time=0.010
Epoch 924: batch 1: Loss=1.099, Time=0.019
Epoch 925: batch 1: Loss=1.099, Time=0.011
Epoch 926: batch 1: Loss=1.099, Time=0.019
Epoch 927: batch 1: Loss=1.099, Time=0.010
Epoch 928: batch 1: Loss=1.099, Time=0.010
Epoch 929: batch 1: Loss=1.099, Time=0.010
Epoch 930: batch 1: Loss=1.099, Time=0.004
Epoch 931: batch 1: Loss=1.099, Time=0.011
Epoch 931: Time=335.408, Epoch time = 0.344, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 932: batch 1: Loss=1.099, Time=0.019
Epoch 933: batch 1: Loss=1.099, Time=0.019
Epoch 934: batch 1: Loss=1.099, Time=0.010
Epoch 935: batch 1: Loss=1.099, Time=0.010
Epoch 936: batch 1: Loss=1.099, Time=0.010
Epoch 937: batch 1: Loss=1.099, Time=0.010
Epoch 938: batch 1: Loss=1.099, Time=0.010
Epoch 939: batch 1: Loss=1.099, Time=0.019
Epoch 940: batch 1: Loss=1.099, Time=0.010
Epoch 941: batch 1: Loss=1.099, Time=0.010
Epoch 941: Time=338.991, Epoch time = 0.337, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 942: batch 1: Loss=1.099, Time=0.011
Epoch 943: batch 1: Loss=1.099, Time=0.011
Epoch 944: batch 1: Loss=1.099, Time=0.019
Epoch 945: batch 1: Loss=1.099, Time=0.010
Epoch 946: batch 1: Loss=1.099, Time=0.008
Epoch 947: batch 1: Loss=1.099, Time=0.010
Epoch 948: batch 1: Loss=1.099, Time=0.010
Epoch 949: batch 1: Loss=1.099, Time=0.010
Epoch 950: batch 1: Loss=1.099, Time=0.010
Epoch 951: batch 1: Loss=1.099, Time=0.011
Epoch 951: Time=342.508, Epoch time = 0.336, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 952: batch 1: Loss=1.099, Time=0.010
Epoch 953: batch 1: Loss=1.099, Time=0.010
Epoch 954: batch 1: Loss=1.099, Time=0.019
Epoch 955: batch 1: Loss=1.099, Time=0.019
Epoch 956: batch 1: Loss=1.099, Time=0.019
Epoch 957: batch 1: Loss=1.099, Time=0.019
Epoch 958: batch 1: Loss=1.099, Time=0.010
Epoch 959: batch 1: Loss=1.099, Time=0.010
Epoch 960: batch 1: Loss=1.099, Time=0.010
Epoch 961: batch 1: Loss=1.099, Time=0.010
Epoch 961: Time=346.118, Epoch time = 0.327, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 962: batch 1: Loss=1.099, Time=0.010
Epoch 963: batch 1: Loss=1.099, Time=0.019
Epoch 964: batch 1: Loss=1.099, Time=0.010
Epoch 965: batch 1: Loss=1.099, Time=0.019
Epoch 966: batch 1: Loss=1.099, Time=0.010
Epoch 967: batch 1: Loss=1.099, Time=0.010
Epoch 968: batch 1: Loss=1.099, Time=0.010
Epoch 969: batch 1: Loss=1.099, Time=0.019
Epoch 970: batch 1: Loss=1.099, Time=0.010
Epoch 971: batch 1: Loss=1.099, Time=0.010
Epoch 971: Time=349.638, Epoch time = 0.367, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 972: batch 1: Loss=1.099, Time=0.019
Epoch 973: batch 1: Loss=1.099, Time=0.011
Epoch 974: batch 1: Loss=1.099, Time=0.010
Epoch 975: batch 1: Loss=1.099, Time=0.014
Epoch 976: batch 1: Loss=1.099, Time=0.010
Epoch 977: batch 1: Loss=1.099, Time=0.010
Epoch 978: batch 1: Loss=1.099, Time=0.010
Epoch 979: batch 1: Loss=1.099, Time=0.010
Epoch 980: batch 1: Loss=1.099, Time=0.010
Epoch 981: batch 1: Loss=1.099, Time=0.010
Epoch 981: Time=353.184, Epoch time = 0.329, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 982: batch 1: Loss=1.099, Time=0.019
Epoch 983: batch 1: Loss=1.099, Time=0.011
Epoch 984: batch 1: Loss=1.099, Time=0.019
Epoch 985: batch 1: Loss=1.099, Time=0.019
Epoch 986: batch 1: Loss=1.099, Time=0.010
Epoch 987: batch 1: Loss=1.099, Time=0.010
Epoch 988: batch 1: Loss=1.099, Time=0.019
Epoch 989: batch 1: Loss=1.099, Time=0.017
Epoch 990: batch 1: Loss=1.099, Time=0.010
Epoch 991: batch 1: Loss=1.099, Time=0.010
Epoch 991: Time=356.779, Epoch time = 0.329, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 992: batch 1: Loss=1.099, Time=0.005
Epoch 993: batch 1: Loss=1.099, Time=0.019
Epoch 994: batch 1: Loss=1.099, Time=0.010
Epoch 995: batch 1: Loss=1.099, Time=0.012
Epoch 996: batch 1: Loss=1.099, Time=0.010
Epoch 997: batch 1: Loss=1.099, Time=0.010
Epoch 998: batch 1: Loss=1.099, Time=0.010
Epoch 999: batch 1: Loss=1.099, Time=0.006
Epoch 1000: batch 1: Loss=1.099, Time=0.010
Epoch 1001: batch 1: Loss=1.099, Time=0.019
Epoch 1001: Time=360.386, Epoch time = 0.356, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1002: batch 1: Loss=1.099, Time=0.003
Epoch 1003: batch 1: Loss=1.099, Time=0.010
Epoch 1004: batch 1: Loss=1.099, Time=0.010
Epoch 1005: batch 1: Loss=1.099, Time=0.010
Epoch 1006: batch 1: Loss=1.099, Time=0.005
Epoch 1007: batch 1: Loss=1.099, Time=0.010
Epoch 1008: batch 1: Loss=1.099, Time=0.019
Epoch 1009: batch 1: Loss=1.099, Time=0.019
Epoch 1010: batch 1: Loss=1.099, Time=0.010
Epoch 1011: batch 1: Loss=1.099, Time=0.011
Epoch 1011: Time=363.876, Epoch time = 0.319, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1012: batch 1: Loss=1.099, Time=0.010
Epoch 1013: batch 1: Loss=1.099, Time=0.010
Epoch 1014: batch 1: Loss=1.099, Time=0.010
Epoch 1015: batch 1: Loss=1.099, Time=0.010
Epoch 1016: batch 1: Loss=1.099, Time=0.020
Epoch 1017: batch 1: Loss=1.099, Time=0.011
Epoch 1018: batch 1: Loss=1.099, Time=0.010
Epoch 1019: batch 1: Loss=1.099, Time=0.010
Epoch 1020: batch 1: Loss=1.099, Time=0.012
Epoch 1021: batch 1: Loss=1.099, Time=0.010
Epoch 1021: Time=367.526, Epoch time = 0.349, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1022: batch 1: Loss=1.099, Time=0.011
Epoch 1023: batch 1: Loss=1.099, Time=0.010
Epoch 1024: batch 1: Loss=1.099, Time=0.011
Epoch 1025: batch 1: Loss=1.099, Time=0.010
Epoch 1026: batch 1: Loss=1.099, Time=0.019
Epoch 1027: batch 1: Loss=1.099, Time=0.010
Epoch 1028: batch 1: Loss=1.099, Time=0.010
Epoch 1029: batch 1: Loss=1.099, Time=0.019
Epoch 1030: batch 1: Loss=1.099, Time=0.010
Epoch 1031: batch 1: Loss=1.099, Time=0.012
Epoch 1031: Time=371.151, Epoch time = 0.350, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1032: batch 1: Loss=1.099, Time=0.010
Epoch 1033: batch 1: Loss=1.099, Time=0.011
Epoch 1034: batch 1: Loss=1.099, Time=0.019
Epoch 1035: batch 1: Loss=1.099, Time=0.019
Epoch 1036: batch 1: Loss=1.099, Time=0.010
Epoch 1037: batch 1: Loss=1.099, Time=0.010
Epoch 1038: batch 1: Loss=1.099, Time=0.010
Epoch 1039: batch 1: Loss=1.099, Time=0.010
Epoch 1040: batch 1: Loss=1.099, Time=0.010
Epoch 1041: batch 1: Loss=1.099, Time=0.010
Epoch 1041: Time=374.751, Epoch time = 0.312, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1042: batch 1: Loss=1.099, Time=0.019
Epoch 1043: batch 1: Loss=1.099, Time=0.010
Epoch 1044: batch 1: Loss=1.099, Time=0.010
Epoch 1045: batch 1: Loss=1.099, Time=0.010
Epoch 1046: batch 1: Loss=1.099, Time=0.010
Epoch 1047: batch 1: Loss=1.099, Time=0.019
Epoch 1048: batch 1: Loss=1.099, Time=0.010
Epoch 1049: batch 1: Loss=1.099, Time=0.010
Epoch 1050: batch 1: Loss=1.099, Time=0.005
Epoch 1051: batch 1: Loss=1.099, Time=0.019
Epoch 1051: Time=378.285, Epoch time = 0.362, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1052: batch 1: Loss=1.099, Time=0.019
Epoch 1053: batch 1: Loss=1.099, Time=0.010
Epoch 1054: batch 1: Loss=1.099, Time=0.010
Epoch 1055: batch 1: Loss=1.099, Time=0.010
Epoch 1056: batch 1: Loss=1.099, Time=0.010
Epoch 1057: batch 1: Loss=1.099, Time=0.010
Epoch 1058: batch 1: Loss=1.099, Time=0.010
Epoch 1059: batch 1: Loss=1.099, Time=0.010
Epoch 1060: batch 1: Loss=1.099, Time=0.019
Epoch 1061: batch 1: Loss=1.099, Time=0.010
Epoch 1061: Time=381.902, Epoch time = 0.324, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1062: batch 1: Loss=1.099, Time=0.011
Epoch 1063: batch 1: Loss=1.099, Time=0.011
Epoch 1064: batch 1: Loss=1.099, Time=0.020
Epoch 1065: batch 1: Loss=1.099, Time=0.005
Epoch 1066: batch 1: Loss=1.099, Time=0.010
Epoch 1067: batch 1: Loss=1.099, Time=0.019
Epoch 1068: batch 1: Loss=1.099, Time=0.010
Epoch 1069: batch 1: Loss=1.099, Time=0.019
Epoch 1070: batch 1: Loss=1.099, Time=0.010
Epoch 1071: batch 1: Loss=1.099, Time=0.010
Epoch 1071: Time=385.526, Epoch time = 0.328, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1072: batch 1: Loss=1.099, Time=0.019
Epoch 1073: batch 1: Loss=1.099, Time=0.011
Epoch 1074: batch 1: Loss=1.099, Time=0.010
Epoch 1075: batch 1: Loss=1.099, Time=0.010
Epoch 1076: batch 1: Loss=1.099, Time=0.010
Epoch 1077: batch 1: Loss=1.099, Time=0.005
Epoch 1078: batch 1: Loss=1.099, Time=0.010
Epoch 1079: batch 1: Loss=1.099, Time=0.010
Epoch 1080: batch 1: Loss=1.099, Time=0.019
Epoch 1081: batch 1: Loss=1.099, Time=0.010
Epoch 1081: Time=389.081, Epoch time = 0.328, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1082: batch 1: Loss=1.099, Time=0.020
Epoch 1083: batch 1: Loss=1.099, Time=0.010
Epoch 1084: batch 1: Loss=1.099, Time=0.010
Epoch 1085: batch 1: Loss=1.099, Time=0.019
Epoch 1086: batch 1: Loss=1.099, Time=0.019
Epoch 1087: batch 1: Loss=1.099, Time=0.010
Epoch 1088: batch 1: Loss=1.099, Time=0.010
Epoch 1089: batch 1: Loss=1.099, Time=0.010
Epoch 1090: batch 1: Loss=1.099, Time=0.010
Epoch 1091: batch 1: Loss=1.099, Time=0.010
Epoch 1091: Time=392.656, Epoch time = 0.309, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1092: batch 1: Loss=1.099, Time=0.010
Epoch 1093: batch 1: Loss=1.099, Time=0.010
Epoch 1094: batch 1: Loss=1.099, Time=0.007
Epoch 1095: batch 1: Loss=1.099, Time=0.010
Epoch 1096: batch 1: Loss=1.099, Time=0.019
Epoch 1097: batch 1: Loss=1.099, Time=0.010
Epoch 1098: batch 1: Loss=1.099, Time=0.010
Epoch 1099: batch 1: Loss=1.099, Time=0.010
Epoch 1100: batch 1: Loss=1.099, Time=0.010
Epoch 1101: batch 1: Loss=1.099, Time=0.019
Epoch 1101: Time=396.239, Epoch time = 0.355, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1102: batch 1: Loss=1.099, Time=0.019
Epoch 1103: batch 1: Loss=1.099, Time=0.010
Epoch 1104: batch 1: Loss=1.099, Time=0.010
Epoch 1105: batch 1: Loss=1.099, Time=0.007
Epoch 1106: batch 1: Loss=1.099, Time=0.010
Epoch 1107: batch 1: Loss=1.099, Time=0.019
Epoch 1108: batch 1: Loss=1.099, Time=0.010
Epoch 1109: batch 1: Loss=1.099, Time=0.014
Epoch 1110: batch 1: Loss=1.099, Time=0.010
Epoch 1111: batch 1: Loss=1.099, Time=0.019
Epoch 1111: Time=399.869, Epoch time = 0.328, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1112: batch 1: Loss=1.099, Time=0.010
Epoch 1113: batch 1: Loss=1.099, Time=0.010
Epoch 1114: batch 1: Loss=1.099, Time=0.019
Epoch 1115: batch 1: Loss=1.099, Time=0.010
Epoch 1116: batch 1: Loss=1.099, Time=0.010
Epoch 1117: batch 1: Loss=1.099, Time=0.020
Epoch 1118: batch 1: Loss=1.099, Time=0.010
Epoch 1119: batch 1: Loss=1.099, Time=0.010
Epoch 1120: batch 1: Loss=1.099, Time=0.010
Epoch 1121: batch 1: Loss=1.099, Time=0.020
Epoch 1121: Time=403.520, Epoch time = 0.357, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1122: batch 1: Loss=1.099, Time=0.010
Epoch 1123: batch 1: Loss=1.099, Time=0.019
Epoch 1124: batch 1: Loss=1.099, Time=0.019
Epoch 1125: batch 1: Loss=1.099, Time=0.010
Epoch 1126: batch 1: Loss=1.099, Time=0.012
Epoch 1127: batch 1: Loss=1.099, Time=0.010
Epoch 1128: batch 1: Loss=1.099, Time=0.019
Epoch 1129: batch 1: Loss=1.099, Time=0.019
Epoch 1130: batch 1: Loss=1.099, Time=0.010
Epoch 1131: batch 1: Loss=1.099, Time=0.010
Epoch 1131: Time=407.091, Epoch time = 0.319, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1132: batch 1: Loss=1.099, Time=0.010
Epoch 1133: batch 1: Loss=1.099, Time=0.019
Epoch 1134: batch 1: Loss=1.099, Time=0.010
Epoch 1135: batch 1: Loss=1.099, Time=0.011
Epoch 1136: batch 1: Loss=1.099, Time=0.005
Epoch 1137: batch 1: Loss=1.099, Time=0.019
Epoch 1138: batch 1: Loss=1.099, Time=0.019
Epoch 1139: batch 1: Loss=1.099, Time=0.005
Epoch 1140: batch 1: Loss=1.099, Time=0.010
Epoch 1141: batch 1: Loss=1.099, Time=0.010
Epoch 1141: Time=410.675, Epoch time = 0.357, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1142: batch 1: Loss=1.099, Time=0.019
Epoch 1143: batch 1: Loss=1.099, Time=0.015
Epoch 1144: batch 1: Loss=1.099, Time=0.010
Epoch 1145: batch 1: Loss=1.099, Time=0.010
Epoch 1146: batch 1: Loss=1.099, Time=0.010
Epoch 1147: batch 1: Loss=1.099, Time=0.004
Epoch 1148: batch 1: Loss=1.099, Time=0.020
Epoch 1149: batch 1: Loss=1.099, Time=0.010
Epoch 1150: batch 1: Loss=1.099, Time=0.010
Epoch 1151: batch 1: Loss=1.099, Time=0.010
Epoch 1151: Time=414.231, Epoch time = 0.346, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1152: batch 1: Loss=1.099, Time=0.019
Epoch 1153: batch 1: Loss=1.099, Time=0.010
Epoch 1154: batch 1: Loss=1.099, Time=0.010
Epoch 1155: batch 1: Loss=1.099, Time=0.019
Epoch 1156: batch 1: Loss=1.099, Time=0.010
Epoch 1157: batch 1: Loss=1.099, Time=0.010
Epoch 1158: batch 1: Loss=1.099, Time=0.010
Epoch 1159: batch 1: Loss=1.099, Time=0.010
Epoch 1160: batch 1: Loss=1.099, Time=0.010
Epoch 1161: batch 1: Loss=1.099, Time=0.010
Epoch 1161: Time=417.806, Epoch time = 0.321, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1162: batch 1: Loss=1.099, Time=0.011
Epoch 1163: batch 1: Loss=1.099, Time=0.019
Epoch 1164: batch 1: Loss=1.099, Time=0.006
Epoch 1165: batch 1: Loss=1.099, Time=0.010
Epoch 1166: batch 1: Loss=1.099, Time=0.020
Epoch 1167: batch 1: Loss=1.099, Time=0.010
Epoch 1168: batch 1: Loss=1.099, Time=0.019
Epoch 1169: batch 1: Loss=1.099, Time=0.010
Epoch 1170: batch 1: Loss=1.099, Time=0.010
Epoch 1171: batch 1: Loss=1.099, Time=0.010
Epoch 1171: Time=421.417, Epoch time = 0.341, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1172: batch 1: Loss=1.099, Time=0.011
Epoch 1173: batch 1: Loss=1.099, Time=0.010
Epoch 1174: batch 1: Loss=1.099, Time=0.019
Epoch 1175: batch 1: Loss=1.099, Time=0.010
Epoch 1176: batch 1: Loss=1.099, Time=0.011
Epoch 1177: batch 1: Loss=1.099, Time=0.010
Epoch 1178: batch 1: Loss=1.099, Time=0.010
Epoch 1179: batch 1: Loss=1.099, Time=0.010
Epoch 1180: batch 1: Loss=1.099, Time=0.010
Epoch 1181: batch 1: Loss=1.099, Time=0.020
Epoch 1181: Time=424.992, Epoch time = 0.304, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1182: batch 1: Loss=1.099, Time=0.014
Epoch 1183: batch 1: Loss=1.099, Time=0.019
Epoch 1184: batch 1: Loss=1.099, Time=0.010
Epoch 1185: batch 1: Loss=1.099, Time=0.006
Epoch 1186: batch 1: Loss=1.099, Time=0.010
Epoch 1187: batch 1: Loss=1.099, Time=0.019
Epoch 1188: batch 1: Loss=1.099, Time=0.010
Epoch 1189: batch 1: Loss=1.099, Time=0.010
Epoch 1190: batch 1: Loss=1.099, Time=0.010
Epoch 1191: batch 1: Loss=1.099, Time=0.020
Epoch 1191: Time=428.573, Epoch time = 0.357, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1192: batch 1: Loss=1.099, Time=0.010
Epoch 1193: batch 1: Loss=1.099, Time=0.010
Epoch 1194: batch 1: Loss=1.099, Time=0.010
Epoch 1195: batch 1: Loss=1.099, Time=0.019
Epoch 1196: batch 1: Loss=1.099, Time=0.010
Epoch 1197: batch 1: Loss=1.099, Time=0.010
Epoch 1198: batch 1: Loss=1.099, Time=0.019
Epoch 1199: batch 1: Loss=1.099, Time=0.010
Epoch 1200: batch 1: Loss=1.099, Time=0.010
Epoch 1201: batch 1: Loss=1.099, Time=0.010
Epoch 1201: Time=432.158, Epoch time = 0.321, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1202: batch 1: Loss=1.099, Time=0.010
Epoch 1203: batch 1: Loss=1.099, Time=0.019
Epoch 1204: batch 1: Loss=1.099, Time=0.010
Epoch 1205: batch 1: Loss=1.099, Time=0.010
Epoch 1206: batch 1: Loss=1.099, Time=0.010
Epoch 1207: batch 1: Loss=1.099, Time=0.011
Epoch 1208: batch 1: Loss=1.099, Time=0.010
Epoch 1209: batch 1: Loss=1.099, Time=0.010
Epoch 1210: batch 1: Loss=1.099, Time=0.011
Epoch 1211: batch 1: Loss=1.099, Time=0.010
Epoch 1211: Time=435.694, Epoch time = 0.349, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1212: batch 1: Loss=1.099, Time=0.010
Epoch 1213: batch 1: Loss=1.099, Time=0.010
Epoch 1214: batch 1: Loss=1.099, Time=0.018
Epoch 1215: batch 1: Loss=1.099, Time=0.010
Epoch 1216: batch 1: Loss=1.099, Time=0.010
Epoch 1217: batch 1: Loss=1.099, Time=0.010
Epoch 1218: batch 1: Loss=1.099, Time=0.010
Epoch 1219: batch 1: Loss=1.099, Time=0.019
Epoch 1220: batch 1: Loss=1.099, Time=0.010
Epoch 1221: batch 1: Loss=1.099, Time=0.010
Epoch 1221: Time=439.266, Epoch time = 0.334, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1222: batch 1: Loss=1.099, Time=0.010
Epoch 1223: batch 1: Loss=1.099, Time=0.010
Epoch 1224: batch 1: Loss=1.099, Time=0.010
Epoch 1225: batch 1: Loss=1.099, Time=0.010
Epoch 1226: batch 1: Loss=1.099, Time=0.019
Epoch 1227: batch 1: Loss=1.099, Time=0.019
Epoch 1228: batch 1: Loss=1.099, Time=0.010
Epoch 1229: batch 1: Loss=1.099, Time=0.010
Epoch 1230: batch 1: Loss=1.099, Time=0.019
Epoch 1231: batch 1: Loss=1.099, Time=0.020
Epoch 1231: Time=442.873, Epoch time = 0.353, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1232: batch 1: Loss=1.099, Time=0.010
Epoch 1233: batch 1: Loss=1.099, Time=0.010
Epoch 1234: batch 1: Loss=1.099, Time=0.011
Epoch 1235: batch 1: Loss=1.099, Time=0.013
Epoch 1236: batch 1: Loss=1.099, Time=0.010
Epoch 1237: batch 1: Loss=1.099, Time=0.019
Epoch 1238: batch 1: Loss=1.099, Time=0.010
Epoch 1239: batch 1: Loss=1.099, Time=0.019
Epoch 1240: batch 1: Loss=1.099, Time=0.015
Epoch 1241: batch 1: Loss=1.099, Time=0.011
Epoch 1241: Time=446.425, Epoch time = 0.341, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1242: batch 1: Loss=1.099, Time=0.014
Epoch 1243: batch 1: Loss=1.099, Time=0.011
Epoch 1244: batch 1: Loss=1.099, Time=0.010
Epoch 1245: batch 1: Loss=1.099, Time=0.019
Epoch 1246: batch 1: Loss=1.099, Time=0.010
Epoch 1247: batch 1: Loss=1.099, Time=0.010
Epoch 1248: batch 1: Loss=1.099, Time=0.010
Epoch 1249: batch 1: Loss=1.099, Time=0.010
Epoch 1250: batch 1: Loss=1.099, Time=0.014
Epoch 1251: batch 1: Loss=1.099, Time=0.020
Epoch 1251: Time=450.070, Epoch time = 0.334, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1252: batch 1: Loss=1.099, Time=0.010
Epoch 1253: batch 1: Loss=1.099, Time=0.010
Epoch 1254: batch 1: Loss=1.099, Time=0.010
Epoch 1255: batch 1: Loss=1.099, Time=0.010
Epoch 1256: batch 1: Loss=1.099, Time=0.010
Epoch 1257: batch 1: Loss=1.099, Time=0.010
Epoch 1258: batch 1: Loss=1.099, Time=0.010
Epoch 1259: batch 1: Loss=1.099, Time=0.010
Epoch 1260: batch 1: Loss=1.099, Time=0.010
Epoch 1261: batch 1: Loss=1.099, Time=0.006
Epoch 1261: Time=453.647, Epoch time = 0.338, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1262: batch 1: Loss=1.099, Time=0.011
Epoch 1263: batch 1: Loss=1.099, Time=0.010
Epoch 1264: batch 1: Loss=1.099, Time=0.010
Epoch 1265: batch 1: Loss=1.099, Time=0.011
Epoch 1266: batch 1: Loss=1.099, Time=0.010
Epoch 1267: batch 1: Loss=1.099, Time=0.010
Epoch 1268: batch 1: Loss=1.099, Time=0.010
Epoch 1269: batch 1: Loss=1.099, Time=0.010
Epoch 1270: batch 1: Loss=1.099, Time=0.011
Epoch 1271: batch 1: Loss=1.099, Time=0.011
Epoch 1271: Time=457.239, Epoch time = 0.309, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1272: batch 1: Loss=1.099, Time=0.008
Epoch 1273: batch 1: Loss=1.099, Time=0.011
Epoch 1274: batch 1: Loss=1.099, Time=0.020
Epoch 1275: batch 1: Loss=1.099, Time=0.010
Epoch 1276: batch 1: Loss=1.099, Time=0.010
Epoch 1277: batch 1: Loss=1.099, Time=0.010
Epoch 1278: batch 1: Loss=1.099, Time=0.010
Epoch 1279: batch 1: Loss=1.099, Time=0.010
Epoch 1280: batch 1: Loss=1.099, Time=0.019
Epoch 1281: batch 1: Loss=1.099, Time=0.010
Epoch 1281: Time=460.835, Epoch time = 0.318, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1282: batch 1: Loss=1.099, Time=0.019
Epoch 1283: batch 1: Loss=1.099, Time=0.019
Epoch 1284: batch 1: Loss=1.099, Time=0.010
Epoch 1285: batch 1: Loss=1.099, Time=0.010
Epoch 1286: batch 1: Loss=1.099, Time=0.010
Epoch 1287: batch 1: Loss=1.099, Time=0.005
Epoch 1288: batch 1: Loss=1.099, Time=0.010
Epoch 1289: batch 1: Loss=1.099, Time=0.010
Epoch 1290: batch 1: Loss=1.099, Time=0.010
Epoch 1291: batch 1: Loss=1.099, Time=0.017
Epoch 1291: Time=464.349, Epoch time = 0.337, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1292: batch 1: Loss=1.099, Time=0.010
Epoch 1293: batch 1: Loss=1.099, Time=0.004
Epoch 1294: batch 1: Loss=1.099, Time=0.010
Epoch 1295: batch 1: Loss=1.099, Time=0.010
Epoch 1296: batch 1: Loss=1.099, Time=0.010
Epoch 1297: batch 1: Loss=1.099, Time=0.010
Epoch 1298: batch 1: Loss=1.099, Time=0.019
Epoch 1299: batch 1: Loss=1.099, Time=0.010
Epoch 1300: batch 1: Loss=1.099, Time=0.010
Epoch 1301: batch 1: Loss=1.099, Time=0.019
Epoch 1301: Time=467.952, Epoch time = 0.357, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1302: batch 1: Loss=1.099, Time=0.011
Epoch 1303: batch 1: Loss=1.099, Time=0.019
Epoch 1304: batch 1: Loss=1.099, Time=0.010
Epoch 1305: batch 1: Loss=1.099, Time=0.010
Epoch 1306: batch 1: Loss=1.099, Time=0.010
Epoch 1307: batch 1: Loss=1.099, Time=0.010
Epoch 1308: batch 1: Loss=1.099, Time=0.010
Epoch 1309: batch 1: Loss=1.099, Time=0.010
Epoch 1310: batch 1: Loss=1.099, Time=0.010
Epoch 1311: batch 1: Loss=1.099, Time=0.010
Epoch 1311: Time=471.403, Epoch time = 0.329, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1312: batch 1: Loss=1.099, Time=0.011
Epoch 1313: batch 1: Loss=1.099, Time=0.012
Epoch 1314: batch 1: Loss=1.099, Time=0.010
Epoch 1315: batch 1: Loss=1.099, Time=0.010
Epoch 1316: batch 1: Loss=1.099, Time=0.010
Epoch 1317: batch 1: Loss=1.099, Time=0.010
Epoch 1318: batch 1: Loss=1.099, Time=0.010
Epoch 1319: batch 1: Loss=1.099, Time=0.010
Epoch 1320: batch 1: Loss=1.099, Time=0.010
Epoch 1321: batch 1: Loss=1.099, Time=0.010
Epoch 1321: Time=474.996, Epoch time = 0.340, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1322: batch 1: Loss=1.099, Time=0.011
Epoch 1323: batch 1: Loss=1.099, Time=0.010
Epoch 1324: batch 1: Loss=1.099, Time=0.005
Epoch 1325: batch 1: Loss=1.099, Time=0.010
Epoch 1326: batch 1: Loss=1.099, Time=0.019
Epoch 1327: batch 1: Loss=1.099, Time=0.010
Epoch 1328: batch 1: Loss=1.099, Time=0.010
Epoch 1329: batch 1: Loss=1.099, Time=0.019
Epoch 1330: batch 1: Loss=1.099, Time=0.010
Epoch 1331: batch 1: Loss=1.099, Time=0.010
Epoch 1331: Time=478.588, Epoch time = 0.322, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1332: batch 1: Loss=1.099, Time=0.011
Epoch 1333: batch 1: Loss=1.099, Time=0.011
Epoch 1334: batch 1: Loss=1.099, Time=0.010
Epoch 1335: batch 1: Loss=1.099, Time=0.010
Epoch 1336: batch 1: Loss=1.099, Time=0.011
Epoch 1337: batch 1: Loss=1.099, Time=0.010
Epoch 1338: batch 1: Loss=1.099, Time=0.010
Epoch 1339: batch 1: Loss=1.099, Time=0.010
Epoch 1340: batch 1: Loss=1.099, Time=0.010
Epoch 1341: batch 1: Loss=1.099, Time=0.020
Epoch 1341: Time=482.171, Epoch time = 0.344, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1342: batch 1: Loss=1.099, Time=0.019
Epoch 1343: batch 1: Loss=1.099, Time=0.010
Epoch 1344: batch 1: Loss=1.099, Time=0.010
Epoch 1345: batch 1: Loss=1.099, Time=0.010
Epoch 1346: batch 1: Loss=1.099, Time=0.019
Epoch 1347: batch 1: Loss=1.099, Time=0.019
Epoch 1348: batch 1: Loss=1.099, Time=0.015
Epoch 1349: batch 1: Loss=1.099, Time=0.014
Epoch 1350: batch 1: Loss=1.099, Time=0.010
Epoch 1351: batch 1: Loss=1.099, Time=0.019
Epoch 1351: Time=485.825, Epoch time = 0.324, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1352: batch 1: Loss=1.099, Time=0.011
Epoch 1353: batch 1: Loss=1.099, Time=0.012
Epoch 1354: batch 1: Loss=1.099, Time=0.010
Epoch 1355: batch 1: Loss=1.099, Time=0.010
Epoch 1356: batch 1: Loss=1.099, Time=0.019
Epoch 1357: batch 1: Loss=1.099, Time=0.011
Epoch 1358: batch 1: Loss=1.099, Time=0.010
Epoch 1359: batch 1: Loss=1.099, Time=0.010
Epoch 1360: batch 1: Loss=1.099, Time=0.019
Epoch 1361: batch 1: Loss=1.099, Time=0.010
Epoch 1361: Time=489.444, Epoch time = 0.332, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1362: batch 1: Loss=1.099, Time=0.010
Epoch 1363: batch 1: Loss=1.099, Time=0.019
Epoch 1364: batch 1: Loss=1.099, Time=0.010
Epoch 1365: batch 1: Loss=1.099, Time=0.019
Epoch 1366: batch 1: Loss=1.099, Time=0.010
Epoch 1367: batch 1: Loss=1.099, Time=0.012
Epoch 1368: batch 1: Loss=1.099, Time=0.015
Epoch 1369: batch 1: Loss=1.099, Time=0.010
Epoch 1370: batch 1: Loss=1.099, Time=0.010
Epoch 1371: batch 1: Loss=1.099, Time=0.010
Epoch 1371: Time=493.020, Epoch time = 0.344, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1372: batch 1: Loss=1.099, Time=0.005
Epoch 1373: batch 1: Loss=1.099, Time=0.010
Epoch 1374: batch 1: Loss=1.099, Time=0.012
Epoch 1375: batch 1: Loss=1.099, Time=0.010
Epoch 1376: batch 1: Loss=1.099, Time=0.010
Epoch 1377: batch 1: Loss=1.099, Time=0.019
Epoch 1378: batch 1: Loss=1.099, Time=0.019
Epoch 1379: batch 1: Loss=1.099, Time=0.010
Epoch 1380: batch 1: Loss=1.099, Time=0.010
Epoch 1381: batch 1: Loss=1.099, Time=0.010
Epoch 1381: Time=496.572, Epoch time = 0.348, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1382: batch 1: Loss=1.099, Time=0.010
Epoch 1383: batch 1: Loss=1.099, Time=0.010
Epoch 1384: batch 1: Loss=1.099, Time=0.010
Epoch 1385: batch 1: Loss=1.099, Time=0.010
Epoch 1386: batch 1: Loss=1.099, Time=0.010
Epoch 1387: batch 1: Loss=1.099, Time=0.010
Epoch 1388: batch 1: Loss=1.099, Time=0.010
Epoch 1389: batch 1: Loss=1.099, Time=0.010
Epoch 1390: batch 1: Loss=1.099, Time=0.010
Epoch 1391: batch 1: Loss=1.099, Time=0.011
Epoch 1391: Time=500.091, Epoch time = 0.342, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1392: batch 1: Loss=1.099, Time=0.005
Epoch 1393: batch 1: Loss=1.099, Time=0.011
Epoch 1394: batch 1: Loss=1.099, Time=0.010
Epoch 1395: batch 1: Loss=1.099, Time=0.017
Epoch 1396: batch 1: Loss=1.099, Time=0.010
Epoch 1397: batch 1: Loss=1.099, Time=0.010
Epoch 1398: batch 1: Loss=1.099, Time=0.011
Epoch 1399: batch 1: Loss=1.099, Time=0.010
Epoch 1400: batch 1: Loss=1.099, Time=0.019
Epoch 1401: batch 1: Loss=1.099, Time=0.010
Epoch 1401: Time=503.567, Epoch time = 0.318, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1402: batch 1: Loss=1.099, Time=0.010
Epoch 1403: batch 1: Loss=1.099, Time=0.010
Epoch 1404: batch 1: Loss=1.099, Time=0.010
Epoch 1405: batch 1: Loss=1.099, Time=0.010
Epoch 1406: batch 1: Loss=1.099, Time=0.010
Epoch 1407: batch 1: Loss=1.099, Time=0.010
Epoch 1408: batch 1: Loss=1.099, Time=0.010
Epoch 1409: batch 1: Loss=1.099, Time=0.019
Epoch 1410: batch 1: Loss=1.099, Time=0.010
Epoch 1411: batch 1: Loss=1.099, Time=0.005
Epoch 1411: Time=507.027, Epoch time = 0.300, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1412: batch 1: Loss=1.099, Time=0.011
Epoch 1413: batch 1: Loss=1.099, Time=0.010
Epoch 1414: batch 1: Loss=1.099, Time=0.011
Epoch 1415: batch 1: Loss=1.099, Time=0.010
Epoch 1416: batch 1: Loss=1.099, Time=0.010
Epoch 1417: batch 1: Loss=1.099, Time=0.010
Epoch 1418: batch 1: Loss=1.099, Time=0.010
Epoch 1419: batch 1: Loss=1.099, Time=0.010
^CTraceback (most recent call last):
  File "train_for_gamma_Sony_dead_simple_3gammas.py", line 303, in <module>
    feed_dict={in_image: input_patch, gt_gamma: assigned_image_gamma_index, lr: learning_rate})
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 887, in run
    run_metadata_ptr)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1110, in _run
    feed_dict_tensor, options, run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1286, in _do_run
    run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1292, in _do_call
    return fn(*args)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1277, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1367, in _call_tf_sessionrun
    run_metadata)
KeyboardInterrupt
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ cp train_for_gamma_Sony_dead_simple.py simple_ReLU_Sony.py
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ vi simple_ReLU_Sony.py 
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ vi simple_ReLU_Sony.py 
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ vi simple_ReLU_Sony.py 
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ python simple_ReLU_Sony.py 




Found 161 images to train with

2020-12-11 14:10:15.086224: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 14:10:15.233430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 14:10:15.233462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 14:10:15.518916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 14:10:15.518953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 14:10:15.518971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 14:10:15.519065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.87565, 0.00000, 300.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01631, 300.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00164, 300.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00201, 100.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.02310, 250.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00417, 300.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00886, 300.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00233, 250.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00016, 300.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00613, 100.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00012, 100.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 250.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00144, 300.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00327, 100.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00002, 250.00000, 6735543
20 images loaded to CPU RAM in Time=4.746 seconds.
Starting Training on index 4
Epoch 0: batch 1: Loss=1.099, Time=1.029
Traceback (most recent call last):
  File "simple_ReLU_Sony.py", line 329, in <module>
    os.mkdir(result_dir + '%04d' % epoch)
OSError: [Errno 2] No such file or directory: './gt_Sony_simple_ReLU/0000'
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ mkdir gt_Sony_simple_ReLU
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ python simple_ReLU_Sony.py 




Found 161 images to train with

2020-12-11 14:10:45.246220: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 14:10:45.396169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 14:10:45.396200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 14:10:45.681019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 14:10:45.681055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 14:10:45.681070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 14:10:45.681162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.87565, 0.00000, 300.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01648, 100.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 100.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00201, 100.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.02266, 300.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00417, 300.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00887, 250.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00248, 100.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 100.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 300.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00012, 100.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 300.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00146, 250.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00301, 300.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00002, 250.00000, 6735543
20 images loaded to CPU RAM in Time=4.716 seconds.
Starting Training on index 7
Epoch 0: batch 1: Loss=0.941, Time=1.031
Epoch 1: batch 1: Loss=1.099, Time=0.010
Epoch 1: Time=1.721, Epoch time = 0.335, Avg epoch time=0.000

[[1.09263301]
 [1.0931983 ]
 [1.10151434]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 2: batch 1: Loss=1.090, Time=0.010
Epoch 3: batch 1: Loss=1.098, Time=0.010
Epoch 4: batch 1: Loss=1.081, Time=0.011
Epoch 5: batch 1: Loss=1.100, Time=0.010
Epoch 6: batch 1: Loss=1.093, Time=0.011
Epoch 7: batch 1: Loss=1.098, Time=0.010
Epoch 8: batch 1: Loss=1.097, Time=0.010
Epoch 9: batch 1: Loss=1.101, Time=0.016
Epoch 10: batch 1: Loss=1.100, Time=0.011
Epoch 11: batch 1: Loss=1.080, Time=0.010
Epoch 11: Time=5.287, Epoch time = 0.295, Avg epoch time=0.000

[[1.02552783]
 [1.02857804]
 [1.13424563]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 12: batch 1: Loss=1.089, Time=0.012
Epoch 13: batch 1: Loss=1.092, Time=0.010
Epoch 14: batch 1: Loss=1.078, Time=0.010
Epoch 15: batch 1: Loss=1.076, Time=0.010
Epoch 16: batch 1: Loss=1.085, Time=0.019
Epoch 17: batch 1: Loss=1.048, Time=0.010
Epoch 18: batch 1: Loss=1.091, Time=0.010
Epoch 19: batch 1: Loss=1.055, Time=0.010
Epoch 20: batch 1: Loss=1.079, Time=0.011
Epoch 21: batch 1: Loss=1.074, Time=0.010
Epoch 21: Time=8.932, Epoch time = 0.333, Avg epoch time=0.000

[[0.97635472]
 [0.98441982]
 [1.42226052]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 22: batch 1: Loss=1.114, Time=0.011
Epoch 23: batch 1: Loss=1.110, Time=0.010
Epoch 24: batch 1: Loss=1.075, Time=0.011
Epoch 25: batch 1: Loss=1.082, Time=0.010
Epoch 26: batch 1: Loss=1.098, Time=0.010
Epoch 27: batch 1: Loss=1.133, Time=0.010
Epoch 28: batch 1: Loss=1.120, Time=0.005
Epoch 29: batch 1: Loss=1.049, Time=0.010
Epoch 30: batch 1: Loss=1.094, Time=0.010
Epoch 31: batch 1: Loss=1.085, Time=0.010
Epoch 31: Time=12.518, Epoch time = 0.320, Avg epoch time=0.000

[[0.98580253]
 [0.97882175]
 [1.16238368]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 32: batch 1: Loss=1.092, Time=0.010
Epoch 33: batch 1: Loss=1.057, Time=0.019
Epoch 34: batch 1: Loss=1.099, Time=0.019
Epoch 35: batch 1: Loss=1.108, Time=0.019
Epoch 36: batch 1: Loss=1.090, Time=0.010
Epoch 37: batch 1: Loss=1.093, Time=0.010
Epoch 38: batch 1: Loss=1.091, Time=0.019
Epoch 39: batch 1: Loss=1.055, Time=0.019
Epoch 40: batch 1: Loss=1.095, Time=0.007
Epoch 41: batch 1: Loss=1.070, Time=0.011
Epoch 41: Time=16.158, Epoch time = 0.320, Avg epoch time=0.000

[[0.97324455]
 [0.97022498]
 [1.17209268]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 42: batch 1: Loss=1.099, Time=0.010
Epoch 43: batch 1: Loss=1.099, Time=0.010
Epoch 44: batch 1: Loss=1.111, Time=0.010
Epoch 45: batch 1: Loss=1.093, Time=0.010
Epoch 46: batch 1: Loss=1.092, Time=0.011
Epoch 47: batch 1: Loss=1.082, Time=0.010
Epoch 48: batch 1: Loss=1.095, Time=0.010
Epoch 49: batch 1: Loss=1.095, Time=0.019
Epoch 50: batch 1: Loss=1.095, Time=0.005
Epoch 51: batch 1: Loss=1.051, Time=0.010
Epoch 51: Time=19.741, Epoch time = 0.369, Avg epoch time=0.000

[[0.95902836]
 [0.95318377]
 [1.18354475]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 52: batch 1: Loss=1.040, Time=0.020
Epoch 53: batch 1: Loss=1.055, Time=0.010
Epoch 54: batch 1: Loss=1.089, Time=0.010
Epoch 55: batch 1: Loss=1.093, Time=0.019
Epoch 56: batch 1: Loss=1.111, Time=0.011
Epoch 57: batch 1: Loss=1.091, Time=0.007
Epoch 58: batch 1: Loss=1.070, Time=0.019
Epoch 59: batch 1: Loss=1.126, Time=0.010
Epoch 60: batch 1: Loss=1.091, Time=0.019
Epoch 61: batch 1: Loss=1.097, Time=0.005
Epoch 61: Time=23.306, Epoch time = 0.327, Avg epoch time=0.000

[[0.97633213]
 [0.97740996]
 [1.17370832]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 62: batch 1: Loss=1.114, Time=0.010
Epoch 63: batch 1: Loss=1.053, Time=0.010
Epoch 64: batch 1: Loss=1.087, Time=0.010
Epoch 65: batch 1: Loss=1.083, Time=0.010
Epoch 66: batch 1: Loss=1.104, Time=0.010
Epoch 67: batch 1: Loss=1.090, Time=0.010
Epoch 68: batch 1: Loss=1.090, Time=0.010
Epoch 69: batch 1: Loss=1.104, Time=0.010
Epoch 70: batch 1: Loss=1.096, Time=0.008
Epoch 71: batch 1: Loss=1.108, Time=0.019
Epoch 71: Time=26.899, Epoch time = 0.333, Avg epoch time=0.000

[[0.95535088]
 [0.94551128]
 [1.18338668]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 72: batch 1: Loss=1.100, Time=0.014
Epoch 73: batch 1: Loss=1.089, Time=0.019
Epoch 74: batch 1: Loss=1.079, Time=0.010
Epoch 75: batch 1: Loss=1.083, Time=0.010
Epoch 76: batch 1: Loss=1.091, Time=0.011
Epoch 77: batch 1: Loss=1.095, Time=0.019
Epoch 78: batch 1: Loss=1.092, Time=0.019
Epoch 79: batch 1: Loss=1.070, Time=0.010
Epoch 80: batch 1: Loss=1.089, Time=0.011
Epoch 81: batch 1: Loss=1.114, Time=0.011
Epoch 81: Time=30.481, Epoch time = 0.299, Avg epoch time=0.000

[[0.95188439]
 [0.95209837]
 [1.18104231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 82: batch 1: Loss=1.083, Time=0.019
Epoch 83: batch 1: Loss=1.085, Time=0.010
Epoch 84: batch 1: Loss=1.075, Time=0.019
Epoch 85: batch 1: Loss=1.090, Time=0.019
Epoch 86: batch 1: Loss=1.046, Time=0.012
Epoch 87: batch 1: Loss=1.092, Time=0.019
Epoch 88: batch 1: Loss=1.088, Time=0.010
Epoch 89: batch 1: Loss=1.099, Time=0.019
Epoch 90: batch 1: Loss=1.118, Time=0.010
Epoch 91: batch 1: Loss=1.102, Time=0.019
Epoch 91: Time=34.083, Epoch time = 0.356, Avg epoch time=0.000

[[0.95579708]
 [0.96022224]
 [1.2883147 ]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 92: batch 1: Loss=1.085, Time=0.011
Epoch 93: batch 1: Loss=1.100, Time=0.010
Epoch 94: batch 1: Loss=1.090, Time=0.020
Epoch 95: batch 1: Loss=1.095, Time=0.019
Epoch 96: batch 1: Loss=1.090, Time=0.010
Epoch 97: batch 1: Loss=1.125, Time=0.016
Epoch 98: batch 1: Loss=1.089, Time=0.011
Epoch 99: batch 1: Loss=1.093, Time=0.010
Epoch 100: batch 1: Loss=1.090, Time=0.010
Epoch 101: batch 1: Loss=1.089, Time=0.010
Epoch 101: Time=37.638, Epoch time = 0.339, Avg epoch time=0.000

[[0.94965655]
 [0.95408523]
 [1.20251215]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 102: batch 1: Loss=1.095, Time=0.010
Epoch 103: batch 1: Loss=1.085, Time=0.011
Epoch 104: batch 1: Loss=1.094, Time=0.010
Epoch 105: batch 1: Loss=1.076, Time=0.010
Epoch 106: batch 1: Loss=1.119, Time=0.010
Epoch 107: batch 1: Loss=1.091, Time=0.010
Epoch 108: batch 1: Loss=1.089, Time=0.006
Epoch 109: batch 1: Loss=1.098, Time=0.019
Epoch 110: batch 1: Loss=1.082, Time=0.019
Epoch 111: batch 1: Loss=1.091, Time=0.010
Epoch 111: Time=41.242, Epoch time = 0.342, Avg epoch time=0.000

[[0.94183439]
 [0.94159573]
 [1.19145489]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 112: batch 1: Loss=1.092, Time=0.011
Epoch 113: batch 1: Loss=1.082, Time=0.010
Epoch 114: batch 1: Loss=1.087, Time=0.019
Epoch 115: batch 1: Loss=1.076, Time=0.010
Epoch 116: batch 1: Loss=1.082, Time=0.011
Epoch 117: batch 1: Loss=1.076, Time=0.010
Epoch 118: batch 1: Loss=1.084, Time=0.019
Epoch 119: batch 1: Loss=1.096, Time=0.019
Epoch 120: batch 1: Loss=1.092, Time=0.010
Epoch 121: batch 1: Loss=1.074, Time=0.010
Epoch 121: Time=44.786, Epoch time = 0.338, Avg epoch time=0.000

[[0.92744851]
 [0.92790008]
 [1.19671905]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 122: batch 1: Loss=1.087, Time=0.011
Epoch 123: batch 1: Loss=1.070, Time=0.019
Epoch 124: batch 1: Loss=1.060, Time=0.010
Epoch 125: batch 1: Loss=1.089, Time=0.010
Epoch 126: batch 1: Loss=1.092, Time=0.010
Epoch 127: batch 1: Loss=1.126, Time=0.010
Epoch 128: batch 1: Loss=1.099, Time=0.011
Epoch 129: batch 1: Loss=1.038, Time=0.010
Epoch 130: batch 1: Loss=1.091, Time=0.016
Epoch 131: batch 1: Loss=1.088, Time=0.011
Epoch 131: Time=48.436, Epoch time = 0.345, Avg epoch time=0.000

[[0.93758959]
 [0.94056463]
 [1.14798236]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 132: batch 1: Loss=1.063, Time=0.010
Epoch 133: batch 1: Loss=1.096, Time=0.010
Epoch 134: batch 1: Loss=1.091, Time=0.010
Epoch 135: batch 1: Loss=1.058, Time=0.010
Epoch 136: batch 1: Loss=1.077, Time=0.019
Epoch 137: batch 1: Loss=1.056, Time=0.011
Epoch 138: batch 1: Loss=1.095, Time=0.010
Epoch 139: batch 1: Loss=1.090, Time=0.010
Epoch 140: batch 1: Loss=1.090, Time=0.011
Epoch 141: batch 1: Loss=1.093, Time=0.010
Epoch 141: Time=51.975, Epoch time = 0.353, Avg epoch time=0.000

[[0.94252282]
 [0.95369989]
 [1.17900872]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 142: batch 1: Loss=1.065, Time=0.011
Epoch 143: batch 1: Loss=1.078, Time=0.010
Epoch 144: batch 1: Loss=1.081, Time=0.014
Epoch 145: batch 1: Loss=1.097, Time=0.011
Epoch 146: batch 1: Loss=1.102, Time=0.019
Epoch 147: batch 1: Loss=1.086, Time=0.019
Epoch 148: batch 1: Loss=1.098, Time=0.019
Epoch 149: batch 1: Loss=1.068, Time=0.010
Epoch 150: batch 1: Loss=1.049, Time=0.019
Epoch 151: batch 1: Loss=1.086, Time=0.010
Epoch 151: Time=55.623, Epoch time = 0.325, Avg epoch time=0.000

[[0.94502723]
 [0.94498783]
 [1.18577969]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 152: batch 1: Loss=1.087, Time=0.010
Epoch 153: batch 1: Loss=1.091, Time=0.010
Epoch 154: batch 1: Loss=1.031, Time=0.010
Epoch 155: batch 1: Loss=1.046, Time=0.010
Epoch 156: batch 1: Loss=1.024, Time=0.019
Epoch 157: batch 1: Loss=1.038, Time=0.010
Epoch 158: batch 1: Loss=1.049, Time=0.010
Epoch 159: batch 1: Loss=1.019, Time=0.010
Epoch 160: batch 1: Loss=1.062, Time=0.019
Epoch 161: batch 1: Loss=1.062, Time=0.010
Epoch 161: Time=59.214, Epoch time = 0.319, Avg epoch time=0.000

[[0.97909695]
 [0.95786643]
 [1.18009555]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 162: batch 1: Loss=1.040, Time=0.008
Epoch 163: batch 1: Loss=1.069, Time=0.010
Epoch 164: batch 1: Loss=1.039, Time=0.011
Epoch 165: batch 1: Loss=1.106, Time=0.010
Epoch 166: batch 1: Loss=1.476, Time=0.010
Epoch 167: batch 1: Loss=1.039, Time=0.006
Epoch 168: batch 1: Loss=1.001, Time=0.010
Epoch 169: batch 1: Loss=1.104, Time=0.010
Epoch 170: batch 1: Loss=1.112, Time=0.010
Epoch 171: batch 1: Loss=1.068, Time=0.010
Epoch 171: Time=62.739, Epoch time = 0.357, Avg epoch time=0.000

[[1.02149558]
 [1.0214951 ]
 [4.32742596]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 172: batch 1: Loss=1.258, Time=0.020
Epoch 173: batch 1: Loss=1.079, Time=0.010
Epoch 174: batch 1: Loss=1.102, Time=0.010
Epoch 175: batch 1: Loss=1.078, Time=0.010
Epoch 176: batch 1: Loss=1.047, Time=0.010
Epoch 177: batch 1: Loss=1.097, Time=0.010
Epoch 178: batch 1: Loss=1.097, Time=0.020
Epoch 179: batch 1: Loss=1.092, Time=0.009
Epoch 180: batch 1: Loss=1.087, Time=0.010
Epoch 181: batch 1: Loss=1.084, Time=0.010
Epoch 181: Time=66.239, Epoch time = 0.311, Avg epoch time=0.000

[[0.99233514]
 [0.99165046]
 [1.15669835]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 182: batch 1: Loss=1.092, Time=0.010
Epoch 183: batch 1: Loss=1.085, Time=0.010
Epoch 184: batch 1: Loss=1.041, Time=0.010
Epoch 185: batch 1: Loss=1.053, Time=0.011
Epoch 186: batch 1: Loss=1.095, Time=0.010
Epoch 187: batch 1: Loss=1.091, Time=0.020
Epoch 188: batch 1: Loss=1.069, Time=0.010
Epoch 189: batch 1: Loss=1.083, Time=0.010
Epoch 190: batch 1: Loss=1.050, Time=0.010
Epoch 191: batch 1: Loss=1.091, Time=0.011
Epoch 191: Time=69.821, Epoch time = 0.328, Avg epoch time=0.000

[[0.98562598]
 [0.98118675]
 [1.39782095]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 192: batch 1: Loss=1.103, Time=0.011
Epoch 193: batch 1: Loss=1.035, Time=0.018
Epoch 194: batch 1: Loss=1.066, Time=0.010
Epoch 195: batch 1: Loss=1.043, Time=0.019
Epoch 196: batch 1: Loss=1.081, Time=0.010
Epoch 197: batch 1: Loss=1.075, Time=0.010
Epoch 198: batch 1: Loss=1.053, Time=0.010
Epoch 199: batch 1: Loss=1.151, Time=0.019
Epoch 200: batch 1: Loss=1.090, Time=0.010
Epoch 201: batch 1: Loss=1.044, Time=0.011
Epoch 201: Time=73.434, Epoch time = 0.322, Avg epoch time=0.000

[[0.98369169]
 [0.98365414]
 [1.16419554]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 202: batch 1: Loss=1.084, Time=0.010
Epoch 203: batch 1: Loss=1.073, Time=0.010
Epoch 204: batch 1: Loss=1.060, Time=0.010
Epoch 205: batch 1: Loss=1.046, Time=0.010
Epoch 206: batch 1: Loss=1.090, Time=0.010
Epoch 207: batch 1: Loss=1.086, Time=0.011
Epoch 208: batch 1: Loss=1.070, Time=0.010
Epoch 209: batch 1: Loss=1.137, Time=0.010
Epoch 210: batch 1: Loss=1.092, Time=0.019
Epoch 211: batch 1: Loss=1.087, Time=0.011
Epoch 211: Time=77.064, Epoch time = 0.349, Avg epoch time=0.000

[[0.95423722]
 [0.9612506 ]
 [1.12624347]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 212: batch 1: Loss=1.095, Time=0.011
Epoch 213: batch 1: Loss=1.090, Time=0.010
Epoch 214: batch 1: Loss=1.126, Time=0.010
Epoch 215: batch 1: Loss=1.092, Time=0.011
Epoch 216: batch 1: Loss=1.043, Time=0.007
Epoch 217: batch 1: Loss=1.069, Time=0.010
Epoch 218: batch 1: Loss=1.088, Time=0.010
Epoch 219: batch 1: Loss=1.039, Time=0.019
Epoch 220: batch 1: Loss=1.094, Time=0.008
Epoch 221: batch 1: Loss=1.094, Time=0.011
Epoch 221: Time=80.666, Epoch time = 0.348, Avg epoch time=0.000

[[0.94666815]
 [0.94533527]
 [1.18447888]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 222: batch 1: Loss=1.043, Time=0.010
Epoch 223: batch 1: Loss=1.089, Time=0.010
Epoch 224: batch 1: Loss=1.079, Time=0.010
Epoch 225: batch 1: Loss=1.027, Time=0.011
Epoch 226: batch 1: Loss=1.116, Time=0.020
Epoch 227: batch 1: Loss=1.090, Time=0.019
Epoch 228: batch 1: Loss=1.081, Time=0.010
Epoch 229: batch 1: Loss=1.062, Time=0.019
Epoch 230: batch 1: Loss=1.096, Time=0.010
Epoch 231: batch 1: Loss=1.082, Time=0.010
Epoch 231: Time=84.203, Epoch time = 0.339, Avg epoch time=0.000

[[0.94443017]
 [0.92731774]
 [1.18511832]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 232: batch 1: Loss=1.098, Time=0.010
Epoch 233: batch 1: Loss=1.090, Time=0.010
Epoch 234: batch 1: Loss=1.093, Time=0.010
Epoch 235: batch 1: Loss=1.099, Time=0.010
Epoch 236: batch 1: Loss=1.097, Time=0.010
Epoch 237: batch 1: Loss=1.092, Time=0.010
Epoch 238: batch 1: Loss=1.091, Time=0.010
Epoch 239: batch 1: Loss=1.051, Time=0.010
Epoch 240: batch 1: Loss=1.077, Time=0.010
Epoch 241: batch 1: Loss=1.047, Time=0.006
Epoch 241: Time=87.795, Epoch time = 0.337, Avg epoch time=0.000

[[0.95583248]
 [0.9654485 ]
 [1.17634952]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 242: batch 1: Loss=1.064, Time=0.010
Epoch 243: batch 1: Loss=1.085, Time=0.010
Epoch 244: batch 1: Loss=1.092, Time=0.020
Epoch 245: batch 1: Loss=1.093, Time=0.005
Epoch 246: batch 1: Loss=1.095, Time=0.010
Epoch 247: batch 1: Loss=1.067, Time=0.019
Epoch 248: batch 1: Loss=1.068, Time=0.011
Epoch 249: batch 1: Loss=1.097, Time=0.013
Epoch 250: batch 1: Loss=1.082, Time=0.019
Epoch 251: batch 1: Loss=1.098, Time=0.011
Epoch 251: Time=91.444, Epoch time = 0.328, Avg epoch time=0.000

[[0.94387221]
 [0.9429636 ]
 [1.33438456]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 252: batch 1: Loss=1.099, Time=0.019
Epoch 253: batch 1: Loss=1.017, Time=0.011
Epoch 254: batch 1: Loss=1.068, Time=0.010
Epoch 255: batch 1: Loss=1.067, Time=0.011
Epoch 256: batch 1: Loss=1.088, Time=0.010
Epoch 257: batch 1: Loss=1.064, Time=0.010
Epoch 258: batch 1: Loss=1.088, Time=0.010
Epoch 259: batch 1: Loss=1.076, Time=0.010
Epoch 260: batch 1: Loss=1.084, Time=0.012
Epoch 261: batch 1: Loss=1.087, Time=0.010
Epoch 261: Time=94.961, Epoch time = 0.309, Avg epoch time=0.000

[[0.95465791]
 [0.97721303]
 [1.14115608]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 262: batch 1: Loss=1.099, Time=0.020
Epoch 263: batch 1: Loss=1.079, Time=0.011
Epoch 264: batch 1: Loss=1.077, Time=0.010
Epoch 265: batch 1: Loss=1.081, Time=0.010
Epoch 266: batch 1: Loss=1.087, Time=0.010
Epoch 267: batch 1: Loss=1.061, Time=0.019
Epoch 268: batch 1: Loss=1.083, Time=0.019
Epoch 269: batch 1: Loss=1.092, Time=0.010
Epoch 270: batch 1: Loss=1.051, Time=0.011
Epoch 271: batch 1: Loss=1.050, Time=0.010
Epoch 271: Time=98.650, Epoch time = 0.351, Avg epoch time=0.000

[[0.98224235]
 [0.96401685]
 [1.09215164]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 272: batch 1: Loss=1.081, Time=0.010
Epoch 273: batch 1: Loss=1.082, Time=0.010
Epoch 274: batch 1: Loss=1.085, Time=0.010
Epoch 275: batch 1: Loss=1.052, Time=0.010
Epoch 276: batch 1: Loss=0.997, Time=0.010
Epoch 277: batch 1: Loss=1.081, Time=0.020
Epoch 278: batch 1: Loss=1.045, Time=0.011
Epoch 279: batch 1: Loss=1.073, Time=0.010
Epoch 280: batch 1: Loss=1.068, Time=0.015
Epoch 281: batch 1: Loss=1.091, Time=0.011
Epoch 281: Time=102.278, Epoch time = 0.326, Avg epoch time=0.000

[[0.9329375 ]
 [0.93751246]
 [1.12870848]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 282: batch 1: Loss=1.053, Time=0.010
Epoch 283: batch 1: Loss=1.052, Time=0.010
Epoch 284: batch 1: Loss=1.086, Time=0.010
Epoch 285: batch 1: Loss=1.096, Time=0.019
Epoch 286: batch 1: Loss=1.085, Time=0.011
Epoch 287: batch 1: Loss=1.067, Time=0.010
Epoch 288: batch 1: Loss=1.084, Time=0.010
Epoch 289: batch 1: Loss=1.064, Time=0.010
Epoch 290: batch 1: Loss=1.038, Time=0.006
Epoch 291: batch 1: Loss=1.051, Time=0.007
Epoch 291: Time=105.844, Epoch time = 0.340, Avg epoch time=0.000

[[0.96411633]
 [0.96478295]
 [1.7790122 ]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 292: batch 1: Loss=1.116, Time=0.019
Epoch 293: batch 1: Loss=1.103, Time=0.010
Epoch 294: batch 1: Loss=1.115, Time=0.010
Epoch 295: batch 1: Loss=1.008, Time=0.011
Epoch 296: batch 1: Loss=1.024, Time=0.019
Epoch 297: batch 1: Loss=1.069, Time=0.010
Epoch 298: batch 1: Loss=1.084, Time=0.010
Epoch 299: batch 1: Loss=1.075, Time=0.010
Epoch 300: batch 1: Loss=1.088, Time=0.010
Epoch 301: batch 1: Loss=1.074, Time=0.011
Epoch 301: Time=109.465, Epoch time = 0.349, Avg epoch time=0.000

[[0.96752322]
 [0.97108454]
 [1.04285812]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 302: batch 1: Loss=1.071, Time=0.019
Epoch 303: batch 1: Loss=1.043, Time=0.010
Epoch 304: batch 1: Loss=1.086, Time=0.020
Epoch 305: batch 1: Loss=1.065, Time=0.019
Epoch 306: batch 1: Loss=1.095, Time=0.010
Epoch 307: batch 1: Loss=1.118, Time=0.011
Epoch 308: batch 1: Loss=1.065, Time=0.010
Epoch 309: batch 1: Loss=1.085, Time=0.010
Epoch 310: batch 1: Loss=1.080, Time=0.010
Epoch 311: batch 1: Loss=1.046, Time=0.011
Epoch 311: Time=113.002, Epoch time = 0.322, Avg epoch time=0.000

[[0.94984043]
 [0.95072746]
 [1.04711604]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 312: batch 1: Loss=1.062, Time=0.019
Epoch 313: batch 1: Loss=1.081, Time=0.019
Epoch 314: batch 1: Loss=1.090, Time=0.011
Epoch 315: batch 1: Loss=1.080, Time=0.010
Epoch 316: batch 1: Loss=1.020, Time=0.010
Epoch 317: batch 1: Loss=1.062, Time=0.011
Epoch 318: batch 1: Loss=1.070, Time=0.010
Epoch 319: batch 1: Loss=1.072, Time=0.010
Epoch 320: batch 1: Loss=1.071, Time=0.010
Epoch 321: batch 1: Loss=1.071, Time=0.012
Epoch 321: Time=116.659, Epoch time = 0.352, Avg epoch time=0.000

[[0.95387185]
 [0.95666981]
 [1.05546629]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 322: batch 1: Loss=1.027, Time=0.011
Epoch 323: batch 1: Loss=1.111, Time=0.010
Epoch 324: batch 1: Loss=1.102, Time=0.010
Epoch 325: batch 1: Loss=1.083, Time=0.010
Epoch 326: batch 1: Loss=1.083, Time=0.010
Epoch 327: batch 1: Loss=1.125, Time=0.010
Epoch 328: batch 1: Loss=1.094, Time=0.020
Epoch 329: batch 1: Loss=1.037, Time=0.010
Epoch 330: batch 1: Loss=1.040, Time=0.010
Epoch 331: batch 1: Loss=1.067, Time=0.010
Epoch 331: Time=120.239, Epoch time = 0.343, Avg epoch time=0.000

[[0.94513547]
 [0.95175827]
 [1.16705513]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 332: batch 1: Loss=1.077, Time=0.010
Epoch 333: batch 1: Loss=1.090, Time=0.010
Epoch 334: batch 1: Loss=1.091, Time=0.010
Epoch 335: batch 1: Loss=1.098, Time=0.019
Epoch 336: batch 1: Loss=1.065, Time=0.011
Epoch 337: batch 1: Loss=1.082, Time=0.011
Epoch 338: batch 1: Loss=1.098, Time=0.019
Epoch 339: batch 1: Loss=1.095, Time=0.008
Epoch 340: batch 1: Loss=1.099, Time=0.010
Epoch 341: batch 1: Loss=1.083, Time=0.020
Epoch 341: Time=123.864, Epoch time = 0.367, Avg epoch time=0.000

[[0.95665067]
 [0.96586788]
 [1.0543611 ]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 342: batch 1: Loss=1.037, Time=0.019
Epoch 343: batch 1: Loss=1.045, Time=0.010
Epoch 344: batch 1: Loss=1.051, Time=0.010
Epoch 345: batch 1: Loss=1.058, Time=0.020
Epoch 346: batch 1: Loss=1.039, Time=0.011
Epoch 347: batch 1: Loss=1.106, Time=0.010
Epoch 348: batch 1: Loss=1.057, Time=0.010
Epoch 349: batch 1: Loss=1.077, Time=0.019
Epoch 350: batch 1: Loss=1.084, Time=0.010
Epoch 351: batch 1: Loss=1.040, Time=0.010
Epoch 351: Time=127.536, Epoch time = 0.342, Avg epoch time=0.000

[[0.95583594]
 [0.96085966]
 [1.06039226]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 352: batch 1: Loss=1.049, Time=0.011
Epoch 353: batch 1: Loss=1.036, Time=0.019
Epoch 354: batch 1: Loss=1.042, Time=0.016
Epoch 355: batch 1: Loss=1.117, Time=0.010
Epoch 356: batch 1: Loss=1.083, Time=0.011
Epoch 357: batch 1: Loss=1.059, Time=0.010
Epoch 358: batch 1: Loss=1.084, Time=0.010
Epoch 359: batch 1: Loss=1.014, Time=0.010
Epoch 360: batch 1: Loss=1.077, Time=0.010
Epoch 361: batch 1: Loss=1.087, Time=0.011
Epoch 361: Time=131.143, Epoch time = 0.318, Avg epoch time=0.000

[[0.9602046 ]
 [0.94536281]
 [1.05214894]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 362: batch 1: Loss=1.080, Time=0.020
Epoch 363: batch 1: Loss=1.133, Time=0.010
Epoch 364: batch 1: Loss=1.062, Time=0.019
Epoch 365: batch 1: Loss=1.101, Time=0.011
Epoch 366: batch 1: Loss=1.075, Time=0.011
Epoch 367: batch 1: Loss=1.044, Time=0.010
Epoch 368: batch 1: Loss=1.078, Time=0.010
Epoch 369: batch 1: Loss=1.066, Time=0.011
Epoch 370: batch 1: Loss=1.100, Time=0.019
Epoch 371: batch 1: Loss=1.059, Time=0.019
Epoch 371: Time=134.812, Epoch time = 0.352, Avg epoch time=0.000

[[0.9735043 ]
 [0.95539868]
 [1.03090608]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 372: batch 1: Loss=1.088, Time=0.010
Epoch 373: batch 1: Loss=1.088, Time=0.019
Epoch 374: batch 1: Loss=1.066, Time=0.019
Epoch 375: batch 1: Loss=1.042, Time=0.010
Epoch 376: batch 1: Loss=1.047, Time=0.011
Epoch 377: batch 1: Loss=1.047, Time=0.010
Epoch 378: batch 1: Loss=1.085, Time=0.019
Epoch 379: batch 1: Loss=1.147, Time=0.020
Epoch 380: batch 1: Loss=1.076, Time=0.019
Epoch 381: batch 1: Loss=1.089, Time=0.010
Epoch 381: Time=138.361, Epoch time = 0.315, Avg epoch time=0.000

[[0.95847237]
 [0.95992756]
 [1.05641079]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 382: batch 1: Loss=1.093, Time=0.019
Epoch 383: batch 1: Loss=1.090, Time=0.019
Epoch 384: batch 1: Loss=1.079, Time=0.010
Epoch 385: batch 1: Loss=1.048, Time=0.010
Epoch 386: batch 1: Loss=1.061, Time=0.010
Epoch 387: batch 1: Loss=1.089, Time=0.010
Epoch 388: batch 1: Loss=1.077, Time=0.011
Epoch 389: batch 1: Loss=1.046, Time=0.005
Epoch 390: batch 1: Loss=1.095, Time=0.010
Epoch 391: batch 1: Loss=1.083, Time=0.019
Epoch 391: Time=141.987, Epoch time = 0.365, Avg epoch time=0.000

[[0.98947442]
 [0.98236334]
 [1.02674329]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 392: batch 1: Loss=1.101, Time=0.020
Epoch 393: batch 1: Loss=1.127, Time=0.019
Epoch 394: batch 1: Loss=1.097, Time=0.007
Epoch 395: batch 1: Loss=1.080, Time=0.010
Epoch 396: batch 1: Loss=1.087, Time=0.010
Epoch 397: batch 1: Loss=1.123, Time=0.015
Epoch 398: batch 1: Loss=1.090, Time=0.010
Epoch 399: batch 1: Loss=1.039, Time=0.010
Epoch 400: batch 1: Loss=1.044, Time=0.010
Epoch 401: batch 1: Loss=1.087, Time=0.011
Epoch 401: Time=145.588, Epoch time = 0.325, Avg epoch time=0.000

[[0.96717662]
 [0.97234362]
 [1.03999412]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 402: batch 1: Loss=1.089, Time=0.010
Epoch 403: batch 1: Loss=1.083, Time=0.010
Epoch 404: batch 1: Loss=1.081, Time=0.010
Epoch 405: batch 1: Loss=1.095, Time=0.019
Epoch 406: batch 1: Loss=1.033, Time=0.010
Epoch 407: batch 1: Loss=1.114, Time=0.010
Epoch 408: batch 1: Loss=1.040, Time=0.010
Epoch 409: batch 1: Loss=1.085, Time=0.010
Epoch 410: batch 1: Loss=1.074, Time=0.010
Epoch 411: batch 1: Loss=1.086, Time=0.020
Epoch 411: Time=149.214, Epoch time = 0.342, Avg epoch time=0.000

[[0.94339907]
 [0.93528152]
 [1.06762505]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 412: batch 1: Loss=1.083, Time=0.005
Epoch 413: batch 1: Loss=1.078, Time=0.010
Epoch 414: batch 1: Loss=1.054, Time=0.010
Epoch 415: batch 1: Loss=1.040, Time=0.011
Epoch 416: batch 1: Loss=1.037, Time=0.011
Epoch 417: batch 1: Loss=1.179, Time=0.010
Epoch 418: batch 1: Loss=1.162, Time=0.010
Epoch 419: batch 1: Loss=1.117, Time=0.010
Epoch 420: batch 1: Loss=1.086, Time=0.010
Epoch 421: batch 1: Loss=1.010, Time=0.011
Epoch 421: Time=152.758, Epoch time = 0.349, Avg epoch time=0.000

[[0.96101558]
 [0.96127743]
 [1.04293633]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 422: batch 1: Loss=1.085, Time=0.010
Epoch 423: batch 1: Loss=1.081, Time=0.011
Epoch 424: batch 1: Loss=1.067, Time=0.010
Epoch 425: batch 1: Loss=1.080, Time=0.019
Epoch 426: batch 1: Loss=1.057, Time=0.010
Epoch 427: batch 1: Loss=1.086, Time=0.010
Epoch 428: batch 1: Loss=1.098, Time=0.019
Epoch 429: batch 1: Loss=1.086, Time=0.010
Epoch 430: batch 1: Loss=1.085, Time=0.010
Epoch 431: batch 1: Loss=1.127, Time=0.020
Epoch 431: Time=156.342, Epoch time = 0.327, Avg epoch time=0.000

[[0.94829082]
 [0.95451546]
 [1.0385592 ]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 432: batch 1: Loss=1.080, Time=0.019
Epoch 433: batch 1: Loss=1.090, Time=0.010
Epoch 434: batch 1: Loss=1.093, Time=0.020
Epoch 435: batch 1: Loss=1.078, Time=0.011
Epoch 436: batch 1: Loss=1.068, Time=0.011
Epoch 437: batch 1: Loss=1.095, Time=0.010
Epoch 438: batch 1: Loss=1.077, Time=0.019
Epoch 439: batch 1: Loss=1.082, Time=0.011
Epoch 440: batch 1: Loss=1.088, Time=0.018
Epoch 441: batch 1: Loss=1.085, Time=0.007
Epoch 441: Time=159.966, Epoch time = 0.334, Avg epoch time=0.000

[[0.93328071]
 [0.93810534]
 [0.99678802]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 442: batch 1: Loss=1.070, Time=0.020
^CTraceback (most recent call last):
  File "simple_ReLU_Sony.py", line 298, in <module>
    feed_dict={in_image: input_patch, gt_gamma: assigned_image_gamma_index, lr: learning_rate})
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 887, in run
    run_metadata_ptr)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1110, in _run
    feed_dict_tensor, options, run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1286, in _do_run
    run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1292, in _do_call
    return fn(*args)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1277, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1367, in _call_tf_sessionrun
    run_metadata)
KeyboardInterrupt
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ mkdir gt_Sony_simple_ReLU_BN
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ vi simple_ReLU_BN_Sony.py
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ python simple_ReLU_BN_Sony.py 




Found 161 images to train with

2020-12-11 14:21:22.167575: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 14:21:22.322480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 14:21:22.322514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 14:21:22.607453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 14:21:22.607491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 14:21:22.607504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 14:21:22.607595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)
Traceback (most recent call last):
  File "simple_ReLU_BN_Sony.py", line 99, in <module>
    out_gamma = network(in_image)
  File "simple_ReLU_BN_Sony.py", line 52, in network
    bn2 = slim.batch_norm(conv2, scope='g_conv1_bn1')
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py", line 182, in func_with_args
    return func(*args, **current_args)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py", line 650, in batch_norm
    outputs = layer.apply(inputs, training=is_training)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/keras/engine/base_layer.py", line 828, in apply
    return self.__call__(inputs, *args, **kwargs)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/layers/base.py", line 364, in __call__
    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/keras/engine/base_layer.py", line 759, in __call__
    self.build(input_shapes)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/keras/layers/normalization.py", line 297, in build
    trainable=True)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/layers/base.py", line 278, in add_weight
    getter=vs.get_variable)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/keras/engine/base_layer.py", line 586, in add_weight
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/training/checkpointable/base.py", line 591, in _add_variable_with_custom_getter
    **kwargs_for_getter)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 1484, in get_variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 1234, in get_variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 521, in get_variable
    return custom_getter(**custom_getter_kwargs)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py", line 1749, in layer_variable_getter
    return _model_variable_getter(getter, *args, **kwargs)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py", line 1740, in _model_variable_getter
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py", line 182, in func_with_args
    return func(*args, **current_args)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py", line 350, in model_variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py", line 182, in func_with_args
    return func(*args, **current_args)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py", line 277, in variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 492, in _true_getter
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 859, in _get_single_variable
    name, "".join(traceback.format_list(tb))))
ValueError: Variable g_conv1_bn1/beta already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:

  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py", line 277, in variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py", line 182, in func_with_args
    return func(*args, **current_args)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py", line 350, in model_variable
    aggregation=aggregation)

(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ vi simple_ReLU_BN_Sony.py
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ python simple_ReLU_BN_Sony.py 




Found 161 images to train with

2020-12-11 14:22:22.367743: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 14:22:22.520672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 14:22:22.520702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 14:22:22.805414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 14:22:22.805448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 14:22:22.805465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 14:22:22.805559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.89525, 0.00000, 250.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01633, 250.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00164, 300.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00201, 100.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.02465, 100.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00467, 100.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00886, 300.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00228, 300.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 250.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00613, 100.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00012, 250.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 250.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00146, 250.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00327, 100.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00002, 250.00000, 6735543
20 images loaded to CPU RAM in Time=4.759 seconds.
Starting Training on index 2
Epoch 0: at batch 1: Loss=1.099, Time=1.006
Epoch 1: at batch 1: Loss=1.193, Time=0.010
Epoch 1: Time=1.709, Epoch time = 0.327, Avg epoch time=0.000

[[0.99561006]
 [1.07191348]
 [1.06014276]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 2: at batch 1: Loss=1.085, Time=0.010
Epoch 3: at batch 1: Loss=1.067, Time=0.010
Epoch 4: at batch 1: Loss=1.053, Time=0.019
Epoch 5: at batch 1: Loss=1.237, Time=0.011
Epoch 6: at batch 1: Loss=1.045, Time=0.020
Epoch 7: at batch 1: Loss=1.083, Time=0.011
Epoch 8: at batch 1: Loss=1.036, Time=0.010
Epoch 9: at batch 1: Loss=1.162, Time=0.008
Epoch 10: at batch 1: Loss=1.157, Time=0.011
Epoch 11: at batch 1: Loss=1.034, Time=0.011
Epoch 11: Time=5.349, Epoch time = 0.339, Avg epoch time=0.000

[[0.70631713]
 [0.72026706]
 [1.44372559]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 12: at batch 1: Loss=1.104, Time=0.010
Epoch 13: at batch 1: Loss=1.033, Time=0.011
Epoch 14: at batch 1: Loss=1.147, Time=0.011
Epoch 15: at batch 1: Loss=1.041, Time=0.020
Epoch 16: at batch 1: Loss=0.988, Time=0.011
Epoch 17: at batch 1: Loss=0.974, Time=0.013
Epoch 18: at batch 1: Loss=1.043, Time=0.011
Epoch 19: at batch 1: Loss=0.985, Time=0.020
Epoch 20: at batch 1: Loss=1.103, Time=0.011
Epoch 21: at batch 1: Loss=1.078, Time=0.010
Epoch 21: Time=8.963, Epoch time = 0.336, Avg epoch time=0.000

[[0.64832073]
 [0.67474681]
 [0.68722647]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 22: at batch 1: Loss=1.027, Time=0.010
Epoch 23: at batch 1: Loss=1.149, Time=0.010
Epoch 24: at batch 1: Loss=0.916, Time=0.011
Epoch 25: at batch 1: Loss=1.069, Time=0.011
Epoch 26: at batch 1: Loss=1.083, Time=0.011
Epoch 27: at batch 1: Loss=1.022, Time=0.010
Epoch 28: at batch 1: Loss=1.125, Time=0.011
Epoch 29: at batch 1: Loss=1.084, Time=0.011
Epoch 30: at batch 1: Loss=1.132, Time=0.010
Epoch 31: at batch 1: Loss=1.045, Time=0.010
Epoch 31: Time=12.518, Epoch time = 0.298, Avg epoch time=0.000

[[0.62418658]
 [0.63363951]
 [0.62867719]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 32: at batch 1: Loss=1.039, Time=0.011
Epoch 33: at batch 1: Loss=1.134, Time=0.010
Epoch 34: at batch 1: Loss=1.014, Time=0.010
Epoch 35: at batch 1: Loss=1.047, Time=0.011
Epoch 36: at batch 1: Loss=0.983, Time=0.011
Epoch 37: at batch 1: Loss=1.100, Time=0.020
Epoch 38: at batch 1: Loss=1.016, Time=0.010
Epoch 39: at batch 1: Loss=1.074, Time=0.011
Epoch 40: at batch 1: Loss=1.046, Time=0.020
Epoch 41: at batch 1: Loss=1.136, Time=0.011
Epoch 41: Time=16.098, Epoch time = 0.292, Avg epoch time=0.000

[[0.61865121]
 [0.59299481]
 [0.64216381]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 42: at batch 1: Loss=0.941, Time=0.010
Epoch 43: at batch 1: Loss=1.150, Time=0.020
Epoch 44: at batch 1: Loss=1.032, Time=0.010
Epoch 45: at batch 1: Loss=0.963, Time=0.019
Epoch 46: at batch 1: Loss=1.002, Time=0.011
Epoch 47: at batch 1: Loss=1.039, Time=0.010
Epoch 48: at batch 1: Loss=1.098, Time=0.007
Epoch 49: at batch 1: Loss=1.056, Time=0.011
Epoch 50: at batch 1: Loss=1.235, Time=0.020
Epoch 51: at batch 1: Loss=0.967, Time=0.010
Epoch 51: Time=19.814, Epoch time = 0.334, Avg epoch time=0.000

[[0.60265356]
 [0.61835563]
 [0.64573199]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 52: at batch 1: Loss=1.054, Time=0.010
Epoch 53: at batch 1: Loss=1.011, Time=0.020
Epoch 54: at batch 1: Loss=1.090, Time=0.011
Epoch 55: at batch 1: Loss=1.203, Time=0.019
Epoch 56: at batch 1: Loss=1.125, Time=0.020
Epoch 57: at batch 1: Loss=0.968, Time=0.010
Epoch 58: at batch 1: Loss=1.051, Time=0.010
Epoch 59: at batch 1: Loss=0.988, Time=0.011
Epoch 60: at batch 1: Loss=0.929, Time=0.020
Epoch 61: at batch 1: Loss=1.102, Time=0.019
Epoch 61: Time=23.484, Epoch time = 0.324, Avg epoch time=0.000

[[0.63983363]
 [0.6690982 ]
 [0.65729332]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 62: at batch 1: Loss=1.091, Time=0.010
Epoch 63: at batch 1: Loss=1.059, Time=0.011
Epoch 64: at batch 1: Loss=1.109, Time=0.010
Epoch 65: at batch 1: Loss=1.014, Time=0.011
Epoch 66: at batch 1: Loss=0.999, Time=0.014
Epoch 67: at batch 1: Loss=1.044, Time=0.011
Epoch 68: at batch 1: Loss=1.004, Time=0.011
Epoch 69: at batch 1: Loss=1.099, Time=0.012
Epoch 70: at batch 1: Loss=1.030, Time=0.010
Epoch 71: at batch 1: Loss=1.052, Time=0.010
Epoch 71: Time=27.048, Epoch time = 0.325, Avg epoch time=0.000

[[0.61430514]
 [0.59776902]
 [0.59639233]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 72: at batch 1: Loss=1.042, Time=0.010
Epoch 73: at batch 1: Loss=1.251, Time=0.010
Epoch 74: at batch 1: Loss=1.116, Time=0.011
Epoch 75: at batch 1: Loss=1.033, Time=0.010
Epoch 76: at batch 1: Loss=1.035, Time=0.011
Epoch 77: at batch 1: Loss=1.215, Time=0.011
Epoch 78: at batch 1: Loss=1.122, Time=0.010
Epoch 79: at batch 1: Loss=1.009, Time=0.011
Epoch 80: at batch 1: Loss=1.155, Time=0.011
Epoch 81: at batch 1: Loss=0.965, Time=0.005
Epoch 81: Time=30.583, Epoch time = 0.334, Avg epoch time=0.000

[[0.58763272]
 [0.60325915]
 [0.58648843]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 82: at batch 1: Loss=0.981, Time=0.011
Epoch 83: at batch 1: Loss=1.033, Time=0.020
Epoch 84: at batch 1: Loss=0.988, Time=0.010
Epoch 85: at batch 1: Loss=1.022, Time=0.011
Epoch 86: at batch 1: Loss=0.993, Time=0.020
Epoch 87: at batch 1: Loss=1.048, Time=0.010
Epoch 88: at batch 1: Loss=0.992, Time=0.011
Epoch 89: at batch 1: Loss=1.102, Time=0.011
Epoch 90: at batch 1: Loss=1.025, Time=0.011
Epoch 91: at batch 1: Loss=1.140, Time=0.020
Epoch 91: Time=34.176, Epoch time = 0.350, Avg epoch time=0.000

[[0.69493634]
 [0.63491935]
 [0.65804207]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 92: at batch 1: Loss=1.006, Time=0.011
Epoch 93: at batch 1: Loss=1.111, Time=0.010
Epoch 94: at batch 1: Loss=1.044, Time=0.011
Epoch 95: at batch 1: Loss=0.989, Time=0.011
Epoch 96: at batch 1: Loss=0.997, Time=0.010
Epoch 97: at batch 1: Loss=1.233, Time=0.013
Epoch 98: at batch 1: Loss=0.896, Time=0.020
Epoch 99: at batch 1: Loss=1.167, Time=0.011
Epoch 100: at batch 1: Loss=1.168, Time=0.020
Epoch 101: at batch 1: Loss=1.249, Time=0.006
Epoch 101: Time=37.825, Epoch time = 0.347, Avg epoch time=0.000

[[0.70730466]
 [0.69850415]
 [0.21354641]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 102: at batch 1: Loss=1.022, Time=0.011
Epoch 103: at batch 1: Loss=1.129, Time=0.011
Epoch 104: at batch 1: Loss=1.065, Time=0.011
Epoch 105: at batch 1: Loss=1.121, Time=0.010
Epoch 106: at batch 1: Loss=1.107, Time=0.011
Epoch 107: at batch 1: Loss=1.017, Time=0.011
Epoch 108: at batch 1: Loss=1.064, Time=0.005
Epoch 109: at batch 1: Loss=0.951, Time=0.011
Epoch 110: at batch 1: Loss=1.012, Time=0.020
Epoch 111: at batch 1: Loss=1.082, Time=0.010
Epoch 111: Time=41.432, Epoch time = 0.329, Avg epoch time=0.000

[[0.69512552]
 [0.68701923]
 [0.64733106]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 112: at batch 1: Loss=1.022, Time=0.010
Epoch 113: at batch 1: Loss=1.190, Time=0.011
Epoch 114: at batch 1: Loss=1.051, Time=0.019
Epoch 115: at batch 1: Loss=0.986, Time=0.010
Epoch 116: at batch 1: Loss=1.056, Time=0.011
Epoch 117: at batch 1: Loss=0.983, Time=0.010
Epoch 118: at batch 1: Loss=1.056, Time=0.011
Epoch 119: at batch 1: Loss=0.947, Time=0.011
Epoch 120: at batch 1: Loss=0.982, Time=0.019
Epoch 121: at batch 1: Loss=1.066, Time=0.011
Epoch 121: Time=45.086, Epoch time = 0.341, Avg epoch time=0.000

[[0.68743169]
 [0.67689979]
 [1.47571921]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 122: at batch 1: Loss=1.028, Time=0.011
Epoch 123: at batch 1: Loss=0.997, Time=0.011
Epoch 124: at batch 1: Loss=0.954, Time=0.011
Epoch 125: at batch 1: Loss=0.893, Time=0.010
Epoch 126: at batch 1: Loss=1.008, Time=0.020
Epoch 127: at batch 1: Loss=1.293, Time=0.010
Epoch 128: at batch 1: Loss=1.006, Time=0.011
Epoch 129: at batch 1: Loss=1.036, Time=0.010
Epoch 130: at batch 1: Loss=0.984, Time=0.011
Epoch 131: at batch 1: Loss=1.173, Time=0.011
Epoch 131: Time=48.605, Epoch time = 0.320, Avg epoch time=0.000

[[0.60498357]
 [0.60384703]
 [0.62420613]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 132: at batch 1: Loss=0.998, Time=0.010
Epoch 133: at batch 1: Loss=1.039, Time=0.022
Epoch 134: at batch 1: Loss=1.120, Time=0.010
Epoch 135: at batch 1: Loss=1.072, Time=0.010
Epoch 136: at batch 1: Loss=1.072, Time=0.010
Epoch 137: at batch 1: Loss=1.089, Time=0.019
Epoch 138: at batch 1: Loss=1.151, Time=0.011
Epoch 139: at batch 1: Loss=0.954, Time=0.011
Epoch 140: at batch 1: Loss=0.979, Time=0.011
Epoch 141: at batch 1: Loss=1.029, Time=0.019
Epoch 141: Time=52.180, Epoch time = 0.324, Avg epoch time=0.000

[[0.6565423 ]
 [0.57340282]
 [0.13664301]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 142: at batch 1: Loss=1.052, Time=0.010
Epoch 143: at batch 1: Loss=1.156, Time=0.010
Epoch 144: at batch 1: Loss=1.077, Time=0.010
Epoch 145: at batch 1: Loss=1.219, Time=0.011
Epoch 146: at batch 1: Loss=1.052, Time=0.011
Epoch 147: at batch 1: Loss=1.179, Time=0.011
Epoch 148: at batch 1: Loss=1.162, Time=0.011
Epoch 149: at batch 1: Loss=1.077, Time=0.008
Epoch 150: at batch 1: Loss=0.950, Time=0.011
Epoch 151: at batch 1: Loss=1.139, Time=0.010
Epoch 151: Time=55.656, Epoch time = 0.304, Avg epoch time=0.000

[[0.75183338]
 [0.77181423]
 [0.75762194]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 152: at batch 1: Loss=1.073, Time=0.010
Epoch 153: at batch 1: Loss=1.247, Time=0.006
Epoch 154: at batch 1: Loss=0.990, Time=0.011
Epoch 155: at batch 1: Loss=1.024, Time=0.011
Epoch 156: at batch 1: Loss=0.997, Time=0.011
Epoch 157: at batch 1: Loss=1.060, Time=0.011
Epoch 158: at batch 1: Loss=1.011, Time=0.011
Epoch 159: at batch 1: Loss=0.973, Time=0.010
Epoch 160: at batch 1: Loss=1.025, Time=0.020
Epoch 161: at batch 1: Loss=1.126, Time=0.011
Epoch 161: Time=59.145, Epoch time = 0.312, Avg epoch time=0.000

[[0.63587236]
 [0.53300852]
 [0.62132639]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 162: at batch 1: Loss=1.141, Time=0.010
Epoch 163: at batch 1: Loss=1.103, Time=0.020
Epoch 164: at batch 1: Loss=0.983, Time=0.011
Epoch 165: at batch 1: Loss=1.062, Time=0.011
Epoch 166: at batch 1: Loss=1.040, Time=0.011
Epoch 167: at batch 1: Loss=1.083, Time=0.009
Epoch 168: at batch 1: Loss=1.169, Time=0.010
Epoch 169: at batch 1: Loss=0.962, Time=0.011
Epoch 170: at batch 1: Loss=1.014, Time=0.006
Epoch 171: at batch 1: Loss=1.084, Time=0.011
Epoch 171: Time=62.709, Epoch time = 0.323, Avg epoch time=0.000

[[0.65612102]
 [0.67055929]
 [0.65699697]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 172: at batch 1: Loss=1.027, Time=0.011
Epoch 173: at batch 1: Loss=1.147, Time=0.011
Epoch 174: at batch 1: Loss=1.047, Time=0.019
Epoch 175: at batch 1: Loss=0.985, Time=0.020
Epoch 176: at batch 1: Loss=1.050, Time=0.011
Epoch 177: at batch 1: Loss=1.141, Time=0.010
Epoch 178: at batch 1: Loss=0.982, Time=0.011
Epoch 179: at batch 1: Loss=0.992, Time=0.011
Epoch 180: at batch 1: Loss=1.098, Time=0.010
Epoch 181: at batch 1: Loss=1.263, Time=0.010
Epoch 181: Time=66.324, Epoch time = 0.335, Avg epoch time=0.000

[[0.57011116]
 [0.61184329]
 [0.59071106]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 182: at batch 1: Loss=1.016, Time=0.011
Epoch 183: at batch 1: Loss=1.046, Time=0.010
Epoch 184: at batch 1: Loss=1.105, Time=0.011
Epoch 185: at batch 1: Loss=0.967, Time=0.011
Epoch 186: at batch 1: Loss=1.017, Time=0.020
Epoch 187: at batch 1: Loss=0.944, Time=0.011
Epoch 188: at batch 1: Loss=1.083, Time=0.020
Epoch 189: at batch 1: Loss=1.073, Time=0.020
Epoch 190: at batch 1: Loss=1.127, Time=0.011
Epoch 191: at batch 1: Loss=1.082, Time=0.020
Epoch 191: Time=70.014, Epoch time = 0.347, Avg epoch time=0.000

[[0.68524402]
 [0.66355968]
 [0.69563591]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 192: at batch 1: Loss=1.077, Time=0.011
Epoch 193: at batch 1: Loss=1.050, Time=0.010
Epoch 194: at batch 1: Loss=1.138, Time=0.011
Epoch 195: at batch 1: Loss=0.968, Time=0.011
Epoch 196: at batch 1: Loss=0.963, Time=0.011
Epoch 197: at batch 1: Loss=1.076, Time=0.010
Epoch 198: at batch 1: Loss=1.129, Time=0.011
Epoch 199: at batch 1: Loss=1.018, Time=0.011
Epoch 200: at batch 1: Loss=1.197, Time=0.011
Epoch 201: at batch 1: Loss=1.094, Time=0.019
Epoch 201: Time=73.565, Epoch time = 0.324, Avg epoch time=0.000

[[0.89533854]
 [0.76755637]
 [0.89202404]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 202: at batch 1: Loss=1.100, Time=0.010
Epoch 203: at batch 1: Loss=1.041, Time=0.011
Epoch 204: at batch 1: Loss=0.994, Time=0.011
Epoch 205: at batch 1: Loss=0.983, Time=0.011
Epoch 206: at batch 1: Loss=0.961, Time=0.022
Epoch 207: at batch 1: Loss=0.949, Time=0.013
Epoch 208: at batch 1: Loss=1.003, Time=0.020
Epoch 209: at batch 1: Loss=1.070, Time=0.011
Epoch 210: at batch 1: Loss=1.064, Time=0.011
Epoch 211: at batch 1: Loss=0.999, Time=0.010
Epoch 211: Time=77.248, Epoch time = 0.338, Avg epoch time=0.000

[[0.67361975]
 [0.66219151]
 [0.69389683]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 212: at batch 1: Loss=1.020, Time=0.010
Epoch 213: at batch 1: Loss=1.095, Time=0.010
Epoch 214: at batch 1: Loss=1.033, Time=0.011
Epoch 215: at batch 1: Loss=1.082, Time=0.011
Epoch 216: at batch 1: Loss=1.032, Time=0.011
Epoch 217: at batch 1: Loss=1.306, Time=0.009
Epoch 218: at batch 1: Loss=1.097, Time=0.011
Epoch 219: at batch 1: Loss=1.035, Time=0.010
Epoch 220: at batch 1: Loss=1.078, Time=0.010
Epoch 221: at batch 1: Loss=1.143, Time=0.010
Epoch 221: Time=80.814, Epoch time = 0.335, Avg epoch time=0.000

[[0.68499184]
 [1.09861231]
 [0.72702736]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 222: at batch 1: Loss=1.203, Time=0.019
Epoch 223: at batch 1: Loss=1.165, Time=0.011
Epoch 224: at batch 1: Loss=1.023, Time=0.020
Epoch 225: at batch 1: Loss=1.192, Time=0.007
Epoch 226: at batch 1: Loss=1.070, Time=0.011
Epoch 227: at batch 1: Loss=1.043, Time=0.011
Epoch 228: at batch 1: Loss=1.040, Time=0.010
Epoch 229: at batch 1: Loss=0.975, Time=0.013
Epoch 230: at batch 1: Loss=1.020, Time=0.011
Epoch 231: at batch 1: Loss=1.242, Time=0.019
Epoch 231: Time=84.428, Epoch time = 0.307, Avg epoch time=0.000

[[0.68705112]
 [0.67925084]
 [0.72229117]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 232: at batch 1: Loss=1.157, Time=0.011
Epoch 233: at batch 1: Loss=1.037, Time=0.019
Epoch 234: at batch 1: Loss=1.055, Time=0.010
Epoch 235: at batch 1: Loss=1.109, Time=0.020
Epoch 236: at batch 1: Loss=1.060, Time=0.011
Epoch 237: at batch 1: Loss=1.006, Time=0.019
Epoch 238: at batch 1: Loss=1.057, Time=0.019
Epoch 239: at batch 1: Loss=1.156, Time=0.010
Epoch 240: at batch 1: Loss=1.174, Time=0.010
Epoch 241: at batch 1: Loss=1.048, Time=0.011
Epoch 241: Time=87.955, Epoch time = 0.317, Avg epoch time=0.000

[[0.65971637]
 [0.71459109]
 [0.65690404]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 242: at batch 1: Loss=0.982, Time=0.010
Epoch 243: at batch 1: Loss=1.055, Time=0.011
Epoch 244: at batch 1: Loss=1.011, Time=0.011
Epoch 245: at batch 1: Loss=1.122, Time=0.011
Epoch 246: at batch 1: Loss=1.116, Time=0.011
Epoch 247: at batch 1: Loss=1.028, Time=0.010
Epoch 248: at batch 1: Loss=0.918, Time=0.010
Epoch 249: at batch 1: Loss=1.030, Time=0.011
Epoch 250: at batch 1: Loss=1.044, Time=0.011
Epoch 251: at batch 1: Loss=1.061, Time=0.011
Epoch 251: Time=91.525, Epoch time = 0.350, Avg epoch time=0.000

[[0.61946487]
 [0.57897651]
 [3.49085116]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 252: at batch 1: Loss=1.168, Time=0.010
Epoch 253: at batch 1: Loss=1.001, Time=0.020
Epoch 254: at batch 1: Loss=1.060, Time=0.011
Epoch 255: at batch 1: Loss=1.039, Time=0.010
Epoch 256: at batch 1: Loss=0.973, Time=0.010
Epoch 257: at batch 1: Loss=1.112, Time=0.011
Epoch 258: at batch 1: Loss=0.981, Time=0.010
Epoch 259: at batch 1: Loss=1.049, Time=0.011
Epoch 260: at batch 1: Loss=0.882, Time=0.011
Epoch 261: at batch 1: Loss=1.019, Time=0.010
Epoch 261: Time=95.087, Epoch time = 0.329, Avg epoch time=0.000

[[0.61246234]
 [0.50852549]
 [0.56682324]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 262: at batch 1: Loss=1.022, Time=0.019
Epoch 263: at batch 1: Loss=0.970, Time=0.011
Epoch 264: at batch 1: Loss=1.240, Time=0.011
Epoch 265: at batch 1: Loss=1.012, Time=0.011
Epoch 266: at batch 1: Loss=1.000, Time=0.014
Epoch 267: at batch 1: Loss=1.061, Time=0.011
Epoch 268: at batch 1: Loss=0.980, Time=0.011
Epoch 269: at batch 1: Loss=1.059, Time=0.010
Epoch 270: at batch 1: Loss=0.955, Time=0.010
Epoch 271: at batch 1: Loss=1.028, Time=0.010
Epoch 271: Time=98.681, Epoch time = 0.345, Avg epoch time=0.000

[[0.59567779]
 [0.60978562]
 [0.56952804]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 272: at batch 1: Loss=0.913, Time=0.010
Epoch 273: at batch 1: Loss=0.870, Time=0.014
Epoch 274: at batch 1: Loss=1.059, Time=0.020
Epoch 275: at batch 1: Loss=1.183, Time=0.010
Epoch 276: at batch 1: Loss=0.984, Time=0.010
Epoch 277: at batch 1: Loss=1.047, Time=0.011
Epoch 278: at batch 1: Loss=1.041, Time=0.011
Epoch 279: at batch 1: Loss=1.081, Time=0.011
Epoch 280: at batch 1: Loss=0.985, Time=0.020
Epoch 281: at batch 1: Loss=1.158, Time=0.010
Epoch 281: Time=102.329, Epoch time = 0.356, Avg epoch time=0.000

[[0.68329865]
 [0.6316309 ]
 [0.6627084 ]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 282: at batch 1: Loss=1.171, Time=0.011
Epoch 283: at batch 1: Loss=1.081, Time=0.011
Epoch 284: at batch 1: Loss=1.065, Time=0.013
Epoch 285: at batch 1: Loss=1.030, Time=0.011
Epoch 286: at batch 1: Loss=1.026, Time=0.011
Epoch 287: at batch 1: Loss=1.217, Time=0.011
Epoch 288: at batch 1: Loss=0.971, Time=0.009
Epoch 289: at batch 1: Loss=1.025, Time=0.011
Epoch 290: at batch 1: Loss=1.066, Time=0.020
Epoch 291: at batch 1: Loss=1.041, Time=0.011
Epoch 291: Time=105.853, Epoch time = 0.343, Avg epoch time=0.000

[[0.7618804 ]
 [0.66832554]
 [0.73894715]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 292: at batch 1: Loss=1.148, Time=0.010
Epoch 293: at batch 1: Loss=1.049, Time=0.011
Epoch 294: at batch 1: Loss=1.033, Time=0.010
Epoch 295: at batch 1: Loss=1.160, Time=0.019
Epoch 296: at batch 1: Loss=1.027, Time=0.010
Epoch 297: at batch 1: Loss=1.069, Time=0.011
Epoch 298: at batch 1: Loss=1.036, Time=0.011
Epoch 299: at batch 1: Loss=1.081, Time=0.011
Epoch 300: at batch 1: Loss=1.102, Time=0.011
Epoch 301: at batch 1: Loss=1.020, Time=0.010
Epoch 301: Time=109.417, Epoch time = 0.313, Avg epoch time=0.000

[[0.62593198]
 [0.56924123]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 302: at batch 1: Loss=1.032, Time=0.009
Epoch 303: at batch 1: Loss=1.026, Time=0.010
Epoch 304: at batch 1: Loss=1.192, Time=0.010
Epoch 305: at batch 1: Loss=1.049, Time=0.019
Epoch 306: at batch 1: Loss=0.982, Time=0.011
Epoch 307: at batch 1: Loss=0.974, Time=0.020
Epoch 308: at batch 1: Loss=1.073, Time=0.010
Epoch 309: at batch 1: Loss=1.005, Time=0.008
Epoch 310: at batch 1: Loss=1.043, Time=0.019
Epoch 311: at batch 1: Loss=1.071, Time=0.019
Epoch 311: Time=112.997, Epoch time = 0.332, Avg epoch time=0.000

[[0.45058995]
 [0.47147965]
 [0.48499006]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 312: at batch 1: Loss=0.823, Time=0.011
Epoch 313: at batch 1: Loss=1.089, Time=0.011
^CTraceback (most recent call last):
  File "simple_ReLU_BN_Sony.py", line 301, in <module>
    feed_dict={in_image: input_patch, gt_gamma: assigned_image_gamma_index, lr: learning_rate})
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 887, in run
    run_metadata_ptr)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1110, in _run
    feed_dict_tensor, options, run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1286, in _do_run
    run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1292, in _do_call
    return fn(*args)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1277, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1367, in _call_tf_sessionrun
    run_metadata)
KeyboardInterrupt
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ vi simple_ReLU_BN_Sony.py
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ python simple_ReLU_BN_Sony.py 




Found 161 images to train with

2020-12-11 14:24:56.975626: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 14:24:57.124608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 14:24:57.124640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 14:24:57.409443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 14:24:57.409481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 14:24:57.409496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 14:24:57.409587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)
loaded ./gt_Sony_simple_ReLU_BN/model.ckpt

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 310
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95669, 0.00000, 100.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01631, 300.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 100.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00190, 250.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.02266, 300.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00417, 300.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00887, 250.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00233, 250.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 250.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00613, 100.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00012, 250.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 300.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00146, 250.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00327, 100.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00002, 300.00000, 6735543
rawpy read the 20th file at location: ./dataset/Sony/long/00072_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00003, 100.00000, 7298885
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00143, 250.00000, 1272259
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 142725
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00466, 250.00000, 822369
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00012, 100.00000, 2983955
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00116, 250.00000, 2393979
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.03307, 300.00000, 2641491
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00003, 100.00000, 1597850
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 300.00000, 1430113
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
rawpy read the 30th file at location: ./dataset/Sony/long/00039_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.07893, 250.00000, 535
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00247, 300.00000, 2877047
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00027, 100.00000, 271135
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 11918285
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00056, 300.00000, 3901
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 100.00000, 684739
rawpy read the 40th file at location: ./dataset/Sony/long/00200_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00246, 250.00000, 1458719
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00976, 300.00000, 1212279
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00237, 300.00000, 2952517
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00215, 300.00000, 158803
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00165, 300.00000, 2486907
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00215, 100.00000, 7900835
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00007, 100.00000, 4543563
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.05083, 100.00000, 3437
rawpy read the 50th file at location: ./dataset/Sony/long/00024_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00048, 300.00000, 33748
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00375, 100.00000, 3626303
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01255, 250.00000, 304767
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00063, 100.00000, 5644
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00062, 250.00000, 4526
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00007, 250.00000, 11755519
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00016, 100.00000, 2512821
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01888, 100.00000, 2025
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00338, 250.00000, 5557479
rawpy read the 60th file at location: ./dataset/Sony/long/00084_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00375, 100.00000, 67803
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00210, 300.00000, 103
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 300.00000, 1696711
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00637, 250.00000, 2302635
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00054, 100.00000, 1589659
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00720, 100.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00563, 100.00000, 3437411
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.01027, 100.00000, 1033619
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00001, 100.00000, 742143
rawpy read the 70th file at location: ./dataset/Sony/long/00164_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00419, 250.00000, 509891
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 433279
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00104, 300.00000, 6156358
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00004, 100.00000, 2110981
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00090, 100.00000, 277500
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.02918, 300.00000, 646472
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00057, 300.00000, 5676651
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 300.00000, 7066147
rawpy read the 80th file at location: ./dataset/Sony/long/00128_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00343, 100.00000, 4421929
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.01954, 100.00000, 489052
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00000, 100.00000, 10328681
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00127, 250.00000, 2198927
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00010, 250.00000, 5346741
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00144, 300.00000, 646955
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00084, 100.00000, 3032047
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00608, 250.00000, 1407
rawpy read the 90th file at location: ./dataset/Sony/long/00057_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00011, 250.00000, 6606155
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00028, 100.00000, 353239
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00076, 100.00000, 877649
min, max, mean, gamma, argmax: 0.00000, 0.00288, 0.00000, 100.00000, 810977
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00000, 100.00000, 4792466
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00044, 300.00000, 3173995
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00212, 250.00000, 3012800
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00086, 300.00000, 732975
rawpy read the 100th file at location: ./dataset/Sony/long/00059_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01514, 300.00000, 5126389
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 100.00000, 221629
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00000, 100.00000, 895895
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00095, 100.00000, 121547
min, max, mean, gamma, argmax: 0.00000, 0.89525, 0.00000, 250.00000, 6694829
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 2019203
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00106, 300.00000, 2924589
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 6922649
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00182, 250.00000, 8237
rawpy read the 110th file at location: ./dataset/Sony/long/00026_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00099, 300.00000, 255039
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00826, 100.00000, 3862619
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00166, 100.00000, 27523
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00467, 100.00000, 4373627
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00212, 100.00000, 6454
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00032, 250.00000, 4246091
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00129, 300.00000, 952285
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00472, 250.00000, 2253
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
rawpy read the 120th file at location: ./dataset/Sony/long/00012_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 300.00000, 6320171
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00034, 300.00000, 8352977
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00176, 300.00000, 2730987
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 250.00000, 830169
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00217, 250.00000, 106691
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00767, 300.00000, 2536575
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 6777631
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
rawpy read the 130th file at location: ./dataset/Sony/long/00090_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00283, 100.00000, 6265
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 100.00000, 9536203
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00905, 300.00000, 1211799
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 1962014
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00132, 100.00000, 1095547
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00109, 300.00000, 208955
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00488, 300.00000, 1787501
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00045, 250.00000, 2237695
rawpy read the 140th file at location: ./dataset/Sony/long/00114_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00015, 250.00000, 2570045
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00002, 300.00000, 4933369
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00017, 300.00000, 2972
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00014, 300.00000, 8615375
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.06347, 100.00000, 1502619
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00130, 300.00000, 1940733
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00007, 100.00000, 8449
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00079, 250.00000, 506409
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
rawpy read the 150th file at location: ./dataset/Sony/long/00156_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00819, 250.00000, 2309
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00134, 250.00000, 1993235
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.03581, 300.00000, 2694439
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00925, 100.00000, 2353163
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00030, 300.00000, 2700797
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.01404, 250.00000, 7293
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00021, 250.00000, 581525
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00004, 250.00000, 4860611
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00430, 100.00000, 5285
rawpy read the 160th file at location: ./dataset/Sony/long/00219_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
161 images loaded to CPU RAM in Time=37.382 seconds.
Epoch 311: at batch 1: Loss=1.099, Time=1.039
Epoch 311: Time=3.772, Epoch time = 3.772, Avg epoch time=1.000

[[1.21000898]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 312: at batch 1: Loss=1.135, Time=0.010
Epoch 313: at batch 1: Loss=1.177, Time=0.010
Epoch 314: at batch 1: Loss=1.141, Time=0.019
Epoch 315: at batch 1: Loss=1.126, Time=0.017
Epoch 316: at batch 1: Loss=1.094, Time=0.019
Epoch 317: at batch 1: Loss=1.118, Time=0.019
^CTraceback (most recent call last):
  File "simple_ReLU_BN_Sony.py", line 301, in <module>
    feed_dict={in_image: input_patch, gt_gamma: assigned_image_gamma_index, lr: learning_rate})
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 887, in run
    run_metadata_ptr)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1110, in _run
    feed_dict_tensor, options, run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1286, in _do_run
    run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1292, in _do_call
    return fn(*args)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1277, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1367, in _call_tf_sessionrun
    run_metadata)
KeyboardInterrupt
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ mkdir gt_Sony_simple_ReLU_BN_new
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ python simple_ReLU_BN_Sony.py 




Found 161 images to train with

2020-12-11 14:26:20.549580: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 14:26:20.705290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 14:26:20.705322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 14:26:20.989757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 14:26:20.989793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 14:26:20.989802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 14:26:20.989895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)
loaded ./gt_Sony_simple_ReLU_BN/model.ckpt

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 310
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.87565, 0.00000, 300.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01648, 100.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00164, 300.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00190, 250.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.02310, 250.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00417, 300.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00886, 300.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00233, 250.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 250.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00613, 100.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00012, 250.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 300.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00144, 300.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00307, 250.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00002, 250.00000, 6735543
rawpy read the 20th file at location: ./dataset/Sony/long/00072_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00003, 100.00000, 7298885
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00143, 250.00000, 1272259
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00000, 100.00000, 142725
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00456, 300.00000, 822369
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00011, 250.00000, 2983955
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00116, 250.00000, 2393979
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.03574, 100.00000, 2641491
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00003, 100.00000, 1597850
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 300.00000, 1430113
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
rawpy read the 30th file at location: ./dataset/Sony/long/00039_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.07940, 100.00000, 535
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00247, 300.00000, 2877047
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00027, 100.00000, 271135
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 11918285
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00057, 250.00000, 3901
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 100.00000, 684739
rawpy read the 40th file at location: ./dataset/Sony/long/00200_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00246, 250.00000, 1458719
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00998, 250.00000, 1212279
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00237, 300.00000, 2952517
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00219, 250.00000, 158803
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00179, 100.00000, 2486907
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00202, 250.00000, 7900835
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00005, 300.00000, 4543563
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.05083, 100.00000, 3437
rawpy read the 50th file at location: ./dataset/Sony/long/00024_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00048, 300.00000, 33748
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00352, 250.00000, 3626303
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01253, 300.00000, 304767
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00063, 100.00000, 5644
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00062, 100.00000, 4526
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00007, 300.00000, 11755519
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00012, 250.00000, 2512821
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01888, 100.00000, 2025
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00342, 100.00000, 5557479
rawpy read the 60th file at location: ./dataset/Sony/long/00084_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00340, 300.00000, 67803
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00228, 100.00000, 103
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 100.00000, 1696711
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00688, 100.00000, 2302635
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00054, 100.00000, 1589659
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00720, 100.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00517, 300.00000, 3437411
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00952, 300.00000, 1033619
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00001, 250.00000, 742143
rawpy read the 70th file at location: ./dataset/Sony/long/00164_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00411, 300.00000, 509891
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 433279
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00106, 250.00000, 6156358
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00004, 300.00000, 2110981
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00084, 300.00000, 277500
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.02923, 100.00000, 646472
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00058, 250.00000, 5676651
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 300.00000, 7066147
rawpy read the 80th file at location: ./dataset/Sony/long/00128_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00343, 100.00000, 4421929
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.01954, 100.00000, 489052
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00000, 100.00000, 10328681
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00136, 100.00000, 2198927
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00009, 300.00000, 5346741
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00147, 250.00000, 646955
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00084, 100.00000, 3032047
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00608, 250.00000, 1407
rawpy read the 90th file at location: ./dataset/Sony/long/00057_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00013, 100.00000, 6606155
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00027, 300.00000, 353239
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00075, 250.00000, 877649
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00000, 100.00000, 4792466
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00044, 300.00000, 3173995
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00212, 250.00000, 3012800
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00086, 250.00000, 732975
rawpy read the 100th file at location: ./dataset/Sony/long/00059_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01523, 100.00000, 5126389
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 300.00000, 221629
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 895895
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00095, 100.00000, 121547
min, max, mean, gamma, argmax: 0.00000, 0.89525, 0.00000, 250.00000, 6694829
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 2019203
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00106, 300.00000, 2924589
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00000, 100.00000, 6922649
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00182, 250.00000, 8237
rawpy read the 110th file at location: ./dataset/Sony/long/00026_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00099, 300.00000, 255039
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00781, 250.00000, 3862619
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00166, 100.00000, 27523
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00438, 250.00000, 4373627
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00212, 100.00000, 6454
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00032, 300.00000, 4246091
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00131, 250.00000, 952285
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00464, 300.00000, 2253
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
rawpy read the 120th file at location: ./dataset/Sony/long/00012_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 250.00000, 6320171
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00037, 100.00000, 8352977
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00176, 300.00000, 2730987
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 100.00000, 830169
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00216, 300.00000, 106691
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00781, 250.00000, 2536575
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 6777631
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
rawpy read the 130th file at location: ./dataset/Sony/long/00090_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00265, 250.00000, 6265
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 100.00000, 9536203
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00922, 250.00000, 1211799
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 1962014
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00132, 100.00000, 1095547
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00109, 250.00000, 208955
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00488, 300.00000, 1787501
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00045, 250.00000, 2237695
rawpy read the 140th file at location: ./dataset/Sony/long/00114_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00016, 100.00000, 2570045
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00002, 250.00000, 4933369
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00017, 250.00000, 2972
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00016, 100.00000, 8615375
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.06324, 250.00000, 1502619
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00130, 300.00000, 1940733
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00007, 100.00000, 8449
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00078, 300.00000, 506409
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
rawpy read the 150th file at location: ./dataset/Sony/long/00156_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00819, 250.00000, 2309
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00143, 100.00000, 1993235
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.03581, 300.00000, 2694439
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00922, 250.00000, 2353163
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00030, 250.00000, 2700797
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.01404, 250.00000, 7293
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00021, 250.00000, 581525
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00004, 300.00000, 4860611
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00320, 300.00000, 5285
rawpy read the 160th file at location: ./dataset/Sony/long/00219_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
161 images loaded to CPU RAM in Time=37.771 seconds.
Epoch 311: at batch 1: Loss=1.099, Time=1.030
Epoch 311: Time=3.759, Epoch time = 3.759, Avg epoch time=1.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 312: at batch 1: Loss=1.120, Time=0.011
Epoch 313: at batch 1: Loss=1.100, Time=0.011
Epoch 314: at batch 1: Loss=1.144, Time=0.009
Epoch 315: at batch 1: Loss=1.108, Time=0.011
Epoch 316: at batch 1: Loss=1.111, Time=0.010
Epoch 317: at batch 1: Loss=1.106, Time=0.011
Epoch 318: at batch 1: Loss=1.096, Time=0.011
Epoch 319: at batch 1: Loss=1.104, Time=0.020
Epoch 320: at batch 1: Loss=1.132, Time=0.011
Epoch 321: at batch 1: Loss=1.082, Time=0.011
Epoch 321: Time=31.744, Epoch time = 2.763, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 322: at batch 1: Loss=1.130, Time=0.011
Epoch 323: at batch 1: Loss=1.104, Time=0.010
Epoch 324: at batch 1: Loss=1.099, Time=0.011
Epoch 325: at batch 1: Loss=1.106, Time=0.011
Epoch 326: at batch 1: Loss=1.121, Time=0.011
Epoch 327: at batch 1: Loss=1.094, Time=0.011
Epoch 328: at batch 1: Loss=1.127, Time=0.019
Epoch 329: at batch 1: Loss=1.100, Time=0.011
Epoch 330: at batch 1: Loss=1.103, Time=0.019
Epoch 331: at batch 1: Loss=1.110, Time=0.010
Epoch 331: Time=59.878, Epoch time = 2.793, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 332: at batch 1: Loss=1.095, Time=0.010
Epoch 333: at batch 1: Loss=1.100, Time=0.011
Epoch 334: at batch 1: Loss=1.093, Time=0.011
Epoch 335: at batch 1: Loss=1.100, Time=0.010
Epoch 336: at batch 1: Loss=1.099, Time=0.011
Epoch 337: at batch 1: Loss=1.095, Time=0.011
Epoch 338: at batch 1: Loss=1.093, Time=0.011
Epoch 339: at batch 1: Loss=1.114, Time=0.010
Epoch 340: at batch 1: Loss=1.104, Time=0.019
Epoch 341: at batch 1: Loss=1.099, Time=0.010
Epoch 341: Time=87.554, Epoch time = 2.769, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 342: at batch 1: Loss=1.099, Time=0.010
Epoch 343: at batch 1: Loss=1.098, Time=0.011
Epoch 344: at batch 1: Loss=1.098, Time=0.011
Epoch 345: at batch 1: Loss=1.097, Time=0.014
Epoch 346: at batch 1: Loss=1.096, Time=0.010
Epoch 347: at batch 1: Loss=1.101, Time=0.019
Epoch 348: at batch 1: Loss=1.098, Time=0.019
Epoch 349: at batch 1: Loss=1.095, Time=0.010
Epoch 350: at batch 1: Loss=1.100, Time=0.020
Epoch 351: at batch 1: Loss=1.135, Time=0.010
^CTraceback (most recent call last):
  File "simple_ReLU_BN_Sony.py", line 301, in <module>
    feed_dict={in_image: input_patch, gt_gamma: assigned_image_gamma_index, lr: learning_rate})
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 887, in run
    run_metadata_ptr)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1110, in _run
    feed_dict_tensor, options, run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1286, in _do_run
    run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1292, in _do_call
    return fn(*args)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1277, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1367, in _call_tf_sessionrun
    run_metadata)
KeyboardInterrupt
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ vi simple_ReLU_BN_Sony.py
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ python simple_ReLU_BN_Sony.py 




Found 161 images to train with

2020-12-11 14:29:27.742499: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 14:29:27.890006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 14:29:27.890039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 14:29:28.175701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 14:29:28.175739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 14:29:28.175755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 14:29:28.175852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95669, 0.00000, 100.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01648, 100.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00164, 300.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00187, 300.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.02310, 250.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00427, 250.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00887, 250.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00248, 100.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 100.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 250.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00012, 300.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00117, 100.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00144, 300.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00327, 100.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00002, 300.00000, 6735543
20 images loaded to CPU RAM in Time=4.735 seconds.
Starting Training on index 8
Epoch 0: at batch 1: Loss=1.099, Time=1.042
Epoch 1: at batch 1: Loss=1.154, Time=0.011
Epoch 1: Time=1.740, Epoch time = 0.343, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [2.07221913]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 2: at batch 1: Loss=1.132, Time=0.010
Epoch 3: at batch 1: Loss=1.060, Time=0.010
Epoch 4: at batch 1: Loss=1.170, Time=0.011
Epoch 5: at batch 1: Loss=1.187, Time=0.011
Epoch 6: at batch 1: Loss=1.175, Time=0.010
Epoch 7: at batch 1: Loss=1.177, Time=0.011
Epoch 8: at batch 1: Loss=1.056, Time=0.010
Epoch 9: at batch 1: Loss=1.129, Time=0.010
Epoch 10: at batch 1: Loss=1.154, Time=0.012
Epoch 11: at batch 1: Loss=1.094, Time=0.010
Epoch 11: Time=5.363, Epoch time = 0.354, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [0.12124692]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 12: at batch 1: Loss=1.050, Time=0.012
Epoch 13: at batch 1: Loss=1.117, Time=0.019
Epoch 14: at batch 1: Loss=1.141, Time=0.010
Epoch 15: at batch 1: Loss=1.138, Time=0.011
Epoch 16: at batch 1: Loss=1.289, Time=0.019
Epoch 17: at batch 1: Loss=1.293, Time=0.011
Epoch 18: at batch 1: Loss=1.176, Time=0.010
Epoch 19: at batch 1: Loss=1.097, Time=0.010
^CTraceback (most recent call last):
  File "simple_ReLU_BN_Sony.py", line 301, in <module>
    feed_dict={in_image: input_patch, gt_gamma: assigned_image_gamma_index, lr: learning_rate})
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 887, in run
    run_metadata_ptr)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1110, in _run
    feed_dict_tensor, options, run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1286, in _do_run
    run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1292, in _do_call
    return fn(*args)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1277, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1367, in _call_tf_sessionrun
    run_metadata)
KeyboardInterrupt
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ vi simple_ReLU_BN_Sony.py
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ python simple_ReLU_BN_Sony.py 




Found 161 images to train with

2020-12-11 14:30:12.062735: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 14:30:12.212798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 14:30:12.212830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 14:30:12.497554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 14:30:12.497591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 14:30:12.497601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 14:30:12.497763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)

Loaded ./gt_Sony_simple_ReLU_BN_new/model.ckpt

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 10
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.89525, 0.00000, 250.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01648, 100.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 250.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00201, 100.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.02465, 100.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00467, 100.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00886, 300.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00233, 250.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 100.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00613, 100.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00012, 250.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 250.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00155, 100.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00301, 300.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00002, 250.00000, 6735543
rawpy read the 20th file at location: ./dataset/Sony/long/00072_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00003, 250.00000, 7298885
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00153, 100.00000, 1272259
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00000, 100.00000, 142725
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00466, 250.00000, 822369
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00011, 300.00000, 2983955
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00116, 250.00000, 2393979
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.03368, 250.00000, 2641491
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00003, 250.00000, 1597850
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 100.00000, 1430113
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
rawpy read the 30th file at location: ./dataset/Sony/long/00039_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.07888, 300.00000, 535
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00247, 250.00000, 2877047
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00027, 100.00000, 271135
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 11918285
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00057, 250.00000, 3901
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 100.00000, 684739
rawpy read the 40th file at location: ./dataset/Sony/long/00200_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00235, 300.00000, 1458719
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00976, 300.00000, 1212279
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00241, 250.00000, 2952517
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00219, 250.00000, 158803
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00168, 250.00000, 2486907
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00215, 100.00000, 7900835
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00006, 250.00000, 4543563
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.05081, 300.00000, 3437
rawpy read the 50th file at location: ./dataset/Sony/long/00024_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00048, 250.00000, 33748
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00352, 250.00000, 3626303
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01267, 100.00000, 304767
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00058, 300.00000, 5644
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00062, 100.00000, 4526
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00007, 250.00000, 11755519
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00016, 100.00000, 2512821
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01888, 100.00000, 2025
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00342, 100.00000, 5557479
rawpy read the 60th file at location: ./dataset/Sony/long/00084_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00375, 100.00000, 67803
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00214, 250.00000, 103
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 300.00000, 1696711
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00622, 300.00000, 2302635
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00053, 300.00000, 1589659
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00674, 250.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00528, 250.00000, 3437411
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.01027, 100.00000, 1033619
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00001, 250.00000, 742143
rawpy read the 70th file at location: ./dataset/Sony/long/00164_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00444, 100.00000, 509891
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 433279
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00114, 100.00000, 6156358
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00004, 100.00000, 2110981
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00085, 250.00000, 277500
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.02918, 300.00000, 646472
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00062, 100.00000, 5676651
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 300.00000, 7066147
rawpy read the 80th file at location: ./dataset/Sony/long/00128_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00320, 250.00000, 4421929
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.01853, 250.00000, 489052
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00000, 100.00000, 10328681
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00136, 100.00000, 2198927
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00009, 300.00000, 5346741
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00144, 300.00000, 646955
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00079, 250.00000, 3032047
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00608, 250.00000, 1407
rawpy read the 90th file at location: ./dataset/Sony/long/00057_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00013, 100.00000, 6606155
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00027, 300.00000, 353239
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00076, 100.00000, 877649
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 4792466
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00044, 300.00000, 3173995
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00226, 100.00000, 3012800
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00087, 100.00000, 732975
rawpy read the 100th file at location: ./dataset/Sony/long/00059_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01514, 300.00000, 5126389
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 300.00000, 221629
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 895895
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00090, 250.00000, 121547
min, max, mean, gamma, argmax: 0.00000, 0.95669, 0.00000, 100.00000, 6694829
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 2019203
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00106, 300.00000, 2924589
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 6922649
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00179, 300.00000, 8237
rawpy read the 110th file at location: ./dataset/Sony/long/00026_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00099, 300.00000, 255039
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00826, 100.00000, 3862619
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00166, 100.00000, 27523
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00438, 250.00000, 4373627
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00196, 300.00000, 6454
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00032, 100.00000, 4246091
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00139, 100.00000, 952285
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00472, 250.00000, 2253
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
rawpy read the 120th file at location: ./dataset/Sony/long/00012_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 250.00000, 6320171
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00035, 250.00000, 8352977
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00191, 100.00000, 2730987
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 300.00000, 830169
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00216, 300.00000, 106691
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00781, 250.00000, 2536575
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 6777631
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
rawpy read the 130th file at location: ./dataset/Sony/long/00090_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00260, 300.00000, 6265
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 300.00000, 9536203
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00922, 250.00000, 1211799
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 1962014
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00132, 100.00000, 1095547
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00110, 100.00000, 208955
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00488, 300.00000, 1787501
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00044, 300.00000, 2237695
rawpy read the 140th file at location: ./dataset/Sony/long/00114_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00016, 100.00000, 2570045
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00002, 100.00000, 4933369
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00018, 100.00000, 2972
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00016, 100.00000, 8615375
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.06347, 100.00000, 1502619
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00135, 250.00000, 1940733
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00007, 250.00000, 8449
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00079, 250.00000, 506409
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
rawpy read the 150th file at location: ./dataset/Sony/long/00156_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00804, 300.00000, 2309
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00143, 100.00000, 1993235
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.03645, 250.00000, 2694439
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00922, 300.00000, 2353163
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00030, 300.00000, 2700797
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.01503, 100.00000, 7293
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00021, 100.00000, 581525
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00004, 300.00000, 4860611
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00430, 100.00000, 5285
rawpy read the 160th file at location: ./dataset/Sony/long/00219_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
161 images loaded to CPU RAM in Time=37.285 seconds.
Epoch 11: at batch 1: Loss=1.099, Time=1.002
Epoch 11: Time=3.666, Epoch time = 3.666, Avg epoch time=1.000

[[1.09861231]
 [1.09861231]
 [0.34066105]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 12: at batch 1: Loss=1.077, Time=0.010
Epoch 13: at batch 1: Loss=1.119, Time=0.010
Epoch 14: at batch 1: Loss=1.115, Time=0.010
Epoch 15: at batch 1: Loss=1.115, Time=0.013
Epoch 16: at batch 1: Loss=1.163, Time=0.011
Epoch 17: at batch 1: Loss=1.092, Time=0.010
Epoch 18: at batch 1: Loss=1.122, Time=0.019
Epoch 19: at batch 1: Loss=1.149, Time=0.011
Epoch 20: at batch 1: Loss=1.157, Time=0.020
Epoch 21: at batch 1: Loss=1.133, Time=0.010
Epoch 21: Time=31.520, Epoch time = 2.729, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 22: at batch 1: Loss=1.108, Time=0.019
Epoch 23: at batch 1: Loss=1.118, Time=0.020
Epoch 24: at batch 1: Loss=1.133, Time=0.011
Epoch 25: at batch 1: Loss=1.144, Time=0.020
Epoch 26: at batch 1: Loss=1.148, Time=0.011
Epoch 27: at batch 1: Loss=1.123, Time=0.010
Epoch 28: at batch 1: Loss=1.104, Time=0.011
Epoch 29: at batch 1: Loss=1.140, Time=0.011
Epoch 30: at batch 1: Loss=1.134, Time=0.011
Epoch 31: at batch 1: Loss=1.120, Time=0.010
Epoch 31: Time=59.231, Epoch time = 2.693, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 32: at batch 1: Loss=1.128, Time=0.019
Epoch 33: at batch 1: Loss=1.089, Time=0.011
Epoch 34: at batch 1: Loss=1.143, Time=0.011
Epoch 35: at batch 1: Loss=1.126, Time=0.010
Epoch 36: at batch 1: Loss=1.110, Time=0.010
Epoch 37: at batch 1: Loss=1.104, Time=0.011
Epoch 38: at batch 1: Loss=1.113, Time=0.020
Epoch 39: at batch 1: Loss=1.110, Time=0.011
Epoch 40: at batch 1: Loss=1.092, Time=0.011
Epoch 41: at batch 1: Loss=1.102, Time=0.019
Epoch 41: Time=86.950, Epoch time = 2.751, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 42: at batch 1: Loss=1.117, Time=0.019
Epoch 43: at batch 1: Loss=1.093, Time=0.022
Epoch 44: at batch 1: Loss=1.108, Time=0.011
Epoch 45: at batch 1: Loss=1.103, Time=0.021
Epoch 46: at batch 1: Loss=1.106, Time=0.005
Epoch 47: at batch 1: Loss=1.103, Time=0.011
Epoch 48: at batch 1: Loss=1.095, Time=0.011
Epoch 49: at batch 1: Loss=1.107, Time=0.011
Epoch 50: at batch 1: Loss=1.099, Time=0.011
Epoch 51: at batch 1: Loss=1.102, Time=0.016
Epoch 51: Time=114.681, Epoch time = 2.778, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 52: at batch 1: Loss=1.096, Time=0.010
Epoch 53: at batch 1: Loss=1.100, Time=0.011
Epoch 54: at batch 1: Loss=1.097, Time=0.010
Epoch 55: at batch 1: Loss=1.099, Time=0.020
Epoch 56: at batch 1: Loss=1.089, Time=0.011
Epoch 57: at batch 1: Loss=1.105, Time=0.019
Epoch 58: at batch 1: Loss=1.129, Time=0.010
Epoch 59: at batch 1: Loss=1.105, Time=0.010
Epoch 60: at batch 1: Loss=1.114, Time=0.020
Epoch 61: at batch 1: Loss=1.106, Time=0.010
Epoch 61: Time=142.391, Epoch time = 2.753, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 62: at batch 1: Loss=1.096, Time=0.010
Epoch 63: at batch 1: Loss=1.094, Time=0.010
Epoch 64: at batch 1: Loss=1.098, Time=0.020
Epoch 65: at batch 1: Loss=1.098, Time=0.011
Epoch 66: at batch 1: Loss=1.099, Time=0.011
Epoch 67: at batch 1: Loss=1.104, Time=0.007
Epoch 68: at batch 1: Loss=1.096, Time=0.011
Epoch 69: at batch 1: Loss=1.092, Time=0.010
Epoch 70: at batch 1: Loss=1.095, Time=0.014
Epoch 71: at batch 1: Loss=1.099, Time=0.014
Epoch 71: Time=170.139, Epoch time = 2.696, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 72: at batch 1: Loss=1.094, Time=0.011
Epoch 73: at batch 1: Loss=1.099, Time=0.011
Epoch 74: at batch 1: Loss=1.099, Time=0.007
Epoch 75: at batch 1: Loss=1.116, Time=0.019
Epoch 76: at batch 1: Loss=1.099, Time=0.011
Epoch 77: at batch 1: Loss=1.099, Time=0.011
Epoch 78: at batch 1: Loss=1.099, Time=0.005
Epoch 79: at batch 1: Loss=1.092, Time=0.011
Epoch 80: at batch 1: Loss=1.099, Time=0.020
Epoch 81: at batch 1: Loss=1.099, Time=0.010
Epoch 81: Time=198.190, Epoch time = 2.729, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 82: at batch 1: Loss=1.098, Time=0.011
Epoch 83: at batch 1: Loss=1.100, Time=0.019
Epoch 84: at batch 1: Loss=1.099, Time=0.011
Epoch 85: at batch 1: Loss=1.096, Time=0.011
Epoch 86: at batch 1: Loss=1.094, Time=0.011
Epoch 87: at batch 1: Loss=1.101, Time=0.011
Epoch 88: at batch 1: Loss=1.099, Time=0.010
Epoch 89: at batch 1: Loss=1.099, Time=0.011
Epoch 90: at batch 1: Loss=1.096, Time=0.019
Epoch 91: at batch 1: Loss=1.099, Time=0.011
Epoch 91: Time=226.150, Epoch time = 2.789, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 92: at batch 1: Loss=1.116, Time=0.010
Epoch 93: at batch 1: Loss=1.100, Time=0.020
Epoch 94: at batch 1: Loss=1.099, Time=0.010
Epoch 95: at batch 1: Loss=1.098, Time=0.010
Epoch 96: at batch 1: Loss=1.099, Time=0.020
Epoch 97: at batch 1: Loss=1.100, Time=0.011
Epoch 98: at batch 1: Loss=1.099, Time=0.011
Epoch 99: at batch 1: Loss=1.100, Time=0.012
Epoch 100: at batch 1: Loss=1.099, Time=0.020
Epoch 101: at batch 1: Loss=1.099, Time=0.019
Epoch 101: Time=253.894, Epoch time = 2.736, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 102: at batch 1: Loss=1.099, Time=0.010
Epoch 103: at batch 1: Loss=1.095, Time=0.011
Epoch 104: at batch 1: Loss=1.105, Time=0.007
Epoch 105: at batch 1: Loss=1.099, Time=0.010
Epoch 106: at batch 1: Loss=1.099, Time=0.011
Epoch 107: at batch 1: Loss=1.099, Time=0.016
Epoch 108: at batch 1: Loss=1.099, Time=0.011
Epoch 109: at batch 1: Loss=1.099, Time=0.010
Epoch 110: at batch 1: Loss=1.102, Time=0.005
Epoch 111: at batch 1: Loss=1.099, Time=0.014
Epoch 111: Time=281.525, Epoch time = 2.796, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 112: at batch 1: Loss=1.099, Time=0.010
Epoch 113: at batch 1: Loss=1.099, Time=0.010
Epoch 114: at batch 1: Loss=1.097, Time=0.016
Epoch 115: at batch 1: Loss=1.099, Time=0.010
Epoch 116: at batch 1: Loss=1.099, Time=0.010
Epoch 117: at batch 1: Loss=1.099, Time=0.011
Epoch 118: at batch 1: Loss=1.099, Time=0.010
Epoch 119: at batch 1: Loss=1.093, Time=0.010
Epoch 120: at batch 1: Loss=1.101, Time=0.009
Epoch 121: at batch 1: Loss=1.101, Time=0.011
Epoch 121: Time=309.142, Epoch time = 2.647, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 122: at batch 1: Loss=1.099, Time=0.019
Epoch 123: at batch 1: Loss=1.099, Time=0.011
Epoch 124: at batch 1: Loss=1.099, Time=0.020
Epoch 125: at batch 1: Loss=1.099, Time=0.011
Epoch 126: at batch 1: Loss=1.099, Time=0.010
Epoch 127: at batch 1: Loss=1.099, Time=0.011
Epoch 128: at batch 1: Loss=1.099, Time=0.019
Epoch 129: at batch 1: Loss=1.099, Time=0.006
Epoch 130: at batch 1: Loss=1.099, Time=0.010
Epoch 131: at batch 1: Loss=1.099, Time=0.011
Epoch 131: Time=336.923, Epoch time = 2.689, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 132: at batch 1: Loss=1.099, Time=0.010
Epoch 133: at batch 1: Loss=1.099, Time=0.005
Epoch 134: at batch 1: Loss=1.099, Time=0.019
Epoch 135: at batch 1: Loss=1.099, Time=0.020
Epoch 136: at batch 1: Loss=1.099, Time=0.011
Epoch 137: at batch 1: Loss=1.099, Time=0.011
Epoch 138: at batch 1: Loss=1.099, Time=0.011
Epoch 139: at batch 1: Loss=1.099, Time=0.011
Epoch 140: at batch 1: Loss=1.099, Time=0.020
Epoch 141: at batch 1: Loss=1.099, Time=0.010
Epoch 141: Time=364.687, Epoch time = 2.705, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 142: at batch 1: Loss=1.099, Time=0.010
Epoch 143: at batch 1: Loss=1.106, Time=0.010
Epoch 144: at batch 1: Loss=1.093, Time=0.011
Epoch 145: at batch 1: Loss=1.099, Time=0.011
Epoch 146: at batch 1: Loss=1.099, Time=0.019
Epoch 147: at batch 1: Loss=1.099, Time=0.011
Epoch 148: at batch 1: Loss=1.099, Time=0.019
Epoch 149: at batch 1: Loss=1.099, Time=0.011
Epoch 150: at batch 1: Loss=1.099, Time=0.010
Epoch 151: at batch 1: Loss=1.099, Time=0.010
Epoch 151: Time=392.379, Epoch time = 2.768, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 152: at batch 1: Loss=1.099, Time=0.006
Epoch 153: at batch 1: Loss=1.099, Time=0.011
Epoch 154: at batch 1: Loss=1.099, Time=0.011
Epoch 155: at batch 1: Loss=1.099, Time=0.011
Epoch 156: at batch 1: Loss=1.099, Time=0.020
Epoch 157: at batch 1: Loss=1.099, Time=0.009
Epoch 158: at batch 1: Loss=1.099, Time=0.019
Epoch 159: at batch 1: Loss=1.099, Time=0.011
Epoch 160: at batch 1: Loss=1.099, Time=0.019
Epoch 161: at batch 1: Loss=1.099, Time=0.010
Epoch 161: Time=420.034, Epoch time = 2.724, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 162: at batch 1: Loss=1.099, Time=0.011
Epoch 163: at batch 1: Loss=1.099, Time=0.011
Epoch 164: at batch 1: Loss=1.099, Time=0.024
Epoch 165: at batch 1: Loss=1.099, Time=0.010
Epoch 166: at batch 1: Loss=1.099, Time=0.010
Epoch 167: at batch 1: Loss=1.099, Time=0.020
Epoch 168: at batch 1: Loss=1.099, Time=0.010
Epoch 169: at batch 1: Loss=1.099, Time=0.019
Epoch 170: at batch 1: Loss=1.099, Time=0.011
Epoch 171: at batch 1: Loss=1.099, Time=0.010
Epoch 171: Time=447.953, Epoch time = 2.733, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 172: at batch 1: Loss=1.099, Time=0.020
Epoch 173: at batch 1: Loss=1.099, Time=0.010
Epoch 174: at batch 1: Loss=1.106, Time=0.010
Epoch 175: at batch 1: Loss=1.099, Time=0.007
Epoch 176: at batch 1: Loss=1.099, Time=0.010
Epoch 177: at batch 1: Loss=1.099, Time=0.011
Epoch 178: at batch 1: Loss=1.099, Time=0.022
Epoch 179: at batch 1: Loss=1.099, Time=0.011
Epoch 180: at batch 1: Loss=1.099, Time=0.010
Epoch 181: at batch 1: Loss=1.099, Time=0.010
Epoch 181: Time=475.986, Epoch time = 2.769, Avg epoch time=2.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 182: at batch 1: Loss=1.099, Time=0.020
Epoch 183: at batch 1: Loss=1.099, Time=0.010
Epoch 184: at batch 1: Loss=1.099, Time=0.010
Epoch 185: at batch 1: Loss=1.099, Time=0.011
Epoch 186: at batch 1: Loss=1.099, Time=0.011
^CTraceback (most recent call last):
  File "simple_ReLU_BN_Sony.py", line 301, in <module>
    feed_dict={in_image: input_patch, gt_gamma: assigned_image_gamma_index, lr: learning_rate})
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 887, in run
    run_metadata_ptr)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1110, in _run
    feed_dict_tensor, options, run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1286, in _do_run
    run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1292, in _do_call
    return fn(*args)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1277, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1367, in _call_tf_sessionrun
    run_metadata)
KeyboardInterrupt
(sid2) [ir967@gr034 Learning-to-See-in-the-Dark]$ Connection to localhost closed by remote host.
Connection to localhost closed.
(base) Ilyeechs-MacBook-Pro:~ ilyeech$ ssh -Y greene
 _   ___   ___   _   _   _ ____   ____ 
| \ | \ \ / / | | | | | | |  _ \ / ___|
|  \| |\ V /| | | | | |_| | |_) | |    
| |\  | | | | |_| | |  _  |  __/| |___ 
|_| \_| |_|  \___/  |_| |_|_|    \____|
 

  ____                          
 / ___|_ __ ___  ___ _ __   ___ 
| |  _| '__/ _ \/ _ \ '_ \ / _ \
| |_| | | |  __/  __/ | | |  __/
 \____|_|  \___|\___|_| |_|\___|

ir967@localhost's password: 
Last login: Fri Dec 11 12:09:41 2020 from 216.165.66.211
(base) [ir967@log-3 ~]$ squeue -u ir967
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON) 
(base) [ir967@log-3 ~]$ cd $SCRATCH/SID
(base) [ir967@log-3 SID]$ cd Learning-to-See-in-the-Dark/
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ srun -t1:00:00 --mem=18460 --gres=gpu:1 --pty /bin/bash
(base) [ir967@gr022 Learning-to-See-in-the-Dark]$ ssh gr022
Warning: Permanently added 'gr022' (ECDSA) to the list of known hosts.
(base) [ir967@gr022 ~]$ cd $SCRATCH/SID
(base) [ir967@gr022 SID]$ cd Learning-to-See-in-the-Dark/
(base) [ir967@gr022 Learning-to-See-in-the-Dark]$ conda activate sid2
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ ls gt_Sony_simple_ReLU_BN_new/
0000  0020  0040  0060  0080  0100  0120  0140  0160  0180        model.ckpt.data-00000-of-00001  model.ckpt.meta
0010  0030  0050  0070  0090  0110  0130  0150  0170  checkpoint  model.ckpt.index
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ mkdir gt_Sony_simple_ReLU_BN_batched
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ vi simple_batched.py
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ python simple_batched.py 
  File "simple_batched.py", line 30
    train_dataset = tf.
                      ^
SyntaxError: invalid syntax
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ vi simple_batched.py
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ python simple_batched.py 




Found 161 images to train with

2020-12-11 15:46:42.478373: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 15:46:42.621199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:2f:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 15:46:42.621235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 15:46:44.948065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 15:46:44.948100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 15:46:44.948126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 15:46:44.948278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:2f:00.0, compute capability: 7.5)
Traceback (most recent call last):
  File "simple_batched.py", line 130, in <module>
    print('No checkpoint found at ' + ckpt.model_checkpoint_path + '. Hence, will create')
AttributeError: 'NoneType' object has no attribute 'model_checkpoint_path'
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ vi simple_batched.py
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ python simple_batched.py 




Found 161 images to train with

2020-12-11 15:47:33.404740: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 15:47:33.546664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:2f:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 15:47:33.546694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 15:47:33.836871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 15:47:33.836905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 15:47:33.836925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 15:47:33.837022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:2f:00.0, compute capability: 7.5)
No checkpoint found at ./gt_Sony_simple_ReLU_BN_batched/. Hence, will create

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.87565, 0.00000, 300.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01631, 300.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 100.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00187, 300.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.02266, 300.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00427, 250.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00886, 300.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00248, 100.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00016, 300.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 300.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00012, 100.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 250.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00144, 300.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00307, 250.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00002, 300.00000, 6735543
20 images loaded to CPU RAM in Time=5.646 seconds.
Traceback (most recent call last):
  File "simple_batched.py", line 279, in <module>
    ind = train_ids[ind]
TypeError: only integer scalar arrays can be converted to a scalar index
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ vi simple_batched.py
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ python simple_batched.py 




Found 161 images to train with

2020-12-11 15:50:46.557273: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 15:50:46.700862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:2f:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 15:50:46.700893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 15:50:46.992437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 15:50:46.992470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 15:50:46.992486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 15:50:46.992665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:2f:00.0, compute capability: 7.5)
No checkpoint found at ./gt_Sony_simple_ReLU_BN_batched/. Hence, will create

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95669, 0.00000, 100.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01631, 300.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00164, 300.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00190, 250.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.02310, 250.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00417, 300.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00886, 300.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00233, 250.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00016, 300.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 300.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00012, 100.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 300.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00144, 300.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00327, 100.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00003, 100.00000, 6735543
20 images loaded to CPU RAM in Time=4.777 seconds.
Starting Training on index [ 18 148  38 186  27 148 129 132 202  44 129  46 148  33  78  73]
Traceback (most recent call last):
  File "simple_batched.py", line 284, in <module>
    assigned_image_gamma_index = gammas.index(assigned_image_gamma)#Should be same as in assigned_image_gamma_indices
ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ vi simple_batched.py
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ python simple_batched.py 




Found 161 images to train with

2020-12-11 15:56:30.681497: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 15:56:30.821338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:2f:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 15:56:30.821369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 15:56:31.113119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 15:56:31.113155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 15:56:31.113175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 15:56:31.113276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:2f:00.0, compute capability: 7.5)
No checkpoint found at ./gt_Sony_simple_ReLU_BN_batched/. Hence, will create

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.87565, 0.00000, 300.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01631, 300.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00164, 300.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00190, 250.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.02310, 250.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00417, 300.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00894, 100.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00248, 100.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00016, 300.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 300.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00012, 250.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00117, 100.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00146, 250.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00307, 250.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00003, 100.00000, 6735543
20 images loaded to CPU RAM in Time=4.745 seconds.
Starting Training on index [132 129 129 118  73 148  27 118 148 129 119  33 148  81 118 186]
Starting Training on gammas [300 300 300 100 300 100 100 100 100 300 300 100 100 100 100 300]
Traceback (most recent call last):
  File "simple_batched.py", line 293, in <module>
    H = input_images[ind[0]].shape[1]
AttributeError: 'NoneType' object has no attribute 'shape'
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ vi simple_batched.py
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ python simple_batched.py 




Found 161 images to train with

2020-12-11 16:03:40.501476: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 16:03:40.641239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:2f:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 16:03:40.641269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 16:03:40.928816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 16:03:40.928849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 16:03:40.928878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 16:03:40.928972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:2f:00.0, compute capability: 7.5)
No checkpoint found at ./gt_Sony_simple_ReLU_BN_batched/. Hence, will create

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.87565, 0.00000, 300.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01648, 100.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00164, 300.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00190, 250.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.02266, 300.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00427, 250.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00886, 300.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00228, 300.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 100.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00613, 100.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00012, 300.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00117, 100.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00146, 250.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00301, 300.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00003, 100.00000, 6735543
20 images loaded to CPU RAM in Time=4.786 seconds.
Starting Training on index [ 78  38  18 148 123 132 123  99 148  44 129  33  18  99  29 129]
Starting Training on gammas [300 250 300 100 100 300 100 250 100 300 300 100 300 250 250 300]
Traceback (most recent call last):
  File "simple_batched.py", line 293, in <module>
    H = input_images[ind].shape[1]
TypeError: only integer scalar arrays can be converted to a scalar index
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ vi simple_batched.py
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ python simple_batched.py 




Found 161 images to train with

2020-12-11 16:05:40.646899: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 16:05:40.784958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:2f:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 16:05:40.784989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 16:05:41.075475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 16:05:41.075512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 16:05:41.075557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 16:05:41.075664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:2f:00.0, compute capability: 7.5)
No checkpoint found at ./gt_Sony_simple_ReLU_BN_batched/. Hence, will create

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95669, 0.00000, 100.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01631, 300.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 100.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00201, 100.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.02310, 250.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00417, 300.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00887, 250.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00233, 250.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 250.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00613, 100.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00012, 300.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 250.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00146, 250.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00327, 100.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00003, 100.00000, 6735543
20 images loaded to CPU RAM in Time=4.753 seconds.
Starting Training on index [118  78  81  78  73 123  81  27  33 119  27 132  27  44  18 148]
Starting Training on gammas [250 250 100 250 250 250 100 250 100 300 250 250 250 250 100 100]
Traceback (most recent call last):
  File "simple_batched.py", line 293, in <module>
    H = input_images[ind[0]].shape[1]
AttributeError: 'NoneType' object has no attribute 'shape'
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ python train_for_gamma_Sony_
train_for_gamma_Sony_3output_more_simpler_wider.py  train_for_gamma_Sony_dead_simple_3gammas.py
train_for_gamma_Sony_3output.py                     train_for_gamma_Sony_dead_simple.py
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ python train_for_gamma_Sony_dead_simple
train_for_gamma_Sony_dead_simple_3gammas.py  train_for_gamma_Sony_dead_simple.py
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ python train_for_gamma_Sony_dead_simple_3gammas.py 




Found 161 images to train with

2020-12-11 16:06:39.181145: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 16:06:39.318948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:2f:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 16:06:39.318978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 16:06:39.610145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 16:06:39.610180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 16:06:39.610189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 16:06:39.610287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:2f:00.0, compute capability: 7.5)
loaded ./gt_Sony_dead_simple_3gammas/model.ckpt

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 1410
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95669, 0.00000, 100.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01648, 100.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 100.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00201, 100.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.02465, 100.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00467, 100.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00894, 100.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00248, 100.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 100.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00613, 100.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00012, 100.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00117, 100.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00155, 100.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00327, 100.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00003, 100.00000, 6735543
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.89525, 0.00000, 250.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01633, 250.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 250.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00190, 250.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.02310, 250.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00427, 250.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00887, 250.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00233, 250.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 250.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 250.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00012, 250.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 250.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00146, 250.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00307, 250.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00002, 250.00000, 6735543
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.87565, 0.00000, 300.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01631, 300.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00164, 300.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00187, 300.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.02266, 300.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00417, 300.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00886, 300.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00228, 300.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00016, 300.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 300.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00012, 300.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 300.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00144, 300.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00301, 300.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00002, 300.00000, 6735543
60 images loaded to CPU RAM in Time=13.898 seconds.
Epoch 1411: batch 1: Loss=1.099, Time=2.277
Epoch 1411: Time=2.626, Epoch time = 2.626, Avg epoch time=1.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1412: batch 1: Loss=1.099, Time=0.010
Epoch 1413: batch 1: Loss=1.099, Time=0.010
Epoch 1414: batch 1: Loss=1.099, Time=0.010
Epoch 1415: batch 1: Loss=1.099, Time=0.010
Epoch 1416: batch 1: Loss=1.099, Time=0.019
Epoch 1417: batch 1: Loss=1.099, Time=0.011
Epoch 1418: batch 1: Loss=1.099, Time=0.010
^CTraceback (most recent call last):
  File "train_for_gamma_Sony_dead_simple_3gammas.py", line 303, in <module>
    feed_dict={in_image: input_patch, gt_gamma: assigned_image_gamma_index, lr: learning_rate})
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 887, in run
    run_metadata_ptr)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1110, in _run
    feed_dict_tensor, options, run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1286, in _do_run
    run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1292, in _do_call
    return fn(*args)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1277, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1367, in _call_tf_sessionrun
    run_metadata)
KeyboardInterrupt
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ vi simple_batched.py
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ python train_for_gamma_Sony_dead_simple_3gammas.py 




Found 161 images to train with

2020-12-11 16:10:58.723055: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
^C2020-12-11 16:10:58.863970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:2f:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 16:10:58.863998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 16:10:59.153112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 16:10:59.153148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 16:10:59.153162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 16:10:59.153258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:2f:00.0, compute capability: 7.5)
Traceback (most recent call last):
  File "train_for_gamma_Sony_dead_simple_3gammas.py", line 93, in <module>
    sess = tf.Session()
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1511, in __init__
    super(Session, self).__init__(target, graph, config=config)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 634, in __init__
    self._session = tf_session.TF_NewSessionRef(self._graph._c_graph, opts)
KeyboardInterrupt
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ ^C
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ python simple_batched.py 




Found 161 images to train with

2020-12-11 16:11:04.156463: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 16:11:04.295085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:2f:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 16:11:04.295114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 16:11:04.586791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 16:11:04.586829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 16:11:04.586842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 16:11:04.586941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:2f:00.0, compute capability: 7.5)
No checkpoint found at ./gt_Sony_simple_ReLU_BN_batched/. Hence, will create

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
Traceback (most recent call last):
  File "simple_batched.py", line 241, in <module>
    input_image = np.multiply(input_image, 65535)#CAN I DO THIS? Will it remove  the information on Gamma?
NameError: name 'input_image' is not defined
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ vi simple_batched.py
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ python simple_batched.py 




Found 161 images to train with

2020-12-11 16:12:20.523347: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 16:12:20.662271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:2f:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 16:12:20.662302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 16:12:20.951373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 16:12:20.951409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 16:12:20.951418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 16:12:20.951515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:2f:00.0, compute capability: 7.5)
No checkpoint found at ./gt_Sony_simple_ReLU_BN_batched/. Hence, will create

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95669, 0.00000, 100.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01631, 300.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 100.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00190, 250.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.02465, 100.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00417, 300.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00887, 250.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00228, 300.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 250.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 300.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00012, 250.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00117, 100.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00155, 100.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00307, 250.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00002, 250.00000, 6735543
20 images loaded to CPU RAM in Time=4.788 seconds.
Starting Training on index [202  38 132 118 129  70 118  44  78 129  46  18 186  44  46 148]
Starting Training on gammas [100 300 300 100 250 250 100 300 100 250 250 250 250 300 250 100]
Traceback (most recent call last):
  File "simple_batched.py", line 294, in <module>
    H = input_images[ind[0]].shape[0]
AttributeError: 'NoneType' object has no attribute 'shape'
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ vi simple_batched.py
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ python simple_batched.py 




Found 161 images to train with

2020-12-11 16:19:44.090065: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 16:19:44.231501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:2f:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 16:19:44.231535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 16:19:44.519673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 16:19:44.519708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 16:19:44.519722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 16:19:44.519820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:2f:00.0, compute capability: 7.5)
No checkpoint found at ./gt_Sony_simple_ReLU_BN_batched/. Hence, will create

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.89525, 0.00000, 250.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01631, 300.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00164, 300.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00187, 300.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.02310, 250.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00467, 100.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00887, 250.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00248, 100.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 250.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 250.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00012, 300.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00117, 100.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00146, 250.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00327, 100.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00002, 300.00000, 6735543
20 images loaded to CPU RAM in Time=4.759 seconds.
Starting Training on index [ 2  3  6 19 13 11  5 17 19 11  5 15 13  2  1 10], dataset index: [ 29 132 118 202  27 129  33  70 202 129  33  44  27  29 148  38]
Starting Training on gammas [300 250 300 300 250 100 300 250 300 100 300 100 250 300 250 250]
Traceback (most recent call last):
  File "simple_batched.py", line 300, in <module>
    input_patch = input_images[ind][yy:yy + ps, xx:xx + ps, :]
TypeError: only integer scalar arrays can be converted to a scalar index
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ vi simple_batched.py
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ python simple_batched.py 




Found 161 images to train with

2020-12-11 16:22:57.854313: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 16:22:57.997155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:2f:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 16:22:57.997186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 16:22:58.285470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 16:22:58.285505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 16:22:58.285604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 16:22:58.285704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:2f:00.0, compute capability: 7.5)
No checkpoint found at ./gt_Sony_simple_ReLU_BN_batched/. Hence, will create

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95669, 0.00000, 100.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01631, 300.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00164, 300.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00201, 100.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.02310, 250.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00427, 250.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00887, 250.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00233, 250.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 250.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00613, 100.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00012, 100.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00117, 100.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00155, 100.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00327, 100.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00002, 250.00000, 6735543
20 images loaded to CPU RAM in Time=4.771 seconds.

moved images data to numpy array
Starting Training on index [17  1  6 18  2 11 18 16  9 12 17  6  5  0 16  7], dataset index: [ 70 148 118 123  29 129 123  99 186  46  70 118  33  18  99  78]
Starting Training on gammas [250 100 100 100 300 250 100 100 250 250 250 100 300 300 100 250]
Traceback (most recent call last):
  File "simple_batched.py", line 302, in <module>
    input_patch = input_images[ind][yy:yy + ps, xx:xx + ps, :]
IndexError: too many indices for array
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ vi simple_batched.py
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ python simple_batched.py 
Traceback (most recent call last):
  File "simple_batched.py", line 11, in <module>
    from textwrap import indent
ImportError: cannot import name indent
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ vi simple_batched.py
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ vi simple_batched.py
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ python simple_batched.py 




Found 161 images to train with

2020-12-11 16:38:16.528117: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 16:38:16.672489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:2f:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 16:38:16.672519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 16:38:16.963279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 16:38:16.963312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 16:38:16.963328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 16:38:16.963425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:2f:00.0, compute capability: 7.5)
No checkpoint found at ./gt_Sony_simple_ReLU_BN_batched/. Hence, will create

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.89525, 0.00000, 250.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01631, 300.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 100.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00201, 100.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.02465, 100.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00427, 250.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00887, 250.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00228, 300.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 100.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 300.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00012, 250.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00117, 100.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00155, 100.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00301, 300.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00002, 250.00000, 6735543
20 images loaded to CPU RAM in Time=4.711 seconds.

moved images data to numpy array
Starting Training on index [11  4  3  9 14 16 11 17  9 14  7  3  3 10  7 19], dataset index: [129  73 132 186 119  99 129  70 186 119  78 132 132  38  78 202]
Starting Training on gammas [300 100 100 300 250 100 300 100 300 250 100 100 100 250 100 250]
Traceback (most recent call last):
  File "simple_batched.py", line 307, in <module>
    input_patch_list[k] = input_images[ind[k], yy:yy + ps, xx:xx + ps, :]
IndexError: too many indices for array
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ vi simple_batched.py
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ python simple_batched.py 




Found 161 images to train with

2020-12-11 16:40:56.944809: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 16:40:57.081659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:2f:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 16:40:57.081691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 16:40:57.365813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 16:40:57.365845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 16:40:57.365856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 16:40:57.365951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:2f:00.0, compute capability: 7.5)
No checkpoint found at ./gt_Sony_simple_ReLU_BN_batched/. Hence, will create

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.89525, 0.00000, 250.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01633, 250.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 250.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00201, 100.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.02266, 300.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00417, 300.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00887, 250.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00228, 300.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 100.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 250.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00012, 250.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 300.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00155, 100.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00327, 100.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00002, 300.00000, 6735543
20 images loaded to CPU RAM in Time=4.781 seconds.
(6000,)

moved images data to numpy array
Starting Training on index [10 19 17 15  9  7 10  8  9 13 19 18 11  7 19  7], dataset index: [ 38 202  70  44 186  78  38  81 186  27 202 123 129  78 202  78]
Starting Training on gammas [250 300 250 300 100 300 250 300 100 250 300 100 300 300 300 300]
Traceback (most recent call last):
  File "simple_batched.py", line 308, in <module>
    input_patch_list[k] = input_images[ind[k], yy:yy + ps, xx:xx + ps, :]
IndexError: too many indices for array
(sid2) [ir967@gr022 Learning-to-See-in-the-Dark]$ srun: Force Terminated job 402035
slurmstepd: error: *** STEP 402035.0 ON gr022-ib0 CANCELLED AT 2020-12-11T16:44:40 DUE TO TIME LIMIT ***
client_loop: send disconnect: Broken pipe
(base) [ir967@gr022 Learning-to-See-in-the-Dark]$ exit
srun: error: gr022-ib0: task 0: Exited with exit code 255
srun: Terminating job step 402035.0
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ srun -t0:30:00 --mem=18460 --gres=gpu:1 --pty /bin/bash
(base) [ir967@gr020 Learning-to-See-in-the-Dark]$ cd $SCRATCH/SID
(base) [ir967@gr020 SID]$ cd Learning-to-See-in-the-Dark/
(base) [ir967@gr020 Learning-to-See-in-the-Dark]$ conda activate sid2
(sid2) [ir967@gr020 Learning-to-See-in-the-Dark]$ cp simple_
simple_batched.py       simple_ReLU_BN_Sony.py  simple_ReLU_Sony.py     
(sid2) [ir967@gr020 Learning-to-See-in-the-Dark]$ cp simple_batched.py simple_batched_numpy.py
(sid2) [ir967@gr020 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy.py 
(sid2) [ir967@gr020 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy.py 
(sid2) [ir967@gr020 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py 
  File "simple_batched_numpy.py", line 144
SyntaxError: Non-ASCII character '\xc3' in file simple_batched_numpy.py on line 144, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details
(sid2) [ir967@gr020 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy.py 
(sid2) [ir967@gr020 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py 




Found 161 images to train with

Training on 20 images only

2020-12-11 17:05:27.692965: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 17:05:27.810018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:86:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 17:05:27.810057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 17:05:30.383247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 17:05:30.383283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 17:05:30.383307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 17:05:30.383460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5)
No checkpoint found at ./gt_Sony_simple_ReLU_BN_batched/. Hence, will create

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
Traceback (most recent call last):
  File "simple_batched_numpy.py", line 253, in <module>
    input_images_numpy[ind] = input_image
ValueError: could not broadcast input array from shape (1424,2128,4) into shape (4240,2832,3)
(sid2) [ir967@gr020 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy.py 
(sid2) [ir967@gr020 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py 




Found 161 images to train with

Training on 20 images only

2020-12-11 17:07:31.630303: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 17:07:31.774207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:86:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 17:07:31.774241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 17:07:32.058761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 17:07:32.058800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 17:07:32.058822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 17:07:32.058928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5)
No checkpoint found at ./gt_Sony_simple_ReLU_BN_batched/. Hence, will create

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95669, 0.00000, 100.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01648, 100.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 250.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00187, 300.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.02266, 300.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00427, 250.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00886, 300.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00228, 300.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 100.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 300.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00012, 300.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 250.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00146, 250.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00327, 100.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00002, 250.00000, 6735543
20 images loaded to CPU RAM in Time=6.645 seconds.

moved images data to numpy array
Starting Training on index [ 3 15  4  9  2  9 10  0  6  1  9  0  9 16  4  0], dataset index: [132  44  73 186  29 186  38  18 118 148 186  18 186  99  73  18]
Starting Training on gammas [300 250 100 100 100 100 300 300 300 100 100 300 100 250 100 300]
Traceback (most recent call last):
  File "simple_batched_numpy.py", line 336, in <module>
    feed_dict={in_image: input_patch, gt_gamma: assigned_image_gamma_index, lr: learning_rate})
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 887, in run
    run_metadata_ptr)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1086, in _run
    str(subfeed_t.get_shape())))
ValueError: Cannot feed value of shape (1, 16) for Tensor u'Placeholder_1:0', which has shape '(?, 1)'
(sid2) [ir967@gr020 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy.py 
(sid2) [ir967@gr020 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py 




Found 161 images to train with

Training on 20 images only

2020-12-11 17:11:24.112986: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 17:11:24.255374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:86:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 17:11:24.255408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 17:11:24.540087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 17:11:24.540124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 17:11:24.540149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 17:11:24.540321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5)
No checkpoint found at ./gt_Sony_simple_ReLU_BN_batched/. Hence, will create

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.87565, 0.00000, 300.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01633, 250.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 250.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00201, 100.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.02266, 300.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00417, 300.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00886, 300.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00248, 100.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 250.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00613, 100.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00012, 100.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 250.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00155, 100.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00301, 300.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00002, 300.00000, 6735543
20 images loaded to CPU RAM in Time=5.974 seconds.

moved images data to numpy array
Starting Training on index [ 8  3 18  6  3 16  7 13 19 17 19  8  7 15 17  9], dataset index: [ 81 132 123 118 132  99  78  27 202  70 202  81  78  44  70 186]
Starting Training on gammas [300 250 300 100 250 100 300 100 300 250 300 300 300 250 250 300]
Traceback (most recent call last):
  File "simple_batched_numpy.py", line 316, in <module>
    assigned_image_gamma_index = np.tranpose(np.array([assigned_image_gamma_index]))#conversion for the sake of gt_gamma
AttributeError: 'module' object has no attribute 'tranpose'
(sid2) [ir967@gr020 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy.py 
(sid2) [ir967@gr020 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py 




Found 161 images to train with

Training on 20 images only

2020-12-11 17:12:28.740874: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 17:12:28.882198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:86:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 17:12:28.882233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 17:12:29.166988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 17:12:29.167027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 17:12:29.167085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 17:12:29.167257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5)
No checkpoint found at ./gt_Sony_simple_ReLU_BN_batched/. Hence, will create

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.87565, 0.00000, 300.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01633, 250.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 100.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00187, 300.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.02310, 250.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00427, 250.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00886, 300.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00228, 300.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 100.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 300.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00012, 100.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00117, 100.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00144, 300.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00307, 250.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00003, 100.00000, 6735543
20 images loaded to CPU RAM in Time=5.927 seconds.

moved images data to numpy array
Starting Training on index [10 13  3 12  5  3 14 19  1  8  1 10 19  3 15  3], dataset index: [ 38  27 132  46  33 132 119 202 148  81 148  38 202 132  44 132]
Starting Training on gammas [300 300 250 100 100 250 100 100 300 250 300 300 100 250 100 250]
Epoch 0: at batch 1: Loss=0.843, Time=2.729
Epoch 1: at batch 1: Loss=0.930, Time=0.028
Epoch 1: Time=2.803, Epoch time = 0.028, Avg epoch time=1.000

[[0.97304958]
 [0.84323788]
 [0.97304958]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 2: at batch 1: Loss=1.049, Time=0.025
Epoch 3: at batch 1: Loss=1.052, Time=0.026
Epoch 4: at batch 1: Loss=1.000, Time=0.024
Epoch 5: at batch 1: Loss=1.063, Time=0.033
Epoch 6: at batch 1: Loss=1.201, Time=0.026
Epoch 7: at batch 1: Loss=1.301, Time=0.024
Epoch 8: at batch 1: Loss=1.094, Time=0.024
Epoch 9: at batch 1: Loss=1.026, Time=0.029
Epoch 10: at batch 1: Loss=1.051, Time=0.026
Epoch 11: at batch 1: Loss=1.332, Time=0.036
Epoch 11: Time=3.361, Epoch time = 0.036, Avg epoch time=0.000

[[1.10427427]
 [1.55574822]
 [1.10427427]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 12: at batch 1: Loss=1.473, Time=0.024
Epoch 13: at batch 1: Loss=1.400, Time=0.025
Epoch 14: at batch 1: Loss=1.299, Time=0.024
Epoch 15: at batch 1: Loss=1.345, Time=0.027
Epoch 16: at batch 1: Loss=1.153, Time=0.025
Epoch 17: at batch 1: Loss=1.036, Time=0.028
Epoch 18: at batch 1: Loss=1.063, Time=0.027
Epoch 19: at batch 1: Loss=1.116, Time=0.027
Epoch 20: at batch 1: Loss=1.074, Time=0.026
Epoch 21: at batch 1: Loss=1.108, Time=0.025
Epoch 21: Time=3.895, Epoch time = 0.025, Avg epoch time=0.000

[[1.12545574]
 [1.12545574]
 [1.04855418]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 22: at batch 1: Loss=1.053, Time=0.025
Epoch 23: at batch 1: Loss=1.054, Time=0.024
Epoch 24: at batch 1: Loss=1.084, Time=0.022
Epoch 25: at batch 1: Loss=1.078, Time=0.025
Epoch 26: at batch 1: Loss=1.073, Time=0.027
Epoch 27: at batch 1: Loss=1.080, Time=0.023
Epoch 28: at batch 1: Loss=1.122, Time=0.025
Epoch 29: at batch 1: Loss=1.207, Time=0.023
Epoch 30: at batch 1: Loss=1.165, Time=0.022
Epoch 31: at batch 1: Loss=1.136, Time=0.027
Epoch 31: Time=4.425, Epoch time = 0.027, Avg epoch time=0.000

[[1.08376431]
 [1.09465981]
 [1.08376431]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 32: at batch 1: Loss=1.107, Time=0.026
Epoch 33: at batch 1: Loss=1.108, Time=0.027
Epoch 34: at batch 1: Loss=1.056, Time=0.023
Epoch 35: at batch 1: Loss=1.056, Time=0.022
Epoch 36: at batch 1: Loss=1.046, Time=0.026
Epoch 37: at batch 1: Loss=1.285, Time=0.023
Epoch 38: at batch 1: Loss=1.187, Time=0.025
Epoch 39: at batch 1: Loss=1.092, Time=0.034
Epoch 40: at batch 1: Loss=1.172, Time=0.026
Epoch 41: at batch 1: Loss=1.130, Time=0.022
Epoch 41: Time=4.965, Epoch time = 0.022, Avg epoch time=0.000

[[1.04243028]
 [1.10707259]
 [1.10707259]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 42: at batch 1: Loss=1.115, Time=0.025
Epoch 43: at batch 1: Loss=1.017, Time=0.023
Epoch 44: at batch 1: Loss=1.077, Time=0.025
Epoch 45: at batch 1: Loss=1.324, Time=0.024
Epoch 46: at batch 1: Loss=1.232, Time=0.026
Epoch 47: at batch 1: Loss=1.139, Time=0.035
Epoch 48: at batch 1: Loss=1.067, Time=0.027
Epoch 49: at batch 1: Loss=1.287, Time=0.027
Epoch 50: at batch 1: Loss=1.481, Time=0.025
Epoch 51: at batch 1: Loss=1.239, Time=0.025
Epoch 51: Time=5.515, Epoch time = 0.025, Avg epoch time=0.000

[[1.72232354]
 [1.10417521]
 [1.10417521]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 52: at batch 1: Loss=1.296, Time=0.031
Epoch 53: at batch 1: Loss=1.237, Time=0.034
Epoch 54: at batch 1: Loss=1.038, Time=0.024
Epoch 55: at batch 1: Loss=1.017, Time=0.022
Epoch 56: at batch 1: Loss=1.054, Time=0.022
Epoch 57: at batch 1: Loss=1.018, Time=0.025
Epoch 58: at batch 1: Loss=1.090, Time=0.022
Epoch 59: at batch 1: Loss=1.099, Time=0.023
Epoch 60: at batch 1: Loss=1.142, Time=0.027
Epoch 61: at batch 1: Loss=1.306, Time=0.023
Epoch 61: Time=6.051, Epoch time = 0.023, Avg epoch time=0.000

[[1.08517694]
 [1.08387959]
 [1.46921086]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 62: at batch 1: Loss=1.389, Time=0.027
Epoch 63: at batch 1: Loss=1.287, Time=0.024
Epoch 64: at batch 1: Loss=1.215, Time=0.022
Epoch 65: at batch 1: Loss=1.073, Time=0.025
Epoch 66: at batch 1: Loss=1.381, Time=0.033
Epoch 67: at batch 1: Loss=1.278, Time=0.029
Epoch 68: at batch 1: Loss=1.353, Time=0.024
Epoch 69: at batch 1: Loss=1.095, Time=0.027
Epoch 70: at batch 1: Loss=1.099, Time=0.030
Epoch 71: at batch 1: Loss=1.253, Time=0.025
Epoch 71: Time=6.597, Epoch time = 0.025, Avg epoch time=0.000

[[1.43263578]
 [1.10111415]
 [1.43037295]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 72: at batch 1: Loss=1.164, Time=0.026
Epoch 73: at batch 1: Loss=1.621, Time=0.024
Epoch 74: at batch 1: Loss=1.887, Time=0.024
Epoch 75: at batch 1: Loss=1.310, Time=0.024
Epoch 76: at batch 1: Loss=1.185, Time=0.025
Epoch 77: at batch 1: Loss=1.151, Time=0.035
Epoch 78: at batch 1: Loss=1.034, Time=0.027
Epoch 79: at batch 1: Loss=0.979, Time=0.033
Epoch 80: at batch 1: Loss=1.040, Time=0.025
Epoch 81: at batch 1: Loss=1.089, Time=0.035
Epoch 81: Time=7.156, Epoch time = 0.035, Avg epoch time=0.000

[[1.09515595]
 [1.12205577]
 [0.94182926]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 82: at batch 1: Loss=1.218, Time=0.027
Epoch 83: at batch 1: Loss=1.228, Time=0.025
Epoch 84: at batch 1: Loss=1.162, Time=0.023
Epoch 85: at batch 1: Loss=1.137, Time=0.030
Epoch 86: at batch 1: Loss=1.072, Time=0.024
Epoch 87: at batch 1: Loss=1.128, Time=0.025
Epoch 88: at batch 1: Loss=1.071, Time=0.024
Epoch 89: at batch 1: Loss=1.305, Time=0.030
Epoch 90: at batch 1: Loss=1.160, Time=0.027
Epoch 91: at batch 1: Loss=1.141, Time=0.024
Epoch 91: Time=7.699, Epoch time = 0.024, Avg epoch time=0.000

[[1.09612131]
 [1.09612131]
 [1.54209089]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 92: at batch 1: Loss=1.250, Time=0.024
Epoch 93: at batch 1: Loss=1.175, Time=0.024
Epoch 94: at batch 1: Loss=0.999, Time=0.026
Epoch 95: at batch 1: Loss=1.100, Time=0.022
Epoch 96: at batch 1: Loss=1.388, Time=0.033
Epoch 97: at batch 1: Loss=1.209, Time=0.023
Epoch 98: at batch 1: Loss=1.166, Time=0.021
Epoch 99: at batch 1: Loss=1.323, Time=0.022
Epoch 100: at batch 1: Loss=1.193, Time=0.024
Epoch 101: at batch 1: Loss=1.079, Time=0.024
Epoch 101: Time=8.224, Epoch time = 0.024, Avg epoch time=0.000

[[1.01518869]
 [1.01518869]
 [1.09954667]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 102: at batch 1: Loss=1.060, Time=0.026
Epoch 103: at batch 1: Loss=1.202, Time=0.027
Epoch 104: at batch 1: Loss=1.247, Time=0.037
Epoch 105: at batch 1: Loss=1.185, Time=0.034
Epoch 106: at batch 1: Loss=1.083, Time=0.027
Epoch 107: at batch 1: Loss=1.368, Time=0.027
Epoch 108: at batch 1: Loss=1.198, Time=0.021
Epoch 109: at batch 1: Loss=1.107, Time=0.024
Epoch 110: at batch 1: Loss=1.333, Time=0.027
Epoch 111: at batch 1: Loss=1.186, Time=0.024
Epoch 111: Time=8.779, Epoch time = 0.024, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.41804528]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 112: at batch 1: Loss=1.141, Time=0.024
Epoch 113: at batch 1: Loss=1.126, Time=0.025
Epoch 114: at batch 1: Loss=1.116, Time=0.022
Epoch 115: at batch 1: Loss=1.018, Time=0.023
Epoch 116: at batch 1: Loss=1.019, Time=0.022
Epoch 117: at batch 1: Loss=1.173, Time=0.021
Epoch 118: at batch 1: Loss=1.109, Time=0.034
Epoch 119: at batch 1: Loss=1.107, Time=0.031
Epoch 120: at batch 1: Loss=1.150, Time=0.027
Epoch 121: at batch 1: Loss=1.118, Time=0.027
Epoch 121: Time=9.320, Epoch time = 0.027, Avg epoch time=0.000

[[1.09861231]
 [0.99229747]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 122: at batch 1: Loss=1.105, Time=0.024
Epoch 123: at batch 1: Loss=1.198, Time=0.027
Epoch 124: at batch 1: Loss=1.325, Time=0.020
Epoch 125: at batch 1: Loss=1.237, Time=0.023
Epoch 126: at batch 1: Loss=1.101, Time=0.027
Epoch 127: at batch 1: Loss=1.165, Time=0.024
Epoch 128: at batch 1: Loss=1.329, Time=0.022
Epoch 129: at batch 1: Loss=1.196, Time=0.023
Epoch 130: at batch 1: Loss=1.204, Time=0.035
Epoch 131: at batch 1: Loss=1.130, Time=0.021
Epoch 131: Time=9.852, Epoch time = 0.021, Avg epoch time=0.000

[[1.16383123]
 [1.12098074]
 [1.16383123]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 132: at batch 1: Loss=1.148, Time=0.022
Epoch 133: at batch 1: Loss=1.091, Time=0.032
Epoch 134: at batch 1: Loss=1.188, Time=0.022
Epoch 135: at batch 1: Loss=1.613, Time=0.023
Epoch 136: at batch 1: Loss=1.300, Time=0.025
Epoch 137: at batch 1: Loss=1.262, Time=0.025
Epoch 138: at batch 1: Loss=1.106, Time=0.030
Epoch 139: at batch 1: Loss=1.089, Time=0.023
Epoch 140: at batch 1: Loss=1.056, Time=0.032
Epoch 141: at batch 1: Loss=1.285, Time=0.021
Epoch 141: Time=10.391, Epoch time = 0.021, Avg epoch time=0.000

[[1.03614473]
 [1.46425128]
 [1.46425128]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 142: at batch 1: Loss=1.152, Time=0.025
Epoch 143: at batch 1: Loss=1.062, Time=0.026
Epoch 144: at batch 1: Loss=1.090, Time=0.022
Epoch 145: at batch 1: Loss=1.209, Time=0.022
Epoch 146: at batch 1: Loss=1.310, Time=0.027
Epoch 147: at batch 1: Loss=1.473, Time=0.023
Epoch 148: at batch 1: Loss=1.267, Time=0.021
Epoch 149: at batch 1: Loss=1.146, Time=0.023
Epoch 150: at batch 1: Loss=1.151, Time=0.020
Epoch 151: at batch 1: Loss=1.258, Time=0.024
Epoch 151: Time=10.908, Epoch time = 0.024, Avg epoch time=0.000

[[1.14293766]
 [1.35070825]
 [1.35070825]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 152: at batch 1: Loss=1.128, Time=0.023
Epoch 153: at batch 1: Loss=1.116, Time=0.024
Epoch 154: at batch 1: Loss=1.100, Time=0.026
Epoch 155: at batch 1: Loss=1.108, Time=0.025
Epoch 156: at batch 1: Loss=1.012, Time=0.034
Epoch 157: at batch 1: Loss=1.039, Time=0.024
Epoch 158: at batch 1: Loss=1.063, Time=0.021
Epoch 159: at batch 1: Loss=1.018, Time=0.031
Epoch 160: at batch 1: Loss=1.496, Time=0.032
Epoch 161: at batch 1: Loss=1.316, Time=0.024
Epoch 161: Time=11.455, Epoch time = 0.024, Avg epoch time=0.000

[[1.05011499]
 [0.99247926]
 [1.05011499]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 162: at batch 1: Loss=1.280, Time=0.022
Epoch 163: at batch 1: Loss=1.169, Time=0.024
Epoch 164: at batch 1: Loss=1.128, Time=0.024
Epoch 165: at batch 1: Loss=1.198, Time=0.024
Epoch 166: at batch 1: Loss=1.125, Time=0.022
Epoch 167: at batch 1: Loss=1.111, Time=0.024
Epoch 168: at batch 1: Loss=1.153, Time=0.024
Epoch 169: at batch 1: Loss=1.106, Time=0.021
Epoch 170: at batch 1: Loss=1.237, Time=0.026
Epoch 171: at batch 1: Loss=1.283, Time=0.022
Epoch 171: Time=11.972, Epoch time = 0.022, Avg epoch time=0.000

[[1.34770823]
 [1.17669547]
 [1.35650098]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 172: at batch 1: Loss=1.335, Time=0.025
Epoch 173: at batch 1: Loss=1.224, Time=0.022
Epoch 174: at batch 1: Loss=1.153, Time=0.025
Epoch 175: at batch 1: Loss=1.105, Time=0.021
Epoch 176: at batch 1: Loss=1.129, Time=0.024
Epoch 177: at batch 1: Loss=1.074, Time=0.026
Epoch 178: at batch 1: Loss=1.076, Time=0.027
Epoch 179: at batch 1: Loss=1.103, Time=0.025
Epoch 180: at batch 1: Loss=1.103, Time=0.020
Epoch 181: at batch 1: Loss=1.136, Time=0.026
Epoch 181: Time=12.503, Epoch time = 0.026, Avg epoch time=0.000

[[1.13780951]
 [1.13780951]
 [1.13780951]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 182: at batch 1: Loss=1.201, Time=0.033
Epoch 183: at batch 1: Loss=1.099, Time=0.021
Epoch 184: at batch 1: Loss=1.032, Time=0.024
Epoch 185: at batch 1: Loss=1.076, Time=0.022
Epoch 186: at batch 1: Loss=1.060, Time=0.024
Epoch 187: at batch 1: Loss=1.066, Time=0.024
Epoch 188: at batch 1: Loss=1.085, Time=0.021
Epoch 189: at batch 1: Loss=1.193, Time=0.022
Epoch 190: at batch 1: Loss=1.158, Time=0.025
Epoch 191: at batch 1: Loss=1.244, Time=0.032
Epoch 191: Time=13.034, Epoch time = 0.033, Avg epoch time=0.000

[[1.28040302]
 [1.28006649]
 [1.12061691]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 192: at batch 1: Loss=1.201, Time=0.021
Epoch 193: at batch 1: Loss=1.149, Time=0.026
Epoch 194: at batch 1: Loss=1.109, Time=0.025
Epoch 195: at batch 1: Loss=1.049, Time=0.024
Epoch 196: at batch 1: Loss=1.082, Time=0.022
Epoch 197: at batch 1: Loss=1.097, Time=0.026
Epoch 198: at batch 1: Loss=1.102, Time=0.027
Epoch 199: at batch 1: Loss=1.181, Time=0.021
Epoch 200: at batch 1: Loss=1.077, Time=0.024
Epoch 201: at batch 1: Loss=1.254, Time=0.024
Epoch 201: Time=13.555, Epoch time = 0.024, Avg epoch time=0.000

[[1.00530553]
 [1.45533562]
 [1.45533562]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 202: at batch 1: Loss=1.192, Time=0.023
Epoch 203: at batch 1: Loss=1.237, Time=0.023
Epoch 204: at batch 1: Loss=1.278, Time=0.021
Epoch 205: at batch 1: Loss=1.097, Time=0.025
Epoch 206: at batch 1: Loss=1.123, Time=0.024
Epoch 207: at batch 1: Loss=1.104, Time=0.022
Epoch 208: at batch 1: Loss=1.072, Time=0.027
Epoch 209: at batch 1: Loss=1.084, Time=0.031
Epoch 210: at batch 1: Loss=1.097, Time=0.027
Epoch 211: at batch 1: Loss=1.059, Time=0.024
Epoch 211: Time=14.092, Epoch time = 0.024, Avg epoch time=0.000

[[1.10402262]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 212: at batch 1: Loss=1.076, Time=0.021
Epoch 213: at batch 1: Loss=1.331, Time=0.023
Epoch 214: at batch 1: Loss=1.228, Time=0.023
Epoch 215: at batch 1: Loss=1.287, Time=0.026
Epoch 216: at batch 1: Loss=1.178, Time=0.024
Epoch 217: at batch 1: Loss=1.243, Time=0.024
Epoch 218: at batch 1: Loss=1.186, Time=0.027
Epoch 219: at batch 1: Loss=1.193, Time=0.026
Epoch 220: at batch 1: Loss=1.198, Time=0.023
Epoch 221: at batch 1: Loss=1.131, Time=0.026
Epoch 221: Time=14.623, Epoch time = 0.026, Avg epoch time=0.000

[[1.0425427 ]
 [1.0425427 ]
 [1.19128537]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 222: at batch 1: Loss=1.051, Time=0.032
Epoch 223: at batch 1: Loss=1.054, Time=0.023
Epoch 224: at batch 1: Loss=1.075, Time=0.024
Epoch 225: at batch 1: Loss=1.085, Time=0.023
Epoch 226: at batch 1: Loss=1.250, Time=0.030
Epoch 227: at batch 1: Loss=1.196, Time=0.026
Epoch 228: at batch 1: Loss=1.678, Time=0.022
Epoch 229: at batch 1: Loss=1.360, Time=0.024
Epoch 230: at batch 1: Loss=1.303, Time=0.020
Epoch 231: at batch 1: Loss=1.276, Time=0.033
Epoch 231: Time=15.169, Epoch time = 0.033, Avg epoch time=0.000

[[1.15661466]
 [1.38980484]
 [1.15661466]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 232: at batch 1: Loss=1.146, Time=0.023
Epoch 233: at batch 1: Loss=1.103, Time=0.035
Epoch 234: at batch 1: Loss=1.091, Time=0.024
Epoch 235: at batch 1: Loss=1.564, Time=0.023
Epoch 236: at batch 1: Loss=1.225, Time=0.025
Epoch 237: at batch 1: Loss=1.235, Time=0.021
Epoch 238: at batch 1: Loss=1.369, Time=0.023
Epoch 239: at batch 1: Loss=1.263, Time=0.024
Epoch 240: at batch 1: Loss=1.020, Time=0.023
Epoch 241: at batch 1: Loss=1.218, Time=0.027
Epoch 241: Time=15.700, Epoch time = 0.027, Avg epoch time=0.000

[[1.31194448]
 [0.90149719]
 [1.31194448]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 242: at batch 1: Loss=1.407, Time=0.024
Epoch 243: at batch 1: Loss=1.212, Time=0.025
Epoch 244: at batch 1: Loss=1.365, Time=0.024
Epoch 245: at batch 1: Loss=1.267, Time=0.023
Epoch 246: at batch 1: Loss=1.134, Time=0.023
Epoch 247: at batch 1: Loss=1.121, Time=0.021
Epoch 248: at batch 1: Loss=1.099, Time=0.035
Epoch 249: at batch 1: Loss=1.392, Time=0.023
Epoch 250: at batch 1: Loss=1.211, Time=0.025
Epoch 251: at batch 1: Loss=1.168, Time=0.033
Epoch 251: Time=16.240, Epoch time = 0.033, Avg epoch time=0.000

[[1.10230482]
 [1.09861231]
 [1.54928768]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 252: at batch 1: Loss=1.137, Time=0.026
Epoch 253: at batch 1: Loss=1.176, Time=0.034
Epoch 254: at batch 1: Loss=1.136, Time=0.023
Epoch 255: at batch 1: Loss=1.087, Time=0.024
Epoch 256: at batch 1: Loss=1.110, Time=0.022
Epoch 257: at batch 1: Loss=1.105, Time=0.026
Epoch 258: at batch 1: Loss=1.105, Time=0.027
Epoch 259: at batch 1: Loss=1.066, Time=0.021
Epoch 260: at batch 1: Loss=1.086, Time=0.024
Epoch 261: at batch 1: Loss=1.041, Time=0.020
Epoch 261: Time=16.772, Epoch time = 0.020, Avg epoch time=0.000

[[0.98150092]
 [1.09861231]
 [0.98150092]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 262: at batch 1: Loss=0.863, Time=0.022
Epoch 263: at batch 1: Loss=1.152, Time=0.025
Epoch 264: at batch 1: Loss=1.196, Time=0.025
Epoch 265: at batch 1: Loss=1.077, Time=0.026
Epoch 266: at batch 1: Loss=1.174, Time=0.022
Epoch 267: at batch 1: Loss=1.448, Time=0.024
Epoch 268: at batch 1: Loss=1.266, Time=0.025
Epoch 269: at batch 1: Loss=1.129, Time=0.023
Epoch 270: at batch 1: Loss=1.196, Time=0.021
Epoch 271: at batch 1: Loss=1.074, Time=0.021
Epoch 271: Time=17.291, Epoch time = 0.021, Avg epoch time=0.000

[[1.27550006]
 [1.06547523]
 [1.06547523]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 272: at batch 1: Loss=1.036, Time=0.026
Epoch 273: at batch 1: Loss=1.066, Time=0.028
Epoch 274: at batch 1: Loss=0.992, Time=0.023
Epoch 275: at batch 1: Loss=1.149, Time=0.033
Epoch 276: at batch 1: Loss=1.118, Time=0.023
Epoch 277: at batch 1: Loss=0.964, Time=0.024
Epoch 278: at batch 1: Loss=0.972, Time=0.023
Epoch 279: at batch 1: Loss=1.238, Time=0.035
Epoch 280: at batch 1: Loss=1.176, Time=0.022
Epoch 281: at batch 1: Loss=1.549, Time=0.024
Epoch 281: Time=17.844, Epoch time = 0.024, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 282: at batch 1: Loss=1.285, Time=0.029
Epoch 283: at batch 1: Loss=1.179, Time=0.022
Epoch 284: at batch 1: Loss=1.159, Time=0.024
Epoch 285: at batch 1: Loss=1.079, Time=0.024
Epoch 286: at batch 1: Loss=1.159, Time=0.032
Epoch 287: at batch 1: Loss=1.088, Time=0.022
Epoch 288: at batch 1: Loss=1.060, Time=0.026
Epoch 289: at batch 1: Loss=1.096, Time=0.022
Epoch 290: at batch 1: Loss=1.222, Time=0.026
Epoch 291: at batch 1: Loss=1.163, Time=0.025
Epoch 291: Time=18.378, Epoch time = 0.025, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 292: at batch 1: Loss=1.097, Time=0.024
Epoch 293: at batch 1: Loss=1.092, Time=0.024
Epoch 294: at batch 1: Loss=1.091, Time=0.024
Epoch 295: at batch 1: Loss=1.042, Time=0.023
Epoch 296: at batch 1: Loss=1.142, Time=0.030
Epoch 297: at batch 1: Loss=1.139, Time=0.026
Epoch 298: at batch 1: Loss=1.091, Time=0.022
Epoch 299: at batch 1: Loss=1.064, Time=0.032
Epoch 300: at batch 1: Loss=1.103, Time=0.022
Epoch 301: at batch 1: Loss=1.118, Time=0.034
Epoch 301: Time=18.922, Epoch time = 0.034, Avg epoch time=0.000

[[1.14251137]
 [1.14251137]
 [1.12079728]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 302: at batch 1: Loss=1.166, Time=0.026
Epoch 303: at batch 1: Loss=1.149, Time=0.021
Epoch 304: at batch 1: Loss=1.114, Time=0.022
Epoch 305: at batch 1: Loss=1.114, Time=0.026
Epoch 306: at batch 1: Loss=1.113, Time=0.024
Epoch 307: at batch 1: Loss=1.164, Time=0.022
Epoch 308: at batch 1: Loss=1.097, Time=0.021
Epoch 309: at batch 1: Loss=1.087, Time=0.029
Epoch 310: at batch 1: Loss=1.091, Time=0.024
Epoch 311: at batch 1: Loss=1.137, Time=0.023
Epoch 311: Time=19.446, Epoch time = 0.023, Avg epoch time=0.000

[[1.09484291]
 [1.09861231]
 [1.17033648]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 312: at batch 1: Loss=1.120, Time=0.023
Epoch 313: at batch 1: Loss=1.104, Time=0.025
Epoch 314: at batch 1: Loss=1.101, Time=0.024
Epoch 315: at batch 1: Loss=1.081, Time=0.022
Epoch 316: at batch 1: Loss=1.146, Time=0.023
Epoch 317: at batch 1: Loss=1.088, Time=0.026
Epoch 318: at batch 1: Loss=1.258, Time=0.022
Epoch 319: at batch 1: Loss=1.669, Time=0.023
Epoch 320: at batch 1: Loss=1.261, Time=0.024
Epoch 321: at batch 1: Loss=1.141, Time=0.022
Epoch 321: Time=19.964, Epoch time = 0.022, Avg epoch time=0.000

[[1.10840082]
 [1.10840082]
 [1.10840082]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 322: at batch 1: Loss=1.095, Time=0.026
Epoch 323: at batch 1: Loss=1.080, Time=0.026
Epoch 324: at batch 1: Loss=1.210, Time=0.023
Epoch 325: at batch 1: Loss=1.115, Time=0.026
Epoch 326: at batch 1: Loss=1.128, Time=0.023
Epoch 327: at batch 1: Loss=1.120, Time=0.026
Epoch 328: at batch 1: Loss=1.131, Time=0.031
Epoch 329: at batch 1: Loss=1.117, Time=0.024
Epoch 330: at batch 1: Loss=1.133, Time=0.023
Epoch 331: at batch 1: Loss=1.079, Time=0.023
Epoch 331: Time=20.497, Epoch time = 0.023, Avg epoch time=0.000

[[1.04325056]
 [1.14644122]
 [1.04325056]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 332: at batch 1: Loss=1.106, Time=0.026
Epoch 333: at batch 1: Loss=1.102, Time=0.026
Epoch 334: at batch 1: Loss=1.096, Time=0.027
Epoch 335: at batch 1: Loss=1.099, Time=0.021
Epoch 336: at batch 1: Loss=1.099, Time=0.033
Epoch 337: at batch 1: Loss=1.101, Time=0.033
Epoch 338: at batch 1: Loss=1.092, Time=0.033
Epoch 339: at batch 1: Loss=1.097, Time=0.025
Epoch 340: at batch 1: Loss=1.092, Time=0.022
Epoch 341: at batch 1: Loss=1.094, Time=0.026
Epoch 341: Time=21.092, Epoch time = 0.026, Avg epoch time=0.000

[[1.09861231]
 [1.0887872 ]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 342: at batch 1: Loss=0.983, Time=0.021
Epoch 343: at batch 1: Loss=1.148, Time=0.024
Epoch 344: at batch 1: Loss=1.019, Time=0.023
Epoch 345: at batch 1: Loss=1.023, Time=0.021
Epoch 346: at batch 1: Loss=0.989, Time=0.027
Epoch 347: at batch 1: Loss=1.404, Time=0.026
Epoch 348: at batch 1: Loss=1.252, Time=0.027
Epoch 349: at batch 1: Loss=1.218, Time=0.026
Epoch 350: at batch 1: Loss=1.215, Time=0.023
Epoch 351: at batch 1: Loss=1.267, Time=0.023
Epoch 351: Time=21.623, Epoch time = 0.023, Avg epoch time=0.000

[[1.28857231]
 [1.12991893]
 [1.11560798]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 352: at batch 1: Loss=1.148, Time=0.022
Epoch 353: at batch 1: Loss=1.077, Time=0.025
Epoch 354: at batch 1: Loss=1.031, Time=0.024
Epoch 355: at batch 1: Loss=0.966, Time=0.022
Epoch 356: at batch 1: Loss=1.016, Time=0.024
Epoch 357: at batch 1: Loss=1.051, Time=0.026
Epoch 358: at batch 1: Loss=1.073, Time=0.022
Epoch 359: at batch 1: Loss=1.088, Time=0.021
Epoch 360: at batch 1: Loss=1.245, Time=0.022
Epoch 361: at batch 1: Loss=1.470, Time=0.024
Epoch 361: Time=22.140, Epoch time = 0.024, Avg epoch time=0.000

[[1.59479809]
 [1.09738708]
 [1.09738708]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 362: at batch 1: Loss=1.186, Time=0.021
Epoch 363: at batch 1: Loss=1.129, Time=0.026
Epoch 364: at batch 1: Loss=1.026, Time=0.026
Epoch 365: at batch 1: Loss=1.088, Time=0.025
Epoch 366: at batch 1: Loss=1.067, Time=0.026
Epoch 367: at batch 1: Loss=1.086, Time=0.032
Epoch 368: at batch 1: Loss=1.135, Time=0.021
Epoch 369: at batch 1: Loss=1.055, Time=0.023
Epoch 370: at batch 1: Loss=1.119, Time=0.024
Epoch 371: at batch 1: Loss=1.081, Time=0.033
Epoch 371: Time=22.679, Epoch time = 0.033, Avg epoch time=0.000

[[1.0382247]
 [1.0382247]
 [1.0382247]
 ...
 [0.       ]
 [0.       ]
 [0.       ]]
Epoch 372: at batch 1: Loss=1.083, Time=0.025
Epoch 373: at batch 1: Loss=1.098, Time=0.023
Epoch 374: at batch 1: Loss=1.113, Time=0.033
Epoch 375: at batch 1: Loss=1.357, Time=0.026
Epoch 376: at batch 1: Loss=1.151, Time=0.035
Epoch 377: at batch 1: Loss=1.124, Time=0.026
Epoch 378: at batch 1: Loss=1.090, Time=0.023
Epoch 379: at batch 1: Loss=1.439, Time=0.023
Epoch 380: at batch 1: Loss=1.253, Time=0.026
Epoch 381: at batch 1: Loss=1.102, Time=0.022
Epoch 381: Time=23.223, Epoch time = 0.022, Avg epoch time=0.000

[[1.10694146]
 [1.10694146]
 [1.10694146]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 382: at batch 1: Loss=1.183, Time=0.024
Epoch 383: at batch 1: Loss=1.131, Time=0.025
Epoch 384: at batch 1: Loss=1.251, Time=0.023
Epoch 385: at batch 1: Loss=1.206, Time=0.023
Epoch 386: at batch 1: Loss=1.251, Time=0.023
Epoch 387: at batch 1: Loss=1.094, Time=0.022
Epoch 388: at batch 1: Loss=1.190, Time=0.023
Epoch 389: at batch 1: Loss=1.182, Time=0.022
Epoch 390: at batch 1: Loss=1.126, Time=0.026
Epoch 391: at batch 1: Loss=1.111, Time=0.023
Epoch 391: Time=23.740, Epoch time = 0.024, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 392: at batch 1: Loss=1.107, Time=0.024
Epoch 393: at batch 1: Loss=1.057, Time=0.026
Epoch 394: at batch 1: Loss=1.087, Time=0.026
Epoch 395: at batch 1: Loss=1.095, Time=0.024
Epoch 396: at batch 1: Loss=1.094, Time=0.023
Epoch 397: at batch 1: Loss=1.158, Time=0.021
Epoch 398: at batch 1: Loss=1.134, Time=0.023
Epoch 399: at batch 1: Loss=1.182, Time=0.023
Epoch 400: at batch 1: Loss=1.122, Time=0.023
Epoch 401: at batch 1: Loss=1.116, Time=0.026
Epoch 401: Time=24.272, Epoch time = 0.026, Avg epoch time=0.000

[[1.09861231]
 [1.2176559 ]
 [1.2176559 ]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 402: at batch 1: Loss=1.146, Time=0.023
Epoch 403: at batch 1: Loss=1.096, Time=0.024
Epoch 404: at batch 1: Loss=1.078, Time=0.025
Epoch 405: at batch 1: Loss=1.537, Time=0.024
Epoch 406: at batch 1: Loss=1.207, Time=0.024
Epoch 407: at batch 1: Loss=1.234, Time=0.032
Epoch 408: at batch 1: Loss=1.053, Time=0.033
Epoch 409: at batch 1: Loss=1.059, Time=0.027
Epoch 410: at batch 1: Loss=1.181, Time=0.033
Epoch 411: at batch 1: Loss=1.218, Time=0.024
Epoch 411: Time=24.823, Epoch time = 0.024, Avg epoch time=0.000

[[1.11914492]
 [1.24542916]
 [1.27112579]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 412: at batch 1: Loss=1.139, Time=0.020
Epoch 413: at batch 1: Loss=1.138, Time=0.035
Epoch 414: at batch 1: Loss=1.121, Time=0.031
Epoch 415: at batch 1: Loss=1.100, Time=0.023
Epoch 416: at batch 1: Loss=1.087, Time=0.031
Epoch 417: at batch 1: Loss=1.094, Time=0.034
Epoch 418: at batch 1: Loss=1.096, Time=0.021
Epoch 419: at batch 1: Loss=1.556, Time=0.021
Epoch 420: at batch 1: Loss=1.693, Time=0.026
Epoch 421: at batch 1: Loss=1.448, Time=0.026
Epoch 421: Time=25.373, Epoch time = 0.026, Avg epoch time=0.000

[[1.81699526]
 [1.75351632]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 422: at batch 1: Loss=1.104, Time=0.023
Epoch 423: at batch 1: Loss=1.252, Time=0.023
Epoch 424: at batch 1: Loss=1.201, Time=0.026
Epoch 425: at batch 1: Loss=1.049, Time=0.024
Epoch 426: at batch 1: Loss=1.117, Time=0.026
Epoch 427: at batch 1: Loss=1.281, Time=0.024
Epoch 428: at batch 1: Loss=1.186, Time=0.024
Epoch 429: at batch 1: Loss=1.215, Time=0.021
Epoch 430: at batch 1: Loss=1.054, Time=0.027
Epoch 431: at batch 1: Loss=1.061, Time=0.020
Epoch 431: Time=25.893, Epoch time = 0.021, Avg epoch time=0.000

[[0.93327188]
 [0.93327188]
 [1.23227477]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 432: at batch 1: Loss=1.240, Time=0.023
Epoch 433: at batch 1: Loss=1.156, Time=0.022
Epoch 434: at batch 1: Loss=1.199, Time=0.022
Epoch 435: at batch 1: Loss=1.138, Time=0.024
Epoch 436: at batch 1: Loss=1.105, Time=0.024
Epoch 437: at batch 1: Loss=1.075, Time=0.024
Epoch 438: at batch 1: Loss=1.094, Time=0.024
Epoch 439: at batch 1: Loss=1.050, Time=0.023
Epoch 440: at batch 1: Loss=1.162, Time=0.021
Epoch 441: at batch 1: Loss=1.082, Time=0.022
Epoch 441: Time=26.405, Epoch time = 0.023, Avg epoch time=0.000

[[1.05062962]
 [1.05062962]
 [1.05062962]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 442: at batch 1: Loss=1.161, Time=0.024
Epoch 443: at batch 1: Loss=1.134, Time=0.021
Epoch 444: at batch 1: Loss=1.122, Time=0.022
Epoch 445: at batch 1: Loss=1.106, Time=0.028
Epoch 446: at batch 1: Loss=1.106, Time=0.021
Epoch 447: at batch 1: Loss=1.141, Time=0.035
Epoch 448: at batch 1: Loss=1.129, Time=0.026
Epoch 449: at batch 1: Loss=1.170, Time=0.026
Epoch 450: at batch 1: Loss=1.163, Time=0.026
Epoch 451: at batch 1: Loss=1.113, Time=0.024
Epoch 451: Time=26.941, Epoch time = 0.024, Avg epoch time=0.000

[[1.06669629]
 [1.15483952]
 [1.15483952]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 452: at batch 1: Loss=1.272, Time=0.024
Epoch 453: at batch 1: Loss=1.139, Time=0.024
Epoch 454: at batch 1: Loss=1.098, Time=0.021
Epoch 455: at batch 1: Loss=1.086, Time=0.024
Epoch 456: at batch 1: Loss=1.091, Time=0.024
Epoch 457: at batch 1: Loss=1.140, Time=0.021
Epoch 458: at batch 1: Loss=1.121, Time=0.024
Epoch 459: at batch 1: Loss=1.186, Time=0.026
Epoch 460: at batch 1: Loss=1.126, Time=0.025
Epoch 461: at batch 1: Loss=1.103, Time=0.023
Epoch 461: Time=27.457, Epoch time = 0.023, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 462: at batch 1: Loss=1.034, Time=0.021
Epoch 463: at batch 1: Loss=1.067, Time=0.027
Epoch 464: at batch 1: Loss=1.089, Time=0.035
Epoch 465: at batch 1: Loss=1.101, Time=0.022
Epoch 466: at batch 1: Loss=0.998, Time=0.023
Epoch 467: at batch 1: Loss=0.954, Time=0.024
Epoch 468: at batch 1: Loss=1.071, Time=0.026
Epoch 469: at batch 1: Loss=1.153, Time=0.021
Epoch 470: at batch 1: Loss=1.100, Time=0.027
Epoch 471: at batch 1: Loss=1.103, Time=0.034
Epoch 471: Time=28.000, Epoch time = 0.034, Avg epoch time=0.000

[[1.09301972]
 [1.08996868]
 [1.08996868]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 472: at batch 1: Loss=1.088, Time=0.026
Epoch 473: at batch 1: Loss=1.097, Time=0.024
Epoch 474: at batch 1: Loss=1.099, Time=0.023
Epoch 475: at batch 1: Loss=1.014, Time=0.021
Epoch 476: at batch 1: Loss=1.063, Time=0.022
Epoch 477: at batch 1: Loss=1.077, Time=0.024
Epoch 478: at batch 1: Loss=1.048, Time=0.026
Epoch 479: at batch 1: Loss=1.067, Time=0.023
Epoch 480: at batch 1: Loss=1.042, Time=0.024
Epoch 481: at batch 1: Loss=1.080, Time=0.025
Epoch 481: Time=28.525, Epoch time = 0.025, Avg epoch time=0.000

[[1.10210752]
 [1.10210752]
 [1.10210752]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 482: at batch 1: Loss=1.154, Time=0.027
Epoch 483: at batch 1: Loss=1.081, Time=0.023
Epoch 484: at batch 1: Loss=1.046, Time=0.021
Epoch 485: at batch 1: Loss=1.159, Time=0.024
Epoch 486: at batch 1: Loss=1.119, Time=0.024
Epoch 487: at batch 1: Loss=1.120, Time=0.023
Epoch 488: at batch 1: Loss=1.050, Time=0.024
Epoch 489: at batch 1: Loss=1.005, Time=0.027
Epoch 490: at batch 1: Loss=1.115, Time=0.025
Epoch 491: at batch 1: Loss=1.140, Time=0.024
Epoch 491: Time=29.054, Epoch time = 0.024, Avg epoch time=0.000

[[1.17340612]
 [1.17340612]
 [1.11033499]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 492: at batch 1: Loss=1.201, Time=0.025
Epoch 493: at batch 1: Loss=1.182, Time=0.025
Epoch 494: at batch 1: Loss=1.110, Time=0.021
Epoch 495: at batch 1: Loss=1.034, Time=0.024
Epoch 496: at batch 1: Loss=1.070, Time=0.027
Epoch 497: at batch 1: Loss=1.067, Time=0.033
Epoch 498: at batch 1: Loss=1.185, Time=0.027
Epoch 499: at batch 1: Loss=1.229, Time=0.023
Epoch 500: at batch 1: Loss=1.138, Time=0.024
Epoch 501: at batch 1: Loss=1.328, Time=0.024
Epoch 501: Time=29.604, Epoch time = 0.024, Avg epoch time=0.000

[[1.45539284]
 [1.0694952 ]
 [1.45539284]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 502: at batch 1: Loss=1.194, Time=0.023
Epoch 503: at batch 1: Loss=1.101, Time=0.032
Epoch 504: at batch 1: Loss=1.128, Time=0.024
Epoch 505: at batch 1: Loss=1.100, Time=0.027
Epoch 506: at batch 1: Loss=1.123, Time=0.021
Epoch 507: at batch 1: Loss=1.082, Time=0.027
Epoch 508: at batch 1: Loss=1.125, Time=0.027
Epoch 509: at batch 1: Loss=1.136, Time=0.024
Epoch 510: at batch 1: Loss=1.105, Time=0.024
Epoch 511: at batch 1: Loss=1.107, Time=0.025
Epoch 511: Time=30.141, Epoch time = 0.025, Avg epoch time=0.000

[[1.10198665]
 [1.10198665]
 [1.04265738]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 512: at batch 1: Loss=1.188, Time=0.023
Epoch 513: at batch 1: Loss=1.148, Time=0.027
Epoch 514: at batch 1: Loss=1.085, Time=0.027
Epoch 515: at batch 1: Loss=1.091, Time=0.033
Epoch 516: at batch 1: Loss=1.108, Time=0.025
Epoch 517: at batch 1: Loss=1.163, Time=0.024
Epoch 518: at batch 1: Loss=1.103, Time=0.024
Epoch 519: at batch 1: Loss=1.122, Time=0.036
Epoch 520: at batch 1: Loss=1.061, Time=0.024
Epoch 521: at batch 1: Loss=1.033, Time=0.024
Epoch 521: Time=30.690, Epoch time = 0.024, Avg epoch time=0.000

[[1.05804467]
 [1.0003773 ]
 [1.0003773 ]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 522: at batch 1: Loss=1.053, Time=0.023
Epoch 523: at batch 1: Loss=1.084, Time=0.025
Epoch 524: at batch 1: Loss=1.127, Time=0.024
Epoch 525: at batch 1: Loss=1.232, Time=0.023
Epoch 526: at batch 1: Loss=1.187, Time=0.032
Epoch 527: at batch 1: Loss=1.203, Time=0.024
Epoch 528: at batch 1: Loss=1.122, Time=0.024
Epoch 529: at batch 1: Loss=1.109, Time=0.024
Epoch 530: at batch 1: Loss=1.089, Time=0.032
Epoch 531: at batch 1: Loss=1.067, Time=0.024
Epoch 531: Time=31.233, Epoch time = 0.025, Avg epoch time=0.000

[[1.06106365]
 [1.08336926]
 [1.05441988]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 532: at batch 1: Loss=1.079, Time=0.024
Epoch 533: at batch 1: Loss=1.090, Time=0.021
Epoch 534: at batch 1: Loss=1.070, Time=0.026
Epoch 535: at batch 1: Loss=1.339, Time=0.027
Epoch 536: at batch 1: Loss=1.107, Time=0.023
Epoch 537: at batch 1: Loss=1.164, Time=0.024
Epoch 538: at batch 1: Loss=1.259, Time=0.022
Epoch 539: at batch 1: Loss=1.197, Time=0.023
Epoch 540: at batch 1: Loss=1.187, Time=0.024
Epoch 541: at batch 1: Loss=1.098, Time=0.027
Epoch 541: Time=31.755, Epoch time = 0.027, Avg epoch time=0.000

[[1.15397656]
 [1.07234049]
 [1.15397656]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 542: at batch 1: Loss=1.093, Time=0.023
Epoch 543: at batch 1: Loss=1.087, Time=0.025
Epoch 544: at batch 1: Loss=1.322, Time=0.021
Epoch 545: at batch 1: Loss=1.203, Time=0.026
Epoch 546: at batch 1: Loss=1.103, Time=0.022
Epoch 547: at batch 1: Loss=1.066, Time=0.027
Epoch 548: at batch 1: Loss=1.088, Time=0.031
Epoch 549: at batch 1: Loss=1.132, Time=0.021
Epoch 550: at batch 1: Loss=1.146, Time=0.027
Epoch 551: at batch 1: Loss=1.124, Time=0.021
Epoch 551: Time=32.280, Epoch time = 0.021, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.15477681]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 552: at batch 1: Loss=1.285, Time=0.024
Epoch 553: at batch 1: Loss=1.225, Time=0.033
Epoch 554: at batch 1: Loss=1.256, Time=0.026
Epoch 555: at batch 1: Loss=1.214, Time=0.024
Epoch 556: at batch 1: Loss=1.150, Time=0.023
Epoch 557: at batch 1: Loss=1.209, Time=0.028
Epoch 558: at batch 1: Loss=1.378, Time=0.021
Epoch 559: at batch 1: Loss=1.227, Time=0.028
Epoch 560: at batch 1: Loss=1.143, Time=0.024
Epoch 561: at batch 1: Loss=1.309, Time=0.022
Epoch 561: Time=32.816, Epoch time = 0.022, Avg epoch time=0.000

[[1.09861231]
 [1.4336071 ]
 [1.24658179]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 562: at batch 1: Loss=1.234, Time=0.034
Epoch 563: at batch 1: Loss=1.139, Time=0.026
Epoch 564: at batch 1: Loss=1.124, Time=0.024
Epoch 565: at batch 1: Loss=1.079, Time=0.024
Epoch 566: at batch 1: Loss=1.065, Time=0.024
Epoch 567: at batch 1: Loss=1.074, Time=0.024
Epoch 568: at batch 1: Loss=1.090, Time=0.022
Epoch 569: at batch 1: Loss=1.236, Time=0.025
Epoch 570: at batch 1: Loss=1.164, Time=0.028
Epoch 571: at batch 1: Loss=1.136, Time=0.024
Epoch 571: Time=33.354, Epoch time = 0.024, Avg epoch time=0.000

[[1.10141802]
 [1.35400569]
 [1.0953331 ]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 572: at batch 1: Loss=1.180, Time=0.025
Epoch 573: at batch 1: Loss=1.178, Time=0.023
Epoch 574: at batch 1: Loss=1.096, Time=0.025
Epoch 575: at batch 1: Loss=1.105, Time=0.023
Epoch 576: at batch 1: Loss=1.345, Time=0.025
Epoch 577: at batch 1: Loss=1.211, Time=0.026
Epoch 578: at batch 1: Loss=1.107, Time=0.026
Epoch 579: at batch 1: Loss=1.071, Time=0.024
Epoch 580: at batch 1: Loss=1.017, Time=0.027
Epoch 581: at batch 1: Loss=1.070, Time=0.024
Epoch 581: Time=33.892, Epoch time = 0.024, Avg epoch time=0.000

[[1.10865092]
 [1.10865092]
 [1.10865092]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 582: at batch 1: Loss=1.059, Time=0.024
Epoch 583: at batch 1: Loss=1.079, Time=0.023
Epoch 584: at batch 1: Loss=1.038, Time=0.020
Epoch 585: at batch 1: Loss=1.071, Time=0.021
Epoch 586: at batch 1: Loss=1.076, Time=0.023
Epoch 587: at batch 1: Loss=1.089, Time=0.025
Epoch 588: at batch 1: Loss=1.089, Time=0.024
Epoch 589: at batch 1: Loss=1.105, Time=0.024
Epoch 590: at batch 1: Loss=1.101, Time=0.035
Epoch 591: at batch 1: Loss=1.064, Time=0.024
Epoch 591: Time=34.423, Epoch time = 0.024, Avg epoch time=0.000

[[1.10865092]
 [1.02728415]
 [1.02728415]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 592: at batch 1: Loss=1.067, Time=0.035
Epoch 593: at batch 1: Loss=1.085, Time=0.023
Epoch 594: at batch 1: Loss=1.070, Time=0.027
Epoch 595: at batch 1: Loss=1.087, Time=0.025
Epoch 596: at batch 1: Loss=1.000, Time=0.024
Epoch 597: at batch 1: Loss=1.042, Time=0.023
Epoch 598: at batch 1: Loss=1.080, Time=0.034
Epoch 599: at batch 1: Loss=1.090, Time=0.025
Epoch 600: at batch 1: Loss=1.005, Time=0.026
Epoch 601: at batch 1: Loss=1.033, Time=0.021
Epoch 601: Time=34.970, Epoch time = 0.021, Avg epoch time=0.000

[[1.05618322]
 [1.05618322]
 [0.93669236]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 602: at batch 1: Loss=1.063, Time=0.025
Epoch 603: at batch 1: Loss=1.085, Time=0.025
Epoch 604: at batch 1: Loss=1.135, Time=0.025
Epoch 605: at batch 1: Loss=1.156, Time=0.023
Epoch 606: at batch 1: Loss=1.063, Time=0.022
Epoch 607: at batch 1: Loss=1.117, Time=0.026
Epoch 608: at batch 1: Loss=1.204, Time=0.022
Epoch 609: at batch 1: Loss=1.156, Time=0.024
Epoch 610: at batch 1: Loss=1.144, Time=0.022
Epoch 611: at batch 1: Loss=1.117, Time=0.034
Epoch 611: Time=35.502, Epoch time = 0.034, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 612: at batch 1: Loss=1.150, Time=0.025
Epoch 613: at batch 1: Loss=1.170, Time=0.022
Epoch 614: at batch 1: Loss=1.127, Time=0.033
Epoch 615: at batch 1: Loss=1.117, Time=0.022
Epoch 616: at batch 1: Loss=1.087, Time=0.025
Epoch 617: at batch 1: Loss=1.096, Time=0.024
Epoch 618: at batch 1: Loss=1.095, Time=0.021
Epoch 619: at batch 1: Loss=1.099, Time=0.022
Epoch 620: at batch 1: Loss=1.036, Time=0.027
Epoch 621: at batch 1: Loss=1.203, Time=0.021
Epoch 621: Time=36.030, Epoch time = 0.021, Avg epoch time=0.000

[[1.34312832]
 [0.9737733 ]
 [0.9737733 ]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 622: at batch 1: Loss=1.235, Time=0.022
Epoch 623: at batch 1: Loss=1.187, Time=0.028
Epoch 624: at batch 1: Loss=1.368, Time=0.033
Epoch 625: at batch 1: Loss=1.204, Time=0.024
Epoch 626: at batch 1: Loss=1.135, Time=0.025
Epoch 627: at batch 1: Loss=1.094, Time=0.031
Epoch 628: at batch 1: Loss=1.079, Time=0.026
Epoch 629: at batch 1: Loss=1.084, Time=0.025
Epoch 630: at batch 1: Loss=1.091, Time=0.027
Epoch 631: at batch 1: Loss=1.097, Time=0.023
Epoch 631: Time=36.578, Epoch time = 0.024, Avg epoch time=0.000

[[1.09861231]
 [1.08458984]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 632: at batch 1: Loss=1.097, Time=0.024
Epoch 633: at batch 1: Loss=1.111, Time=0.023
Epoch 634: at batch 1: Loss=1.154, Time=0.025
Epoch 635: at batch 1: Loss=0.994, Time=0.022
^CTraceback (most recent call last):
  File "simple_batched_numpy.py", line 362, in <module>
    saver.save(sess, checkpoint_dir + 'model.ckpt')
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/training/saver.py", line 1458, in save
    meta_graph_filename, strip_default_attrs=strip_default_attrs)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/training/saver.py", line 1503, in export_meta_graph
    strip_default_attrs=strip_default_attrs)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/training/saver.py", line 1792, in export_meta_graph
    **kwargs)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/framework/meta_graph.py", line 1007, in export_scoped_meta_graph
    as_text=as_text)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/framework/graph_io.py", line 73, in write_graph
    file_io.atomic_write_string_to_file(path, graph_def.SerializeToString())
KeyboardInterrupt
(sid2) [ir967@gr020 Learning-to-See-in-the-Dark]$ mkdir gt_Sony_simple_ReLU_BN_batched_new
(sid2) [ir967@gr020 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy.py 
(sid2) [ir967@gr020 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py 




Found 161 images to train with

Training on 20 images only

2020-12-11 17:14:00.391112: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 17:14:00.529081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:86:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 17:14:00.529116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 17:14:00.814567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 17:14:00.814607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 17:14:00.814635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 17:14:00.814743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5)
No checkpoint found at ./gt_Sony_simple_ReLU_BN_batched_new/. Hence, will create

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.87565, 0.00000, 300.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01633, 250.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 100.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00190, 250.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.02465, 100.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00427, 250.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00886, 300.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00248, 100.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00016, 300.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00613, 100.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00012, 300.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 300.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00144, 300.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00301, 300.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00002, 300.00000, 6735543
20 images loaded to CPU RAM in Time=5.838 seconds.

moved images data to numpy array
Starting Training on index [ 1  1  0 18  2 14 16  3 14 10 17  3 18  8 18 19], dataset index: [148 148  18 123  29 119  99 132 119  38  70 132 123  81 123 202]
Starting Training on gammas [300 300 250 300 250 300 300 250 300 300 100 250 300 250 300 300]
Epoch 0: at batch 1: Loss=1.394, Time=1.074
Epoch 1: at batch 1: Loss=1.186, Time=0.024
Epoch 1: Time=1.144, Epoch time = 0.024, Avg epoch time=0.000

[[1.11725509]
 [1.3935647 ]
 [1.11725509]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 2: at batch 1: Loss=1.028, Time=0.023
Epoch 3: at batch 1: Loss=1.032, Time=0.023
Epoch 4: at batch 1: Loss=1.069, Time=0.023
Epoch 5: at batch 1: Loss=1.074, Time=0.024
Epoch 6: at batch 1: Loss=1.086, Time=0.026
Epoch 7: at batch 1: Loss=1.085, Time=0.022
Epoch 8: at batch 1: Loss=0.962, Time=0.033
Epoch 9: at batch 1: Loss=1.234, Time=0.031
Epoch 10: at batch 1: Loss=1.183, Time=0.023
Epoch 11: at batch 1: Loss=1.131, Time=0.035
Epoch 11: Time=1.686, Epoch time = 0.035, Avg epoch time=0.000

[[1.46849513]
 [1.0835793 ]
 [1.0835793 ]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 12: at batch 1: Loss=1.094, Time=0.026
Epoch 13: at batch 1: Loss=1.188, Time=0.024
Epoch 14: at batch 1: Loss=1.267, Time=0.024
Epoch 15: at batch 1: Loss=1.182, Time=0.033
Epoch 16: at batch 1: Loss=1.342, Time=0.022
Epoch 17: at batch 1: Loss=1.292, Time=0.035
Epoch 18: at batch 1: Loss=1.135, Time=0.022
Epoch 19: at batch 1: Loss=1.055, Time=0.023
Epoch 20: at batch 1: Loss=1.024, Time=0.022
Epoch 21: at batch 1: Loss=1.290, Time=0.024
Epoch 21: Time=2.214, Epoch time = 0.024, Avg epoch time=0.000

[[0.98388207]
 [1.60132194]
 [1.60132194]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 22: at batch 1: Loss=1.387, Time=0.034
Epoch 23: at batch 1: Loss=1.512, Time=0.024
Epoch 24: at batch 1: Loss=1.256, Time=0.024
Epoch 25: at batch 1: Loss=1.386, Time=0.034
Epoch 26: at batch 1: Loss=1.489, Time=0.024
Epoch 27: at batch 1: Loss=1.309, Time=0.022
Epoch 28: at batch 1: Loss=1.265, Time=0.031
Epoch 29: at batch 1: Loss=1.122, Time=0.022
Epoch 30: at batch 1: Loss=1.613, Time=0.024
Epoch 31: at batch 1: Loss=1.158, Time=0.031
Epoch 31: Time=2.764, Epoch time = 0.031, Avg epoch time=0.000

[[1.92900467]
 [1.92900467]
 [0.84630454]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 32: at batch 1: Loss=0.960, Time=0.025
Epoch 33: at batch 1: Loss=1.115, Time=0.023
Epoch 34: at batch 1: Loss=1.207, Time=0.024
Epoch 35: at batch 1: Loss=1.219, Time=0.033
Epoch 36: at batch 1: Loss=1.083, Time=0.024
Epoch 37: at batch 1: Loss=1.234, Time=0.022
Epoch 38: at batch 1: Loss=1.176, Time=0.026
Epoch 39: at batch 1: Loss=1.049, Time=0.024
Epoch 40: at batch 1: Loss=1.190, Time=0.026
Epoch 41: at batch 1: Loss=1.106, Time=0.024
Epoch 41: Time=3.307, Epoch time = 0.024, Avg epoch time=0.000

[[0.98228073]
 [1.04241657]
 [1.04241657]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 42: at batch 1: Loss=1.068, Time=0.025
Epoch 43: at batch 1: Loss=1.191, Time=0.024
Epoch 44: at batch 1: Loss=1.127, Time=0.026
Epoch 45: at batch 1: Loss=1.090, Time=0.023
Epoch 46: at batch 1: Loss=1.089, Time=0.025
Epoch 47: at batch 1: Loss=1.120, Time=0.022
Epoch 48: at batch 1: Loss=1.098, Time=0.028
Epoch 49: at batch 1: Loss=1.083, Time=0.024
Epoch 50: at batch 1: Loss=1.052, Time=0.024
Epoch 51: at batch 1: Loss=1.048, Time=0.026
Epoch 51: Time=3.838, Epoch time = 0.026, Avg epoch time=0.000

[[1.07854366]
 [1.03507948]
 [1.06296754]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 52: at batch 1: Loss=1.331, Time=0.033
Epoch 53: at batch 1: Loss=1.610, Time=0.023
Epoch 54: at batch 1: Loss=1.316, Time=0.026
Epoch 55: at batch 1: Loss=1.240, Time=0.026
Epoch 56: at batch 1: Loss=1.079, Time=0.024
Epoch 57: at batch 1: Loss=0.998, Time=0.023
Epoch 58: at batch 1: Loss=1.026, Time=0.028
Epoch 59: at batch 1: Loss=1.083, Time=0.023
Epoch 60: at batch 1: Loss=1.127, Time=0.025
Epoch 61: at batch 1: Loss=1.026, Time=0.026
Epoch 61: Time=4.375, Epoch time = 0.026, Avg epoch time=0.000

[[0.92831373]
 [0.92831373]
 [1.15557051]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 62: at batch 1: Loss=1.082, Time=0.023
Epoch 63: at batch 1: Loss=1.063, Time=0.024
Epoch 64: at batch 1: Loss=1.125, Time=0.022
Epoch 65: at batch 1: Loss=1.300, Time=0.026
Epoch 66: at batch 1: Loss=1.050, Time=0.026
Epoch 67: at batch 1: Loss=0.926, Time=0.024
Epoch 68: at batch 1: Loss=1.010, Time=0.026
Epoch 69: at batch 1: Loss=1.062, Time=0.025
Epoch 70: at batch 1: Loss=1.051, Time=0.021
Epoch 71: at batch 1: Loss=1.044, Time=0.024
Epoch 71: Time=4.896, Epoch time = 0.024, Avg epoch time=0.000

[[1.01464963]
 [1.07937956]
 [1.1053741 ]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 72: at batch 1: Loss=1.434, Time=0.024
Epoch 73: at batch 1: Loss=1.404, Time=0.024
Epoch 74: at batch 1: Loss=1.139, Time=0.025
Epoch 75: at batch 1: Loss=1.414, Time=0.024
Epoch 76: at batch 1: Loss=1.416, Time=0.023
Epoch 77: at batch 1: Loss=1.242, Time=0.022
Epoch 78: at batch 1: Loss=1.147, Time=0.022
Epoch 79: at batch 1: Loss=1.196, Time=0.027
Epoch 80: at batch 1: Loss=1.112, Time=0.024
Epoch 81: at batch 1: Loss=1.194, Time=0.024
Epoch 81: Time=5.415, Epoch time = 0.024, Avg epoch time=0.000

[[1.24473691]
 [1.24473691]
 [1.20501566]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 82: at batch 1: Loss=1.293, Time=0.030
Epoch 83: at batch 1: Loss=1.593, Time=0.033
Epoch 84: at batch 1: Loss=1.335, Time=0.025
Epoch 85: at batch 1: Loss=1.151, Time=0.026
Epoch 86: at batch 1: Loss=1.267, Time=0.024
Epoch 87: at batch 1: Loss=1.123, Time=0.025
Epoch 88: at batch 1: Loss=1.070, Time=0.021
Epoch 89: at batch 1: Loss=1.143, Time=0.024
Epoch 90: at batch 1: Loss=1.471, Time=0.022
Epoch 91: at batch 1: Loss=1.450, Time=0.021
Epoch 91: Time=5.947, Epoch time = 0.021, Avg epoch time=0.000

[[1.3509562]
 [1.3509562]
 [1.3509562]
 ...
 [0.       ]
 [0.       ]
 [0.       ]]
Epoch 92: at batch 1: Loss=1.311, Time=0.021
Epoch 93: at batch 1: Loss=1.289, Time=0.021
Epoch 94: at batch 1: Loss=1.014, Time=0.025
Epoch 95: at batch 1: Loss=1.089, Time=0.020
Epoch 96: at batch 1: Loss=1.130, Time=0.024
Epoch 97: at batch 1: Loss=1.289, Time=0.026
Epoch 98: at batch 1: Loss=1.297, Time=0.033
Epoch 99: at batch 1: Loss=1.203, Time=0.023
Epoch 100: at batch 1: Loss=1.116, Time=0.021
Epoch 101: at batch 1: Loss=1.151, Time=0.022
Epoch 101: Time=6.463, Epoch time = 0.022, Avg epoch time=0.000

[[1.09830308]
 [1.44833136]
 [1.17712736]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 102: at batch 1: Loss=1.199, Time=0.025
Epoch 103: at batch 1: Loss=1.128, Time=0.023
Epoch 104: at batch 1: Loss=1.206, Time=0.021
Epoch 105: at batch 1: Loss=1.068, Time=0.032
Epoch 106: at batch 1: Loss=1.129, Time=0.023
Epoch 107: at batch 1: Loss=1.094, Time=0.026
Epoch 108: at batch 1: Loss=1.033, Time=0.032
Epoch 109: at batch 1: Loss=1.079, Time=0.024
Epoch 110: at batch 1: Loss=0.993, Time=0.021
Epoch 111: at batch 1: Loss=1.244, Time=0.021
Epoch 111: Time=6.995, Epoch time = 0.021, Avg epoch time=0.000

[[1.11713016]
 [0.95003259]
 [0.95003259]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 112: at batch 1: Loss=1.170, Time=0.019
Epoch 113: at batch 1: Loss=1.108, Time=0.033
Epoch 114: at batch 1: Loss=1.151, Time=0.022
Epoch 115: at batch 1: Loss=1.517, Time=0.021
Epoch 116: at batch 1: Loss=1.318, Time=0.026
Epoch 117: at batch 1: Loss=1.291, Time=0.031
Epoch 118: at batch 1: Loss=1.445, Time=0.026
Epoch 119: at batch 1: Loss=1.150, Time=0.025
Epoch 120: at batch 1: Loss=1.085, Time=0.023
Epoch 121: at batch 1: Loss=1.072, Time=0.025
Epoch 121: Time=7.527, Epoch time = 0.025, Avg epoch time=0.000

[[1.07071912]
 [1.07071912]
 [1.07071912]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 122: at batch 1: Loss=0.974, Time=0.024
Epoch 123: at batch 1: Loss=1.016, Time=0.026
Epoch 124: at batch 1: Loss=1.061, Time=0.026
Epoch 125: at batch 1: Loss=1.035, Time=0.023
Epoch 126: at batch 1: Loss=0.979, Time=0.024
Epoch 127: at batch 1: Loss=0.988, Time=0.022
Epoch 128: at batch 1: Loss=1.311, Time=0.024
Epoch 129: at batch 1: Loss=1.080, Time=0.023
Epoch 130: at batch 1: Loss=1.084, Time=0.024
Epoch 131: at batch 1: Loss=1.698, Time=0.026
Epoch 131: Time=8.051, Epoch time = 0.026, Avg epoch time=0.000

[[0.91638398]
 [1.04080176]
 [2.17252207]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 132: at batch 1: Loss=1.235, Time=0.022
Epoch 133: at batch 1: Loss=1.155, Time=0.022
Epoch 134: at batch 1: Loss=1.283, Time=0.021
Epoch 135: at batch 1: Loss=1.279, Time=0.024
Epoch 136: at batch 1: Loss=1.129, Time=0.035
Epoch 137: at batch 1: Loss=1.190, Time=0.023
Epoch 138: at batch 1: Loss=1.112, Time=0.020
Epoch 139: at batch 1: Loss=1.058, Time=0.023
Epoch 140: at batch 1: Loss=1.429, Time=0.026
Epoch 141: at batch 1: Loss=1.190, Time=0.023
Epoch 141: Time=8.570, Epoch time = 0.023, Avg epoch time=0.000

[[1.10021901]
 [1.10021901]
 [1.0592041 ]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 142: at batch 1: Loss=1.105, Time=0.021
Epoch 143: at batch 1: Loss=1.073, Time=0.022
Epoch 144: at batch 1: Loss=1.058, Time=0.023
Epoch 145: at batch 1: Loss=1.074, Time=0.026
Epoch 146: at batch 1: Loss=1.092, Time=0.025
Epoch 147: at batch 1: Loss=0.963, Time=0.026
Epoch 148: at batch 1: Loss=1.032, Time=0.021
Epoch 149: at batch 1: Loss=1.126, Time=0.034
Epoch 150: at batch 1: Loss=1.135, Time=0.025
Epoch 151: at batch 1: Loss=1.154, Time=0.025
Epoch 151: Time=9.102, Epoch time = 0.025, Avg epoch time=0.000

[[1.17812371]
 [1.06159925]
 [1.06159925]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 152: at batch 1: Loss=1.056, Time=0.024
Epoch 153: at batch 1: Loss=1.149, Time=0.026
Epoch 154: at batch 1: Loss=1.199, Time=0.023
Epoch 155: at batch 1: Loss=1.165, Time=0.025
Epoch 156: at batch 1: Loss=1.087, Time=0.023
Epoch 157: at batch 1: Loss=1.092, Time=0.021
Epoch 158: at batch 1: Loss=1.417, Time=0.032
Epoch 159: at batch 1: Loss=1.250, Time=0.023
Epoch 160: at batch 1: Loss=1.211, Time=0.034
Epoch 161: at batch 1: Loss=1.144, Time=0.022
Epoch 161: Time=9.634, Epoch time = 0.022, Avg epoch time=0.000

[[1.09151149]
 [1.09151149]
 [1.09151149]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 162: at batch 1: Loss=1.093, Time=0.024
Epoch 163: at batch 1: Loss=1.155, Time=0.021
Epoch 164: at batch 1: Loss=1.122, Time=0.024
Epoch 165: at batch 1: Loss=1.119, Time=0.024
Epoch 166: at batch 1: Loss=1.124, Time=0.023
Epoch 167: at batch 1: Loss=1.103, Time=0.033
Epoch 168: at batch 1: Loss=1.152, Time=0.025
Epoch 169: at batch 1: Loss=1.114, Time=0.026
Epoch 170: at batch 1: Loss=1.038, Time=0.021
Epoch 171: at batch 1: Loss=1.033, Time=0.030
Epoch 171: Time=10.165, Epoch time = 0.030, Avg epoch time=0.000

[[1.03267837]
 [1.03267837]
 [1.00289392]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 172: at batch 1: Loss=1.089, Time=0.026
Epoch 173: at batch 1: Loss=1.060, Time=0.031
Epoch 174: at batch 1: Loss=1.037, Time=0.024
Epoch 175: at batch 1: Loss=1.121, Time=0.025
Epoch 176: at batch 1: Loss=1.089, Time=0.035
Epoch 177: at batch 1: Loss=1.089, Time=0.026
Epoch 178: at batch 1: Loss=1.087, Time=0.030
Epoch 179: at batch 1: Loss=1.100, Time=0.034
Epoch 180: at batch 1: Loss=1.092, Time=0.026
Epoch 181: at batch 1: Loss=1.089, Time=0.025
Epoch 181: Time=10.727, Epoch time = 0.025, Avg epoch time=0.000

[[1.08681631]
 [1.0871104 ]
 [1.0871104 ]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 182: at batch 1: Loss=1.103, Time=0.037
Epoch 183: at batch 1: Loss=1.076, Time=0.025
Epoch 184: at batch 1: Loss=1.050, Time=0.032
Epoch 185: at batch 1: Loss=0.969, Time=0.025
Epoch 186: at batch 1: Loss=1.035, Time=0.025
Epoch 187: at batch 1: Loss=1.266, Time=0.032
Epoch 188: at batch 1: Loss=1.169, Time=0.022
Epoch 189: at batch 1: Loss=1.194, Time=0.021
Epoch 190: at batch 1: Loss=1.103, Time=0.025
Epoch 191: at batch 1: Loss=1.082, Time=0.024
Epoch 191: Time=11.287, Epoch time = 0.025, Avg epoch time=0.000

[[1.04769945]
 [1.04769945]
 [0.9912008 ]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 192: at batch 1: Loss=1.134, Time=0.033
Epoch 193: at batch 1: Loss=1.473, Time=0.023
Epoch 194: at batch 1: Loss=1.256, Time=0.021
Epoch 195: at batch 1: Loss=1.219, Time=0.023
Epoch 196: at batch 1: Loss=1.011, Time=0.025
Epoch 197: at batch 1: Loss=1.020, Time=0.025
Epoch 198: at batch 1: Loss=1.332, Time=0.021
Epoch 199: at batch 1: Loss=1.275, Time=0.023
Epoch 200: at batch 1: Loss=1.322, Time=0.022
Epoch 201: at batch 1: Loss=1.158, Time=0.024
Epoch 201: Time=11.807, Epoch time = 0.024, Avg epoch time=0.000

[[1.08032894]
 [1.08032894]
 [0.85698307]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 202: at batch 1: Loss=1.188, Time=0.023
Epoch 203: at batch 1: Loss=1.104, Time=0.024
Epoch 204: at batch 1: Loss=1.075, Time=0.023
Epoch 205: at batch 1: Loss=1.346, Time=0.024
Epoch 206: at batch 1: Loss=1.234, Time=0.023
Epoch 207: at batch 1: Loss=1.147, Time=0.024
Epoch 208: at batch 1: Loss=1.344, Time=0.023
Epoch 209: at batch 1: Loss=1.160, Time=0.025
Epoch 210: at batch 1: Loss=1.099, Time=0.025
Epoch 211: at batch 1: Loss=0.954, Time=0.024
Epoch 211: Time=12.330, Epoch time = 0.024, Avg epoch time=0.000

[[0.86497271]
 [0.86497271]
 [1.04330397]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 212: at batch 1: Loss=0.950, Time=0.023
Epoch 213: at batch 1: Loss=0.925, Time=0.025
Epoch 214: at batch 1: Loss=1.070, Time=0.023
Epoch 215: at batch 1: Loss=1.040, Time=0.022
Epoch 216: at batch 1: Loss=1.072, Time=0.033
Epoch 217: at batch 1: Loss=1.393, Time=0.026
Epoch 218: at batch 1: Loss=1.243, Time=0.021
Epoch 219: at batch 1: Loss=1.338, Time=0.032
Epoch 220: at batch 1: Loss=1.217, Time=0.024
Epoch 221: at batch 1: Loss=1.771, Time=0.022
Epoch 221: Time=12.861, Epoch time = 0.022, Avg epoch time=0.000

[[1.33619189]
 [1.08801687]
 [2.49803114]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 222: at batch 1: Loss=1.299, Time=0.025
Epoch 223: at batch 1: Loss=1.062, Time=0.026
Epoch 224: at batch 1: Loss=1.022, Time=0.022
Epoch 225: at batch 1: Loss=0.988, Time=0.023
Epoch 226: at batch 1: Loss=1.138, Time=0.026
Epoch 227: at batch 1: Loss=1.419, Time=0.025
Epoch 228: at batch 1: Loss=1.184, Time=0.021
Epoch 229: at batch 1: Loss=1.199, Time=0.023
Epoch 230: at batch 1: Loss=1.419, Time=0.021
Epoch 231: at batch 1: Loss=1.176, Time=0.025
Epoch 231: Time=13.378, Epoch time = 0.025, Avg epoch time=0.000

[[1.25856817]
 [0.97918212]
 [1.69916451]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 232: at batch 1: Loss=1.140, Time=0.024
Epoch 233: at batch 1: Loss=1.079, Time=0.030
Epoch 234: at batch 1: Loss=1.012, Time=0.020
Epoch 235: at batch 1: Loss=1.333, Time=0.021
Epoch 236: at batch 1: Loss=1.316, Time=0.025
Epoch 237: at batch 1: Loss=1.065, Time=0.025
Epoch 238: at batch 1: Loss=1.128, Time=0.034
Epoch 239: at batch 1: Loss=1.002, Time=0.027
Epoch 240: at batch 1: Loss=1.071, Time=0.025
Epoch 241: at batch 1: Loss=1.042, Time=0.023
Epoch 241: Time=13.914, Epoch time = 0.023, Avg epoch time=0.000

[[0.98979688]
 [0.98979688]
 [1.12690604]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 242: at batch 1: Loss=1.054, Time=0.025
Epoch 243: at batch 1: Loss=1.079, Time=0.022
Epoch 244: at batch 1: Loss=1.123, Time=0.026
Epoch 245: at batch 1: Loss=1.138, Time=0.023
Epoch 246: at batch 1: Loss=1.158, Time=0.021
Epoch 247: at batch 1: Loss=1.117, Time=0.026
Epoch 248: at batch 1: Loss=1.059, Time=0.023
Epoch 249: at batch 1: Loss=1.253, Time=0.025
Epoch 250: at batch 1: Loss=1.126, Time=0.026
Epoch 251: at batch 1: Loss=1.135, Time=0.024
Epoch 251: Time=14.435, Epoch time = 0.024, Avg epoch time=0.000

[[1.01982844]
 [1.10836768]
 [1.10836768]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 252: at batch 1: Loss=1.106, Time=0.021
Epoch 253: at batch 1: Loss=1.111, Time=0.023
Epoch 254: at batch 1: Loss=1.066, Time=0.024
Epoch 255: at batch 1: Loss=1.037, Time=0.024
Epoch 256: at batch 1: Loss=1.024, Time=0.035
Epoch 257: at batch 1: Loss=1.210, Time=0.024
Epoch 258: at batch 1: Loss=1.458, Time=0.032
Epoch 259: at batch 1: Loss=1.421, Time=0.031
Epoch 260: at batch 1: Loss=1.183, Time=0.024
Epoch 261: at batch 1: Loss=1.114, Time=0.032
Epoch 261: Time=14.988, Epoch time = 0.032, Avg epoch time=0.000

[[1.13114786]
 [1.13114786]
 [1.13114786]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 262: at batch 1: Loss=1.094, Time=0.021
Epoch 263: at batch 1: Loss=1.087, Time=0.020
Epoch 264: at batch 1: Loss=1.191, Time=0.023
Epoch 265: at batch 1: Loss=1.087, Time=0.021
Epoch 266: at batch 1: Loss=1.150, Time=0.024
Epoch 267: at batch 1: Loss=1.028, Time=0.020
Epoch 268: at batch 1: Loss=1.179, Time=0.021
Epoch 269: at batch 1: Loss=1.139, Time=0.031
Epoch 270: at batch 1: Loss=1.112, Time=0.025
Epoch 271: at batch 1: Loss=1.081, Time=0.032
Epoch 271: Time=15.506, Epoch time = 0.032, Avg epoch time=0.000

[[1.0984869 ]
 [1.01152301]
 [1.0984869 ]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 272: at batch 1: Loss=1.079, Time=0.024
Epoch 273: at batch 1: Loss=1.053, Time=0.023
Epoch 274: at batch 1: Loss=0.992, Time=0.030
Epoch 275: at batch 1: Loss=1.210, Time=0.022
Epoch 276: at batch 1: Loss=1.005, Time=0.024
Epoch 277: at batch 1: Loss=0.981, Time=0.023
Epoch 278: at batch 1: Loss=1.025, Time=0.025
Epoch 279: at batch 1: Loss=1.081, Time=0.021
Epoch 280: at batch 1: Loss=1.072, Time=0.021
Epoch 281: at batch 1: Loss=1.013, Time=0.023
Epoch 281: Time=16.026, Epoch time = 0.023, Avg epoch time=0.000

[[1.12717152]
 [0.92202604]
 [1.04716027]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 282: at batch 1: Loss=1.051, Time=0.025
Epoch 283: at batch 1: Loss=1.214, Time=0.023
Epoch 284: at batch 1: Loss=1.118, Time=0.023
Epoch 285: at batch 1: Loss=1.158, Time=0.026
Epoch 286: at batch 1: Loss=1.109, Time=0.025
Epoch 287: at batch 1: Loss=1.042, Time=0.022
Epoch 288: at batch 1: Loss=1.095, Time=0.025
Epoch 289: at batch 1: Loss=1.058, Time=0.024
Epoch 290: at batch 1: Loss=1.039, Time=0.021
Epoch 291: at batch 1: Loss=1.127, Time=0.021
Epoch 291: Time=16.541, Epoch time = 0.021, Avg epoch time=0.000

[[1.04206967]
 [1.23792624]
 [1.23792624]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 292: at batch 1: Loss=1.073, Time=0.030
Epoch 293: at batch 1: Loss=1.042, Time=0.024
Epoch 294: at batch 1: Loss=0.983, Time=0.021
Epoch 295: at batch 1: Loss=1.034, Time=0.025
Epoch 296: at batch 1: Loss=1.031, Time=0.024
Epoch 297: at batch 1: Loss=1.216, Time=0.022
Epoch 298: at batch 1: Loss=1.103, Time=0.025
Epoch 299: at batch 1: Loss=1.133, Time=0.023
Epoch 300: at batch 1: Loss=1.162, Time=0.023
Epoch 301: at batch 1: Loss=1.463, Time=0.023
Epoch 301: Time=17.061, Epoch time = 0.023, Avg epoch time=0.000

[[1.66715813]
 [1.66715813]
 [1.21235943]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 302: at batch 1: Loss=1.259, Time=0.021
Epoch 303: at batch 1: Loss=1.049, Time=0.034
Epoch 304: at batch 1: Loss=1.329, Time=0.025
Epoch 305: at batch 1: Loss=1.193, Time=0.026
Epoch 306: at batch 1: Loss=1.128, Time=0.023
Epoch 307: at batch 1: Loss=1.342, Time=0.032
Epoch 308: at batch 1: Loss=1.208, Time=0.023
Epoch 309: at batch 1: Loss=1.013, Time=0.023
Epoch 310: at batch 1: Loss=1.074, Time=0.025
Epoch 311: at batch 1: Loss=1.093, Time=0.025
Epoch 311: Time=17.605, Epoch time = 0.025, Avg epoch time=0.000

[[1.13029981]
 [1.07114768]
 [1.13029981]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 312: at batch 1: Loss=1.056, Time=0.033
Epoch 313: at batch 1: Loss=1.067, Time=0.023
Epoch 314: at batch 1: Loss=1.583, Time=0.024
Epoch 315: at batch 1: Loss=1.143, Time=0.023
Epoch 316: at batch 1: Loss=1.077, Time=0.022
Epoch 317: at batch 1: Loss=1.088, Time=0.023
Epoch 318: at batch 1: Loss=1.133, Time=0.021
Epoch 319: at batch 1: Loss=1.088, Time=0.021
Epoch 320: at batch 1: Loss=1.138, Time=0.025
Epoch 321: at batch 1: Loss=1.047, Time=0.025
Epoch 321: Time=18.129, Epoch time = 0.025, Avg epoch time=0.000

[[0.98859423]
 [0.98859423]
 [1.06312728]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 322: at batch 1: Loss=1.080, Time=0.023
Epoch 323: at batch 1: Loss=1.047, Time=0.022
Epoch 324: at batch 1: Loss=1.148, Time=0.022
Epoch 325: at batch 1: Loss=1.122, Time=0.023
Epoch 326: at batch 1: Loss=1.165, Time=0.024
Epoch 327: at batch 1: Loss=1.170, Time=0.025
Epoch 328: at batch 1: Loss=1.163, Time=0.020
Epoch 329: at batch 1: Loss=1.072, Time=0.023
Epoch 330: at batch 1: Loss=1.087, Time=0.023
Epoch 331: at batch 1: Loss=1.079, Time=0.021
Epoch 331: Time=18.634, Epoch time = 0.021, Avg epoch time=0.000

[[1.12180233]
 [1.07305396]
 [1.07305396]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 332: at batch 1: Loss=1.012, Time=0.021
Epoch 333: at batch 1: Loss=1.105, Time=0.023
Epoch 334: at batch 1: Loss=1.106, Time=0.026
Epoch 335: at batch 1: Loss=1.022, Time=0.023
Epoch 336: at batch 1: Loss=1.041, Time=0.033
Epoch 337: at batch 1: Loss=1.063, Time=0.020
Epoch 338: at batch 1: Loss=1.153, Time=0.033
Epoch 339: at batch 1: Loss=1.260, Time=0.024
Epoch 340: at batch 1: Loss=1.168, Time=0.033
Epoch 341: at batch 1: Loss=1.117, Time=0.024
Epoch 341: Time=19.174, Epoch time = 0.024, Avg epoch time=0.000

[[1.11695278]
 [1.08432126]
 [1.32716095]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 342: at batch 1: Loss=1.140, Time=0.023
Epoch 343: at batch 1: Loss=1.112, Time=0.032
Epoch 344: at batch 1: Loss=1.078, Time=0.023
Epoch 345: at batch 1: Loss=1.069, Time=0.021
Epoch 346: at batch 1: Loss=1.203, Time=0.033
Epoch 347: at batch 1: Loss=1.092, Time=0.032
Epoch 348: at batch 1: Loss=1.030, Time=0.023
Epoch 349: at batch 1: Loss=1.083, Time=0.024
Epoch 350: at batch 1: Loss=1.048, Time=0.032
Epoch 351: at batch 1: Loss=1.038, Time=0.024
Epoch 351: Time=19.723, Epoch time = 0.024, Avg epoch time=0.000

[[1.02831805]
 [1.02831805]
 [0.97060758]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 352: at batch 1: Loss=1.038, Time=0.023
Epoch 353: at batch 1: Loss=1.057, Time=0.032
Epoch 354: at batch 1: Loss=1.056, Time=0.023
Epoch 355: at batch 1: Loss=1.082, Time=0.032
Epoch 356: at batch 1: Loss=1.074, Time=0.021
Epoch 357: at batch 1: Loss=1.054, Time=0.022
Epoch 358: at batch 1: Loss=1.056, Time=0.023
Epoch 359: at batch 1: Loss=1.123, Time=0.023
Epoch 360: at batch 1: Loss=1.073, Time=0.023
Epoch 361: at batch 1: Loss=1.037, Time=0.032
Epoch 361: Time=20.257, Epoch time = 0.032, Avg epoch time=0.000

[[1.008811  ]
 [1.17348611]
 [1.008811  ]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 362: at batch 1: Loss=0.992, Time=0.024
Epoch 363: at batch 1: Loss=1.054, Time=0.023
Epoch 364: at batch 1: Loss=1.036, Time=0.022
Epoch 365: at batch 1: Loss=1.075, Time=0.022
Epoch 366: at batch 1: Loss=1.018, Time=0.023
Epoch 367: at batch 1: Loss=1.320, Time=0.025
Epoch 368: at batch 1: Loss=1.175, Time=0.023
Epoch 369: at batch 1: Loss=1.091, Time=0.023
Epoch 370: at batch 1: Loss=1.096, Time=0.022
Epoch 371: at batch 1: Loss=1.055, Time=0.025
Epoch 371: Time=20.771, Epoch time = 0.025, Avg epoch time=0.000

[[1.04386115]
 [1.08538413]
 [1.04386115]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 372: at batch 1: Loss=1.200, Time=0.023
Epoch 373: at batch 1: Loss=1.100, Time=0.030
Epoch 374: at batch 1: Loss=1.036, Time=0.021
Epoch 375: at batch 1: Loss=1.117, Time=0.023
Epoch 376: at batch 1: Loss=1.100, Time=0.023
Epoch 377: at batch 1: Loss=1.050, Time=0.023
Epoch 378: at batch 1: Loss=1.180, Time=0.023
Epoch 379: at batch 1: Loss=1.330, Time=0.023
Epoch 380: at batch 1: Loss=1.035, Time=0.025
Epoch 381: at batch 1: Loss=1.123, Time=0.024
Epoch 381: Time=21.290, Epoch time = 0.024, Avg epoch time=0.000

[[1.21511745]
 [1.38206387]
 [1.21511745]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 382: at batch 1: Loss=1.100, Time=0.021
Epoch 383: at batch 1: Loss=1.065, Time=0.025
Epoch 384: at batch 1: Loss=1.058, Time=0.023
Epoch 385: at batch 1: Loss=1.046, Time=0.034
Epoch 386: at batch 1: Loss=1.058, Time=0.020
Epoch 387: at batch 1: Loss=1.087, Time=0.024
Epoch 388: at batch 1: Loss=1.025, Time=0.023
Epoch 389: at batch 1: Loss=1.128, Time=0.025
Epoch 390: at batch 1: Loss=1.164, Time=0.022
Epoch 391: at batch 1: Loss=1.110, Time=0.027
Epoch 391: Time=21.815, Epoch time = 0.027, Avg epoch time=0.000

[[1.05016351]
 [1.05016351]
 [1.05016351]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 392: at batch 1: Loss=1.058, Time=0.023
Epoch 393: at batch 1: Loss=1.076, Time=0.024
Epoch 394: at batch 1: Loss=1.081, Time=0.024
Epoch 395: at batch 1: Loss=1.082, Time=0.023
Epoch 396: at batch 1: Loss=1.049, Time=0.032
Epoch 397: at batch 1: Loss=1.154, Time=0.025
Epoch 398: at batch 1: Loss=1.044, Time=0.023
Epoch 399: at batch 1: Loss=1.010, Time=0.021
Epoch 400: at batch 1: Loss=0.955, Time=0.021
Epoch 401: at batch 1: Loss=1.039, Time=0.023
Epoch 401: Time=22.335, Epoch time = 0.023, Avg epoch time=0.000

[[1.09849942]
 [0.91150427]
 [1.09849942]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 402: at batch 1: Loss=1.072, Time=0.023
Epoch 403: at batch 1: Loss=1.055, Time=0.023
Epoch 404: at batch 1: Loss=1.065, Time=0.021
Epoch 405: at batch 1: Loss=1.155, Time=0.020
Epoch 406: at batch 1: Loss=1.173, Time=0.023
Epoch 407: at batch 1: Loss=1.192, Time=0.023
Epoch 408: at batch 1: Loss=1.032, Time=0.021
Epoch 409: at batch 1: Loss=1.051, Time=0.024
Epoch 410: at batch 1: Loss=1.022, Time=0.021
Epoch 411: at batch 1: Loss=1.102, Time=0.021
Epoch 411: Time=22.838, Epoch time = 0.021, Avg epoch time=0.000

[[1.02680111]
 [1.02680111]
 [1.12144136]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 412: at batch 1: Loss=1.094, Time=0.024
Epoch 413: at batch 1: Loss=1.074, Time=0.020
Epoch 414: at batch 1: Loss=1.069, Time=0.023
Epoch 415: at batch 1: Loss=1.065, Time=0.025
Epoch 416: at batch 1: Loss=1.085, Time=0.025
Epoch 417: at batch 1: Loss=1.122, Time=0.021
Epoch 418: at batch 1: Loss=1.019, Time=0.021
Epoch 419: at batch 1: Loss=1.111, Time=0.023
Epoch 420: at batch 1: Loss=1.160, Time=0.023
Epoch 421: at batch 1: Loss=1.136, Time=0.022
Epoch 421: Time=23.353, Epoch time = 0.022, Avg epoch time=0.000

[[0.95118451]
 [1.10619318]
 [1.10619318]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 422: at batch 1: Loss=1.100, Time=0.023
Epoch 423: at batch 1: Loss=1.044, Time=0.023
Epoch 424: at batch 1: Loss=1.188, Time=0.023
Epoch 425: at batch 1: Loss=1.063, Time=0.021
Epoch 426: at batch 1: Loss=0.979, Time=0.021
Epoch 427: at batch 1: Loss=1.047, Time=0.022
Epoch 428: at batch 1: Loss=1.044, Time=0.025
Epoch 429: at batch 1: Loss=1.069, Time=0.022
Epoch 430: at batch 1: Loss=1.440, Time=0.025
Epoch 431: at batch 1: Loss=1.195, Time=0.026
Epoch 431: Time=23.864, Epoch time = 0.026, Avg epoch time=0.000

[[1.00750566]
 [1.00750566]
 [1.00750566]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 432: at batch 1: Loss=1.276, Time=0.022
Epoch 433: at batch 1: Loss=1.133, Time=0.021
Epoch 434: at batch 1: Loss=1.100, Time=0.023
Epoch 435: at batch 1: Loss=1.185, Time=0.022
Epoch 436: at batch 1: Loss=1.078, Time=0.021
Epoch 437: at batch 1: Loss=1.122, Time=0.026
Epoch 438: at batch 1: Loss=1.209, Time=0.024
Epoch 439: at batch 1: Loss=1.194, Time=0.021
Epoch 440: at batch 1: Loss=1.317, Time=0.021
Epoch 441: at batch 1: Loss=1.079, Time=0.023
Epoch 441: Time=24.368, Epoch time = 0.023, Avg epoch time=0.000

[[0.95904672]
 [1.19229186]
 [1.19229186]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 442: at batch 1: Loss=1.109, Time=0.025
Epoch 443: at batch 1: Loss=1.065, Time=0.021
Epoch 444: at batch 1: Loss=1.075, Time=0.023
Epoch 445: at batch 1: Loss=1.197, Time=0.021
Epoch 446: at batch 1: Loss=1.210, Time=0.022
Epoch 447: at batch 1: Loss=1.168, Time=0.026
Epoch 448: at batch 1: Loss=1.114, Time=0.022
Epoch 449: at batch 1: Loss=1.015, Time=0.023
Epoch 450: at batch 1: Loss=1.160, Time=0.030
Epoch 451: at batch 1: Loss=1.125, Time=0.023
Epoch 451: Time=24.887, Epoch time = 0.023, Avg epoch time=0.000

[[1.08004451]
 [1.08686042]
 [1.08004451]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 452: at batch 1: Loss=0.964, Time=0.022
Epoch 453: at batch 1: Loss=1.027, Time=0.023
Epoch 454: at batch 1: Loss=1.014, Time=0.024
Epoch 455: at batch 1: Loss=1.353, Time=0.022
Epoch 456: at batch 1: Loss=1.180, Time=0.023
Epoch 457: at batch 1: Loss=1.556, Time=0.023
Epoch 458: at batch 1: Loss=1.297, Time=0.031
Epoch 459: at batch 1: Loss=1.526, Time=0.023
Epoch 460: at batch 1: Loss=1.274, Time=0.023
Epoch 461: at batch 1: Loss=1.156, Time=0.026
Epoch 461: Time=25.407, Epoch time = 0.026, Avg epoch time=0.000

[[1.05863845]
 [1.08411419]
 [1.03934336]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 462: at batch 1: Loss=1.092, Time=0.022
Epoch 463: at batch 1: Loss=1.070, Time=0.023
Epoch 464: at batch 1: Loss=1.093, Time=0.023
Epoch 465: at batch 1: Loss=1.080, Time=0.024
Epoch 466: at batch 1: Loss=1.072, Time=0.025
Epoch 467: at batch 1: Loss=1.032, Time=0.035
Epoch 468: at batch 1: Loss=1.068, Time=0.036
Epoch 469: at batch 1: Loss=1.072, Time=0.023
Epoch 470: at batch 1: Loss=1.082, Time=0.025
Epoch 471: at batch 1: Loss=1.085, Time=0.025
Epoch 471: Time=25.947, Epoch time = 0.025, Avg epoch time=0.000

[[1.08504462]
 [1.08492744]
 [1.08504462]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 472: at batch 1: Loss=1.135, Time=0.023
Epoch 473: at batch 1: Loss=1.104, Time=0.024
Epoch 474: at batch 1: Loss=1.070, Time=0.023
Epoch 475: at batch 1: Loss=1.065, Time=0.021
Epoch 476: at batch 1: Loss=1.058, Time=0.024
Epoch 477: at batch 1: Loss=1.044, Time=0.025
Epoch 478: at batch 1: Loss=1.154, Time=0.024
Epoch 479: at batch 1: Loss=1.080, Time=0.023
Epoch 480: at batch 1: Loss=1.205, Time=0.024
Epoch 481: at batch 1: Loss=1.090, Time=0.021
Epoch 481: Time=26.461, Epoch time = 0.021, Avg epoch time=0.000

[[1.01768565]
 [1.01768565]
 [1.27743065]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 482: at batch 1: Loss=1.069, Time=0.024
Epoch 483: at batch 1: Loss=1.137, Time=0.022
Epoch 484: at batch 1: Loss=1.108, Time=0.024
Epoch 485: at batch 1: Loss=1.048, Time=0.023
Epoch 486: at batch 1: Loss=1.049, Time=0.022
Epoch 487: at batch 1: Loss=1.116, Time=0.030
Epoch 488: at batch 1: Loss=1.045, Time=0.033
Epoch 489: at batch 1: Loss=1.089, Time=0.026
Epoch 490: at batch 1: Loss=1.096, Time=0.022
Epoch 491: at batch 1: Loss=1.185, Time=0.022
Epoch 491: Time=26.989, Epoch time = 0.022, Avg epoch time=0.000

[[1.23898339]
 [1.23898339]
 [1.23898339]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 492: at batch 1: Loss=1.026, Time=0.024
Epoch 493: at batch 1: Loss=1.120, Time=0.025
Epoch 494: at batch 1: Loss=1.136, Time=0.023
Epoch 495: at batch 1: Loss=1.204, Time=0.024
Epoch 496: at batch 1: Loss=1.079, Time=0.024
Epoch 497: at batch 1: Loss=1.002, Time=0.023
Epoch 498: at batch 1: Loss=1.037, Time=0.021
Epoch 499: at batch 1: Loss=1.032, Time=0.024
Epoch 500: at batch 1: Loss=1.062, Time=0.024
Epoch 501: at batch 1: Loss=1.101, Time=0.021
Epoch 501: Time=27.506, Epoch time = 0.021, Avg epoch time=0.000

[[1.11793888]
 [1.03159451]
 [1.11793888]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 502: at batch 1: Loss=1.154, Time=0.025
Epoch 503: at batch 1: Loss=1.046, Time=0.025
Epoch 504: at batch 1: Loss=1.063, Time=0.021
Epoch 505: at batch 1: Loss=1.023, Time=0.024
Epoch 506: at batch 1: Loss=1.193, Time=0.021
Epoch 507: at batch 1: Loss=1.238, Time=0.025
Epoch 508: at batch 1: Loss=1.317, Time=0.026
Epoch 509: at batch 1: Loss=1.408, Time=0.032
Epoch 510: at batch 1: Loss=1.226, Time=0.024
Epoch 511: at batch 1: Loss=1.149, Time=0.022
Epoch 511: Time=28.031, Epoch time = 0.022, Avg epoch time=0.000

[[1.10249209]
 [1.33673573]
 [1.10249209]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 512: at batch 1: Loss=1.249, Time=0.021
Epoch 513: at batch 1: Loss=1.127, Time=0.023
Epoch 514: at batch 1: Loss=1.014, Time=0.024
Epoch 515: at batch 1: Loss=1.041, Time=0.026
Epoch 516: at batch 1: Loss=1.246, Time=0.022
Epoch 517: at batch 1: Loss=1.172, Time=0.026
Epoch 518: at batch 1: Loss=1.075, Time=0.023
Epoch 519: at batch 1: Loss=1.021, Time=0.024
Epoch 520: at batch 1: Loss=1.022, Time=0.025
Epoch 521: at batch 1: Loss=1.085, Time=0.024
Epoch 521: Time=28.551, Epoch time = 0.024, Avg epoch time=0.000

[[1.01358199]
 [1.13466978]
 [1.13466978]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 522: at batch 1: Loss=1.107, Time=0.025
Epoch 523: at batch 1: Loss=1.068, Time=0.024
Epoch 524: at batch 1: Loss=1.076, Time=0.033
Epoch 525: at batch 1: Loss=1.112, Time=0.032
Epoch 526: at batch 1: Loss=1.081, Time=0.024
Epoch 527: at batch 1: Loss=1.057, Time=0.024
Epoch 528: at batch 1: Loss=1.088, Time=0.022
Epoch 529: at batch 1: Loss=1.045, Time=0.025
Epoch 530: at batch 1: Loss=1.057, Time=0.025
Epoch 531: at batch 1: Loss=1.083, Time=0.021
Epoch 531: Time=29.088, Epoch time = 0.021, Avg epoch time=0.000

[[1.11712825]
 [1.06916857]
 [1.11712825]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 532: at batch 1: Loss=1.092, Time=0.024
Epoch 533: at batch 1: Loss=1.037, Time=0.026
Epoch 534: at batch 1: Loss=1.049, Time=0.023
Epoch 535: at batch 1: Loss=1.016, Time=0.033
Epoch 536: at batch 1: Loss=1.001, Time=0.022
Epoch 537: at batch 1: Loss=1.033, Time=0.023
Epoch 538: at batch 1: Loss=1.094, Time=0.024
Epoch 539: at batch 1: Loss=1.069, Time=0.023
Epoch 540: at batch 1: Loss=1.078, Time=0.023
Epoch 541: at batch 1: Loss=1.156, Time=0.021
Epoch 541: Time=29.612, Epoch time = 0.021, Avg epoch time=0.000

[[1.25971985]
 [1.25971985]
 [1.09031868]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 542: at batch 1: Loss=1.095, Time=0.024
Epoch 543: at batch 1: Loss=1.063, Time=0.031
Epoch 544: at batch 1: Loss=1.058, Time=0.023
Epoch 545: at batch 1: Loss=1.036, Time=0.022
Epoch 546: at batch 1: Loss=1.000, Time=0.024
Epoch 547: at batch 1: Loss=1.074, Time=0.022
Epoch 548: at batch 1: Loss=1.052, Time=0.033
Epoch 549: at batch 1: Loss=1.058, Time=0.021
Epoch 550: at batch 1: Loss=1.076, Time=0.026
Epoch 551: at batch 1: Loss=1.115, Time=0.024
Epoch 551: Time=30.142, Epoch time = 0.024, Avg epoch time=0.000

[[1.14498234]
 [1.14498234]
 [1.14498234]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 552: at batch 1: Loss=1.111, Time=0.026
Epoch 553: at batch 1: Loss=1.106, Time=0.022
Epoch 554: at batch 1: Loss=1.209, Time=0.025
Epoch 555: at batch 1: Loss=1.250, Time=0.024
Epoch 556: at batch 1: Loss=1.153, Time=0.026
Epoch 557: at batch 1: Loss=1.116, Time=0.024
Epoch 558: at batch 1: Loss=1.126, Time=0.026
Epoch 559: at batch 1: Loss=1.107, Time=0.025
Epoch 560: at batch 1: Loss=1.093, Time=0.026
Epoch 561: at batch 1: Loss=1.068, Time=0.033
Epoch 561: Time=30.679, Epoch time = 0.033, Avg epoch time=0.000

[[1.0740118 ]
 [1.0740118 ]
 [1.04832685]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 562: at batch 1: Loss=1.093, Time=0.026
Epoch 563: at batch 1: Loss=1.040, Time=0.026
Epoch 564: at batch 1: Loss=1.039, Time=0.025
Epoch 565: at batch 1: Loss=1.245, Time=0.021
Epoch 566: at batch 1: Loss=1.046, Time=0.026
Epoch 567: at batch 1: Loss=1.068, Time=0.025
Epoch 568: at batch 1: Loss=1.137, Time=0.026
Epoch 569: at batch 1: Loss=1.119, Time=0.024
Epoch 570: at batch 1: Loss=1.044, Time=0.033
Epoch 571: at batch 1: Loss=1.312, Time=0.024
Epoch 571: Time=31.215, Epoch time = 0.024, Avg epoch time=0.000

[[1.53888297]
 [1.53888297]
 [1.14821208]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 572: at batch 1: Loss=1.263, Time=0.026
Epoch 573: at batch 1: Loss=1.149, Time=0.023
Epoch 574: at batch 1: Loss=1.152, Time=0.022
Epoch 575: at batch 1: Loss=1.095, Time=0.026
Epoch 576: at batch 1: Loss=1.126, Time=0.032
Epoch 577: at batch 1: Loss=1.073, Time=0.025
Epoch 578: at batch 1: Loss=1.105, Time=0.023
Epoch 579: at batch 1: Loss=1.096, Time=0.026
Epoch 580: at batch 1: Loss=1.202, Time=0.023
Epoch 581: at batch 1: Loss=1.288, Time=0.024
Epoch 581: Time=31.753, Epoch time = 0.024, Avg epoch time=0.000

[[1.09361863]
 [1.06555855]
 [1.27699459]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 582: at batch 1: Loss=1.165, Time=0.024
Epoch 583: at batch 1: Loss=1.149, Time=0.025
Epoch 584: at batch 1: Loss=1.111, Time=0.022
Epoch 585: at batch 1: Loss=1.118, Time=0.023
Epoch 586: at batch 1: Loss=1.101, Time=0.030
Epoch 587: at batch 1: Loss=1.089, Time=0.027
Epoch 588: at batch 1: Loss=1.072, Time=0.024
Epoch 589: at batch 1: Loss=1.066, Time=0.025
Epoch 590: at batch 1: Loss=1.124, Time=0.024
Epoch 591: at batch 1: Loss=1.040, Time=0.024
Epoch 591: Time=32.283, Epoch time = 0.024, Avg epoch time=0.000

[[0.95171475]
 [1.06450808]
 [1.16936719]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 592: at batch 1: Loss=1.058, Time=0.026
Epoch 593: at batch 1: Loss=1.065, Time=0.023
Epoch 594: at batch 1: Loss=1.299, Time=0.024
Epoch 595: at batch 1: Loss=1.169, Time=0.024
Epoch 596: at batch 1: Loss=1.056, Time=0.022
Epoch 597: at batch 1: Loss=1.052, Time=0.026
Epoch 598: at batch 1: Loss=1.092, Time=0.022
Epoch 599: at batch 1: Loss=1.080, Time=0.026
Epoch 600: at batch 1: Loss=1.077, Time=0.024
Epoch 601: at batch 1: Loss=1.092, Time=0.023
Epoch 601: Time=32.804, Epoch time = 0.024, Avg epoch time=0.000

[[1.101161  ]
 [1.06847882]
 [1.101161  ]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 602: at batch 1: Loss=1.080, Time=0.024
Epoch 603: at batch 1: Loss=1.327, Time=0.027
Epoch 604: at batch 1: Loss=1.123, Time=0.024
Epoch 605: at batch 1: Loss=1.127, Time=0.022
Epoch 606: at batch 1: Loss=1.074, Time=0.023
Epoch 607: at batch 1: Loss=1.415, Time=0.024
Epoch 608: at batch 1: Loss=1.203, Time=0.023
Epoch 609: at batch 1: Loss=1.104, Time=0.024
Epoch 610: at batch 1: Loss=1.212, Time=0.024
Epoch 611: at batch 1: Loss=1.124, Time=0.024
Epoch 611: Time=33.332, Epoch time = 0.024, Avg epoch time=0.000

[[1.0553031 ]
 [0.99170947]
 [0.99170947]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 612: at batch 1: Loss=1.027, Time=0.021
Epoch 613: at batch 1: Loss=1.003, Time=0.024
Epoch 614: at batch 1: Loss=1.207, Time=0.023
Epoch 615: at batch 1: Loss=1.148, Time=0.024
Epoch 616: at batch 1: Loss=1.214, Time=0.023
Epoch 617: at batch 1: Loss=1.113, Time=0.023
Epoch 618: at batch 1: Loss=1.193, Time=0.022
Epoch 619: at batch 1: Loss=1.168, Time=0.026
Epoch 620: at batch 1: Loss=1.093, Time=0.025
Epoch 621: at batch 1: Loss=1.060, Time=0.021
Epoch 621: Time=33.845, Epoch time = 0.021, Avg epoch time=0.000

[[1.02100766]
 [1.02100766]
 [1.02100766]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 622: at batch 1: Loss=1.062, Time=0.024
Epoch 623: at batch 1: Loss=1.071, Time=0.030
Epoch 624: at batch 1: Loss=1.036, Time=0.026
Epoch 625: at batch 1: Loss=1.064, Time=0.023
Epoch 626: at batch 1: Loss=1.083, Time=0.024
Epoch 627: at batch 1: Loss=1.124, Time=0.025
Epoch 628: at batch 1: Loss=1.071, Time=0.032
Epoch 629: at batch 1: Loss=1.132, Time=0.024
Epoch 630: at batch 1: Loss=1.065, Time=0.024
Epoch 631: at batch 1: Loss=1.072, Time=0.026
Epoch 631: Time=34.385, Epoch time = 0.026, Avg epoch time=0.000

[[1.03002095]
 [1.08459496]
 [1.08459496]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 632: at batch 1: Loss=1.070, Time=0.025
Epoch 633: at batch 1: Loss=1.078, Time=0.026
Epoch 634: at batch 1: Loss=1.050, Time=0.023
Epoch 635: at batch 1: Loss=1.107, Time=0.025
Epoch 636: at batch 1: Loss=1.087, Time=0.023
Epoch 637: at batch 1: Loss=1.246, Time=0.022
Epoch 638: at batch 1: Loss=1.133, Time=0.036
Epoch 639: at batch 1: Loss=1.107, Time=0.026
Epoch 640: at batch 1: Loss=1.066, Time=0.022
Epoch 641: at batch 1: Loss=1.112, Time=0.034
Epoch 641: Time=34.928, Epoch time = 0.034, Avg epoch time=0.000

[[1.13863993]
 [1.05256724]
 [1.13863993]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 642: at batch 1: Loss=1.204, Time=0.025
Epoch 643: at batch 1: Loss=1.170, Time=0.024
Epoch 644: at batch 1: Loss=1.044, Time=0.022
Epoch 645: at batch 1: Loss=1.034, Time=0.025
Epoch 646: at batch 1: Loss=1.036, Time=0.024
Epoch 647: at batch 1: Loss=1.077, Time=0.033
Epoch 648: at batch 1: Loss=1.082, Time=0.025
Epoch 649: at batch 1: Loss=1.060, Time=0.021
Epoch 650: at batch 1: Loss=1.034, Time=0.022
Epoch 651: at batch 1: Loss=1.089, Time=0.031
Epoch 651: Time=35.460, Epoch time = 0.031, Avg epoch time=0.000

[[1.01132154]
 [1.01132154]
 [1.13523507]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 652: at batch 1: Loss=1.109, Time=0.022
Epoch 653: at batch 1: Loss=1.112, Time=0.026
Epoch 654: at batch 1: Loss=1.132, Time=0.026
Epoch 655: at batch 1: Loss=1.106, Time=0.023
Epoch 656: at batch 1: Loss=1.087, Time=0.024
Epoch 657: at batch 1: Loss=1.079, Time=0.022
Epoch 658: at batch 1: Loss=1.030, Time=0.032
Epoch 659: at batch 1: Loss=1.189, Time=0.033
Epoch 660: at batch 1: Loss=1.203, Time=0.026
Epoch 661: at batch 1: Loss=1.098, Time=0.026
Epoch 661: Time=36.000, Epoch time = 0.026, Avg epoch time=0.000

[[1.0645653]
 [1.0645653]
 [1.0645653]
 ...
 [0.       ]
 [0.       ]
 [0.       ]]
Epoch 662: at batch 1: Loss=1.060, Time=0.035
Epoch 663: at batch 1: Loss=1.054, Time=0.022
Epoch 664: at batch 1: Loss=1.053, Time=0.020
Epoch 665: at batch 1: Loss=1.444, Time=0.033
Epoch 666: at batch 1: Loss=1.321, Time=0.022
Epoch 667: at batch 1: Loss=1.161, Time=0.022
Epoch 668: at batch 1: Loss=1.197, Time=0.024
Epoch 669: at batch 1: Loss=1.118, Time=0.026
Epoch 670: at batch 1: Loss=1.108, Time=0.025
Epoch 671: at batch 1: Loss=1.078, Time=0.024
Epoch 671: Time=36.539, Epoch time = 0.024, Avg epoch time=0.000

[[1.1178813 ]
 [1.05351985]
 [1.05351985]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 672: at batch 1: Loss=1.105, Time=0.021
Epoch 673: at batch 1: Loss=1.048, Time=0.035
Epoch 674: at batch 1: Loss=1.075, Time=0.022
Epoch 675: at batch 1: Loss=1.518, Time=0.025
Epoch 676: at batch 1: Loss=1.398, Time=0.024
Epoch 677: at batch 1: Loss=1.489, Time=0.024
Epoch 678: at batch 1: Loss=1.288, Time=0.026
Epoch 679: at batch 1: Loss=1.306, Time=0.026
Epoch 680: at batch 1: Loss=1.188, Time=0.022
Epoch 681: at batch 1: Loss=1.252, Time=0.024
Epoch 681: Time=37.069, Epoch time = 0.024, Avg epoch time=0.000

[[1.30924785]
 [1.30924785]
 [1.30924785]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 682: at batch 1: Loss=1.222, Time=0.025
Epoch 683: at batch 1: Loss=1.159, Time=0.025
Epoch 684: at batch 1: Loss=1.108, Time=0.023
Epoch 685: at batch 1: Loss=1.173, Time=0.031
Epoch 686: at batch 1: Loss=1.148, Time=0.026
Epoch 687: at batch 1: Loss=1.108, Time=0.024
Epoch 688: at batch 1: Loss=1.157, Time=0.024
Epoch 689: at batch 1: Loss=1.146, Time=0.023
Epoch 690: at batch 1: Loss=1.157, Time=0.025
Epoch 691: at batch 1: Loss=1.051, Time=0.026
Epoch 691: Time=37.601, Epoch time = 0.026, Avg epoch time=0.000

[[1.13249683]
 [0.92785406]
 [1.12612367]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 692: at batch 1: Loss=1.085, Time=0.021
Epoch 693: at batch 1: Loss=1.077, Time=0.021
Epoch 694: at batch 1: Loss=1.158, Time=0.021
Epoch 695: at batch 1: Loss=1.115, Time=0.022
Epoch 696: at batch 1: Loss=1.066, Time=0.026
Epoch 697: at batch 1: Loss=1.053, Time=0.024
Epoch 698: at batch 1: Loss=0.996, Time=0.025
Epoch 699: at batch 1: Loss=1.054, Time=0.021
Epoch 700: at batch 1: Loss=1.057, Time=0.031
Epoch 701: at batch 1: Loss=1.107, Time=0.027
Epoch 701: Time=38.132, Epoch time = 0.027, Avg epoch time=0.000

[[1.1505599]
 [1.0518657]
 [1.0518657]
 ...
 [0.       ]
 [0.       ]
 [0.       ]]
Epoch 702: at batch 1: Loss=1.082, Time=0.021
Epoch 703: at batch 1: Loss=1.102, Time=0.027
Epoch 704: at batch 1: Loss=1.265, Time=0.022
Epoch 705: at batch 1: Loss=1.119, Time=0.026
Epoch 706: at batch 1: Loss=1.194, Time=0.023
Epoch 707: at batch 1: Loss=1.120, Time=0.022
Epoch 708: at batch 1: Loss=1.135, Time=0.033
Epoch 709: at batch 1: Loss=1.090, Time=0.020
Epoch 710: at batch 1: Loss=1.094, Time=0.024
Epoch 711: at batch 1: Loss=1.074, Time=0.022
Epoch 711: Time=38.658, Epoch time = 0.022, Avg epoch time=0.000

[[1.07784772]
 [1.07784772]
 [1.05321014]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 712: at batch 1: Loss=1.101, Time=0.024
Epoch 713: at batch 1: Loss=1.046, Time=0.022
Epoch 714: at batch 1: Loss=1.325, Time=0.036
Epoch 715: at batch 1: Loss=1.140, Time=0.026
Epoch 716: at batch 1: Loss=1.146, Time=0.022
Epoch 717: at batch 1: Loss=1.108, Time=0.021
Epoch 718: at batch 1: Loss=1.094, Time=0.034
Epoch 719: at batch 1: Loss=1.055, Time=0.033
Epoch 720: at batch 1: Loss=1.109, Time=0.021
Epoch 721: at batch 1: Loss=1.055, Time=0.024
Epoch 721: Time=39.202, Epoch time = 0.024, Avg epoch time=0.000

[[1.14622641]
 [1.02045929]
 [1.02045929]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 722: at batch 1: Loss=0.955, Time=0.034
Epoch 723: at batch 1: Loss=0.963, Time=0.026
Epoch 724: at batch 1: Loss=1.065, Time=0.025
Epoch 725: at batch 1: Loss=1.071, Time=0.024
Epoch 726: at batch 1: Loss=1.054, Time=0.023
Epoch 727: at batch 1: Loss=1.043, Time=0.034
Epoch 728: at batch 1: Loss=1.120, Time=0.021
Epoch 729: at batch 1: Loss=1.075, Time=0.022
Epoch 730: at batch 1: Loss=1.141, Time=0.023
Epoch 731: at batch 1: Loss=1.295, Time=0.031
Epoch 731: Time=39.745, Epoch time = 0.031, Avg epoch time=0.000

[[1.35952091]
 [1.35952091]
 [1.35952091]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 732: at batch 1: Loss=1.141, Time=0.025
Epoch 733: at batch 1: Loss=1.161, Time=0.030
Epoch 734: at batch 1: Loss=1.096, Time=0.022
Epoch 735: at batch 1: Loss=1.119, Time=0.024
Epoch 736: at batch 1: Loss=1.099, Time=0.026
Epoch 737: at batch 1: Loss=1.369, Time=0.033
Epoch 738: at batch 1: Loss=1.148, Time=0.024
Epoch 739: at batch 1: Loss=1.096, Time=0.024
Epoch 740: at batch 1: Loss=1.100, Time=0.023
Epoch 741: at batch 1: Loss=1.044, Time=0.035
Epoch 741: Time=40.294, Epoch time = 0.035, Avg epoch time=0.000

[[1.11471307]
 [1.11471307]
 [1.06985021]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 742: at batch 1: Loss=1.145, Time=0.024
Epoch 743: at batch 1: Loss=1.125, Time=0.032
Epoch 744: at batch 1: Loss=1.108, Time=0.026
Epoch 745: at batch 1: Loss=1.139, Time=0.022
Epoch 746: at batch 1: Loss=1.095, Time=0.024
Epoch 747: at batch 1: Loss=1.059, Time=0.023
Epoch 748: at batch 1: Loss=1.092, Time=0.025
Epoch 749: at batch 1: Loss=0.976, Time=0.024
Epoch 750: at batch 1: Loss=1.061, Time=0.023
Epoch 751: at batch 1: Loss=1.089, Time=0.023
Epoch 751: Time=40.825, Epoch time = 0.023, Avg epoch time=0.000

[[1.13196778]
 [1.11189914]
 [1.11189914]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 752: at batch 1: Loss=1.014, Time=0.021
Epoch 753: at batch 1: Loss=1.084, Time=0.026
Epoch 754: at batch 1: Loss=1.073, Time=0.020
Epoch 755: at batch 1: Loss=1.079, Time=0.024
Epoch 756: at batch 1: Loss=1.054, Time=0.027
Epoch 757: at batch 1: Loss=1.085, Time=0.024
Epoch 758: at batch 1: Loss=1.074, Time=0.023
Epoch 759: at batch 1: Loss=1.077, Time=0.024
Epoch 760: at batch 1: Loss=1.054, Time=0.025
Epoch 761: at batch 1: Loss=0.993, Time=0.024
Epoch 761: Time=41.345, Epoch time = 0.024, Avg epoch time=0.000

[[1.0347966 ]
 [0.95529407]
 [1.0347966 ]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 762: at batch 1: Loss=1.053, Time=0.029
Epoch 763: at batch 1: Loss=1.042, Time=0.023
Epoch 764: at batch 1: Loss=1.026, Time=0.026
Epoch 765: at batch 1: Loss=1.043, Time=0.025
Epoch 766: at batch 1: Loss=1.039, Time=0.032
Epoch 767: at batch 1: Loss=1.055, Time=0.024
Epoch 768: at batch 1: Loss=1.096, Time=0.023
Epoch 769: at batch 1: Loss=1.105, Time=0.025
Epoch 770: at batch 1: Loss=1.185, Time=0.031
Epoch 771: at batch 1: Loss=1.135, Time=0.025
Epoch 771: Time=41.889, Epoch time = 0.025, Avg epoch time=0.000

[[1.13468671]
 [1.11230135]
 [1.11230135]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 772: at batch 1: Loss=1.185, Time=0.022
Epoch 773: at batch 1: Loss=1.080, Time=0.024
Epoch 774: at batch 1: Loss=1.131, Time=0.021
Epoch 775: at batch 1: Loss=1.088, Time=0.032
Epoch 776: at batch 1: Loss=1.118, Time=0.034
Epoch 777: at batch 1: Loss=1.117, Time=0.023
Epoch 778: at batch 1: Loss=1.117, Time=0.023
Epoch 779: at batch 1: Loss=1.030, Time=0.022
Epoch 780: at batch 1: Loss=1.054, Time=0.025
Epoch 781: at batch 1: Loss=1.041, Time=0.022
Epoch 781: Time=42.417, Epoch time = 0.022, Avg epoch time=0.000

[[1.08554173]
 [1.02596045]
 [1.08554173]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 782: at batch 1: Loss=1.013, Time=0.025
Epoch 783: at batch 1: Loss=1.031, Time=0.021
Epoch 784: at batch 1: Loss=1.051, Time=0.023
Epoch 785: at batch 1: Loss=1.088, Time=0.025
Epoch 786: at batch 1: Loss=1.075, Time=0.026
Epoch 787: at batch 1: Loss=1.119, Time=0.024
Epoch 788: at batch 1: Loss=1.132, Time=0.026
Epoch 789: at batch 1: Loss=1.100, Time=0.026
Epoch 790: at batch 1: Loss=1.074, Time=0.023
Epoch 791: at batch 1: Loss=1.080, Time=0.024
Epoch 791: Time=42.941, Epoch time = 0.024, Avg epoch time=0.000

[[1.08307707]
 [1.08307707]
 [1.07972145]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 792: at batch 1: Loss=1.080, Time=0.022
Epoch 793: at batch 1: Loss=1.015, Time=0.024
Epoch 794: at batch 1: Loss=1.054, Time=0.022
Epoch 795: at batch 1: Loss=1.126, Time=0.031
Epoch 796: at batch 1: Loss=1.054, Time=0.022
Epoch 797: at batch 1: Loss=1.417, Time=0.022
Epoch 798: at batch 1: Loss=1.324, Time=0.027
Epoch 799: at batch 1: Loss=1.213, Time=0.022
Epoch 800: at batch 1: Loss=1.403, Time=0.025
Epoch 801: at batch 1: Loss=1.207, Time=0.026
Epoch 801: Time=43.478, Epoch time = 0.026, Avg epoch time=0.000

[[1.0129559]
 [1.0129559]
 [1.0129559]
 ...
 [0.       ]
 [0.       ]
 [0.       ]]
^CTraceback (most recent call last):
  File "simple_batched_numpy.py", line 362, in <module>
    saver.save(sess, checkpoint_dir + 'model.ckpt')
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/training/saver.py", line 1458, in save
    meta_graph_filename, strip_default_attrs=strip_default_attrs)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/training/saver.py", line 1503, in export_meta_graph
    strip_default_attrs=strip_default_attrs)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/training/saver.py", line 1792, in export_meta_graph
    **kwargs)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/framework/meta_graph.py", line 1007, in export_scoped_meta_graph
    as_text=as_text)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/framework/graph_io.py", line 73, in write_graph
    file_io.atomic_write_string_to_file(path, graph_def.SerializeToString())
KeyboardInterrupt
(sid2) [ir967@gr020 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy.py 
(sid2) [ir967@gr020 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py 




Found 161 images to train with

Training on 161 images only

2020-12-11 17:15:04.880899: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 17:15:05.017995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:86:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 17:15:05.018028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 17:15:05.303535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 17:15:05.303574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 17:15:05.303595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 17:15:05.303700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5)

Loaded ./gt_Sony_simple_ReLU_BN_batched_new/model.ckpt

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 800
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.87565, 0.00000, 300.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01648, 100.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00164, 300.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00190, 250.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.02266, 300.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00467, 100.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00886, 300.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00233, 250.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00016, 300.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00613, 100.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00012, 250.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00117, 100.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00146, 250.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00307, 250.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00003, 100.00000, 6735543
rawpy read the 20th file at location: ./dataset/Sony/long/00072_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00003, 100.00000, 7298885
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00143, 250.00000, 1272259
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 142725
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00466, 250.00000, 822369
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00012, 100.00000, 2983955
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00123, 100.00000, 2393979
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.03307, 300.00000, 2641491
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00003, 100.00000, 1597850
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 100.00000, 1430113
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
rawpy read the 30th file at location: ./dataset/Sony/long/00039_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.07940, 100.00000, 535
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00247, 300.00000, 2877047
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00027, 300.00000, 271135
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 11918285
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00060, 100.00000, 3901
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 300.00000, 684739
rawpy read the 40th file at location: ./dataset/Sony/long/00200_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00299, 100.00000, 1458719
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.01101, 100.00000, 1212279
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00257, 100.00000, 2952517
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00235, 100.00000, 158803
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00168, 250.00000, 2486907
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00202, 250.00000, 7900835
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00005, 300.00000, 4543563
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.05083, 100.00000, 3437
rawpy read the 50th file at location: ./dataset/Sony/long/00024_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00048, 300.00000, 33748
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00346, 300.00000, 3626303
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01253, 300.00000, 304767
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00059, 250.00000, 5644
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00062, 250.00000, 4526
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00007, 300.00000, 11755519
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00016, 100.00000, 2512821
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01871, 250.00000, 2025
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00338, 250.00000, 5557479
rawpy read the 60th file at location: ./dataset/Sony/long/00084_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00375, 100.00000, 67803
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00228, 100.00000, 103
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 300.00000, 1696711
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00688, 100.00000, 2302635
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00053, 250.00000, 1589659
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00674, 250.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00517, 300.00000, 3437411
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.01027, 100.00000, 1033619
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00001, 100.00000, 742143
rawpy read the 70th file at location: ./dataset/Sony/long/00164_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00444, 100.00000, 509891
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 433279
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00114, 100.00000, 6156358
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00004, 100.00000, 2110981
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00090, 100.00000, 277500
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.02923, 100.00000, 646472
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00062, 100.00000, 5676651
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 100.00000, 7066147
rawpy read the 80th file at location: ./dataset/Sony/long/00128_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00313, 300.00000, 4421929
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.01822, 300.00000, 489052
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00000, 100.00000, 10328681
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00124, 300.00000, 2198927
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00009, 300.00000, 5346741
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00147, 250.00000, 646955
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00084, 100.00000, 3032047
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00608, 250.00000, 1407
rawpy read the 90th file at location: ./dataset/Sony/long/00057_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00013, 100.00000, 6606155
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00027, 250.00000, 353239
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00075, 250.00000, 877649
min, max, mean, gamma, argmax: 0.00000, 0.00288, 0.00000, 100.00000, 810977
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 4792466
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00044, 300.00000, 3173995
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00212, 250.00000, 3012800
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00086, 250.00000, 732975
rawpy read the 100th file at location: ./dataset/Sony/long/00059_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01514, 300.00000, 5126389
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 250.00000, 221629
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 895895
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00090, 250.00000, 121547
min, max, mean, gamma, argmax: 0.00000, 0.95669, 0.00000, 100.00000, 6694829
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 2019203
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00108, 250.00000, 2924589
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 6922649
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00182, 250.00000, 8237
rawpy read the 110th file at location: ./dataset/Sony/long/00026_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00099, 250.00000, 255039
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00766, 300.00000, 3862619
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00162, 250.00000, 27523
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00467, 100.00000, 4373627
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00196, 300.00000, 6454
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00032, 300.00000, 4246091
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00139, 100.00000, 952285
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00499, 100.00000, 2253
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
rawpy read the 120th file at location: ./dataset/Sony/long/00012_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 300.00000, 6320171
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00034, 300.00000, 8352977
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00176, 300.00000, 2730987
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 300.00000, 830169
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00216, 300.00000, 106691
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00781, 250.00000, 2536575
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 6777631
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
rawpy read the 130th file at location: ./dataset/Sony/long/00090_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00265, 250.00000, 6265
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 250.00000, 9536203
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00981, 100.00000, 1211799
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00000, 100.00000, 1962014
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00124, 250.00000, 1095547
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00110, 100.00000, 208955
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00497, 250.00000, 1787501
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00048, 100.00000, 2237695
rawpy read the 140th file at location: ./dataset/Sony/long/00114_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00015, 250.00000, 2570045
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00002, 250.00000, 4933369
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00017, 300.00000, 2972
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00016, 100.00000, 8615375
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.06347, 100.00000, 1502619
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00151, 100.00000, 1940733
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00007, 250.00000, 8449
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00083, 100.00000, 506409
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
rawpy read the 150th file at location: ./dataset/Sony/long/00156_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00804, 300.00000, 2309
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00131, 300.00000, 1993235
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.03645, 250.00000, 2694439
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00922, 250.00000, 2353163
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00030, 250.00000, 2700797
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.01503, 100.00000, 7293
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00021, 300.00000, 581525
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00004, 250.00000, 4860611
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00430, 100.00000, 5285
rawpy read the 160th file at location: ./dataset/Sony/long/00219_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
161 images loaded to CPU RAM in Time=52.855 seconds.

moved images data to numpy array
Epoch 801: at batch 1: Loss=1.152, Time=1.064
Epoch 801: Time=1.363, Epoch time = 1.363, Avg epoch time=0.000

[[0.        ]
 [1.08891547]
 [1.14527082]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 802: at batch 1: Loss=1.133, Time=0.026
Epoch 803: at batch 1: Loss=1.162, Time=0.029
Epoch 804: at batch 1: Loss=1.140, Time=0.025
Epoch 805: at batch 1: Loss=1.121, Time=0.022
Epoch 806: at batch 1: Loss=1.105, Time=0.025
Epoch 807: at batch 1: Loss=1.112, Time=0.026
Epoch 808: at batch 1: Loss=1.102, Time=0.033
Epoch 809: at batch 1: Loss=1.156, Time=0.023
Epoch 810: at batch 1: Loss=1.118, Time=0.025
Epoch 811: at batch 1: Loss=1.152, Time=0.027
Epoch 811: Time=4.636, Epoch time = 0.304, Avg epoch time=0.000

[[1.16821635]
 [1.09861231]
 [1.10237539]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 812: at batch 1: Loss=1.149, Time=0.024
Epoch 813: at batch 1: Loss=1.120, Time=0.024
Epoch 814: at batch 1: Loss=1.116, Time=0.021
Epoch 815: at batch 1: Loss=1.104, Time=0.025
Epoch 816: at batch 1: Loss=1.108, Time=0.024
Epoch 817: at batch 1: Loss=1.099, Time=0.030
Epoch 818: at batch 1: Loss=1.131, Time=0.025
Epoch 819: at batch 1: Loss=1.097, Time=0.024
Epoch 820: at batch 1: Loss=1.111, Time=0.034
Epoch 821: at batch 1: Loss=1.146, Time=0.025
Epoch 821: Time=8.003, Epoch time = 0.317, Avg epoch time=0.000

[[1.09728789]
 [1.18038297]
 [1.03855574]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 822: at batch 1: Loss=1.138, Time=0.025
Epoch 823: at batch 1: Loss=1.127, Time=0.025
Epoch 824: at batch 1: Loss=1.104, Time=0.024
Epoch 825: at batch 1: Loss=1.100, Time=0.024
Epoch 826: at batch 1: Loss=1.097, Time=0.028
Epoch 827: at batch 1: Loss=1.092, Time=0.025
Epoch 828: at batch 1: Loss=1.153, Time=0.022
Epoch 829: at batch 1: Loss=1.131, Time=0.033
Epoch 830: at batch 1: Loss=1.124, Time=0.025
Epoch 831: at batch 1: Loss=1.114, Time=0.025
Epoch 831: Time=11.318, Epoch time = 0.304, Avg epoch time=0.000

[[1.09861231]
 [0.98232716]
 [1.11085963]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 832: at batch 1: Loss=1.107, Time=0.025
Epoch 833: at batch 1: Loss=1.102, Time=0.024
Epoch 834: at batch 1: Loss=1.106, Time=0.024
Epoch 835: at batch 1: Loss=1.125, Time=0.023
Epoch 836: at batch 1: Loss=1.108, Time=0.023
Epoch 837: at batch 1: Loss=1.123, Time=0.025
Epoch 838: at batch 1: Loss=1.094, Time=0.022
Epoch 839: at batch 1: Loss=1.107, Time=0.024
Epoch 840: at batch 1: Loss=1.144, Time=0.024
Epoch 841: at batch 1: Loss=1.112, Time=0.025
Epoch 841: Time=14.631, Epoch time = 0.299, Avg epoch time=0.000

[[1.12706566]
 [1.10619617]
 [1.24666131]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 842: at batch 1: Loss=1.120, Time=0.021
Epoch 843: at batch 1: Loss=1.122, Time=0.025
Epoch 844: at batch 1: Loss=1.103, Time=0.027
Epoch 845: at batch 1: Loss=1.109, Time=0.024
Epoch 846: at batch 1: Loss=1.126, Time=0.024
Epoch 847: at batch 1: Loss=1.108, Time=0.025
Epoch 848: at batch 1: Loss=1.106, Time=0.022
Epoch 849: at batch 1: Loss=1.093, Time=0.033
Epoch 850: at batch 1: Loss=1.098, Time=0.022
Epoch 851: at batch 1: Loss=1.128, Time=0.030
Epoch 851: Time=17.946, Epoch time = 0.302, Avg epoch time=0.000

[[1.07244921]
 [1.09861231]
 [1.00657332]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 852: at batch 1: Loss=1.110, Time=0.025
Epoch 853: at batch 1: Loss=1.099, Time=0.026
Epoch 854: at batch 1: Loss=1.120, Time=0.024
Epoch 855: at batch 1: Loss=1.098, Time=0.035
Epoch 856: at batch 1: Loss=1.099, Time=0.025
Epoch 857: at batch 1: Loss=1.123, Time=0.025
Epoch 858: at batch 1: Loss=1.122, Time=0.034
Epoch 859: at batch 1: Loss=1.081, Time=0.027
Epoch 860: at batch 1: Loss=1.096, Time=0.022
Epoch 861: at batch 1: Loss=1.141, Time=0.027
Epoch 861: Time=21.290, Epoch time = 0.300, Avg epoch time=0.000

[[1.29656732]
 [1.08679676]
 [1.08948016]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 862: at batch 1: Loss=1.131, Time=0.027
Epoch 863: at batch 1: Loss=1.146, Time=0.024
Epoch 864: at batch 1: Loss=1.115, Time=0.024
Epoch 865: at batch 1: Loss=1.157, Time=0.021
Epoch 866: at batch 1: Loss=1.136, Time=0.031
Epoch 867: at batch 1: Loss=1.104, Time=0.024
Epoch 868: at batch 1: Loss=1.116, Time=0.025
Epoch 869: at batch 1: Loss=1.122, Time=0.026
Epoch 870: at batch 1: Loss=1.104, Time=0.032
Epoch 871: at batch 1: Loss=1.109, Time=0.022
Epoch 871: Time=24.556, Epoch time = 0.271, Avg epoch time=0.000

[[1.20644784]
 [1.09861231]
 [1.09875989]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 872: at batch 1: Loss=1.127, Time=0.027
Epoch 873: at batch 1: Loss=1.116, Time=0.023
Epoch 874: at batch 1: Loss=1.164, Time=0.026
Epoch 875: at batch 1: Loss=1.136, Time=0.024
Epoch 876: at batch 1: Loss=1.176, Time=0.034
Epoch 877: at batch 1: Loss=1.148, Time=0.023
Epoch 878: at batch 1: Loss=1.111, Time=0.022
Epoch 879: at batch 1: Loss=1.115, Time=0.023
Epoch 880: at batch 1: Loss=1.151, Time=0.022
Epoch 881: at batch 1: Loss=1.138, Time=0.027
Epoch 881: Time=27.762, Epoch time = 0.277, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.10447454]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 882: at batch 1: Loss=1.121, Time=0.035
Epoch 883: at batch 1: Loss=1.122, Time=0.025
Epoch 884: at batch 1: Loss=1.113, Time=0.026
Epoch 885: at batch 1: Loss=1.094, Time=0.024
Epoch 886: at batch 1: Loss=1.136, Time=0.036
Epoch 887: at batch 1: Loss=1.120, Time=0.033
Epoch 888: at batch 1: Loss=1.104, Time=0.024
Epoch 889: at batch 1: Loss=1.103, Time=0.024
Epoch 890: at batch 1: Loss=1.087, Time=0.024
Epoch 891: at batch 1: Loss=1.116, Time=0.025
Epoch 891: Time=31.071, Epoch time = 0.288, Avg epoch time=0.000

[[1.22029734]
 [1.18681955]
 [1.10151601]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 892: at batch 1: Loss=1.124, Time=0.023
Epoch 893: at batch 1: Loss=1.110, Time=0.027
^CTraceback (most recent call last):
  File "simple_batched_numpy.py", line 323, in <module>
    feed_dict={in_image: input_patch, gt_gamma: assigned_image_gamma_index, lr: learning_rate})
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 887, in run
    run_metadata_ptr)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1110, in _run
    feed_dict_tensor, options, run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1286, in _do_run
    run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1292, in _do_call
    return fn(*args)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1277, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1367, in _call_tf_sessionrun
    run_metadata)
KeyboardInterrupt
(sid2) [ir967@gr020 Learning-to-See-in-the-Dark]$ srun: Force Terminated job 402169
slurmstepd: error: *** STEP 402169.0 ON gr020-ib0 CANCELLED AT 2020-12-11T17:18:40 DUE TO TIME LIMIT ***
exit
srun: error: gr020-ib0: task 0: Exited with exit code 1
srun: Terminating job step 402169.0
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ srun -t0:12:00 --mem=18460 --gres=gpu:1 --pty /bin/bash
(base) [ir967@gr020 Learning-to-See-in-the-Dark]$ cd $SCRATCH/SID
(base) [ir967@gr020 SID]$ cd Learning-to-See-in-the-Dark/
(base) [ir967@gr020 Learning-to-See-in-the-Dark]$ conda activate sid2
(sid2) [ir967@gr020 Learning-to-See-in-the-Dark]$ vi simple_
simple_batched_numpy.py  simple_batched.py        simple_ReLU_BN_Sony.py   simple_ReLU_Sony.py
(sid2) [ir967@gr020 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy.py 
(sid2) [ir967@gr020 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py 




Found 161 images to train with

Training on 161 images only

2020-12-11 17:19:47.013722: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 17:19:47.150653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:86:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 17:19:47.150687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 17:19:47.434952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 17:19:47.434990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 17:19:47.435015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 17:19:47.435122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5)

Loaded ./gt_Sony_simple_ReLU_BN_batched_new/model.ckpt

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 890
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95669, 0.00000, 100.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01633, 250.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 100.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00190, 250.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.02465, 100.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00417, 300.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00887, 250.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00233, 250.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 100.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 250.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00012, 100.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 300.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00144, 300.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00301, 300.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00003, 100.00000, 6735543
rawpy read the 20th file at location: ./dataset/Sony/long/00072_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00003, 100.00000, 7298885
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00143, 250.00000, 1272259
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00000, 100.00000, 142725
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00456, 300.00000, 822369
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00011, 300.00000, 2983955
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00116, 250.00000, 2393979
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.03307, 300.00000, 2641491
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00003, 250.00000, 1597850
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 300.00000, 1430113
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
rawpy read the 30th file at location: ./dataset/Sony/long/00039_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.07940, 100.00000, 535
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00249, 100.00000, 2877047
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00027, 100.00000, 271135
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 11918285
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00056, 300.00000, 3901
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 100.00000, 684739
rawpy read the 40th file at location: ./dataset/Sony/long/00200_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00246, 250.00000, 1458719
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00998, 250.00000, 1212279
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00257, 100.00000, 2952517
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00215, 300.00000, 158803
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00179, 100.00000, 2486907
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00202, 250.00000, 7900835
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00007, 100.00000, 4543563
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.05081, 300.00000, 3437
rawpy read the 50th file at location: ./dataset/Sony/long/00024_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00048, 250.00000, 33748
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00346, 300.00000, 3626303
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01253, 300.00000, 304767
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00063, 100.00000, 5644
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00062, 300.00000, 4526
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00007, 250.00000, 11755519
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00012, 250.00000, 2512821
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01871, 250.00000, 2025
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00338, 300.00000, 5557479
rawpy read the 60th file at location: ./dataset/Sony/long/00084_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00347, 250.00000, 67803
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00210, 300.00000, 103
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 250.00000, 1696711
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00637, 250.00000, 2302635
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00054, 100.00000, 1589659
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00661, 300.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00517, 300.00000, 3437411
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00969, 250.00000, 1033619
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00001, 300.00000, 742143
rawpy read the 70th file at location: ./dataset/Sony/long/00164_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00419, 250.00000, 509891
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 433279
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00106, 250.00000, 6156358
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00004, 100.00000, 2110981
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00084, 300.00000, 277500
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.02923, 100.00000, 646472
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00057, 300.00000, 5676651
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 100.00000, 7066147
rawpy read the 80th file at location: ./dataset/Sony/long/00128_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00320, 250.00000, 4421929
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.01853, 250.00000, 489052
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00000, 100.00000, 10328681
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00127, 250.00000, 2198927
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00012, 100.00000, 5346741
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00156, 100.00000, 646955
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00084, 100.00000, 3032047
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00596, 300.00000, 1407
rawpy read the 90th file at location: ./dataset/Sony/long/00057_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00013, 100.00000, 6606155
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00028, 100.00000, 353239
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00075, 300.00000, 877649
min, max, mean, gamma, argmax: 0.00000, 0.00288, 0.00000, 100.00000, 810977
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 4792466
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00045, 250.00000, 3173995
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00212, 250.00000, 3012800
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00086, 250.00000, 732975
rawpy read the 100th file at location: ./dataset/Sony/long/00059_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01514, 300.00000, 5126389
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 250.00000, 221629
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00000, 100.00000, 895895
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00090, 250.00000, 121547
min, max, mean, gamma, argmax: 0.00000, 0.87565, 0.00000, 300.00000, 6694829
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 2019203
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00114, 100.00000, 2924589
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 6922649
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00182, 250.00000, 8237
rawpy read the 110th file at location: ./dataset/Sony/long/00026_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00099, 300.00000, 255039
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00826, 100.00000, 3862619
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00162, 300.00000, 27523
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00438, 250.00000, 4373627
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00212, 100.00000, 6454
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00032, 100.00000, 4246091
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00131, 250.00000, 952285
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00472, 250.00000, 2253
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
rawpy read the 120th file at location: ./dataset/Sony/long/00012_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 300.00000, 6320171
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00037, 100.00000, 8352977
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00180, 250.00000, 2730987
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 100.00000, 830169
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00217, 250.00000, 106691
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00767, 300.00000, 2536575
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 6777631
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
rawpy read the 130th file at location: ./dataset/Sony/long/00090_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00260, 300.00000, 6265
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00000, 250.00000, 9536203
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00905, 300.00000, 1211799
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 1962014
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00132, 100.00000, 1095547
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00109, 250.00000, 208955
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00488, 300.00000, 1787501
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00045, 250.00000, 2237695
rawpy read the 140th file at location: ./dataset/Sony/long/00114_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00015, 300.00000, 2570045
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00002, 250.00000, 4933369
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00018, 100.00000, 2972
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00016, 100.00000, 8615375
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.06347, 100.00000, 1502619
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00135, 250.00000, 1940733
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00007, 100.00000, 8449
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00083, 100.00000, 506409
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
rawpy read the 150th file at location: ./dataset/Sony/long/00156_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00819, 250.00000, 2309
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00134, 250.00000, 1993235
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.03581, 300.00000, 2694439
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00922, 250.00000, 2353163
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00030, 300.00000, 2700797
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.01375, 300.00000, 7293
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00021, 300.00000, 581525
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00004, 100.00000, 4860611
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00320, 300.00000, 5285
rawpy read the 160th file at location: ./dataset/Sony/long/00219_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
161 images loaded to CPU RAM in Time=47.183 seconds.

moved images data to numpy array
Traceback (most recent call last):
  File "simple_batched_numpy.py", line 298, in <module>
    input_patch = np.array(BATCH_SIZE, ps, ps, D)
ValueError: only 2 non-keyword arguments accepted
(sid2) [ir967@gr020 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy.py 
(sid2) [ir967@gr020 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py 




Found 161 images to train with

Training on 32 images only

2020-12-11 17:22:07.615547: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 17:22:07.751406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:86:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 17:22:07.751442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 17:22:08.036369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 17:22:08.036412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 17:22:08.036434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 17:22:08.036534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5)

Loaded ./gt_Sony_simple_ReLU_BN_batched_new/model.ckpt

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 890
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95669, 0.00000, 100.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01648, 100.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 100.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00190, 250.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.02465, 100.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00427, 250.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00894, 100.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00248, 100.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00016, 300.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 300.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00012, 300.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00117, 100.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00155, 100.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00327, 100.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00003, 100.00000, 6735543
rawpy read the 20th file at location: ./dataset/Sony/long/00072_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00003, 300.00000, 7298885
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00141, 300.00000, 1272259
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00000, 100.00000, 142725
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00456, 300.00000, 822369
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00011, 300.00000, 2983955
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00114, 300.00000, 2393979
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.03574, 100.00000, 2641491
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00003, 250.00000, 1597850
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 250.00000, 1430113
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
rawpy read the 30th file at location: ./dataset/Sony/long/00039_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.07940, 100.00000, 535
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
32 images loaded to CPU RAM in Time=9.320 seconds.

moved images data to numpy array
Epoch 891: at batch 1: Loss=1.082, Time=1.090
Epoch 891: Time=1.126, Epoch time = 1.126, Avg epoch time=0.000

[[1.08213353]
 [0.        ]
 [1.04016924]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 892: at batch 1: Loss=1.080, Time=0.029
Epoch 893: at batch 1: Loss=1.092, Time=0.028
Epoch 894: at batch 1: Loss=1.099, Time=0.034
Epoch 895: at batch 1: Loss=1.122, Time=0.023
Epoch 896: at batch 1: Loss=1.096, Time=0.023
Epoch 897: at batch 1: Loss=1.090, Time=0.023
Epoch 898: at batch 1: Loss=1.113, Time=0.029
Epoch 899: at batch 1: Loss=1.088, Time=0.033
Epoch 900: at batch 1: Loss=1.098, Time=0.041
Epoch 901: at batch 1: Loss=1.281, Time=0.029
Epoch 901: Time=2.023, Epoch time = 0.064, Avg epoch time=0.000

[[1.0821867 ]
 [1.05760932]
 [1.05760932]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 902: at batch 1: Loss=1.086, Time=0.028
Epoch 903: at batch 1: Loss=1.104, Time=0.030
Epoch 904: at batch 1: Loss=1.054, Time=0.025
Epoch 905: at batch 1: Loss=1.154, Time=0.032
Epoch 906: at batch 1: Loss=1.108, Time=0.024
Epoch 907: at batch 1: Loss=1.120, Time=0.024
Epoch 908: at batch 1: Loss=1.143, Time=0.028
Epoch 909: at batch 1: Loss=1.184, Time=0.030
Epoch 910: at batch 1: Loss=1.145, Time=0.024
Epoch 911: at batch 1: Loss=1.094, Time=0.030
Epoch 911: Time=2.872, Epoch time = 0.060, Avg epoch time=0.000

[[1.08875585]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 912: at batch 1: Loss=1.072, Time=0.024
Epoch 913: at batch 1: Loss=1.129, Time=0.033
Epoch 914: at batch 1: Loss=1.079, Time=0.032
Epoch 915: at batch 1: Loss=1.058, Time=0.032
Epoch 916: at batch 1: Loss=1.084, Time=0.043
Epoch 917: at batch 1: Loss=1.243, Time=0.027
Epoch 918: at batch 1: Loss=1.146, Time=0.031
Epoch 919: at batch 1: Loss=1.152, Time=0.033
Epoch 920: at batch 1: Loss=1.134, Time=0.031
Epoch 921: at batch 1: Loss=1.080, Time=0.022
Epoch 921: Time=3.780, Epoch time = 0.051, Avg epoch time=0.000

[[1.09861231]
 [1.02557099]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 922: at batch 1: Loss=1.072, Time=0.029
Epoch 923: at batch 1: Loss=1.070, Time=0.026
Epoch 924: at batch 1: Loss=1.103, Time=0.042
Epoch 925: at batch 1: Loss=1.087, Time=0.030
Epoch 926: at batch 1: Loss=1.158, Time=0.025
Epoch 927: at batch 1: Loss=1.150, Time=0.030
Epoch 928: at batch 1: Loss=1.271, Time=0.023
Epoch 929: at batch 1: Loss=1.170, Time=0.031
Epoch 930: at batch 1: Loss=1.101, Time=0.033
Epoch 931: at batch 1: Loss=1.082, Time=0.022
Epoch 931: Time=4.672, Epoch time = 0.056, Avg epoch time=0.000

[[1.13310051]
 [1.14023483]
 [1.11472797]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 932: at batch 1: Loss=1.087, Time=0.032
Epoch 933: at batch 1: Loss=1.083, Time=0.032
Epoch 934: at batch 1: Loss=1.085, Time=0.039
Epoch 935: at batch 1: Loss=1.175, Time=0.024
Epoch 936: at batch 1: Loss=1.134, Time=0.025
Epoch 937: at batch 1: Loss=1.102, Time=0.029
Epoch 938: at batch 1: Loss=1.102, Time=0.026
Epoch 939: at batch 1: Loss=1.066, Time=0.034
Epoch 940: at batch 1: Loss=1.132, Time=0.026
Epoch 941: at batch 1: Loss=1.120, Time=0.024
Epoch 941: Time=5.588, Epoch time = 0.062, Avg epoch time=0.000

[[1.09861231]
 [1.06503689]
 [1.28100848]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 942: at batch 1: Loss=1.106, Time=0.023
Epoch 943: at batch 1: Loss=1.004, Time=0.021
Epoch 944: at batch 1: Loss=1.089, Time=0.024
Epoch 945: at batch 1: Loss=1.099, Time=0.032
Epoch 946: at batch 1: Loss=1.108, Time=0.030
Epoch 947: at batch 1: Loss=1.096, Time=0.031
Epoch 948: at batch 1: Loss=1.076, Time=0.027
Epoch 949: at batch 1: Loss=1.113, Time=0.023
Epoch 950: at batch 1: Loss=1.074, Time=0.029
Epoch 951: at batch 1: Loss=1.059, Time=0.033
Epoch 951: Time=6.446, Epoch time = 0.065, Avg epoch time=0.000

[[1.06174755]
 [0.98303169]
 [1.06174755]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 952: at batch 1: Loss=1.071, Time=0.029
Epoch 953: at batch 1: Loss=1.064, Time=0.032
Epoch 954: at batch 1: Loss=1.096, Time=0.031
Epoch 955: at batch 1: Loss=1.152, Time=0.025
Epoch 956: at batch 1: Loss=1.144, Time=0.027
Epoch 957: at batch 1: Loss=1.117, Time=0.025
Epoch 958: at batch 1: Loss=1.033, Time=0.028
Epoch 959: at batch 1: Loss=1.059, Time=0.022
Epoch 960: at batch 1: Loss=1.079, Time=0.031
Epoch 961: at batch 1: Loss=1.038, Time=0.024
Epoch 961: Time=7.306, Epoch time = 0.053, Avg epoch time=0.000

[[1.04275417]
 [1.10374594]
 [0.95476186]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 962: at batch 1: Loss=1.098, Time=0.022
Epoch 963: at batch 1: Loss=1.135, Time=0.037
Epoch 964: at batch 1: Loss=1.071, Time=0.024
Epoch 965: at batch 1: Loss=1.052, Time=0.028
Epoch 966: at batch 1: Loss=1.083, Time=0.024
Epoch 967: at batch 1: Loss=1.095, Time=0.032
Epoch 968: at batch 1: Loss=1.093, Time=0.026
Epoch 969: at batch 1: Loss=1.105, Time=0.024
Epoch 970: at batch 1: Loss=1.127, Time=0.040
Epoch 971: at batch 1: Loss=1.137, Time=0.025
Epoch 971: Time=8.192, Epoch time = 0.056, Avg epoch time=0.000

[[1.09902954]
 [1.07456291]
 [1.09902954]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 972: at batch 1: Loss=0.989, Time=0.027
Epoch 973: at batch 1: Loss=1.034, Time=0.031
Epoch 974: at batch 1: Loss=1.121, Time=0.033
Epoch 975: at batch 1: Loss=1.076, Time=0.029
Epoch 976: at batch 1: Loss=1.133, Time=0.024
Epoch 977: at batch 1: Loss=1.114, Time=0.024
Epoch 978: at batch 1: Loss=1.099, Time=0.034
Epoch 979: at batch 1: Loss=1.066, Time=0.032
Epoch 980: at batch 1: Loss=1.001, Time=0.027
Epoch 981: at batch 1: Loss=1.059, Time=0.039
Epoch 981: Time=9.096, Epoch time = 0.074, Avg epoch time=0.000

[[1.09861231]
 [1.03590393]
 [1.04315329]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 982: at batch 1: Loss=1.048, Time=0.030
Epoch 983: at batch 1: Loss=1.131, Time=0.030
Epoch 984: at batch 1: Loss=1.082, Time=0.025
Epoch 985: at batch 1: Loss=1.092, Time=0.024
Epoch 986: at batch 1: Loss=1.084, Time=0.031
Epoch 987: at batch 1: Loss=1.134, Time=0.023
Epoch 988: at batch 1: Loss=1.058, Time=0.030
Epoch 989: at batch 1: Loss=0.995, Time=0.028
Epoch 990: at batch 1: Loss=1.110, Time=0.030
Epoch 991: at batch 1: Loss=1.093, Time=0.032
Epoch 991: Time=9.968, Epoch time = 0.060, Avg epoch time=0.000

[[1.21316779]
 [1.06600499]
 [1.19615138]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 992: at batch 1: Loss=1.093, Time=0.022
Epoch 993: at batch 1: Loss=1.135, Time=0.023
Epoch 994: at batch 1: Loss=1.110, Time=0.032
Epoch 995: at batch 1: Loss=1.072, Time=0.027
Epoch 996: at batch 1: Loss=1.054, Time=0.030
Epoch 997: at batch 1: Loss=1.199, Time=0.023
Epoch 998: at batch 1: Loss=1.093, Time=0.028
Epoch 999: at batch 1: Loss=1.056, Time=0.023
Epoch 1000: at batch 1: Loss=1.082, Time=0.023
Epoch 1001: at batch 1: Loss=1.084, Time=0.034
Epoch 1001: Time=10.797, Epoch time = 0.062, Avg epoch time=0.000

[[1.09100342]
 [1.08975983]
 [1.09100342]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1002: at batch 1: Loss=1.103, Time=0.032
Epoch 1003: at batch 1: Loss=1.097, Time=0.029
Epoch 1004: at batch 1: Loss=1.056, Time=0.029
Epoch 1005: at batch 1: Loss=1.089, Time=0.030
Epoch 1006: at batch 1: Loss=1.057, Time=0.030
Epoch 1007: at batch 1: Loss=1.090, Time=0.029
Epoch 1008: at batch 1: Loss=1.063, Time=0.031
Epoch 1009: at batch 1: Loss=1.115, Time=0.032
Epoch 1010: at batch 1: Loss=1.089, Time=0.037
Epoch 1011: at batch 1: Loss=1.062, Time=0.028
Epoch 1011: Time=11.687, Epoch time = 0.060, Avg epoch time=0.000

[[1.08540535]
 [1.09098172]
 [0.98101783]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1012: at batch 1: Loss=1.047, Time=0.032
Epoch 1013: at batch 1: Loss=1.099, Time=0.029
Epoch 1014: at batch 1: Loss=1.196, Time=0.031
Epoch 1015: at batch 1: Loss=1.133, Time=0.026
Epoch 1016: at batch 1: Loss=1.140, Time=0.029
Epoch 1017: at batch 1: Loss=1.112, Time=0.032
Epoch 1018: at batch 1: Loss=1.082, Time=0.039
Epoch 1019: at batch 1: Loss=1.057, Time=0.027
Epoch 1020: at batch 1: Loss=1.018, Time=0.025
Epoch 1021: at batch 1: Loss=1.027, Time=0.028
Epoch 1021: Time=12.578, Epoch time = 0.052, Avg epoch time=0.000

[[1.1736412]
 [1.0305891]
 [1.1736412]
 ...
 [0.       ]
 [0.       ]
 [0.       ]]
Epoch 1022: at batch 1: Loss=1.051, Time=0.030
Epoch 1023: at batch 1: Loss=1.065, Time=0.029
Epoch 1024: at batch 1: Loss=1.034, Time=0.027
Epoch 1025: at batch 1: Loss=1.006, Time=0.023
Epoch 1026: at batch 1: Loss=1.084, Time=0.023
Epoch 1027: at batch 1: Loss=1.035, Time=0.029
Epoch 1028: at batch 1: Loss=1.067, Time=0.022
Epoch 1029: at batch 1: Loss=1.041, Time=0.026
Epoch 1030: at batch 1: Loss=1.036, Time=0.027
Epoch 1031: at batch 1: Loss=1.036, Time=0.026
Epoch 1031: Time=13.403, Epoch time = 0.051, Avg epoch time=0.000

[[1.01302004]
 [1.01454377]
 [1.01302004]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1032: at batch 1: Loss=1.041, Time=0.026
Epoch 1033: at batch 1: Loss=1.109, Time=0.022
Epoch 1034: at batch 1: Loss=1.176, Time=0.022
Epoch 1035: at batch 1: Loss=1.114, Time=0.038
Epoch 1036: at batch 1: Loss=1.043, Time=0.023
Epoch 1037: at batch 1: Loss=1.117, Time=0.027
Epoch 1038: at batch 1: Loss=1.095, Time=0.025
Epoch 1039: at batch 1: Loss=1.132, Time=0.022
Epoch 1040: at batch 1: Loss=1.136, Time=0.030
Epoch 1041: at batch 1: Loss=1.096, Time=0.028
Epoch 1041: Time=14.260, Epoch time = 0.059, Avg epoch time=0.000

[[1.00314581]
 [0.91342294]
 [0.91342294]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1042: at batch 1: Loss=1.054, Time=0.021
Epoch 1043: at batch 1: Loss=1.075, Time=0.027
Epoch 1044: at batch 1: Loss=1.087, Time=0.032
Epoch 1045: at batch 1: Loss=1.103, Time=0.032
Epoch 1046: at batch 1: Loss=1.043, Time=0.031
Epoch 1047: at batch 1: Loss=1.172, Time=0.027
Epoch 1048: at batch 1: Loss=1.134, Time=0.029
Epoch 1049: at batch 1: Loss=1.044, Time=0.030
Epoch 1050: at batch 1: Loss=1.083, Time=0.023
Epoch 1051: at batch 1: Loss=1.028, Time=0.026
Epoch 1051: Time=15.110, Epoch time = 0.054, Avg epoch time=0.000

[[1.10907626]
 [0.98200381]
 [1.10907626]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1052: at batch 1: Loss=1.094, Time=0.023
Epoch 1053: at batch 1: Loss=1.091, Time=0.040
Epoch 1054: at batch 1: Loss=1.097, Time=0.023
Epoch 1055: at batch 1: Loss=1.091, Time=0.027
Epoch 1056: at batch 1: Loss=1.082, Time=0.032
Epoch 1057: at batch 1: Loss=1.095, Time=0.029
Epoch 1058: at batch 1: Loss=1.065, Time=0.027
Epoch 1059: at batch 1: Loss=1.033, Time=0.030
Epoch 1060: at batch 1: Loss=1.059, Time=0.028
Epoch 1061: at batch 1: Loss=1.071, Time=0.031
Epoch 1061: Time=15.976, Epoch time = 0.061, Avg epoch time=0.000

[[1.05533195]
 [0.96665817]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1062: at batch 1: Loss=1.088, Time=0.032
Epoch 1063: at batch 1: Loss=1.090, Time=0.027
Epoch 1064: at batch 1: Loss=1.138, Time=0.029
Epoch 1065: at batch 1: Loss=1.015, Time=0.029
Epoch 1066: at batch 1: Loss=1.053, Time=0.024
Epoch 1067: at batch 1: Loss=1.071, Time=0.031
Epoch 1068: at batch 1: Loss=1.106, Time=0.031
Epoch 1069: at batch 1: Loss=1.140, Time=0.027
Epoch 1070: at batch 1: Loss=1.096, Time=0.032
Epoch 1071: at batch 1: Loss=1.105, Time=0.027
Epoch 1071: Time=16.851, Epoch time = 0.059, Avg epoch time=0.000

[[1.2103163]
 [1.2103163]
 [1.2103163]
 ...
 [0.       ]
 [0.       ]
 [0.       ]]
Epoch 1072: at batch 1: Loss=1.088, Time=0.024
Epoch 1073: at batch 1: Loss=1.075, Time=0.023
Epoch 1074: at batch 1: Loss=1.075, Time=0.026
Epoch 1075: at batch 1: Loss=1.083, Time=0.024
Epoch 1076: at batch 1: Loss=1.196, Time=0.027
Epoch 1077: at batch 1: Loss=1.111, Time=0.022
Epoch 1078: at batch 1: Loss=1.144, Time=0.030
Epoch 1079: at batch 1: Loss=1.067, Time=0.022
Epoch 1080: at batch 1: Loss=1.065, Time=0.029
Epoch 1081: at batch 1: Loss=1.032, Time=0.026
Epoch 1081: Time=17.720, Epoch time = 0.065, Avg epoch time=0.000

[[0.97707808]
 [1.07537568]
 [1.02046537]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1082: at batch 1: Loss=1.075, Time=0.031
Epoch 1083: at batch 1: Loss=1.085, Time=0.032
Epoch 1084: at batch 1: Loss=1.098, Time=0.029
Epoch 1085: at batch 1: Loss=1.030, Time=0.027
Epoch 1086: at batch 1: Loss=1.067, Time=0.030
Epoch 1087: at batch 1: Loss=1.108, Time=0.031
Epoch 1088: at batch 1: Loss=1.174, Time=0.039
Epoch 1089: at batch 1: Loss=1.105, Time=0.021
Epoch 1090: at batch 1: Loss=1.078, Time=0.029
Epoch 1091: at batch 1: Loss=1.196, Time=0.033
Epoch 1091: Time=18.610, Epoch time = 0.063, Avg epoch time=0.000

[[1.12020946]
 [0.97262937]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1092: at batch 1: Loss=1.094, Time=0.041
Epoch 1093: at batch 1: Loss=1.090, Time=0.029
Epoch 1094: at batch 1: Loss=1.110, Time=0.021
Epoch 1095: at batch 1: Loss=1.091, Time=0.023
Epoch 1096: at batch 1: Loss=1.082, Time=0.032
Epoch 1097: at batch 1: Loss=1.070, Time=0.026
Epoch 1098: at batch 1: Loss=1.069, Time=0.022
Epoch 1099: at batch 1: Loss=1.049, Time=0.031
Epoch 1100: at batch 1: Loss=1.001, Time=0.025
Epoch 1101: at batch 1: Loss=1.058, Time=0.023
Epoch 1101: Time=19.485, Epoch time = 0.057, Avg epoch time=0.000

[[1.02117383]
 [1.34622145]
 [0.92079753]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1102: at batch 1: Loss=1.134, Time=0.024
Epoch 1103: at batch 1: Loss=1.076, Time=0.029
Epoch 1104: at batch 1: Loss=1.025, Time=0.021
Epoch 1105: at batch 1: Loss=1.066, Time=0.029
Epoch 1106: at batch 1: Loss=1.122, Time=0.028
Epoch 1107: at batch 1: Loss=1.071, Time=0.029
Epoch 1108: at batch 1: Loss=1.088, Time=0.026
Epoch 1109: at batch 1: Loss=1.093, Time=0.026
Epoch 1110: at batch 1: Loss=1.035, Time=0.032
Epoch 1111: at batch 1: Loss=1.011, Time=0.029
Epoch 1111: Time=20.330, Epoch time = 0.054, Avg epoch time=0.000

[[1.01850486]
 [1.15822363]
 [0.99656487]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1112: at batch 1: Loss=1.094, Time=0.023
Epoch 1113: at batch 1: Loss=1.091, Time=0.035
Epoch 1114: at batch 1: Loss=1.073, Time=0.022
Epoch 1115: at batch 1: Loss=1.040, Time=0.031
Epoch 1116: at batch 1: Loss=1.048, Time=0.021
Epoch 1117: at batch 1: Loss=1.092, Time=0.034
Epoch 1118: at batch 1: Loss=1.126, Time=0.031
Epoch 1119: at batch 1: Loss=1.122, Time=0.024
Epoch 1120: at batch 1: Loss=1.038, Time=0.028
Epoch 1121: at batch 1: Loss=1.059, Time=0.029
Epoch 1121: Time=21.209, Epoch time = 0.060, Avg epoch time=0.000

[[0.98829973]
 [0.98946798]
 [0.98946798]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1122: at batch 1: Loss=1.010, Time=0.029
Epoch 1123: at batch 1: Loss=1.086, Time=0.029
Epoch 1124: at batch 1: Loss=1.049, Time=0.023
Epoch 1125: at batch 1: Loss=1.018, Time=0.026
Epoch 1126: at batch 1: Loss=1.086, Time=0.029
Epoch 1127: at batch 1: Loss=1.017, Time=0.028
Epoch 1128: at batch 1: Loss=1.026, Time=0.031
Epoch 1129: at batch 1: Loss=1.056, Time=0.032
Epoch 1130: at batch 1: Loss=1.037, Time=0.027
Epoch 1131: at batch 1: Loss=1.097, Time=0.024
Epoch 1131: Time=22.073, Epoch time = 0.053, Avg epoch time=0.000

[[0.96295464]
 [1.08117771]
 [0.98676002]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1132: at batch 1: Loss=1.079, Time=0.029
Epoch 1133: at batch 1: Loss=1.063, Time=0.026
Epoch 1134: at batch 1: Loss=1.076, Time=0.029
Epoch 1135: at batch 1: Loss=1.096, Time=0.032
Epoch 1136: at batch 1: Loss=1.034, Time=0.029
Epoch 1137: at batch 1: Loss=0.973, Time=0.036
Epoch 1138: at batch 1: Loss=1.049, Time=0.027
Epoch 1139: at batch 1: Loss=1.200, Time=0.030
Epoch 1140: at batch 1: Loss=1.008, Time=0.025
Epoch 1141: at batch 1: Loss=0.966, Time=0.030
Epoch 1141: Time=22.965, Epoch time = 0.057, Avg epoch time=0.000

[[1.03547215]
 [1.10891449]
 [0.85923666]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1142: at batch 1: Loss=1.024, Time=0.022
Epoch 1143: at batch 1: Loss=1.154, Time=0.028
Epoch 1144: at batch 1: Loss=1.069, Time=0.033
Epoch 1145: at batch 1: Loss=1.090, Time=0.024
Epoch 1146: at batch 1: Loss=1.086, Time=0.029
Epoch 1147: at batch 1: Loss=1.090, Time=0.026
Epoch 1148: at batch 1: Loss=1.069, Time=0.027
Epoch 1149: at batch 1: Loss=1.069, Time=0.030
Epoch 1150: at batch 1: Loss=1.092, Time=0.022
Epoch 1151: at batch 1: Loss=1.072, Time=0.024
Epoch 1151: Time=23.789, Epoch time = 0.055, Avg epoch time=0.000

[[1.09861231]
 [1.03967834]
 [1.03967834]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1152: at batch 1: Loss=1.019, Time=0.026
Epoch 1153: at batch 1: Loss=1.020, Time=0.024
Epoch 1154: at batch 1: Loss=1.061, Time=0.028
Epoch 1155: at batch 1: Loss=1.069, Time=0.035
Epoch 1156: at batch 1: Loss=1.010, Time=0.029
Epoch 1157: at batch 1: Loss=1.043, Time=0.029
Epoch 1158: at batch 1: Loss=1.065, Time=0.032
Epoch 1159: at batch 1: Loss=1.164, Time=0.023
Epoch 1160: at batch 1: Loss=1.098, Time=0.028
Epoch 1161: at batch 1: Loss=1.035, Time=0.027
Epoch 1161: Time=24.665, Epoch time = 0.056, Avg epoch time=0.000

[[1.07147586]
 [1.07147586]
 [1.07147586]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1162: at batch 1: Loss=1.020, Time=0.033
Epoch 1163: at batch 1: Loss=1.060, Time=0.032
Epoch 1164: at batch 1: Loss=1.075, Time=0.023
Epoch 1165: at batch 1: Loss=1.053, Time=0.029
Epoch 1166: at batch 1: Loss=1.230, Time=0.022
Epoch 1167: at batch 1: Loss=1.104, Time=0.021
Epoch 1168: at batch 1: Loss=1.159, Time=0.030
Epoch 1169: at batch 1: Loss=1.073, Time=0.022
Epoch 1170: at batch 1: Loss=1.072, Time=0.036
Epoch 1171: at batch 1: Loss=1.084, Time=0.023
Epoch 1171: Time=25.556, Epoch time = 0.054, Avg epoch time=0.000

[[1.09861231]
 [0.99363387]
 [1.06019282]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1172: at batch 1: Loss=1.086, Time=0.026
Epoch 1173: at batch 1: Loss=1.077, Time=0.032
Epoch 1174: at batch 1: Loss=1.079, Time=0.029
Epoch 1175: at batch 1: Loss=1.067, Time=0.023
Epoch 1176: at batch 1: Loss=1.067, Time=0.023
Epoch 1177: at batch 1: Loss=1.109, Time=0.025
Epoch 1178: at batch 1: Loss=1.115, Time=0.029
Epoch 1179: at batch 1: Loss=1.149, Time=0.029
Epoch 1180: at batch 1: Loss=1.123, Time=0.032
Epoch 1181: at batch 1: Loss=1.103, Time=0.024
Epoch 1181: Time=26.403, Epoch time = 0.058, Avg epoch time=0.000

[[1.07206404]
 [1.12929869]
 [1.12929869]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1182: at batch 1: Loss=1.162, Time=0.026
Epoch 1183: at batch 1: Loss=1.052, Time=0.028
Epoch 1184: at batch 1: Loss=1.063, Time=0.026
Epoch 1185: at batch 1: Loss=1.061, Time=0.026
Epoch 1186: at batch 1: Loss=1.121, Time=0.021
Epoch 1187: at batch 1: Loss=1.096, Time=0.026
Epoch 1188: at batch 1: Loss=1.110, Time=0.023
Epoch 1189: at batch 1: Loss=1.052, Time=0.021
Epoch 1190: at batch 1: Loss=1.044, Time=0.028
Epoch 1191: at batch 1: Loss=1.085, Time=0.026
Epoch 1191: Time=27.219, Epoch time = 0.053, Avg epoch time=0.000

[[1.08675003]
 [1.09861231]
 [1.108922  ]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1192: at batch 1: Loss=1.116, Time=0.033
Epoch 1193: at batch 1: Loss=1.138, Time=0.023
Epoch 1194: at batch 1: Loss=1.062, Time=0.023
Epoch 1195: at batch 1: Loss=1.032, Time=0.029
Epoch 1196: at batch 1: Loss=1.066, Time=0.029
Epoch 1197: at batch 1: Loss=1.046, Time=0.029
Epoch 1198: at batch 1: Loss=1.117, Time=0.026
Epoch 1199: at batch 1: Loss=1.045, Time=0.026
Epoch 1200: at batch 1: Loss=1.352, Time=0.027
Epoch 1201: at batch 1: Loss=1.214, Time=0.035
Epoch 1201: Time=28.073, Epoch time = 0.064, Avg epoch time=0.000

[[1.24052572]
 [1.08707166]
 [1.08707166]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1202: at batch 1: Loss=1.155, Time=0.021
Epoch 1203: at batch 1: Loss=1.129, Time=0.029
Epoch 1204: at batch 1: Loss=1.066, Time=0.029
Epoch 1205: at batch 1: Loss=1.060, Time=0.023
Epoch 1206: at batch 1: Loss=1.077, Time=0.029
Epoch 1207: at batch 1: Loss=1.109, Time=0.029
Epoch 1208: at batch 1: Loss=1.090, Time=0.022
Epoch 1209: at batch 1: Loss=1.096, Time=0.023
Epoch 1210: at batch 1: Loss=1.122, Time=0.029
Epoch 1211: at batch 1: Loss=1.289, Time=0.035
Epoch 1211: Time=28.932, Epoch time = 0.065, Avg epoch time=0.000

[[1.09167969]
 [1.09167969]
 [1.59678924]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1212: at batch 1: Loss=1.114, Time=0.027
Epoch 1213: at batch 1: Loss=1.040, Time=0.022
Epoch 1214: at batch 1: Loss=1.070, Time=0.027
Epoch 1215: at batch 1: Loss=1.015, Time=0.036
Epoch 1216: at batch 1: Loss=1.061, Time=0.029
Epoch 1217: at batch 1: Loss=1.038, Time=0.026
Epoch 1218: at batch 1: Loss=1.057, Time=0.035
Epoch 1219: at batch 1: Loss=1.080, Time=0.027
Epoch 1220: at batch 1: Loss=1.069, Time=0.031
Epoch 1221: at batch 1: Loss=1.069, Time=0.029
Epoch 1221: Time=29.798, Epoch time = 0.061, Avg epoch time=0.000

[[1.16859102]
 [1.09861231]
 [1.16859102]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1222: at batch 1: Loss=1.078, Time=0.022
Epoch 1223: at batch 1: Loss=1.071, Time=0.040
Epoch 1224: at batch 1: Loss=1.107, Time=0.029
Epoch 1225: at batch 1: Loss=1.078, Time=0.027
Epoch 1226: at batch 1: Loss=1.186, Time=0.030
Epoch 1227: at batch 1: Loss=1.054, Time=0.029
Epoch 1228: at batch 1: Loss=1.065, Time=0.027
Epoch 1229: at batch 1: Loss=1.105, Time=0.031
Epoch 1230: at batch 1: Loss=1.082, Time=0.038
Epoch 1231: at batch 1: Loss=1.073, Time=0.028
Epoch 1231: Time=30.679, Epoch time = 0.057, Avg epoch time=0.000

[[1.06924009]
 [1.0734961 ]
 [1.0734961 ]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1232: at batch 1: Loss=1.093, Time=0.023
Epoch 1233: at batch 1: Loss=1.045, Time=0.029
Epoch 1234: at batch 1: Loss=1.079, Time=0.026
Epoch 1235: at batch 1: Loss=1.006, Time=0.026
Epoch 1236: at batch 1: Loss=1.053, Time=0.032
Epoch 1237: at batch 1: Loss=1.030, Time=0.032
Epoch 1238: at batch 1: Loss=1.113, Time=0.021
Epoch 1239: at batch 1: Loss=1.100, Time=0.028
Epoch 1240: at batch 1: Loss=1.120, Time=0.029
Epoch 1241: at batch 1: Loss=1.014, Time=0.031
Epoch 1241: Time=31.529, Epoch time = 0.061, Avg epoch time=0.000

[[1.11472368]
 [1.17459679]
 [1.05921268]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1242: at batch 1: Loss=1.105, Time=0.027
Epoch 1243: at batch 1: Loss=1.045, Time=0.023
Epoch 1244: at batch 1: Loss=1.091, Time=0.021
Epoch 1245: at batch 1: Loss=1.043, Time=0.024
Epoch 1246: at batch 1: Loss=0.995, Time=0.021
Epoch 1247: at batch 1: Loss=1.022, Time=0.024
Epoch 1248: at batch 1: Loss=1.089, Time=0.021
Epoch 1249: at batch 1: Loss=1.069, Time=0.028
Epoch 1250: at batch 1: Loss=1.047, Time=0.032
Epoch 1251: at batch 1: Loss=1.015, Time=0.028
Epoch 1251: Time=32.365, Epoch time = 0.055, Avg epoch time=0.000

[[0.99102306]
 [1.00326133]
 [0.9804498 ]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1252: at batch 1: Loss=1.035, Time=0.030
Epoch 1253: at batch 1: Loss=1.076, Time=0.030
Epoch 1254: at batch 1: Loss=1.075, Time=0.035
Epoch 1255: at batch 1: Loss=1.116, Time=0.036
Epoch 1256: at batch 1: Loss=1.119, Time=0.024
Epoch 1257: at batch 1: Loss=1.163, Time=0.030
Epoch 1258: at batch 1: Loss=1.081, Time=0.021
Epoch 1259: at batch 1: Loss=1.086, Time=0.031
Epoch 1260: at batch 1: Loss=1.082, Time=0.040
Epoch 1261: at batch 1: Loss=1.109, Time=0.021
Epoch 1261: Time=33.238, Epoch time = 0.052, Avg epoch time=0.000

[[1.09861231]
 [1.08476925]
 [1.07628632]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1262: at batch 1: Loss=1.153, Time=0.030
Epoch 1263: at batch 1: Loss=1.120, Time=0.029
Epoch 1264: at batch 1: Loss=1.112, Time=0.027
Epoch 1265: at batch 1: Loss=1.096, Time=0.029
Epoch 1266: at batch 1: Loss=1.066, Time=0.029
Epoch 1267: at batch 1: Loss=1.095, Time=0.030
Epoch 1268: at batch 1: Loss=1.062, Time=0.032
Epoch 1269: at batch 1: Loss=1.091, Time=0.031
Epoch 1270: at batch 1: Loss=1.287, Time=0.023
Epoch 1271: at batch 1: Loss=1.158, Time=0.028
Epoch 1271: Time=34.122, Epoch time = 0.060, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [0.99193674]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1272: at batch 1: Loss=1.129, Time=0.030
Epoch 1273: at batch 1: Loss=1.087, Time=0.027
Epoch 1274: at batch 1: Loss=1.000, Time=0.024
Epoch 1275: at batch 1: Loss=0.991, Time=0.032
Epoch 1276: at batch 1: Loss=1.064, Time=0.030
Epoch 1277: at batch 1: Loss=1.126, Time=0.030
Epoch 1278: at batch 1: Loss=1.082, Time=0.028
Epoch 1279: at batch 1: Loss=1.043, Time=0.021
Epoch 1280: at batch 1: Loss=1.067, Time=0.024
Epoch 1281: at batch 1: Loss=1.023, Time=0.030
Epoch 1281: Time=34.990, Epoch time = 0.058, Avg epoch time=0.000

[[1.09861231]
 [1.20122957]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1282: at batch 1: Loss=1.042, Time=0.025
Epoch 1283: at batch 1: Loss=0.980, Time=0.031
Epoch 1284: at batch 1: Loss=1.033, Time=0.027
Epoch 1285: at batch 1: Loss=1.070, Time=0.023
Epoch 1286: at batch 1: Loss=1.051, Time=0.019
Epoch 1287: at batch 1: Loss=1.139, Time=0.037
Epoch 1288: at batch 1: Loss=1.123, Time=0.029
Epoch 1289: at batch 1: Loss=1.027, Time=0.030
Epoch 1290: at batch 1: Loss=0.962, Time=0.028
Epoch 1291: at batch 1: Loss=1.083, Time=0.032
Epoch 1291: Time=35.834, Epoch time = 0.060, Avg epoch time=0.000

[[1.09861231]
 [1.06229472]
 [1.23414278]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1292: at batch 1: Loss=1.030, Time=0.026
Epoch 1293: at batch 1: Loss=1.029, Time=0.032
Epoch 1294: at batch 1: Loss=1.076, Time=0.032
Epoch 1295: at batch 1: Loss=1.058, Time=0.031
Epoch 1296: at batch 1: Loss=1.115, Time=0.037
Epoch 1297: at batch 1: Loss=1.110, Time=0.021
Epoch 1298: at batch 1: Loss=1.096, Time=0.029
Epoch 1299: at batch 1: Loss=1.128, Time=0.023
Epoch 1300: at batch 1: Loss=1.142, Time=0.030
Epoch 1301: at batch 1: Loss=1.021, Time=0.026
Epoch 1301: Time=36.671, Epoch time = 0.053, Avg epoch time=0.000

[[1.09861231]
 [0.85620022]
 [0.85620022]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1302: at batch 1: Loss=1.037, Time=0.024
Epoch 1303: at batch 1: Loss=1.057, Time=0.024
Epoch 1304: at batch 1: Loss=1.080, Time=0.026
Epoch 1305: at batch 1: Loss=1.031, Time=0.032
Epoch 1306: at batch 1: Loss=1.033, Time=0.023
Epoch 1307: at batch 1: Loss=1.029, Time=0.029
Epoch 1308: at batch 1: Loss=1.130, Time=0.030
Epoch 1309: at batch 1: Loss=1.200, Time=0.024
Epoch 1310: at batch 1: Loss=1.110, Time=0.036
Epoch 1311: at batch 1: Loss=1.091, Time=0.032
Epoch 1311: Time=37.549, Epoch time = 0.071, Avg epoch time=0.000

[[1.15320456]
 [1.09207344]
 [1.15320456]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1312: at batch 1: Loss=1.161, Time=0.030
Epoch 1313: at batch 1: Loss=1.067, Time=0.022
Epoch 1314: at batch 1: Loss=1.024, Time=0.029
Epoch 1315: at batch 1: Loss=1.017, Time=0.029
Epoch 1316: at batch 1: Loss=1.028, Time=0.032
Epoch 1317: at batch 1: Loss=1.038, Time=0.024
Epoch 1318: at batch 1: Loss=1.071, Time=0.032
Epoch 1319: at batch 1: Loss=1.065, Time=0.026
Epoch 1320: at batch 1: Loss=1.047, Time=0.023
Epoch 1321: at batch 1: Loss=1.061, Time=0.032
Epoch 1321: Time=38.399, Epoch time = 0.054, Avg epoch time=0.000

[[1.11270928]
 [1.04756021]
 [1.0591203 ]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1322: at batch 1: Loss=1.041, Time=0.026
Epoch 1323: at batch 1: Loss=1.008, Time=0.038
Epoch 1324: at batch 1: Loss=1.051, Time=0.021
Epoch 1325: at batch 1: Loss=1.118, Time=0.035
Epoch 1326: at batch 1: Loss=1.055, Time=0.026
Epoch 1327: at batch 1: Loss=1.079, Time=0.023
Epoch 1328: at batch 1: Loss=1.097, Time=0.029
Epoch 1329: at batch 1: Loss=1.121, Time=0.029
Epoch 1330: at batch 1: Loss=1.111, Time=0.021
Epoch 1331: at batch 1: Loss=1.077, Time=0.027
Epoch 1331: Time=39.261, Epoch time = 0.059, Avg epoch time=0.000

[[1.06219435]
 [1.06219435]
 [1.00073338]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1332: at batch 1: Loss=1.057, Time=0.024
Epoch 1333: at batch 1: Loss=1.056, Time=0.026
Epoch 1334: at batch 1: Loss=1.086, Time=0.021
Epoch 1335: at batch 1: Loss=1.100, Time=0.028
Epoch 1336: at batch 1: Loss=1.082, Time=0.026
Epoch 1337: at batch 1: Loss=1.068, Time=0.028
Epoch 1338: at batch 1: Loss=1.029, Time=0.023
Epoch 1339: at batch 1: Loss=1.039, Time=0.026
Epoch 1340: at batch 1: Loss=1.073, Time=0.032
Epoch 1341: at batch 1: Loss=1.083, Time=0.026
Epoch 1341: Time=40.086, Epoch time = 0.056, Avg epoch time=0.000

[[1.09861231]
 [0.96143979]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1342: at batch 1: Loss=1.093, Time=0.028
Epoch 1343: at batch 1: Loss=1.200, Time=0.031
Epoch 1344: at batch 1: Loss=1.078, Time=0.035
Epoch 1345: at batch 1: Loss=1.117, Time=0.025
Epoch 1346: at batch 1: Loss=1.052, Time=0.028
Epoch 1347: at batch 1: Loss=1.054, Time=0.041
Epoch 1348: at batch 1: Loss=1.130, Time=0.032
Epoch 1349: at batch 1: Loss=1.075, Time=0.038
Epoch 1350: at batch 1: Loss=1.102, Time=0.031
Epoch 1351: at batch 1: Loss=1.106, Time=0.030
Epoch 1351: Time=41.010, Epoch time = 0.060, Avg epoch time=0.000

[[1.09861231]
 [1.01994336]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1352: at batch 1: Loss=1.119, Time=0.031
Epoch 1353: at batch 1: Loss=1.230, Time=0.030
Epoch 1354: at batch 1: Loss=1.145, Time=0.020
Epoch 1355: at batch 1: Loss=1.024, Time=0.032
Epoch 1356: at batch 1: Loss=1.091, Time=0.031
Epoch 1357: at batch 1: Loss=1.068, Time=0.029
Epoch 1358: at batch 1: Loss=1.060, Time=0.030
Epoch 1359: at batch 1: Loss=1.126, Time=0.021
Epoch 1360: at batch 1: Loss=1.165, Time=0.026
Epoch 1361: at batch 1: Loss=1.133, Time=0.027
Epoch 1361: Time=41.881, Epoch time = 0.055, Avg epoch time=0.000

[[1.16385102]
 [1.09861231]
 [1.0522871 ]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1362: at batch 1: Loss=1.070, Time=0.030
Epoch 1363: at batch 1: Loss=1.027, Time=0.030
Epoch 1364: at batch 1: Loss=1.047, Time=0.024
Epoch 1365: at batch 1: Loss=1.148, Time=0.027
Epoch 1366: at batch 1: Loss=1.100, Time=0.026
Epoch 1367: at batch 1: Loss=1.054, Time=0.024
Epoch 1368: at batch 1: Loss=1.047, Time=0.022
Epoch 1369: at batch 1: Loss=1.054, Time=0.033
Epoch 1370: at batch 1: Loss=1.082, Time=0.032
Epoch 1371: at batch 1: Loss=1.107, Time=0.041
Epoch 1371: Time=42.750, Epoch time = 0.071, Avg epoch time=0.000

[[1.0489552 ]
 [1.09861231]
 [1.07307494]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1372: at batch 1: Loss=1.157, Time=0.034
Epoch 1373: at batch 1: Loss=1.108, Time=0.027
Epoch 1374: at batch 1: Loss=1.116, Time=0.022
Epoch 1375: at batch 1: Loss=1.095, Time=0.026
Epoch 1376: at batch 1: Loss=1.163, Time=0.027
Epoch 1377: at batch 1: Loss=1.086, Time=0.027
Epoch 1378: at batch 1: Loss=1.103, Time=0.022
Epoch 1379: at batch 1: Loss=1.125, Time=0.024
Epoch 1380: at batch 1: Loss=1.177, Time=0.025
Epoch 1381: at batch 1: Loss=1.151, Time=0.027
Epoch 1381: Time=43.593, Epoch time = 0.055, Avg epoch time=0.000

[[1.09861231]
 [1.09861231]
 [1.09861231]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1382: at batch 1: Loss=1.132, Time=0.033
Epoch 1383: at batch 1: Loss=1.081, Time=0.025
Epoch 1384: at batch 1: Loss=1.136, Time=0.024
Epoch 1385: at batch 1: Loss=1.109, Time=0.031
Epoch 1386: at batch 1: Loss=1.105, Time=0.026
Epoch 1387: at batch 1: Loss=1.102, Time=0.027
Epoch 1388: at batch 1: Loss=1.036, Time=0.026
Epoch 1389: at batch 1: Loss=1.035, Time=0.024
Epoch 1390: at batch 1: Loss=1.031, Time=0.030
Epoch 1391: at batch 1: Loss=1.055, Time=0.032
Epoch 1391: Time=44.487, Epoch time = 0.060, Avg epoch time=0.000

[[1.04888463]
 [1.0692637 ]
 [1.01288724]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1392: at batch 1: Loss=0.968, Time=0.022
Epoch 1393: at batch 1: Loss=0.998, Time=0.021
Epoch 1394: at batch 1: Loss=1.108, Time=0.022
Epoch 1395: at batch 1: Loss=1.199, Time=0.037
Epoch 1396: at batch 1: Loss=1.053, Time=0.033
Epoch 1397: at batch 1: Loss=1.227, Time=0.035
Epoch 1398: at batch 1: Loss=1.150, Time=0.025
Epoch 1399: at batch 1: Loss=1.064, Time=0.029
Epoch 1400: at batch 1: Loss=1.078, Time=0.026
Epoch 1401: at batch 1: Loss=1.160, Time=0.026
Epoch 1401: Time=45.349, Epoch time = 0.055, Avg epoch time=0.000

[[1.10167551]
 [1.07565069]
 [1.31125867]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1402: at batch 1: Loss=1.122, Time=0.029
Epoch 1403: at batch 1: Loss=1.032, Time=0.026
Epoch 1404: at batch 1: Loss=1.109, Time=0.028
Epoch 1405: at batch 1: Loss=1.116, Time=0.028
Epoch 1406: at batch 1: Loss=1.061, Time=0.023
Epoch 1407: at batch 1: Loss=1.023, Time=0.032
Epoch 1408: at batch 1: Loss=1.065, Time=0.021
Epoch 1409: at batch 1: Loss=1.159, Time=0.027
Epoch 1410: at batch 1: Loss=1.097, Time=0.029
Epoch 1411: at batch 1: Loss=1.095, Time=0.039
Epoch 1411: Time=46.238, Epoch time = 0.069, Avg epoch time=0.000

[[1.09478545]
 [1.0392375 ]
 [1.08457887]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1412: at batch 1: Loss=1.060, Time=0.023
Epoch 1413: at batch 1: Loss=1.069, Time=0.024
Epoch 1414: at batch 1: Loss=1.048, Time=0.028
Epoch 1415: at batch 1: Loss=1.069, Time=0.032
Epoch 1416: at batch 1: Loss=1.054, Time=0.030
Epoch 1417: at batch 1: Loss=1.018, Time=0.028
Epoch 1418: at batch 1: Loss=1.075, Time=0.023
Epoch 1419: at batch 1: Loss=1.101, Time=0.030
Epoch 1420: at batch 1: Loss=1.064, Time=0.027
Epoch 1421: at batch 1: Loss=1.045, Time=0.033
Epoch 1421: Time=47.092, Epoch time = 0.061, Avg epoch time=0.000

[[0.99322802]
 [1.14680219]
 [1.14680219]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1422: at batch 1: Loss=1.073, Time=0.039
Epoch 1423: at batch 1: Loss=1.072, Time=0.028
Epoch 1424: at batch 1: Loss=1.044, Time=0.021
Epoch 1425: at batch 1: Loss=1.024, Time=0.025
Epoch 1426: at batch 1: Loss=1.107, Time=0.033
Epoch 1427: at batch 1: Loss=1.120, Time=0.021
Epoch 1428: at batch 1: Loss=1.112, Time=0.025
Epoch 1429: at batch 1: Loss=1.111, Time=0.032
Epoch 1430: at batch 1: Loss=1.093, Time=0.024
Epoch 1431: at batch 1: Loss=1.071, Time=0.028
Epoch 1431: Time=47.960, Epoch time = 0.059, Avg epoch time=0.000

[[1.04884875]
 [1.04884875]
 [1.04884875]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1432: at batch 1: Loss=1.071, Time=0.025
Epoch 1433: at batch 1: Loss=1.066, Time=0.029
Epoch 1434: at batch 1: Loss=1.164, Time=0.027
Epoch 1435: at batch 1: Loss=1.078, Time=0.024
Epoch 1436: at batch 1: Loss=1.028, Time=0.023
Epoch 1437: at batch 1: Loss=1.057, Time=0.033
Epoch 1438: at batch 1: Loss=1.062, Time=0.031
Epoch 1439: at batch 1: Loss=1.111, Time=0.032
Epoch 1440: at batch 1: Loss=1.058, Time=0.024
Epoch 1441: at batch 1: Loss=1.045, Time=0.029
Epoch 1441: Time=48.838, Epoch time = 0.061, Avg epoch time=0.000

[[0.94863182]
 [1.01858234]
 [1.00369453]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1442: at batch 1: Loss=1.022, Time=0.025
Epoch 1443: at batch 1: Loss=1.096, Time=0.028
Epoch 1444: at batch 1: Loss=1.077, Time=0.025
Epoch 1445: at batch 1: Loss=1.041, Time=0.026
Epoch 1446: at batch 1: Loss=1.010, Time=0.030
Epoch 1447: at batch 1: Loss=1.056, Time=0.028
Epoch 1448: at batch 1: Loss=1.059, Time=0.030
Epoch 1449: at batch 1: Loss=1.064, Time=0.029
Epoch 1450: at batch 1: Loss=1.098, Time=0.023
Epoch 1451: at batch 1: Loss=1.116, Time=0.024
Epoch 1451: Time=49.687, Epoch time = 0.054, Avg epoch time=0.000

[[1.19956851]
 [1.19956851]
 [1.05078793]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1452: at batch 1: Loss=1.124, Time=0.027
Epoch 1453: at batch 1: Loss=1.055, Time=0.024
Epoch 1454: at batch 1: Loss=1.030, Time=0.026
Epoch 1455: at batch 1: Loss=1.041, Time=0.031
Epoch 1456: at batch 1: Loss=1.068, Time=0.023
Epoch 1457: at batch 1: Loss=1.035, Time=0.041
Epoch 1458: at batch 1: Loss=1.070, Time=0.035
Epoch 1459: at batch 1: Loss=1.061, Time=0.025
Epoch 1460: at batch 1: Loss=1.072, Time=0.033
Epoch 1461: at batch 1: Loss=1.060, Time=0.028
Epoch 1461: Time=50.584, Epoch time = 0.058, Avg epoch time=0.000

[[1.04026532]
 [1.12072957]
 [1.07611585]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1462: at batch 1: Loss=1.060, Time=0.025
Epoch 1463: at batch 1: Loss=0.994, Time=0.027
Epoch 1464: at batch 1: Loss=1.135, Time=0.028
Epoch 1465: at batch 1: Loss=1.077, Time=0.030
Epoch 1466: at batch 1: Loss=1.093, Time=0.022
Epoch 1467: at batch 1: Loss=1.063, Time=0.027
Epoch 1468: at batch 1: Loss=1.088, Time=0.029
Epoch 1469: at batch 1: Loss=0.963, Time=0.029
Epoch 1470: at batch 1: Loss=1.015, Time=0.021
Epoch 1471: at batch 1: Loss=0.993, Time=0.024
Epoch 1471: Time=51.420, Epoch time = 0.056, Avg epoch time=0.000

[[1.05391788]
 [1.05391788]
 [1.05391788]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1472: at batch 1: Loss=1.030, Time=0.025
Epoch 1473: at batch 1: Loss=0.999, Time=0.023
Epoch 1474: at batch 1: Loss=1.046, Time=0.031
Epoch 1475: at batch 1: Loss=1.071, Time=0.027
Epoch 1476: at batch 1: Loss=1.116, Time=0.032
Epoch 1477: at batch 1: Loss=1.074, Time=0.027
Epoch 1478: at batch 1: Loss=1.177, Time=0.028
Epoch 1479: at batch 1: Loss=1.218, Time=0.027
Epoch 1480: at batch 1: Loss=1.144, Time=0.026
Epoch 1481: at batch 1: Loss=1.204, Time=0.026
Epoch 1481: Time=52.278, Epoch time = 0.056, Avg epoch time=0.000

[[1.05031681]
 [1.05031681]
 [1.05031681]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1482: at batch 1: Loss=1.111, Time=0.026
Epoch 1483: at batch 1: Loss=1.026, Time=0.028
Epoch 1484: at batch 1: Loss=1.043, Time=0.024
Epoch 1485: at batch 1: Loss=1.024, Time=0.029
Epoch 1486: at batch 1: Loss=1.036, Time=0.037
Epoch 1487: at batch 1: Loss=1.064, Time=0.032
Epoch 1488: at batch 1: Loss=1.060, Time=0.032
Epoch 1489: at batch 1: Loss=1.051, Time=0.030
Epoch 1490: at batch 1: Loss=1.106, Time=0.024
Epoch 1491: at batch 1: Loss=1.050, Time=0.033
Epoch 1491: Time=53.166, Epoch time = 0.068, Avg epoch time=0.000

[[0.96954328]
 [1.08168411]
 [1.00520086]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1492: at batch 1: Loss=1.047, Time=0.028
Epoch 1493: at batch 1: Loss=1.066, Time=0.029
Epoch 1494: at batch 1: Loss=1.072, Time=0.032
Epoch 1495: at batch 1: Loss=1.040, Time=0.031
Epoch 1496: at batch 1: Loss=1.041, Time=0.032
Epoch 1497: at batch 1: Loss=1.118, Time=0.030
Epoch 1498: at batch 1: Loss=1.113, Time=0.030
Epoch 1499: at batch 1: Loss=1.029, Time=0.029
Epoch 1500: at batch 1: Loss=1.066, Time=0.030
Epoch 1501: at batch 1: Loss=1.142, Time=0.027
Epoch 1501: Time=54.057, Epoch time = 0.056, Avg epoch time=0.000

[[1.24291289]
 [1.07680655]
 [1.01036906]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1502: at batch 1: Loss=1.169, Time=0.024
Epoch 1503: at batch 1: Loss=1.163, Time=0.024
Epoch 1504: at batch 1: Loss=1.153, Time=0.040
Epoch 1505: at batch 1: Loss=1.077, Time=0.025
Epoch 1506: at batch 1: Loss=1.162, Time=0.030
Epoch 1507: at batch 1: Loss=1.136, Time=0.026
Epoch 1508: at batch 1: Loss=1.104, Time=0.030
Epoch 1509: at batch 1: Loss=1.079, Time=0.030
Epoch 1510: at batch 1: Loss=1.115, Time=0.026
Epoch 1511: at batch 1: Loss=1.063, Time=0.025
Epoch 1511: Time=54.926, Epoch time = 0.056, Avg epoch time=0.000

[[1.09881079]
 [0.96416718]
 [1.07707858]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1512: at batch 1: Loss=1.048, Time=0.031
Epoch 1513: at batch 1: Loss=1.080, Time=0.023
Epoch 1514: at batch 1: Loss=1.078, Time=0.022
Epoch 1515: at batch 1: Loss=1.081, Time=0.025
Epoch 1516: at batch 1: Loss=1.072, Time=0.031
Epoch 1517: at batch 1: Loss=1.033, Time=0.024
Epoch 1518: at batch 1: Loss=1.009, Time=0.023
Epoch 1519: at batch 1: Loss=1.092, Time=0.036
Epoch 1520: at batch 1: Loss=0.994, Time=0.030
Epoch 1521: at batch 1: Loss=1.038, Time=0.027
Epoch 1521: Time=55.792, Epoch time = 0.058, Avg epoch time=0.000

[[1.03187668]
 [1.03187668]
 [0.99834788]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1522: at batch 1: Loss=1.047, Time=0.029
Epoch 1523: at batch 1: Loss=1.128, Time=0.024
Epoch 1524: at batch 1: Loss=1.118, Time=0.033
Epoch 1525: at batch 1: Loss=1.046, Time=0.032
Epoch 1526: at batch 1: Loss=1.044, Time=0.026
Epoch 1527: at batch 1: Loss=1.038, Time=0.025
Epoch 1528: at batch 1: Loss=0.939, Time=0.030
Epoch 1529: at batch 1: Loss=1.013, Time=0.025
Epoch 1530: at batch 1: Loss=0.998, Time=0.021
Epoch 1531: at batch 1: Loss=0.993, Time=0.021
Epoch 1531: Time=56.643, Epoch time = 0.055, Avg epoch time=0.000

[[1.30920732]
 [1.08795738]
 [0.94126171]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1532: at batch 1: Loss=1.097, Time=0.030
Epoch 1533: at batch 1: Loss=1.044, Time=0.021
Epoch 1534: at batch 1: Loss=1.149, Time=0.027
Epoch 1535: at batch 1: Loss=1.158, Time=0.027
Epoch 1536: at batch 1: Loss=1.108, Time=0.032
Epoch 1537: at batch 1: Loss=1.066, Time=0.025
Epoch 1538: at batch 1: Loss=1.006, Time=0.027
Epoch 1539: at batch 1: Loss=1.012, Time=0.026
Epoch 1540: at batch 1: Loss=1.028, Time=0.032
Epoch 1541: at batch 1: Loss=1.010, Time=0.040
Epoch 1541: Time=57.510, Epoch time = 0.066, Avg epoch time=0.000

[[1.09928048]
 [0.98319864]
 [1.09928048]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1542: at batch 1: Loss=0.965, Time=0.022
Epoch 1543: at batch 1: Loss=1.058, Time=0.023
Epoch 1544: at batch 1: Loss=1.024, Time=0.031
Epoch 1545: at batch 1: Loss=1.033, Time=0.027
Epoch 1546: at batch 1: Loss=1.051, Time=0.029
Epoch 1547: at batch 1: Loss=1.117, Time=0.027
Epoch 1548: at batch 1: Loss=1.134, Time=0.030
Epoch 1549: at batch 1: Loss=1.246, Time=0.024
Epoch 1550: at batch 1: Loss=1.218, Time=0.023
Epoch 1551: at batch 1: Loss=1.083, Time=0.024
Epoch 1551: Time=58.350, Epoch time = 0.051, Avg epoch time=0.000

[[1.09160733]
 [0.95136368]
 [1.09160733]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1552: at batch 1: Loss=1.048, Time=0.034
Epoch 1553: at batch 1: Loss=1.066, Time=0.031
Epoch 1554: at batch 1: Loss=1.115, Time=0.030
Epoch 1555: at batch 1: Loss=1.184, Time=0.022
Epoch 1556: at batch 1: Loss=1.102, Time=0.029
Epoch 1557: at batch 1: Loss=1.091, Time=0.029
Epoch 1558: at batch 1: Loss=1.039, Time=0.026
Epoch 1559: at batch 1: Loss=1.048, Time=0.029
Epoch 1560: at batch 1: Loss=1.077, Time=0.029
Epoch 1561: at batch 1: Loss=1.022, Time=0.029
Epoch 1561: Time=59.231, Epoch time = 0.058, Avg epoch time=0.000

[[1.06987834]
 [0.99439919]
 [1.06987834]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1562: at batch 1: Loss=1.041, Time=0.024
Epoch 1563: at batch 1: Loss=1.013, Time=0.024
Epoch 1564: at batch 1: Loss=1.047, Time=0.023
Epoch 1565: at batch 1: Loss=1.004, Time=0.030
Epoch 1566: at batch 1: Loss=1.057, Time=0.023
Epoch 1567: at batch 1: Loss=1.070, Time=0.030
Epoch 1568: at batch 1: Loss=1.060, Time=0.032
Epoch 1569: at batch 1: Loss=1.036, Time=0.030
Epoch 1570: at batch 1: Loss=1.073, Time=0.035
Epoch 1571: at batch 1: Loss=1.051, Time=0.024
Epoch 1571: Time=60.086, Epoch time = 0.051, Avg epoch time=0.000

[[1.30728173]
 [1.30728173]
 [1.30728173]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1572: at batch 1: Loss=1.145, Time=0.027
Epoch 1573: at batch 1: Loss=1.018, Time=0.024
Epoch 1574: at batch 1: Loss=1.050, Time=0.032
Epoch 1575: at batch 1: Loss=1.084, Time=0.029
Epoch 1576: at batch 1: Loss=1.214, Time=0.038
Epoch 1577: at batch 1: Loss=1.140, Time=0.026
Epoch 1578: at batch 1: Loss=1.109, Time=0.032
Epoch 1579: at batch 1: Loss=0.999, Time=0.036
Epoch 1580: at batch 1: Loss=1.015, Time=0.029
Epoch 1581: at batch 1: Loss=1.071, Time=0.023
Epoch 1581: Time=60.954, Epoch time = 0.055, Avg epoch time=0.000

[[0.99644887]
 [0.99644887]
 [1.02731621]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1582: at batch 1: Loss=1.035, Time=0.032
Epoch 1583: at batch 1: Loss=1.129, Time=0.030
Epoch 1584: at batch 1: Loss=1.075, Time=0.031
Epoch 1585: at batch 1: Loss=1.071, Time=0.026
Epoch 1586: at batch 1: Loss=0.995, Time=0.032
Epoch 1587: at batch 1: Loss=1.029, Time=0.023
Epoch 1588: at batch 1: Loss=1.000, Time=0.024
Epoch 1589: at batch 1: Loss=1.051, Time=0.024
Epoch 1590: at batch 1: Loss=1.014, Time=0.027
Epoch 1591: at batch 1: Loss=1.040, Time=0.033
Epoch 1591: Time=61.815, Epoch time = 0.063, Avg epoch time=0.000

[[1.21206641]
 [1.21206641]
 [1.06396449]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1592: at batch 1: Loss=1.105, Time=0.028
Epoch 1593: at batch 1: Loss=1.055, Time=0.025
Epoch 1594: at batch 1: Loss=0.972, Time=0.023
Epoch 1595: at batch 1: Loss=0.979, Time=0.024
Epoch 1596: at batch 1: Loss=1.091, Time=0.029
Epoch 1597: at batch 1: Loss=1.050, Time=0.027
Epoch 1598: at batch 1: Loss=1.194, Time=0.030
Epoch 1599: at batch 1: Loss=1.099, Time=0.023
Epoch 1600: at batch 1: Loss=1.026, Time=0.030
Epoch 1601: at batch 1: Loss=0.960, Time=0.029
Epoch 1601: Time=62.665, Epoch time = 0.060, Avg epoch time=0.000

[[0.98097599]
 [1.07142317]
 [1.07142317]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1602: at batch 1: Loss=1.030, Time=0.024
Epoch 1603: at batch 1: Loss=1.088, Time=0.030
Epoch 1604: at batch 1: Loss=1.025, Time=0.035
Epoch 1605: at batch 1: Loss=1.015, Time=0.027
Epoch 1606: at batch 1: Loss=1.053, Time=0.024
Epoch 1607: at batch 1: Loss=1.022, Time=0.030
Epoch 1608: at batch 1: Loss=1.027, Time=0.024
Epoch 1609: at batch 1: Loss=1.001, Time=0.023
Epoch 1610: at batch 1: Loss=1.044, Time=0.026
Epoch 1611: at batch 1: Loss=1.096, Time=0.023
Epoch 1611: Time=63.510, Epoch time = 0.056, Avg epoch time=0.000

[[0.83931637]
 [0.83931637]
 [0.83931637]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1612: at batch 1: Loss=1.028, Time=0.027
Epoch 1613: at batch 1: Loss=1.069, Time=0.037
Epoch 1614: at batch 1: Loss=1.078, Time=0.029
Epoch 1615: at batch 1: Loss=1.065, Time=0.029
Epoch 1616: at batch 1: Loss=1.102, Time=0.026
Epoch 1617: at batch 1: Loss=1.115, Time=0.028
Epoch 1618: at batch 1: Loss=1.077, Time=0.029
Epoch 1619: at batch 1: Loss=1.058, Time=0.022
Epoch 1620: at batch 1: Loss=1.047, Time=0.026
Epoch 1621: at batch 1: Loss=1.022, Time=0.025
Epoch 1621: Time=64.375, Epoch time = 0.050, Avg epoch time=0.000

[[1.04351091]
 [1.04351091]
 [1.04159307]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1622: at batch 1: Loss=1.025, Time=0.024
Epoch 1623: at batch 1: Loss=1.047, Time=0.030
Epoch 1624: at batch 1: Loss=1.021, Time=0.020
Epoch 1625: at batch 1: Loss=1.088, Time=0.032
Epoch 1626: at batch 1: Loss=1.142, Time=0.024
Epoch 1627: at batch 1: Loss=1.023, Time=0.041
Epoch 1628: at batch 1: Loss=1.060, Time=0.025
Epoch 1629: at batch 1: Loss=1.038, Time=0.038
Epoch 1630: at batch 1: Loss=1.029, Time=0.032
Epoch 1631: at batch 1: Loss=1.160, Time=0.032
Epoch 1631: Time=65.281, Epoch time = 0.062, Avg epoch time=0.000

[[1.14383268]
 [1.25953507]
 [1.14383268]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1632: at batch 1: Loss=1.163, Time=0.032
Epoch 1633: at batch 1: Loss=1.136, Time=0.029
Epoch 1634: at batch 1: Loss=1.088, Time=0.021
Epoch 1635: at batch 1: Loss=1.114, Time=0.027
Epoch 1636: at batch 1: Loss=1.087, Time=0.023
Epoch 1637: at batch 1: Loss=1.063, Time=0.021
Epoch 1638: at batch 1: Loss=1.074, Time=0.027
Epoch 1639: at batch 1: Loss=1.114, Time=0.024
Epoch 1640: at batch 1: Loss=1.165, Time=0.026
Epoch 1641: at batch 1: Loss=1.107, Time=0.027
Epoch 1641: Time=66.127, Epoch time = 0.056, Avg epoch time=0.000

[[1.06330943]
 [0.94415885]
 [0.94415885]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1642: at batch 1: Loss=1.079, Time=0.024
Epoch 1643: at batch 1: Loss=0.968, Time=0.031
Epoch 1644: at batch 1: Loss=1.097, Time=0.026
Epoch 1645: at batch 1: Loss=1.067, Time=0.022
Epoch 1646: at batch 1: Loss=1.126, Time=0.041
Epoch 1647: at batch 1: Loss=1.066, Time=0.027
Epoch 1648: at batch 1: Loss=0.993, Time=0.035
Epoch 1649: at batch 1: Loss=1.000, Time=0.026
Epoch 1650: at batch 1: Loss=1.044, Time=0.023
Epoch 1651: at batch 1: Loss=1.086, Time=0.032
Epoch 1651: Time=67.001, Epoch time = 0.060, Avg epoch time=0.000

[[1.01069438]
 [1.01069438]
 [1.11447597]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1652: at batch 1: Loss=1.055, Time=0.022
Epoch 1653: at batch 1: Loss=1.018, Time=0.026
Epoch 1654: at batch 1: Loss=1.001, Time=0.023
Epoch 1655: at batch 1: Loss=1.016, Time=0.024
Epoch 1656: at batch 1: Loss=1.092, Time=0.026
Epoch 1657: at batch 1: Loss=1.053, Time=0.030
Epoch 1658: at batch 1: Loss=1.102, Time=0.035
Epoch 1659: at batch 1: Loss=1.164, Time=0.032
Epoch 1660: at batch 1: Loss=1.092, Time=0.029
Epoch 1661: at batch 1: Loss=1.052, Time=0.021
Epoch 1661: Time=67.851, Epoch time = 0.048, Avg epoch time=0.000

[[1.20960736]
 [1.14726281]
 [1.20960736]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1662: at batch 1: Loss=1.112, Time=0.038
Epoch 1663: at batch 1: Loss=1.077, Time=0.026
Epoch 1664: at batch 1: Loss=1.066, Time=0.025
Epoch 1665: at batch 1: Loss=1.086, Time=0.032
Epoch 1666: at batch 1: Loss=1.114, Time=0.029
Epoch 1667: at batch 1: Loss=1.062, Time=0.027
Epoch 1668: at batch 1: Loss=1.082, Time=0.020
Epoch 1669: at batch 1: Loss=1.013, Time=0.029
Epoch 1670: at batch 1: Loss=1.021, Time=0.023
Epoch 1671: at batch 1: Loss=1.015, Time=0.023
Epoch 1671: Time=68.716, Epoch time = 0.052, Avg epoch time=0.000

[[1.08272123]
 [1.02715516]
 [0.96499932]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1672: at batch 1: Loss=1.053, Time=0.024
Epoch 1673: at batch 1: Loss=1.111, Time=0.034
Epoch 1674: at batch 1: Loss=1.054, Time=0.033
Epoch 1675: at batch 1: Loss=1.086, Time=0.029
Epoch 1676: at batch 1: Loss=1.023, Time=0.023
Epoch 1677: at batch 1: Loss=1.022, Time=0.029
Epoch 1678: at batch 1: Loss=1.061, Time=0.023
Epoch 1679: at batch 1: Loss=1.060, Time=0.026
Epoch 1680: at batch 1: Loss=1.027, Time=0.029
Epoch 1681: at batch 1: Loss=0.992, Time=0.028
Epoch 1681: Time=69.587, Epoch time = 0.058, Avg epoch time=0.000

[[1.04119587]
 [1.04119587]
 [0.96577632]
 ...
 [0.        ]
 [0.        ]
 [0.        ]]
Epoch 1682: at batch 1: Loss=0.991, Time=0.024
Epoch 1683: at batch 1: Loss=0.998, Time=0.022
Epoch 1684: at batch 1: Loss=1.067, Time=0.026
Epoch 1685: at batch 1: Loss=1.070, Time=0.030
Epoch 1686: at batch 1: Loss=1.029, Time=0.025
Epoch 1687: at batch 1: Loss=1.090, Time=0.026
^CTraceback (most recent call last):
  File "simple_batched_numpy.py", line 327, in <module>
    feed_dict={in_image: input_patch, gt_gamma: assigned_image_gamma_index, lr: learning_rate})
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 887, in run
    run_metadata_ptr)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1110, in _run
    feed_dict_tensor, options, run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1286, in _do_run
    run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1292, in _do_call
    return fn(*args)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1277, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1367, in _call_tf_sessionrun
    run_metadata)
KeyboardInterrupt
(sid2) [ir967@gr020 Learning-to-See-in-the-Dark]$ exit
exit
srun: error: gr020-ib0: task 0: Exited with exit code 1
srun: Terminating job step 402173.0
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ exit
logout
Connection to localhost closed.
(base) Ilyeechs-MacBook-Pro:~ ilyeech$ ssh -Y greene
ssh: connect to host localhost port 8027: Connection refused
(base) Ilyeechs-MacBook-Pro:~ ilyeech$ ssh -Y greene
 _   ___   ___   _   _   _ ____   ____ 
| \ | \ \ / / | | | | | | |  _ \ / ___|
|  \| |\ V /| | | | | |_| | |_) | |    
| |\  | | | | |_| | |  _  |  __/| |___ 
|_| \_| |_|  \___/  |_| |_|_|    \____|
 

  ____                          
 / ___|_ __ ___  ___ _ __   ___ 
| |  _| '__/ _ \/ _ \ '_ \ / _ \
| |_| | | |  __/  __/ | | |  __/
 \____|_|  \___|\___|_| |_|\___|

ir967@localhost's password: 
Last login: Fri Dec 11 15:43:38 2020 from 216.165.66.211
(base) [ir967@log-3 ~]$ cd $SCRATCH/SID
(base) [ir967@log-3 SID]$ cd Learning-to-See-in-the-Dark/
(base) [ir967@log-3 Learning-to-See-in-the-Dark]$ conda activate sid2
(sid2) [ir967@log-3 Learning-to-See-in-the-Dark]$ ls simple_*
simple_batched_numpy.py  simple_batched.py  simple_ReLU_BN_Sony.py  simple_ReLU_Sony.py
(sid2) [ir967@log-3 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy.py 
(sid2) [ir967@log-3 Learning-to-See-in-the-Dark]$ srun -t1:00:00 --gres=gpu:1 --mem=9000MB --pty /bin/bash
(base) [ir967@gr002 Learning-to-See-in-the-Dark]$ cd $SCRATCH/SID
(base) [ir967@gr002 SID]$ cd Learning-to-See-in-the-Dark/
(base) [ir967@gr002 Learning-to-See-in-the-Dark]$ conda activate sid2
(sid2) [ir967@gr002 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy.py 
(sid2) [ir967@gr002 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py 




Found 161 images to train with

Training on 32 images only

2020-12-11 21:03:31.178465: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 21:03:31.328202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:2f:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 21:03:31.328238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 21:03:34.887943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 21:03:34.887978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 21:03:34.887983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 21:03:34.888137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:2f:00.0, compute capability: 7.5)
No checkpoint found at ./gt_Sony_simple_batched_filters/. Hence, will create

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.87565, 0.00000, 300.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01633, 250.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00164, 300.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00201, 100.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.02266, 300.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00467, 100.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00894, 100.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00233, 250.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00016, 300.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 250.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00012, 250.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 300.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00146, 250.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00327, 100.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00003, 100.00000, 6735543
rawpy read the 20th file at location: ./dataset/Sony/long/00072_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00003, 100.00000, 7298885
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00153, 100.00000, 1272259
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 142725
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00456, 300.00000, 822369
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00012, 100.00000, 2983955
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00114, 300.00000, 2393979
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.03307, 300.00000, 2641491
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00003, 300.00000, 1597850
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 250.00000, 1430113
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
rawpy read the 30th file at location: ./dataset/Sony/long/00039_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.07940, 100.00000, 535
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
32 images loaded to CPU RAM in Time=11.469 seconds.

moved images data to numpy array
Starting Training on index [26  4 19 15  9 15 29 23  5  3  5 15 10 30 24 29], dataset index: [112  73 202  44 186  44 231  91  33 132  33  44  38  39  31 231]
Starting Training on gammas [300 100 100 300 100 300 100 300 300 250 300 300 100 100 100 100]
Epoch 0: at batch 1: Loss=1.051, Time=2.968
Traceback (most recent call last):
  File "simple_batched_numpy.py", line 357, in <module>
    os.mkdir(result_dir + '%04d' % epoch)
OSError: [Errno 2] No such file or directory: './gt_Sony_simple_batched_filters/0000'
(sid2) [ir967@gr002 Learning-to-See-in-the-Dark]$ mkdir gt_Sony_simple_batched_filters
(sid2) [ir967@gr002 Learning-to-See-in-the-Dark]$ Connection to localhost closed by remote host.
Connection to localhost closed.
(base) Ilyeechs-MacBook-Pro:~ ilyeech$ ssh -Y greene
 _   ___   ___   _   _   _ ____   ____ 
| \ | \ \ / / | | | | | | |  _ \ / ___|
|  \| |\ V /| | | | | |_| | |_) | |    
| |\  | | | | |_| | |  _  |  __/| |___ 
|_| \_| |_|  \___/  |_| |_|_|    \____|
 

  ____                          
 / ___|_ __ ___  ___ _ __   ___ 
| |  _| '__/ _ \/ _ \ '_ \ / _ \
| |_| | | |  __/  __/ | | |  __/
 \____|_|  \___|\___|_| |_|\___|

ir967@localhost's password: 

Last login: Fri Dec 11 02:58:32 2020 from 10.27.70.99
(base) [ir967@log-1 ~]$ cd $SCRATCH/SID
(base) [ir967@log-1 SID]$ cd Learning-to-See-in-the-Dark/
(base) [ir967@log-1 Learning-to-See-in-the-Dark]$ pwd
/scratch/ir967/SID/Learning-to-See-in-the-Dark
(base) [ir967@log-1 Learning-to-See-in-the-Dark]$ ls simple*
simple_batched_numpy.py  simple_batched.py  simple_ReLU_BN_Sony.py  simple_ReLU_Sony.py
(base) [ir967@log-1 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy.py
(base) [ir967@log-1 Learning-to-See-in-the-Dark]$ srun -t3:00:00 --gres=gpu:1 --mem=5500MB --pty /bin/bash
(base) [ir967@gr018 Learning-to-See-in-the-Dark]$ ssh gr018
Warning: Permanently added 'gr018' (ECDSA) to the list of known hosts.
(base) [ir967@gr018 ~]$ cd $SCRATCH/SID/Learning-to-See-in-the-Dark/
(base) [ir967@gr018 Learning-to-See-in-the-Dark]$ conda activate sid2
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py




Found 161 images to train with

Training on 32 images only

2020-12-11 22:42:31.893292: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 22:42:32.028619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 22:42:32.028652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 22:42:32.300730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 22:42:32.300765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 22:42:32.300770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 22:42:32.300867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)
No checkpoint found at ./gt_Sony_simple_batched_filters/. Hence, will create

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.89525, 0.00000, 250.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01631, 300.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00164, 300.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00187, 300.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.02266, 300.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00467, 100.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00886, 300.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00228, 300.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 250.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 250.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00012, 300.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 250.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00146, 250.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00301, 300.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00003, 100.00000, 6735543
rawpy read the 20th file at location: ./dataset/Sony/long/00072_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00003, 250.00000, 7298885
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00153, 100.00000, 1272259
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00000, 250.00000, 142725
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00466, 250.00000, 822369
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00011, 300.00000, 2983955
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00116, 250.00000, 2393979
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.03368, 250.00000, 2641491
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00003, 100.00000, 1597850
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 250.00000, 1430113
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
rawpy read the 30th file at location: ./dataset/Sony/long/00039_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.07893, 250.00000, 535
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
32 images loaded to CPU RAM in Time=11.110 seconds.

moved images data to numpy array
Starting Training on index [ 3  4  7 10  7  0 29  2 16 13 20 14 20 14  4 20], dataset index: [132  73  78  38  78  18 231  29  99  27  72 119  72 119  73  72]
Starting Training on gammas [250 100 300 300 300 300 300 300 250 250 250 300 250 300 100 250]
Epoch 0: at batch 1: Loss=1.026, Time=1.290
Traceback (most recent call last):
  File "simple_batched_numpy.py", line 344, in <module>
    import matplotlib.pyplot as plt
ImportError: No module named matplotlib.pyplot
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$  conda install matplotlib 
Collecting package metadata (current_repodata.json): done
Solving environment: failed with initial frozen solve. Retrying with flexible solve.
Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.
Collecting package metadata (repodata.json): done
Solving environment: done

## Package Plan ##

  environment location: /scratch/ir967/install/miniconda3/envs/sid2

  added / updated specs:
    - matplotlib


The following packages will be downloaded:

    package                    |            build
    ---------------------------|-----------------
    backports.functools_lru_cache-1.6.1|     pyhd3eb1b0_0          12 KB
    backports_abc-0.5          |             py_1          10 KB
    cycler-0.10.0              |           py27_0          13 KB
    dbus-1.13.18               |       hb2f20db_0         504 KB
    expat-2.2.10               |       he6710b0_2         153 KB
    fontconfig-2.13.0          |       h9420a91_0         227 KB
    functools32-3.2.3.2        |           py27_1          23 KB
    glib-2.63.1                |       h5a9c865_0         2.9 MB
    gst-plugins-base-1.14.0    |       hbbd80ab_1         4.8 MB
    gstreamer-1.14.0           |       hb453b48_1         3.1 MB
    icu-58.2                   |       he6710b0_3        10.5 MB
    kiwisolver-1.1.0           |   py27he6710b0_0          84 KB
    libuuid-1.0.3              |       h1bed415_2          15 KB
    libxcb-1.14                |       h7b6447c_0         505 KB
    libxml2-2.9.10             |       hb55368b_3         1.2 MB
    matplotlib-2.2.3           |   py27hb69df0a_0         4.8 MB
    pcre-8.44                  |       he6710b0_0         212 KB
    pyparsing-2.4.7            |             py_0          65 KB
    pyqt-5.9.2                 |   py27h05f1152_2         4.3 MB
    python-dateutil-2.8.1      |             py_0         215 KB
    pytz-2020.4                |     pyhd3eb1b0_0         180 KB
    qt-5.9.6                   |       h52aff34_0        67.3 MB
    singledispatch-3.4.0.3     |          py_1001          12 KB
    sip-4.19.8                 |   py27hf484d3e_0         275 KB
    subprocess32-3.5.4         |   py27h7b6447c_0          51 KB
    tornado-5.1.1              |   py27h7b6447c_0         615 KB
    ------------------------------------------------------------
                                           Total:       102.0 MB

The following NEW packages will be INSTALLED:

  backports.functoo~ pkgs/main/noarch::backports.functools_lru_cache-1.6.1-pyhd3eb1b0_0
  backports_abc      pkgs/main/noarch::backports_abc-0.5-py_1
  cycler             pkgs/main/linux-64::cycler-0.10.0-py27_0
  dbus               pkgs/main/linux-64::dbus-1.13.18-hb2f20db_0
  expat              pkgs/main/linux-64::expat-2.2.10-he6710b0_2
  fontconfig         pkgs/main/linux-64::fontconfig-2.13.0-h9420a91_0
  functools32        pkgs/main/linux-64::functools32-3.2.3.2-py27_1
  glib               pkgs/main/linux-64::glib-2.63.1-h5a9c865_0
  gst-plugins-base   pkgs/main/linux-64::gst-plugins-base-1.14.0-hbbd80ab_1
  gstreamer          pkgs/main/linux-64::gstreamer-1.14.0-hb453b48_1
  icu                pkgs/main/linux-64::icu-58.2-he6710b0_3
  kiwisolver         pkgs/main/linux-64::kiwisolver-1.1.0-py27he6710b0_0
  libuuid            pkgs/main/linux-64::libuuid-1.0.3-h1bed415_2
  libxcb             pkgs/main/linux-64::libxcb-1.14-h7b6447c_0
  libxml2            pkgs/main/linux-64::libxml2-2.9.10-hb55368b_3
  matplotlib         pkgs/main/linux-64::matplotlib-2.2.3-py27hb69df0a_0
  pcre               pkgs/main/linux-64::pcre-8.44-he6710b0_0
  pyparsing          pkgs/main/noarch::pyparsing-2.4.7-py_0
  pyqt               pkgs/main/linux-64::pyqt-5.9.2-py27h05f1152_2
  python-dateutil    pkgs/main/noarch::python-dateutil-2.8.1-py_0
  pytz               pkgs/main/noarch::pytz-2020.4-pyhd3eb1b0_0
  qt                 pkgs/main/linux-64::qt-5.9.6-h52aff34_0
  singledispatch     pkgs/main/noarch::singledispatch-3.4.0.3-py_1001
  sip                pkgs/main/linux-64::sip-4.19.8-py27hf484d3e_0
  subprocess32       pkgs/main/linux-64::subprocess32-3.5.4-py27h7b6447c_0
  tornado            pkgs/main/linux-64::tornado-5.1.1-py27h7b6447c_0


Proceed ([y]/n)? y


Downloading and Extracting Packages
sip-4.19.8           | 275 KB    | ############################################################################# | 100% 
matplotlib-2.2.3     | 4.8 MB    | ############################################################################# | 100% 
gst-plugins-base-1.1 | 4.8 MB    | ############################################################################# | 100% 
tornado-5.1.1        | 615 KB    | ############################################################################# | 100% 
kiwisolver-1.1.0     | 84 KB     | ############################################################################# | 100% 
expat-2.2.10         | 153 KB    | ############################################################################# | 100% 
singledispatch-3.4.0 | 12 KB     | ############################################################################# | 100% 
python-dateutil-2.8. | 215 KB    | ############################################################################# | 100% 
libuuid-1.0.3        | 15 KB     | ############################################################################# | 100% 
pyqt-5.9.2           | 4.3 MB    | ############################################################################# | 100% 
dbus-1.13.18         | 504 KB    | ############################################################################# | 100% 
qt-5.9.6             | 67.3 MB   | ############################################################################# | 100% 
fontconfig-2.13.0    | 227 KB    | ############################################################################# | 100% 
gstreamer-1.14.0     | 3.1 MB    | ############################################################################# | 100% 
functools32-3.2.3.2  | 23 KB     | ############################################################################# | 100% 
backports.functools_ | 12 KB     | ############################################################################# | 100% 
pytz-2020.4          | 180 KB    | ############################################################################# | 100% 
cycler-0.10.0        | 13 KB     | ############################################################################# | 100% 
glib-2.63.1          | 2.9 MB    | ############################################################################# | 100% 
libxml2-2.9.10       | 1.2 MB    | ############################################################################# | 100% 
icu-58.2             | 10.5 MB   | ############################################################################# | 100% 
pcre-8.44            | 212 KB    | ############################################################################# | 100% 
libxcb-1.14          | 505 KB    | ############################################################################# | 100% 
backports_abc-0.5    | 10 KB     | ############################################################################# | 100% 
pyparsing-2.4.7      | 65 KB     | ############################################################################# | 100% 
subprocess32-3.5.4   | 51 KB     | ############################################################################# | 100% 
Preparing transaction: done
Verifying transaction: done
Executing transaction: done
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py




Found 161 images to train with

Training on 32 images only

2020-12-11 22:45:53.314668: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 22:45:53.445044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 22:45:53.445076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 22:45:53.716359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 22:45:53.716394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 22:45:53.716399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 22:45:53.716495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)

Loaded ./gt_Sony_simple_batched_filters/model.ckpt

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95669, 0.00000, 100.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01631, 300.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 100.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00187, 300.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.02266, 300.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00417, 300.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00887, 250.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00228, 300.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 100.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00613, 100.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00012, 250.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 300.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00144, 300.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00327, 100.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00002, 300.00000, 6735543
rawpy read the 20th file at location: ./dataset/Sony/long/00072_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00003, 300.00000, 7298885
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00141, 300.00000, 1272259
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00000, 100.00000, 142725
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00456, 300.00000, 822369
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00011, 300.00000, 2983955
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00123, 100.00000, 2393979
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.03368, 250.00000, 2641491
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00003, 300.00000, 1597850
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 100.00000, 1430113
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
rawpy read the 30th file at location: ./dataset/Sony/long/00039_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.07888, 300.00000, 535
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
32 images loaded to CPU RAM in Time=9.509 seconds.

moved images data to numpy array
Traceback (most recent call last):
  File "simple_batched_numpy.py", line 346, in <module>
    weights = tf.get_variable('weights')
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 1484, in get_variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 1234, in get_variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 538, in get_variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 492, in _true_getter
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 859, in _get_single_variable
    name, "".join(traceback.format_list(tb))))
ValueError: Variable g_conv1_1/weights already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:

  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py", line 277, in variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py", line 182, in func_with_args
    return func(*args, **current_args)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py", line 350, in model_variable
    aggregation=aggregation)

(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py




Found 161 images to train with

Training on 32 images only

2020-12-11 22:51:47.807628: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 22:51:47.968496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 22:51:47.968527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 22:51:48.240606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 22:51:48.240639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 22:51:48.240644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 22:51:48.240759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)

Loaded ./gt_Sony_simple_batched_filters/model.ckpt

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95669, 0.00000, 100.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01633, 250.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 100.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00201, 100.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.02465, 100.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00467, 100.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00894, 100.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00228, 300.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 100.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 300.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00012, 300.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00117, 100.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00144, 300.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00301, 300.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00002, 250.00000, 6735543
rawpy read the 20th file at location: ./dataset/Sony/long/00072_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00003, 300.00000, 7298885
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00141, 300.00000, 1272259
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 142725
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00497, 100.00000, 822369
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00011, 250.00000, 2983955
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00114, 300.00000, 2393979
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.03574, 100.00000, 2641491
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00003, 100.00000, 1597850
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 250.00000, 1430113
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
rawpy read the 30th file at location: ./dataset/Sony/long/00039_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.07940, 100.00000, 535
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
32 images loaded to CPU RAM in Time=9.173 seconds.

moved images data to numpy array
Traceback (most recent call last):
  File "simple_batched_numpy.py", line 346, in <module>
    weights = tf.get_variable('weights')
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 1484, in get_variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 1234, in get_variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 538, in get_variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 492, in _true_getter
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 859, in _get_single_variable
    name, "".join(traceback.format_list(tb))))
ValueError: Variable g_conv1_1/weights already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:

  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py", line 277, in variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py", line 182, in func_with_args
    return func(*args, **current_args)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py", line 350, in model_variable
    aggregation=aggregation)

(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy.py 
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py




Found 161 images to train with

Training on 32 images only

2020-12-11 22:52:35.136061: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 22:52:35.296900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 22:52:35.296931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 22:52:35.567990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 22:52:35.568024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 22:52:35.568029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 22:52:35.568128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)

Loaded ./gt_Sony_simple_batched_filters/model.ckpt

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.89525, 0.00000, 250.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01648, 100.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00164, 300.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00201, 100.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.02465, 100.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00467, 100.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00887, 250.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00228, 300.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00016, 300.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00613, 100.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00012, 100.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 250.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00146, 250.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00301, 300.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00003, 100.00000, 6735543
rawpy read the 20th file at location: ./dataset/Sony/long/00072_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00003, 300.00000, 7298885
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00141, 300.00000, 1272259
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 142725
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00466, 250.00000, 822369
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00011, 250.00000, 2983955
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00116, 250.00000, 2393979
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.03368, 250.00000, 2641491
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00003, 300.00000, 1597850
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 300.00000, 1430113
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
rawpy read the 30th file at location: ./dataset/Sony/long/00039_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.07940, 100.00000, 535
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
32 images loaded to CPU RAM in Time=9.061 seconds.

moved images data to numpy array
Traceback (most recent call last):
  File "simple_batched_numpy.py", line 346, in <module>
    weights = tf.get_variable('weights')
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 1484, in get_variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 1234, in get_variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 538, in get_variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 492, in _true_getter
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 902, in _get_single_variable
    tf_inspect.getargspec(initializer).args)
ValueError: You can only pass an initializer function that expects no arguments to its callable when the shape is not fully defined. The given initializer function expects the following args ['self', 'shape', 'dtype', 'partition_info']
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy.py 
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py




Found 161 images to train with

Training on 32 images only

2020-12-11 23:10:47.824642: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 23:10:47.986654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 23:10:47.986687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 23:10:48.258245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 23:10:48.258281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 23:10:48.258286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 23:10:48.258392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)

Loaded ./gt_Sony_simple_batched_filters/model.ckpt

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95669, 0.00000, 100.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01648, 100.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00164, 300.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00201, 100.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.02310, 250.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00427, 250.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00886, 300.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00248, 100.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 100.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 250.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00012, 100.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 300.00000, 4586373
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00146, 250.00000, 909101
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00301, 300.00000, 3630407
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00002, 250.00000, 6735543
rawpy read the 20th file at location: ./dataset/Sony/long/00072_00_30s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00003, 300.00000, 7298885
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00143, 250.00000, 1272259
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00000, 300.00000, 142725
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00456, 300.00000, 822369
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00011, 250.00000, 2983955
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00116, 250.00000, 2393979
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.03574, 100.00000, 2641491
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00003, 250.00000, 1597850
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00010, 100.00000, 1430113
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
rawpy read the 30th file at location: ./dataset/Sony/long/00039_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.07888, 300.00000, 535
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
32 images loaded to CPU RAM in Time=9.041 seconds.

moved images data to numpy array
Traceback (most recent call last):
  File "simple_batched_numpy.py", line 346, in <module>
    weights = tf.get_variable('weights').reuse_variables()
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 1484, in get_variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 1234, in get_variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 538, in get_variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 492, in _true_getter
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 859, in _get_single_variable
    name, "".join(traceback.format_list(tb))))
ValueError: Variable g_conv1_1/weights already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:

  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py", line 277, in variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py", line 182, in func_with_args
    return func(*args, **current_args)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py", line 350, in model_variable
    aggregation=aggregation)

(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy.py 
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py




Found 161 images to train with

Training on 16 images only

2020-12-11 23:42:58.804301: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 23:42:58.965483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 23:42:58.965515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 23:42:59.243622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 23:42:59.243658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 23:42:59.243666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 23:42:59.243767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)

Loaded ./gt_Sony_simple_batched_filters/model.ckpt

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.89525, 0.00000, 250.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01633, 250.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 100.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00187, 300.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.02310, 250.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00467, 100.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00894, 100.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00233, 250.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00016, 300.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 250.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00012, 250.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00117, 100.00000, 4586373
16 images loaded to CPU RAM in Time=5.027 seconds.

moved images data to numpy array
Traceback (most recent call last):
  File "simple_batched_numpy.py", line 349, in <module>
    weights = tf.get_variable('weights')
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 1484, in get_variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 1234, in get_variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 538, in get_variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 492, in _true_getter
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 859, in _get_single_variable
    name, "".join(traceback.format_list(tb))))
ValueError: Variable g_conv1_1/weights already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:

  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py", line 277, in variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py", line 182, in func_with_args
    return func(*args, **current_args)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py", line 350, in model_variable
    aggregation=aggregation)

(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy.py 
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py




Found 161 images to train with

Training on 16 images only

2020-12-11 23:44:06.626336: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 23:44:06.774669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 23:44:06.774702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 23:44:07.052325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 23:44:07.052360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 23:44:07.052366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 23:44:07.052478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)

Loaded ./gt_Sony_simple_batched_filters/model.ckpt

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95669, 0.00000, 100.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01631, 300.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00164, 300.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00201, 100.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.02310, 250.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00427, 250.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00894, 100.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00233, 250.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00016, 300.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 300.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00012, 300.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 250.00000, 4586373
16 images loaded to CPU RAM in Time=4.696 seconds.

moved images data to numpy array
Traceback (most recent call last):
  File "simple_batched_numpy.py", line 349, in <module>
    weights = tf.get_variable('weights')
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 1484, in get_variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 1234, in get_variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 538, in get_variable
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 492, in _true_getter
    aggregation=aggregation)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 902, in _get_single_variable
    tf_inspect.getargspec(initializer).args)
ValueError: You can only pass an initializer function that expects no arguments to its callable when the shape is not fully defined. The given initializer function expects the following args ['self', 'shape', 'dtype', 'partition_info']
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy.py 
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py




Found 161 images to train with

Training on 16 images only

2020-12-11 23:51:45.096406: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 23:51:45.254646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 23:51:45.254677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 23:51:45.534553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 23:51:45.534584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 23:51:45.534589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 23:51:45.534699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)

Loaded ./gt_Sony_simple_batched_filters/model.ckpt

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95669, 0.00000, 100.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01631, 300.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 250.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00190, 250.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.02266, 300.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00417, 300.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00001, 250.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00887, 250.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00233, 250.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 100.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00613, 100.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00012, 250.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 300.00000, 4586373
16 images loaded to CPU RAM in Time=4.706 seconds.

moved images data to numpy array
Traceback (most recent call last):
  File "simple_batched_numpy.py", line 352, in <module>
    plt.imsave(plot_dir + "/filter1.png", np.transpose(weights_retrieved, (1, 2, 0), cmap = 'grey'))
TypeError: transpose() got an unexpected keyword argument 'cmap'
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy.py 
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py




Found 161 images to train with

Training on 16 images only

2020-12-11 23:52:23.757374: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 23:52:23.917140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 23:52:23.917183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 23:52:24.195312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 23:52:24.195344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 23:52:24.195349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 23:52:24.195459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)

Loaded ./gt_Sony_simple_batched_filters/model.ckpt

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95669, 0.00000, 100.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01648, 100.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 100.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00190, 250.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.02465, 100.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00427, 250.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00894, 100.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00233, 250.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 250.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00613, 100.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00012, 100.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 300.00000, 4586373
16 images loaded to CPU RAM in Time=4.675 seconds.

moved images data to numpy array
Traceback (most recent call last):
  File "simple_batched_numpy.py", line 352, in <module>
    plt.imsave(plot_dir + "/filter1.png", np.transpose(weights_retrieved, (1, 2, 0)), cmap = 'grey')
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/numpy/core/fromnumeric.py", line 639, in transpose
    return _wrapfunc(a, 'transpose', axes)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/numpy/core/fromnumeric.py", line 66, in _wrapfunc
    return _wrapit(obj, method, *args, **kwds)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/numpy/core/fromnumeric.py", line 46, in _wrapit
    result = getattr(asarray(obj), method)(*args, **kwds)
ValueError: axes don't match array
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy.py 
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py




Found 161 images to train with

Training on 16 images only

2020-12-11 23:56:42.635818: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-11 23:56:42.795475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-11 23:56:42.795508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-11 23:56:43.076772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-11 23:56:43.076805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-11 23:56:43.076810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-11 23:56:43.076989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)

Loaded ./gt_Sony_simple_batched_filters/model.ckpt

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.87565, 0.00000, 300.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01633, 250.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 100.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00190, 250.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.02266, 300.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00417, 300.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00886, 300.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00248, 100.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 100.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 250.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00012, 300.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 250.00000, 4586373
16 images loaded to CPU RAM in Time=4.703 seconds.

moved images data to numpy array
(3, 3, 4, 32)
Traceback (most recent call last):
  File "simple_batched_numpy.py", line 353, in <module>
    plt.imsave(plot_dir + "/filter1.png", np.transpose(weights_retrieved, (1, 2, 0)), cmap = 'grey')
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/numpy/core/fromnumeric.py", line 639, in transpose
    return _wrapfunc(a, 'transpose', axes)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/numpy/core/fromnumeric.py", line 66, in _wrapfunc
    return _wrapit(obj, method, *args, **kwds)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/numpy/core/fromnumeric.py", line 46, in _wrapit
    result = getattr(asarray(obj), method)(*args, **kwds)
ValueError: axes don't match array
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy.py 
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ vi conviz.py
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ vi utils.py
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py
WARNING:tensorflow:From /scratch/ir967/SID/Learning-to-See-in-the-Dark/conviz.py:103: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please use urllib or similar directly.
Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.
WARNING:tensorflow:From /scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting /tmp/data/train-images-idx3-ubyte.gz
Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.
WARNING:tensorflow:From /scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting /tmp/data/train-labels-idx1-ubyte.gz
WARNING:tensorflow:From /scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.
Extracting /tmp/data/t10k-images-idx3-ubyte.gz
Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.
Extracting /tmp/data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
Traceback (most recent call last):
  File "simple_batched_numpy.py", line 13, in <module>
    import conviz
  File "/scratch/ir967/SID/Learning-to-See-in-the-Dark/conviz.py", line 228, in <module>
    predictions = fc(predictions, 1024, keep_prob)
  File "/scratch/ir967/SID/Learning-to-See-in-the-Dark/conviz.py", line 173, in fc
    x_ = tf.reshape(x_, tf.pack([-1, n]))
AttributeError: 'module' object has no attribute 'pack'
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy.py 
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ vi show.py
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ ls
 all_of_gt_Sony
 all_of_gt_Sony_GPU_efficient
 all_of_gt_Sony_GPU_efficient_flattened
 all_of_gt_Sony_GPU_efficient_flattened_3output
 all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler
 all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler_print
 all_of_gt_Sony_GPU_efficient_flattened_3output_more_simpler_wider
 all_of_gt_Sony_GPU_efficient_flattened_3output_print_test
 all_of_gt_Sony_GPU_efficient_flattened_3output_simpler
 checkpoint
 check.sh
 cluster_status.txt
 conviz.py
 conviz.pyc
 dataset
 dead_simple_logs1.txt
 debug_one_hot.txt
 download_dataset.py
 download_models.py
 efficiency
 exper.py
 exper.sbatch
 filters
 gamma_checkpoint
 gamma_experiment.py
 gamma_piecewise.txt
 gt_Sony_dead_simple
 gt_Sony_dead_simple_3gammas
 gt_Sony_dead_simple_new
 gt_Sony_simple_batched_filters
 gt_Sony_simple_ReLU
 gt_Sony_simple_ReLU_BN
 gt_Sony_simple_ReLU_BN_batched
 gt_Sony_simple_ReLU_BN_batched_new
 gt_Sony_simple_ReLU_BN_new
 half_of_gt_Sony
 HPC-hw4-1a.sh
 htop.txt
 images
 images-with-gamma-statistics.txt
 LICENSE.md
 logs
 lspci.out
 _old_code
 README.md
 result_Fuji
 result_Sony
'result_Sony__[1-5]_images'
 result_Sony_20_images
 result_Sony_checkDec6
 result_Sony_with_gamma_net
 result_Sony_with_gamma_net_3output
 run1_5_images_result_Sony
 scontrol_8hours.txt
 show.py
 simple_batched_numpy.py
 simple_batched.py
 simple_ReLU_BN_Sony.py
 simple_ReLU_Sony.py
 slurm-401646.out
 _slurm_out
 sstat_8hours.txt
 test_for_gamma_Sony_3output.py
 test_for_gamma_Sony_3output.sbatch
 test_for_gamma_Sony.py
 test_for_gamma_Sony.sbatch
 test_Fuji.py
 test_Fuji.sbatch
 test_Sony.py
 test_Sony.sbatch
 test_Sony_with_gamma.py
 test_Sony_with_gamma.sbatch
 train_for_gamma_Sony_3output_more_simpler_wider.py
 train_for_gamma_Sony_3output.py
 train_for_gamma_Sony_3output.sbatch
 train_for_gamma_Sony_dead_simple_3gammas.py
 train_for_gamma_Sony_dead_simple_3gammas.sbatch
 train_for_gamma_Sony_dead_simple.py
 train_for_gamma_Sony_dead_simple.sbatch
 train_for_gamma_Sony.py
 train_for_gamma_Sony.sbatch
 train_Fuji.py
 train_Fuji.sbatch
 train_Sony.py
 train_Sony.sbatch
 utils.py
 utils.pyc
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ rm *.pyc
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ ls out/
ls: cannot access 'out/': No such file or directory
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ mkdir out
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ mkdir out/plots
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy.py 
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py




Found 161 images to train with

Training on 16 images only

2020-12-12 00:20:20.568611: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-12 00:20:20.725660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-12 00:20:20.725692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-12 00:20:21.003049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-12 00:20:21.003085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-12 00:20:21.003091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-12 00:20:21.003188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)

Loaded ./gt_Sony_simple_batched_filters/model.ckpt

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.87565, 0.00000, 300.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01648, 100.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 250.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00187, 300.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.02266, 300.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00417, 300.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00886, 300.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00248, 100.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 100.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 300.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00012, 250.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 300.00000, 4586373
16 images loaded to CPU RAM in Time=4.671 seconds.

moved images data to numpy array
(3, 3, 4, 32)
Traceback (most recent call last):
  File "simple_batched_numpy.py", line 354, in <module>
    plot_conv_weights(weights_retrieved, 'conv1', channels_all=True)
  File "/scratch/ir967/SID/Learning-to-See-in-the-Dark/show.py", line 40, in plot_conv_weights
    grid_r, grid_c = utils.get_grid_dim(num_filters)
  File "/scratch/ir967/SID/Learning-to-See-in-the-Dark/utils.py", line 13, in get_grid_dim
    factors = prime_powers(x)
  File "/scratch/ir967/SID/Learning-to-See-in-the-Dark/utils.py", line 30, in prime_powers
    for x in xrange(1, int(math.sqrt(n)) + 1):
TypeError: a float is required
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ vi utils.py
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py




Found 161 images to train with

Training on 16 images only

2020-12-12 00:26:23.166006: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-12 00:26:23.323278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-12 00:26:23.323310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-12 00:26:23.603114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-12 00:26:23.603147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-12 00:26:23.603152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-12 00:26:23.603261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)

Loaded ./gt_Sony_simple_batched_filters/model.ckpt

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.95669, 0.00000, 100.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01648, 100.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 100.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00190, 250.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.02465, 100.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00427, 250.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00886, 300.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00248, 100.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 250.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 250.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00012, 250.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00117, 100.00000, 4586373
16 images loaded to CPU RAM in Time=4.693 seconds.

moved images data to numpy array
(3, 3, 4, 32)
Traceback (most recent call last):
  File "simple_batched_numpy.py", line 354, in <module>
    plot_conv_weights(weights_retrieved, 'conv1', channels_all=True)
  File "/scratch/ir967/SID/Learning-to-See-in-the-Dark/show.py", line 40, in plot_conv_weights
    grid_r, grid_c = utils.get_grid_dim(num_filters)
  File "/scratch/ir967/SID/Learning-to-See-in-the-Dark/utils.py", line 13, in get_grid_dim
    factors = prime_powers(x)
  File "/scratch/ir967/SID/Learning-to-See-in-the-Dark/utils.py", line 30, in prime_powers
    for x in xrange(1, int(float(math.sqrt(float(n)))) + 1):
TypeError: float() argument must be a string or a number
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy.py 
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py




Found 161 images to train with

Training on 16 images only

2020-12-12 00:29:07.129971: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-12 00:29:07.292264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-12 00:29:07.292296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-12 00:29:07.570510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-12 00:29:07.570544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-12 00:29:07.570550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-12 00:29:07.570663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)

Loaded ./gt_Sony_simple_batched_filters/model.ckpt

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.89525, 0.00000, 250.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01631, 300.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 250.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00187, 300.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.02266, 300.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00467, 100.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00894, 100.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00248, 100.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 250.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 250.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00012, 250.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 250.00000, 4586373
16 images loaded to CPU RAM in Time=4.650 seconds.

moved images data to numpy array
(3, 3, 4, 32)
Traceback (most recent call last):
  File "simple_batched_numpy.py", line 354, in <module>
    weights_retrieved = weights_retrieved.numpy()
AttributeError: 'RefVariable' object has no attribute 'numpy'
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy.py 
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py




Found 161 images to train with

Training on 16 images only

2020-12-12 00:30:02.891253: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-12 00:30:03.044771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-12 00:30:03.044804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-12 00:30:03.324195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-12 00:30:03.324230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-12 00:30:03.324235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-12 00:30:03.324348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)

Loaded ./gt_Sony_simple_batched_filters/model.ckpt

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.87565, 0.00000, 300.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01631, 300.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 100.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00201, 100.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.02310, 250.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00417, 300.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00886, 300.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00233, 250.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00016, 300.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 300.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00012, 300.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00117, 100.00000, 4586373
16 images loaded to CPU RAM in Time=4.667 seconds.

moved images data to numpy array
(3, 3, 4, 32)
<class 'tensorflow.python.ops.variables.RefVariable'>
Traceback (most recent call last):
  File "simple_batched_numpy.py", line 355, in <module>
    plot_conv_weights(weights_retrieved, 'conv1', channels_all=True)
  File "/scratch/ir967/SID/Learning-to-See-in-the-Dark/show.py", line 40, in plot_conv_weights
    grid_r, grid_c = utils.get_grid_dim(num_filters)
  File "/scratch/ir967/SID/Learning-to-See-in-the-Dark/utils.py", line 13, in get_grid_dim
    factors = prime_powers(x)
  File "/scratch/ir967/SID/Learning-to-See-in-the-Dark/utils.py", line 30, in prime_powers
    for x in xrange(1, int(float(math.sqrt(float(n)))) + 1):
TypeError: float() argument must be a string or a number
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ vi show.py
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py




Found 161 images to train with

Training on 16 images only

2020-12-12 00:34:44.040851: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-12 00:34:44.199895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-12 00:34:44.199946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-12 00:34:44.478780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-12 00:34:44.478814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-12 00:34:44.478819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-12 00:34:44.478939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)

Loaded ./gt_Sony_simple_batched_filters/model.ckpt

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.87565, 0.00000, 300.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01631, 300.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 250.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00201, 100.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.02465, 100.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00417, 300.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00887, 250.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00233, 250.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 250.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 300.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00012, 300.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 250.00000, 4586373
16 images loaded to CPU RAM in Time=4.695 seconds.

moved images data to numpy array
(3, 3, 4, 32)
<class 'tensorflow.python.ops.variables.RefVariable'>
Traceback (most recent call last):
  File "simple_batched_numpy.py", line 355, in <module>
    plot_conv_weights(weights_retrieved, 'conv1', channels_all=True)
  File "/scratch/ir967/SID/Learning-to-See-in-the-Dark/show.py", line 45, in plot_conv_weights
    max([grid_r, grid_c]))
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/matplotlib/pyplot.py", line 1184, in subplots
    fig = figure(**fig_kw)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/matplotlib/pyplot.py", line 533, in figure
    **kwargs)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/matplotlib/backend_bases.py", line 161, in new_figure_manager
    return cls.new_figure_manager_given_figure(num, fig)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/matplotlib/backend_bases.py", line 167, in new_figure_manager_given_figure
    canvas = cls.FigureCanvas(figure)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/matplotlib/backends/backend_qt5agg.py", line 24, in __init__
    super(FigureCanvasQTAgg, self).__init__(figure=figure)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/matplotlib/backends/backend_qt5.py", line 234, in __init__
    _create_qApp()
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/matplotlib/backends/backend_qt5.py", line 125, in _create_qApp
    raise RuntimeError('Invalid DISPLAY variable')
RuntimeError: Invalid DISPLAY variable
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ vi show.py
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py




Found 161 images to train with

Training on 16 images only

2020-12-12 00:37:33.108832: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-12 00:37:33.271914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-12 00:37:33.271949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-12 00:37:33.550980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-12 00:37:33.551010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-12 00:37:33.551016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-12 00:37:33.551129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)

Loaded ./gt_Sony_simple_batched_filters/model.ckpt

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.87565, 0.00000, 300.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01633, 250.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00164, 300.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00190, 250.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.02266, 300.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00417, 300.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00886, 300.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00228, 300.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 100.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00613, 100.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00012, 100.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 300.00000, 4586373
16 images loaded to CPU RAM in Time=4.688 seconds.

moved images data to numpy array
(3, 3, 4, 32)
<class 'tensorflow.python.ops.variables.RefVariable'>
Traceback (most recent call last):
  File "simple_batched_numpy.py", line 355, in <module>
    plot_conv_weights(weights_retrieved, 'conv1', channels_all=True)
  File "/scratch/ir967/SID/Learning-to-See-in-the-Dark/show.py", line 54, in plot_conv_weights
    ax.imshow(img, vmin=w_min, vmax=w_max, interpolation='nearest', cmap='seismic')
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/matplotlib/__init__.py", line 1867, in inner
    return func(ax, *args, **kwargs)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/matplotlib/axes/_axes.py", line 5501, in imshow
    im.set_data(X)
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/matplotlib/image.py", line 650, in set_data
    raise TypeError("Image data cannot be converted to float")
TypeError: Image data cannot be converted to float
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ vi show.py
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ python simple_batched_numpy.py




Found 161 images to train with

Training on 16 images only

2020-12-12 00:45:28.279656: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-12 00:45:28.437801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-12 00:45:28.437834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-12 00:45:28.718060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-12 00:45:28.718097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-12 00:45:28.718103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-12 00:45:28.718204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)

Loaded ./gt_Sony_simple_batched_filters/model.ckpt

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.89525, 0.00000, 250.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01633, 250.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 250.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 100.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00190, 250.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.02266, 300.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00427, 250.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00001, 300.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00886, 300.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00233, 250.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 100.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 300.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00012, 300.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 300.00000, 4586373
16 images loaded to CPU RAM in Time=4.672 seconds.

moved images data to numpy array
(3, 3, 4, 32)
<class 'tensorflow.python.ops.variables.RefVariable'>
Traceback (most recent call last):
  File "simple_batched_numpy.py", line 355, in <module>
    plot_conv_weights(weights_retrieved, 'conv1', channels_all=True)
  File "/scratch/ir967/SID/Learning-to-See-in-the-Dark/show.py", line 56, in plot_conv_weights
    plt.show(img, vmin=w_min, vmax=w_max, interpolation='nearest', cmap='seismic')#ax.imshow() I replaced
  File "/scratch/ir967/install/miniconda3/envs/sid2/lib/python2.7/site-packages/matplotlib/pyplot.py", line 253, in show
    return _show(*args, **kw)
TypeError: show() got an unexpected keyword argument 'vmax'
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy.py
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ vi simple_batched_numpy_diff_loss.py
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ mkdir gt_Sony_simple_batched_MSE_loss
(sid2) [ir967@gr018 Learning-to-See-in-the-Dark]$ python simple_batched_numpy_diff_loss.py 




Found 161 images to train with

Training on 16 images only

2020-12-12 01:19:10.824207: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-12-12 01:19:10.983531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: Quadro RTX 8000 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:06:00.0
totalMemory: 44.49GiB freeMemory: 44.33GiB
2020-12-12 01:19:10.983564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2020-12-12 01:19:11.263121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-12 01:19:11.263152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 
2020-12-12 01:19:11.263157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N 
2020-12-12 01:19:11.263265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 43038 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:06:00.0, compute capability: 7.5)
No checkpoint found at ./gt_Sony_simple_batched_MSE_loss/. Hence, will create

a: 0.0000000000
b: 1.8054000000
-0.6435445925714693
35.645540742853065

a: 0.0000000000
b: 4.5135000000
-0.8186270064387413
45.34324839031467

a: 0.0000000000
b: 5.4162000000
-0.8441445092110595
46.756647236682134
Gamma curve:
Every 10, 0 to 100
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 100, 0 to 1000
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
Every 1000, 0 to 8000
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 8K, 0 to 64K
[[0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]]
Every 1000, 57536 to 65536
[[    0     0     4    23   120   605  2958 14104]
 [    0     0     0     0     0     0    28  1408]
 [    0     0     0     0     0     0     6   653]]
Every 125, 64536 to 65536
[[14104 17115 20761 25175 30515 36975 44786 54227]
 [ 1408  2284  3702  5994  9696 15670 25302 40817]
 [  653  1167  2083  3715  6616 11770 20917 37129]]
Every 10, 65436 to 65536
[[56340 57207 58088 58982 59890 60812 61747 62697 63662 64641]
 [44908 46657 48474 50361 52321 54357 56473 58670 60952 63323]
 [41639 43592 45637 47777 50017 52362 54817 57386 60075 62889]]
Every 1, 65526 to 65536
[[64641 64739 64838 64937 65036 65136 65235 65335 65435 65535]
 [63323 63565 63808 64051 64296 64542 64789 65036 65285 65535]
 [62889 63178 63468 63759 64051 64345 64641 64937 65235 65535]]
last epoch of previous run: 0
rawpy read the 0th file at location: ./dataset/Sony/long/00018_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.87565, 0.00000, 300.00000, 3485919
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.01633, 250.00000, 1
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 100.00000, 0
min, max, mean, gamma, argmax: 0.00000, 0.00000, 0.00000, 300.00000, 0
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00165, 100.00000, 1177951
min, max, mean, gamma, argmax: 0.00000, 0.94221, 0.00187, 300.00000, 803131
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.02310, 250.00000, 3700
min, max, mean, gamma, argmax: 0.00000, 0.95160, 0.00427, 250.00000, 2882267
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00001, 100.00000, 5540515
rawpy read the 10th file at location: ./dataset/Sony/long/00038_00_10s.ARW
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00886, 300.00000, 2598691
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00248, 100.00000, 4653941
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00017, 250.00000, 6102869
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00611, 250.00000, 1458187
min, max, mean, gamma, argmax: 0.00000, 0.98035, 0.00012, 100.00000, 3426263
min, max, mean, gamma, argmax: 0.00000, 1.00000, 0.00116, 250.00000, 4586373
16 images loaded to CPU RAM in Time=4.682 seconds.

moved images data to numpy array
Starting Training on index [11  8  6 12 10  3  3  5 14  1  2 11 15  5 13  3], dataset index: [129  81 118  46  38 132 132  33 119 148  29 129  44  33  27 132]
Starting Training on gammas [100 250 300 250 300 100 100 100 100 300 250 100 250 100 250 100]
Epoch 0: at batch 1: Loss=0.333, Time=1.276